[{"id":0,"path":"../website/pages/docs/CODE_OF_CONDUCT.asciidoc.html#CODE_OF_CONDUCT.asciidoc","type":"docs","title":"Contributor Covenant Code of Conduct","body":"107. Contributor Covenant Code of Conduct\n"},{"id":1,"path":"../website/pages/docs/CODE_OF_CONDUCT.asciidoc.html#code_of_conduct.asciidoc_our-pledge","type":"docs","title":"Our Pledge","body":"107.1. Our Pledge\nIn the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, gender identity and expression, level of experience, nationality, personal appearance, race, religion, or sexual identity and orientation.\n"},{"id":2,"path":"../website/pages/docs/CODE_OF_CONDUCT.asciidoc.html#code_of_conduct.asciidoc_our-standards","type":"docs","title":"Our Standards","body":"107.2. Our Standards\nExamples of behavior that contributes to creating a positive environment include:\nUsing welcoming and inclusive language\nBeing respectful of differing viewpoints and experiences\nGracefully accepting constructive criticism\nFocusing on what is best for the community\nShowing empathy towards other community members\nExamples of unacceptable behavior by participants include:\nThe use of sexualized language or imagery and unwelcome sexual attention or advances\nTrolling, insulting/derogatory comments, and personal or political attacks\nPublic or private harassment\nPublishing others&apos; private information, such as a physical or electronic address, without explicit permission\nOther conduct which could reasonably be considered inappropriate in a professional setting\n"},{"id":3,"path":"../website/pages/docs/CODE_OF_CONDUCT.asciidoc.html#code_of_conduct.asciidoc_our-responsibilities","type":"docs","title":"Our Responsibilities","body":"107.3. Our Responsibilities\nProject maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior.\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.\n"},{"id":4,"path":"../website/pages/docs/CODE_OF_CONDUCT.asciidoc.html#code_of_conduct.asciidoc_scope","type":"docs","title":"Scope","body":"107.4. Scope\nThis Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.\n"},{"id":5,"path":"../website/pages/docs/CODE_OF_CONDUCT.asciidoc.html#code_of_conduct.asciidoc_enforcement","type":"docs","title":"Enforcement","body":"107.5. Enforcement\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the project team at icsddevonfwsupport.apps2@capgemini.com. All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately.\nProject maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project&#x2019;s leadership.\n"},{"id":6,"path":"../website/pages/docs/CODE_OF_CONDUCT.asciidoc.html#code_of_conduct.asciidoc_attribution","type":"docs","title":"Attribution","body":"107.6. Attribution\nThis Code of Conduct is adapted from the Contributor Covenant, version 1.4,\navailable at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html\n&#x2190;&#xA0;Previous:&#xA0;Contributing&#xA0;| &#x2191;&#xA0;Up:&#xA0;Contributing&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;OSS Compliance&#xA0;&#x2192;\n"},{"id":7,"path":"../website/pages/docs/CONTRIBUTING.asciidoc.html#CONTRIBUTING.asciidoc","type":"docs","title":"Contributing","body":"106. Contributing\ndevonfw is truly free and open.\nWe are looking forward to your contribution and are more than happy to receive your feedback and improvements to code and documentation.\nThis page describes the few conventions to follow.\nPlease note that this is an open and international project and all content has to be in English language.\nAlso read our code of conduct.\n"},{"id":8,"path":"../website/pages/docs/CONTRIBUTING.asciidoc.html#contributing.asciidoc_using-github","type":"docs","title":"Using GitHub","body":"106.1. Using GitHub\nWe are using GitHub as our social coding platform. Hence, we follow the principles of GitHub to deal with changes:\n"},{"id":9,"path":"../website/pages/docs/CONTRIBUTING.asciidoc.html#contributing.asciidoc_account","type":"docs","title":"Account","body":"106.1.1. Account\nIn case you do not have an account please first join GitHub.\nIf you have a CORP username use it also as GitHub username.\nIf possible and suitable also provide your real name in your profile.\nNow that you are logged into GitHub you are ready to go.\n"},{"id":10,"path":"../website/pages/docs/CONTRIBUTING.asciidoc.html#contributing.asciidoc_organizations","type":"docs","title":"Organizations","body":"106.1.2. Organizations\nFor devonfw we have the following organizations on GitHub:\ndevonfw\nThe official devonfw Platform organization.\ndevonfw-sample\nThe organization used for sample and demo repositories. Here you can find things working in action that can give you a jumpstart. We do not claim every sample to be up-to-date. However, it needs to build and run out-of-the-box without errors.\ndevonfw-training\nThe organization used as a starting point for trainings about devonfw. We do not claim the repositories to be self-explanatory. In case you need to participate into a training please contact us.\ndevonfw-forge\nThe organization used for work on incubators and other research projects.\nNew projects start here and in case they evolve properly and get mature, they are moved to the official devonfw organization.\n"},{"id":11,"path":"../website/pages/docs/CONTRIBUTING.asciidoc.html#contributing.asciidoc_repositories","type":"docs","title":"Repositories","body":"106.1.3. Repositories\nWithin the organization we have many different repositories.\nIn case you want to give feedback or provide contributions you need to know the corresponding repository.\nThe major technology stacks have their own repository carrying the prefix devon4 followed by a shortcut for their stack or programming language:\ndevon4j for Java\ndevon4ng for Angular\ndevon4net for .NET\ndevon4x for Xamarin\ndevon4node for node.js\nTools we provide typically have a repository named like the tool they provide (omitting prefixes like devon[fw]):\nCobiGen (incremental code generator)\ndevonfw-ide (development environment)\nsonar-devon4j-plugin (SonarQube plugin for architecture validation)\nCICDgen (generator for CI/CD)\nDocGen (generator for AsciiDoc to PDF and other formats)\nSolicitor (License compatibility checker)\nasciidoc-link-checker\nThere is much more to discover.\nBrowse our organization to find out.\n"},{"id":12,"path":"../website/pages/docs/CONTRIBUTING.asciidoc.html#contributing.asciidoc_trivial-changes","type":"docs","title":"Trivial Changes","body":"106.1.4. Trivial Changes\nPlease note that for trivial changes like a typo in the documentation you do not need to follow a complex process. Please do the following:\nJust browse to the file online on GitHub.\nClick on the small pencil icon on the top right of the file content.\nMake the required changes.\nWhen editing documentation, verify your change by switching to the Preview tab at the top.\nWhen your change is complete, select Create a new branch for this commit and start a pull request at the bottom.\nComit your change by clicking the green Propose file change button at the bottom.\nNow fill summary and description and click on the green Create pull request button.\nThat is all. Thank you very much! For details about pull requests read here.\nFor non-trivial changes please read on.\n"},{"id":13,"path":"../website/pages/docs/CONTRIBUTING.asciidoc.html#contributing.asciidoc_issues","type":"docs","title":"Issues","body":"106.1.5. Issues\nWe are working issue-based, so check if there is already an issue in our tracker for the task you want to work on.\nOtherwise first create a new issue for it (e.g. a bug report or a feature request).\nIf you want to contribute actively to resolve the issue (by providing code, documentation, etc.),\nplease assure via communication in that issue (comments, assigned user, etc.) that this is recognized and accepted by somebody from the community.\nEspecially in case of more complex issues, please get sure not to miss out such consensus with the community\nand ensure that there is a common understanding of what and potentially even how to do it.\nYou surely do not want to invest your valuable work and time into something that will later be rejected by the community.\nWhen you have been assigned to the issue (see Assignees on the right) you are sure that nobody else will work on the same issue in parallel and you are ready to go.\n"},{"id":14,"path":"../website/pages/docs/CONTRIBUTING.asciidoc.html#contributing.asciidoc_branches","type":"docs","title":"Branches","body":"106.1.6. Branches\nTypically the latest development takes place on the master branch (in case there is a develop branch instead, use that one).\nHowever, all changes are consequently done via feature-branches and pull-requests (see next sections).\n"},{"id":15,"path":"../website/pages/docs/CONTRIBUTING.asciidoc.html#contributing.asciidoc_forking","type":"docs","title":"Forking","body":"106.1.7. Forking\nThe github.com platform supports a wonderful feature to fork a repository.\nMake use of this create your private copy where you experiment and prepare your contribution in an isolated environment:\nVisit the original repository you want to contribute to.\nClick on the Fork button at the top right. If asked for a destination choose your personal GitHub account.\nClone this fork with a git-client to your local machine.\nCheckout the branch to use as baseline (see above section).\nFrom there create and checkout a new feature branch (named feature/&#xAB;issue-id&#xBB;-&#xAB;feature-keywords&#xBB;)\nStart your work on this new feature branch.\nSometimes, when working on your fork, there will be changes made to the original repository, which you might want to incorporate into your fork&#x2019;s master branch. To do this, you can sync your fork:\nAdd the remote URL of the original repo to your list of remotes: git remote add upstream &#xAB;remote-url&#xBB;\nFetch the changes from the upstream remote: git fetch upstream\nCheck out your fork&#x2019;s master branch: git checkout master (assuming you&#x2019;re working on a feature branch)\nMerge the changes from upstream/master into your fork&#x2019;s master branch: git merge upstream/master\nThis brings your fork&#x2019;s master branch into sync with the original repository without losing changes on your local feature branch.\nSwitch back to your feature branch to continue work: git checkout &#xAB;feature-branch&#xBB;\n"},{"id":16,"path":"../website/pages/docs/CONTRIBUTING.asciidoc.html#contributing.asciidoc_code-changes","type":"docs","title":"Code Changes","body":"106.1.8. Code Changes\nBefore you start with your code changes, please check the following conventions:\nFor each programming language we have a stack repository (see repositories) containing documentation about the coding conventions (example: Java). Please read and follow these conventions before making (bigger) changes.\nUse devon-ide to setup your development environment and get code formatters, etc. configured properly as we do not like &quot;diff-wars&quot; because of inconsistent formatter settings.\nThank you, happy coding!\n"},{"id":17,"path":"../website/pages/docs/CONTRIBUTING.asciidoc.html#contributing.asciidoc_documentation-changes","type":"docs","title":"Documentation Changes","body":"106.1.9. Documentation Changes\nBefore you start with your documentation changes, please check the following conventions:\nDocumentation will always be found in the documentation folder at the root of a repository.\nAll our documentation is written in the AsciiDoc format.\nAll documentation files need to carry the .asciidoc extension and should be named in lower-train-case style.\nCommon prefixes help to categorize documentation files: tutorial- is used for step-by-step instructions, guide- is used for guidelines on a particular aspect, coding- is for specific conventions or details about source-code, alternative- is for less official options that are not recommended but to still offer knowledge for people using that option, decision- is for rationales why a complex (technology) decision was made.\nPlease read and follow our documentation guidelines.\ncontributing-internal-snippets\n"},{"id":18,"path":"../website/pages/docs/CONTRIBUTING.asciidoc.html#contributing.asciidoc_testing-changes","type":"docs","title":"Testing Changes","body":"106.1.10. Testing Changes\nTo test your changes all you need to do is run the following command:\ndevon build\nIf the build failed, you need to rework your changes.\n"},{"id":19,"path":"../website/pages/docs/CONTRIBUTING.asciidoc.html#contributing.asciidoc_committing-changes","type":"docs","title":"Committing Changes","body":"106.1.11. Committing Changes\nAlways commit your changes in small logical units associated with an issue (see above section) using the commit message format:\n#&#xAB;issue-id&#xBB;: &#xAB;describe your change&#xBB;\nThen GitHub will automatically link the commit with the issue.\nExample:\n#1: added REST service for tablemanagement\nIn case you worked on an issue from a different repository (e.g. change in ide-settings due to issue in ide), we use this commit message format:\n&#xAB;organization&#xBB;/&#xAB;repository&#xBB;#&#xAB;issue-id&#xBB;: &#xAB;describe your change&#xBB;\nExample:\ndevonfw/devon4j#1: added REST service for tablemanagement\n"},{"id":20,"path":"../website/pages/docs/CONTRIBUTING.asciidoc.html#contributing.asciidoc_pushing-changes","type":"docs","title":"Pushing Changes","body":"106.1.12. Pushing Changes\nTo make your changes public you need to push them.\nIf you are doing this for the first time since you started your feature branch, you also need to publish that branch (git push -u origin feature/&#xAB;issue-id&#xBB;-&#xAB;feature-keywords&#xBB;).\nAfter that a git push is sufficient.\n"},{"id":21,"path":"../website/pages/docs/CONTRIBUTING.asciidoc.html#contributing.asciidoc_definition-of-done","type":"docs","title":"Definition of Done","body":"106.1.13. Definition of Done\nTo complete your changes ensure the following aspects:\nYou have tested your changes and the build succeeds.\nCode and documentation are in sync (if you coded new features you also extended documentation, etc.).\nYou followed the coding conventions and documentation guidelines.\nFor new features you have added automated unit tests.\nDo not worry; we will assist you in case you are unsure or missed out on something.\nHowever, you make your and our life easier, if you follow this Definition of Done (DoD) before providing your pull request.\n"},{"id":22,"path":"../website/pages/docs/CONTRIBUTING.asciidoc.html#contributing.asciidoc_pull-requests","type":"docs","title":"Pull Requests","body":"106.1.14. Pull Requests\nOnce you have completed your changes and DoD, you can finally create a pull request (PR).\nPlease ensure the following aspects:\nWhen selecting a title for your pull request, follow the same conventions that apply to commit messages.\nAlso add the related issue(s) to the description of the pull request (e.g. fixes #&#xAB;issue-id&#xBB;).\nIf you are providing a PR that is not yet ready for merging, please use GitHub&#x2019;s draft pull request feature:\nExpand the drop-down menu of the green Create Pull Request button and select Create Draft Pull Request\nYou can make further code changes to your PR by pushing commits to the corresponding feature branch.\nWhen you&#x2019;re ready to get feedback on your PR, click the Ready for review button.\nIf you are providing a PR that is ready for merging, click on the green Create Pull Request button.\nYour pull request will automatically be checked for these requirements:\nCan be merged without conflicts.\nBuilds correctly (no compile or test errors).\nCLA has been signed. If you contribute for the first time, you need to sign the CLA once.\nPlease ensure to do the required tasks and reworks unless all checks are satisfied.\nFrom here a reviewer should take over and give feedback.\nIn the best case, your contribution gets merged and everything is completed.\nYou might also get review feedback and requests for changes.\nIn that case walk through the review feedback and try to resolve it.\nOnce you push your new commits, the PR gets updated automatically and all checks will verify again.\nAlso GitHub will automatically make resolved review comments as outdated.\nIf you do not plan to put any further work into your PR before it is completed and merged, please let us know by writing an according comment.\nWe might find resources to get the PR done for you if it is already valuable.\nIn case you should not get feedback for weeks, do not hesitate to ask the community.\nNote\nIf one (typically the reviewer) has to change the base branch (because the wrong develop branch was used, see above) onto which the changes will be merged, one can do the same by following the instructions at here.\n&#x2191;&#xA0;Up:&#xA0;Contributing&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Contributor Covenant Code of Conduct&#xA0;&#x2192;\n"},{"id":23,"path":"../website/pages/docs/User-Stories.asciidoc.html#User-Stories.asciidoc","type":"docs","title":"User Stories","body":"85. User Stories\nThe list of user stories, exported from JIRA, can be downloaded from here.\n"},{"id":24,"path":"../website/pages/docs/User-Stories.asciidoc.html#user-stories.asciidoc_epic-invite-friends","type":"docs","title":"Epic: Invite friends","body":"85.1. Epic: Invite friends\n"},{"id":25,"path":"../website/pages/docs/User-Stories.asciidoc.html#user-stories.asciidoc_us-create-invite-for-friends","type":"docs","title":"US: create invite for friends","body":"85.1.1. US: create invite for friends\nEpic: Invite friends\nAs a guest I want to create an dinner event by entering date and time and adding potential guests by their emails so that each potential guest will receives an email in order to confirm or decline my invite.\nAcceptance criteria\nonly date and time in future possible and both required\nonly valid email addresses: text@text.xx, one entered email-address is required\nif AGB are not checked, an error message is shown\nafter the invite is done\nI see the confirmation screen of my invite (see wireframe)\nI receive a confirmation email about my invite containing date, time and invited guests\nall guests receive a mail with my invite\n"},{"id":26,"path":"../website/pages/docs/User-Stories.asciidoc.html#user-stories.asciidoc_us-create-reservation","type":"docs","title":"US: create reservation","body":"85.1.2. US: create reservation\nEpic: Invite friends\nAs a guest I want to create a reservation by entering date and time and number of adults and kids\nAcceptance criteria\nonly date and time in future possible and both required\nonly valid email addresses: text@text.xx, one entered email-address is required\nif AGB are not checked, an error message is shown\nafter the reservation is done\nI see a confirmation screen of my reservation with datetime, number of persons and kids\nI receive a confirmation email about my reservation\nWireframes\nsee realtimeboard\n"},{"id":27,"path":"../website/pages/docs/User-Stories.asciidoc.html#user-stories.asciidoc_us-handle-invite","type":"docs","title":"US: handle invite","body":"85.1.3. US: handle invite\nAs an invited guest I would like to receive an email - after somebody as invited me - with the option to accept or decline the invite so that the system knows about my participation\nAC:\nthe mail contains the following information about the invite\nwho has invited\nwho else is invited\ndate and time of the invite\nbutton to accept or decline\nafter pressing the buttons the system will store the status (yes/no) of my invite\n"},{"id":28,"path":"../website/pages/docs/User-Stories.asciidoc.html#user-stories.asciidoc_us-revoke-accepted-invite","type":"docs","title":"US: revoke accepted invite","body":"85.1.4. US: revoke accepted invite\nAs an invited guest I would like to revoke my previous answer in order to inform the system and the inviter about my no showup\nAC:\nthe inviter and myself receives an email about my cancellation\nthe system sets my status of my invite to no\nin case I have placed an order, the order is also removed from the system.\nthe cancellation is only possible 10 minutes before the event takes place. The system shows a message that cancellation is not possible anymore.\n"},{"id":29,"path":"../website/pages/docs/User-Stories.asciidoc.html#user-stories.asciidoc_us-calculate-best-table","type":"docs","title":"US: calculate best table","body":"85.1.5. US: calculate best table\nAs a guest I would like the system to check (1 hour before my invite) all my invites and to reserve a table fitting the number of accepted users\nDetails\nPseudo-algorithm for reservation:\nFind table for given date and time where seats of guests &gt;= Count of invited guests plus one. In case no results, decline request and show error message to user. In case of any result, make a reservation for table&#x2026;&#x200B;.\nFor each decline of a guest remove guest and search with reduced number for new table. In case table is found, reserve it and remove reservation from previous table. In case not, do not change reservations.\n"},{"id":30,"path":"../website/pages/docs/User-Stories.asciidoc.html#user-stories.asciidoc_us-find-table-by-reservation-info","type":"docs","title":"US: find table by reservation info","body":"85.1.6. US: find table by reservation info\nAs a waiter I would like to search by reference number or email address for the reserved table in order to know the table for my visit. (when arriving at the restaurant)\nAC:\nAfter entering the email the systems shows the number of the table. In case no reservation found, a message is shown.\nEntered email address could be email of inviter or any invited guest.\n"},{"id":31,"path":"../website/pages/docs/User-Stories.asciidoc.html#user-stories.asciidoc_us-cancel-invite","type":"docs","title":"US: cancel invite","body":"85.1.7. US: cancel invite\nEpic: Invite friends\nAs a guests who has sent an invite I want to be able to cancel my previous invite in order to inform the restaurant and my invited guests that I will not show up\nAC:\nthe option to cancel the invite is available in the confirmation-mail about my invite\nafter my cancellation all invited guests receives a mail about the cancelation\nI see a confirmation that my invite was cancelled successfully\nafter my cancelation my invite and reservation and all orders related to it are deleted from the system and no one can accept or decline any invite for it\nthe cancellation is only possible one hour before the invite takes place. After that I am not allowed to cancel it any more.\n"},{"id":32,"path":"../website/pages/docs/User-Stories.asciidoc.html#user-stories.asciidoc_epic-digital-menu","type":"docs","title":"Epic: Digital Menu","body":"85.2. Epic: Digital Menu\n"},{"id":33,"path":"../website/pages/docs/User-Stories.asciidoc.html#user-stories.asciidoc_us-filter-menu","type":"docs","title":"US: filter menu","body":"85.2.1. US: filter menu\nAs a guest I want to filter the menu so that I only see the dishes I am interested in\nAC:\nthe guest can filter by\ntype: starter | main dish | dessert; XOR; if nothing is selected all are shown (default value)\nveggy (yes|no|does not matter (default))\nvegan (yes|no|does not matter (default))\nrice (yes|no|does not matter (default))\ncurry (yes|no|does not matter (default))\nnoodle (yes|no|does not matter (default))\nprice (range)\nratings (range)\nmy favorite (yes|no|does not matter (default))&#x2009;&#x2014;&#x2009;free text (search in title and description)\nthe guest can sort by price asc, rating asc\nafter setting the filter only dishes are shown which fulfills those criteria\nby pressing the button reset filter all filter are reset to the initial value\nby pressing the filter button the filter is applied [or is it triggered after each change?]\n"},{"id":34,"path":"../website/pages/docs/User-Stories.asciidoc.html#user-stories.asciidoc_us-define-order","type":"docs","title":"US: Define order","body":"85.2.2. US: Define order\nAs a guest I want to define my order by selecting dishes from the menu\nAC:\nThe guest can add each dish to the order\nIn case the guest adds the same dish multiple times, a counter in the order for this dish is increased for this dish\nThe guest can remove the dish from the order\nThe guest can add for each main dish the type of meat (pork, chicken, tofu)\nThe guest can add for each dish a free-text-comment\nAfter adding/removing any dish the price is calculated including VAT\n"},{"id":35,"path":"../website/pages/docs/User-Stories.asciidoc.html#user-stories.asciidoc_us-order-the-order","type":"docs","title":"US: Order the order","body":"85.2.3. US: Order the order\nAs a guest I want to order my selected dishes (order)\nAC:\nI receive a mail containing my order with all dishes and the final price\nprecondition for ordering:\nEach order must be associated with a reservation / invite. Without any reference no order could be placed. The reference could be obtained from a previous reservation/invite (created during same session) or by the previous accepted invite (link in email) or by entering the reference id when asked by the system.\nIn case precondition is not fulfilled, the guest is asked\nwhether he/she would like to create a reservation/invite and is forwarded to US Invite Friends. Only after finalizing the reservation the order is accepted.\nor he/she would enter previous created reservation-id he/she knows in order to associate his/her order with this reservation\n"},{"id":36,"path":"../website/pages/docs/User-Stories.asciidoc.html#user-stories.asciidoc_us-cancel-order","type":"docs","title":"US: Cancel order","body":"85.2.4. US: Cancel order\nAs a guest I want to cancel my order.\nAC:\nin my received confirmation mail I have the option to cancel my order\nthe cancelation is only possible one hour before my reservation takes place\nmy order is deleted from the system\nRemark: Changing the order is not possible. For that the order must be canceled and created from scratch again\n"},{"id":37,"path":"../website/pages/docs/User-Stories.asciidoc.html#user-stories.asciidoc_us-read-twitter-rating-for-dishes","type":"docs","title":"US: Read twitter rating for dishes","body":"85.2.5. US: Read twitter rating for dishes\nAs a guest I want to read for all dishes the rating done be twitter because I would like to know the opinion of others\nAC:\nFor each dish I see the latest 3 comments done by twitter for this vote (text, username, avatar)\nFor each dish I see the number of likes done by twitter\n"},{"id":38,"path":"../website/pages/docs/User-Stories.asciidoc.html#user-stories.asciidoc_epic-user-profile","type":"docs","title":"Epic: User Profile","body":"85.3. Epic: User Profile\n"},{"id":39,"path":"../website/pages/docs/User-Stories.asciidoc.html#user-stories.asciidoc_us-user-profile","type":"docs","title":"US: User Profile","body":"85.3.1. US: User Profile\nAs a guest I want to have a user profile to associate it with my twitter account to be able to like/rate dishes\nAC:\nUsername of my profile is my email address\nMy profile is protected by password\nI can log in and log out to my profile\nI can reset my password by triggering the reset by mail\nI can associate my profile with my twitter account in order to rate dishes and store my favorites by liking posts associated to dishes\n"},{"id":40,"path":"../website/pages/docs/User-Stories.asciidoc.html#user-stories.asciidoc_epic-rate-by-twitter","type":"docs","title":"Epic: Rate by twitter","body":"85.4. Epic: Rate by twitter\n"},{"id":41,"path":"../website/pages/docs/User-Stories.asciidoc.html#user-stories.asciidoc_us-receive-mail-to-rate-your-dish","type":"docs","title":"US: Receive mail to rate your dish","body":"85.4.1. US: Receive mail to rate your dish\nAs a guest I want to receive a mail by the system in order to rate my dish\n"},{"id":42,"path":"../website/pages/docs/User-Stories.asciidoc.html#user-stories.asciidoc_us-rate-your-dish","type":"docs","title":"US: Rate your dish","body":"85.4.2. US: Rate your dish\nAs a guest I want to add a comment or a like via my twitter account for a dish\nAC:\nBefore I write my rate I would like to be able to read all tweets of other users for this dish\nI would like to see the number of likes for a dish\n"},{"id":43,"path":"../website/pages/docs/User-Stories.asciidoc.html#user-stories.asciidoc_epic-waiter-cockpit","type":"docs","title":"Epic: Waiter Cockpit","body":"85.5. Epic: Waiter Cockpit\n"},{"id":44,"path":"../website/pages/docs/User-Stories.asciidoc.html#user-stories.asciidoc_us-see-all-ordersreservations","type":"docs","title":"US: See all orders/reservations","body":"85.5.1. US: See all orders/reservations\nAs a waiter I want to see all orders/reservation in order to know what is going on in my restaurant\nAC:\nall orders/reservations are shown in a list view (read-only). Those list can be filtered and sorted (similar to excel-data-filters)\norders/reservations are shown in separate lists.\nfor each order the dish, meat, comment, item, reservation-id, reservation datetime, creation-datetime is shown\nfor each reservation the inviters email, the guests-emails, the number of accepts and declines, calculated table number, the reservation-id, reservation date-time and creation-datetime are shown\nthe default filter for all lists is the todays date for reservation datetime. this filter can be deleted.\nonly reservations and orders with reservation date in the future shall be available in this view. All other orders and reservation shall not be deleted; for data analytics those orders and reservation shall still exist in the system.\nchecklist:\ntalk about:\nwho?\nwhat?\nwhy (purpose)\nwhy (objective)\nwhat happens outside the software\nwhat might go wrong\nany question or assumptions (write them down) , DoR should check that those sections are empty.\nis there any better solution?\nhow (technical perspective)\ndo a rough estimate\ncheck INVEST\n&#x2190;&#xA0;Previous:&#xA0;1.\tMy Thai Star &#x2013; Agile Framework&#xA0;| &#x2191;&#xA0;Up:&#xA0;MyThaiStar&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Technical design&#xA0;&#x2192;\n"},{"id":45,"path":"../website/pages/docs/agile.asciidoc.html#agile.asciidoc","type":"docs","title":"My Thai Star &#x2013; Agile Diary","body":"84. 2.\tMy Thai Star &#x2013; Agile Diary\nIn parallel to the Diary Ideation we use this Agile Diary to document our Scrum events. The target of this diary is to describe the differences to the Scrum methodology as well as specific characteristics of the project. We also document the process on how we approach the Scrum methodology over the length of the project.\n"},{"id":46,"path":"../website/pages/docs/agile.asciidoc.html#agile.asciidoc_24.03.2017-sprint-1-planning","type":"docs","title":"24.03.2017 Sprint 1 Planning","body":"84.1. 24.03.2017 Sprint 1 Planning\nWithin the Sprint 1 Planning we used planning poker.com for the estimation of the user stories. The estimation process usually is part of the backlog refinement meeting. Regarding the project circumstances we decided to estimate the user stories during the Sprint Planning. Starting the estimation process we noticed that we had to align our interpretation of the estimation effort as these story points are not equivalent to a certain time interval. The story points are relative values to compare the effort of the user stories. With this in mind we proceeded with the estimation of the user stories. We decided to start Sprint 1 with the following user stories and the total amount of 37 story points:\n&#x2022;\tICSDSHOW-2\tCreate invite for friends\t(8 Story Points)\n&#x2022;\tICSDSHOW-4\tCreate reservation\t\t(3)\n&#x2022;\tICSDSHOW-5\tHandle invite\t\t\t(3)\n&#x2022;\tICSDSHOW-6\tRevoke accepted invite \t(5)\n&#x2022;\tICSDSHOW-9\tCancel invite\t\t\t(3)\n&#x2022;\tICSDSHOW-11\tFilter menu\t\t\t(5)\n&#x2022;\tICSDSHOW-12\tDefine order\t\t\t(5)\n&#x2022;\tICSDSHOW-13\tOrder the order\t\t(5)\nAs the Sprint Planning is time boxed to one hour we managed to hold this meeting within this time window.\n"},{"id":47,"path":"../website/pages/docs/agile.asciidoc.html#agile.asciidoc_27.04.2017-sprint-1-review","type":"docs","title":"27.04.2017 Sprint 1 Review","body":"84.2. 27.04.2017 Sprint 1 Review\nDuring the Sprint 1 Review we had a discussion about the data model proposal. For the discussion we extended this particular Review meeting to 90min. As this discussion took almost 2/3 of the Review meeting we only had a short time left for our review of Sprint 1. For the following scrum events we decided to focus on the primary target of these events and have discussions needed for alignments in separate meetings.\nRegarding the topic of splitting user stories we had the example of a certain user story which included a functionality of a twitter integration (ICSDSHOW-17 User Profile and Twitter integration). As the twitter functionality could not have been implemented at this early point of time we thought about cutting the user story into two user stories. We aligned on mocking the twitter functionality until the dependencies are developed in order to test the components. As this user story is estimated with 13 story points it is a good example for the question whether to cut a user story into multiple user stories or not.\nUnfortunately not all user stories of Sprint 1 could have been completed. Due this situation we discussed on whether pushing all unfinished user stories into the status done or moving them to Sprint 2. We aligned on transferring the unfinished user stories into the next Sprint. During the Sprint 1 the team underestimated that a lot of holidays crossed the Sprint 1 goals. As taking holidays and absences of team members into consideration is part of a Sprint Planning we have a learning effect on setting a Sprint Scope.\n"},{"id":48,"path":"../website/pages/docs/agile.asciidoc.html#agile.asciidoc_03.05.2017-sprint-2-planning","type":"docs","title":"03.05.2017 Sprint 2 Planning","body":"84.3. 03.05.2017 Sprint 2 Planning\nAs we aligned during the Sprint 1 Review on transferring unfinished user stories into Sprint 2 the focus for Sprint 2 was on finishing these transferred user stories. During our discussion on how many user stories we could work on in Sprint 2 we needed to remind ourselves that the overall target is to develop an example application for the DevonFW. Considering this we aligned on a clear target for Sprint 2: To focus on finishing User Stories as we need to aim for a practicable and realizable solution. Everybody aligned on the aim of having a working application at the end of Sprint 2.\nFor the estimation process of user stories we make again usage of planningpoker.com as the team prefers this &#x201C;easy-to-use&#x201D; tool. During our second estimation process we had the situation in which the estimated story points differs strongly from one team member to another. In this case the team members shortly explains how the understood and interpreted the user story. It turned out that team members misinterpreted the user stories. With having this discussion all team members got the same understanding of the specific functionality and scope of a user story. After the alignment the team members adjusted their estimations.\nBeside this need for discussion the team estimated most of the user stories with very similar story points. This fact shows the increase within the effort estimation for each team member in comparison to Sprint 1 planning. Over the short time of two Sprint planning the team received a better understanding and feeling for the estimation with story points.\n"},{"id":49,"path":"../website/pages/docs/agile.asciidoc.html#agile.asciidoc_01.06.2017-sprint-2-review","type":"docs","title":"01.06.2017 Sprint 2 Review","body":"84.4. 01.06.2017 Sprint 2 Review\nAs our Sprint 1 Review four weeks ago was not completely structured like a Sprint Review meeting we focused on the actual intention of a Sprint Review meeting during Sprint 2 Review. This means we demonstrated the completed and implemented functionalities with screen sharing and the product owner accepted the completed tasks.\nWithin the User Story ICSDSHOW-22 &#x201C;See all orders/reservations&#x201D; the functionality &#x201C;filtering the list by date&#x201D; could have not been implemented during Sprint 2. The team was unsure on how to proceed with this task. One team member added that especially in regards of having a coherent release, implementing less but working functionalities is much better than implementing more but not working functionalities. For this the team reminded itself focusing on completing functionalities and not working straight to a working application.\n&#x2190;&#xA0;Previous:&#xA0;1.\tMy Thai Star &#x2013; Agile Framework&#xA0;| &#x2191;&#xA0;Up:&#xA0;MyThaiStar&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;User Stories&#xA0;&#x2192;\n"},{"id":50,"path":"../website/pages/docs/devon4j.asciidoc.html#devon4j.asciidoc","type":"docs","title":"III. devonfw for Java (devon4j)","body":"III. devonfw for Java (devon4j)\nThe devonfw community\ndev-SNAPSHOT, 2021-07-15_07.40.01\ndevonfw provides a solution to building applications which combine best-in-class frameworks and libraries as well as industry proven practices and code conventions.\nIt massively speeds up development, reduces risks and helps you to deliver better results.\nThe following sections contain the complete compendium of devon4j, the Java stack of devonfw.\nYou can also read the latest version of this documentation online in the devon4j wiki\nor at devon4j on devonfw.com.\nArchitecture\nCoding Conventions\nProject structure\nLayers\nGuides\nTutorials\n&#x2190;&#xA0;Previous:&#xA0;Support&#xA0;| &#x2191;&#xA0;Up:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Architecture&#xA0;&#x2192;\n"},{"id":51,"path":"../website/pages/docs/devon4j.asciidoc_architecture.html#devon4j.asciidoc_architecture","type":"docs","title":"Architecture","body":"8. Architecture\nThere are many different views that are summarized by the term architecture. First, we will introduce the key principles and architecture principles of devonfw. Then, we will go into details of the the architecture of an application.\n"},{"id":52,"path":"../website/pages/docs/devon4j.asciidoc_architecture.html#architecture.asciidoc_key-principles","type":"docs","title":"Key Principles","body":"8.1. Key Principles\nFor devonfw we follow these fundamental key principles for all decisions about architecture, design, or choosing standards, libraries, and frameworks:\nKISS\nKeep it small and simple\nOpen\nCommitment to open standards and solutions (no required dependencies to commercial or vendor-specific standards or solutions)\nPatterns\nWe concentrate on providing patterns, best-practices and examples rather than writing framework code.\nSolid\nWe pick solutions that are established and have been proven to be solid and robust in real-live (business) projects.\n"},{"id":53,"path":"../website/pages/docs/devon4j.asciidoc_architecture.html#architecture.asciidoc_architecture-principles","type":"docs","title":"Architecture Principles","body":"8.2. Architecture Principles\nAdditionally we define the following principles that our architecture is based on:\nComponent Oriented Design\nWe follow a strictly component oriented design to address the following sub-principles:\nSeparation of Concerns\nReusability and avoiding redundant code\nInformation Hiding via component API and its exchangeable implementation treated as secret.\nDesign by Contract for self-contained, descriptive, and stable component APIs.\nLayering as well as separation of business logic from technical code for better maintenance.\nData Sovereignty (and high cohesion with low coupling) says that a component is responsible for its data and changes to this data shall only happen via the component. Otherwise, maintenance problems will arise to ensure that data remains consistent. Therefore, interfaces of a component that may be used by other components are designed call-by-value and not call-by-reference.\nHomogeneity\nSolve similar problems in similar ways and establish a uniform code-style.\nAs an architect you should be prepared for the future by reading the TechnoVision.\n"},{"id":54,"path":"../website/pages/docs/devon4j.asciidoc_architecture.html#architecture.asciidoc_application-architecture","type":"docs","title":"Application Architecture","body":"8.3. Application Architecture\nFor the architecture of an application we distinguish the following views:\nThe Business Architecture describes an application from the business perspective. It divides the application into business components and with full abstraction of technical aspects.\nThe Technical Architecture describes an application from the technical implementation perspective. It divides the application into technical layers and defines which technical products and frameworks are used to support these layers.\nThe Infrastructure Architecture describes an application from the operational infrastructure perspective. It defines the nodes used to run the application including clustering, load-balancing and networking. This view is not explored further in this guide.\n"},{"id":55,"path":"../website/pages/docs/devon4j.asciidoc_architecture.html#architecture.asciidoc_business-architecture","type":"docs","title":"Business Architecture","body":"8.3.1. Business Architecture\nThe business architecture divides the application into business components. A business component has a well-defined responsibility that it encapsulates. All aspects related to that responsibility have to be implemented within that business component. Further, the business architecture defines the dependencies between the business components. These dependencies need to be free of cycles. A business component exports its functionality via well-defined interfaces as a self-contained API. A business component may use another business component via its API and compliant with the dependencies defined by the business architecture.\nAs the business domain and logic of an application can be totally different, the devonfw can not define a standardized business architecture. Depending on the business domain it has to be defined from scratch or from a domain reference architecture template. For very small systems it may be suitable to define just a single business component containing all the code.\n"},{"id":56,"path":"../website/pages/docs/devon4j.asciidoc_architecture.html#architecture.asciidoc_technical-architecture","type":"docs","title":"Technical Architecture","body":"8.3.2. Technical Architecture\nThe technical architecture divides the application into technical layers based on the multilayered architecture. A layer is a unit of code with the same category such as a service or presentation logic. So, a layer is often supported by a technical framework. Each business component can therefore be split into component parts for each layer. However, a business component may not have component parts for every layer (e.g. only a presentation part that utilized logic from other components).\nAn overview of the technical reference architecture of the devonfw is given by figure &quot;Technical Reference Architecture&quot;.\nIt defines the following layers visualized as horizontal boxes:\nclient layer for the front-end (GUI).\nservice layer for the services used to expose functionality of the\nback-end to the client or other consumers.\nbatch layer for exposing functionality in batch-processes (e.g. mass imports).\nlogic layer for the business logic.\ndata-access layer for the data access (esp. persistence).\nAlso, you can see the (business) components as vertical boxes (e.g. A and X) and how they are composed out of component parts each one assigned to one of the technical layers.\nFurther, there are technical components for cross-cutting aspects grouped by the gray box on the left. Here is a complete list:\nSecurity\nLogging\nMonitoring\nTransaction-Handling\nException-Handling\nInternationalization\nDependency-Injection\nFigure 5. Technical Reference Architecture\nPlease click on the architecture image to open it as SVG and click on the layers and cross-cutting topics to open the according documentation guide.\nWe reflect this architecture in our code as described in our coding conventions allowing a traceability of business components, use-cases, layers, etc. into the code and giving\ndevelopers a sound orientation within the project.\nFurther, the architecture diagram shows the allowed dependencies illustrated by the dark green connectors.\nWithin a business component a component part can call the next component part on the layer directly below via a dependency on its API (vertical connectors).\nWhile this is natural and obvious, it is generally forbidden to have dependencies upwards the layers\nor to skip a layer by a direct dependency on a component part two or more layers below.\nThe general dependencies allowed between business components are defined by the business architecture.\nIn our reference architecture diagram we assume that the business component A1 is allowed to depend\non component A2. Therefore, a use-case within the logic component part of A1 is allowed to call a\nuse-case from A2 via a dependency on the component API. The same applies for dialogs on the client layer.\nThis is illustrated by the horizontal connectors. Please note that persistence entities are part of the API of the data-access component part so only the logic component part of the same\nbusiness component may depend on them.\nThe technical architecture has to address non-functional requirements:\nscalability\nis established by keeping state in the client and making the server state-less (except for login session). Via load-balancers new server nodes can be added to improve performance (horizontal scaling).\navailability and reliability\nare addressed by clustering with redundant nodes avoiding any single-point-of failure. If one node fails the system is still available. Further, the software has to be robust so there are no dead-locks or other bad effects that can make the system unavailable or not reliable.\nsecurity\nis archived in the devonfw by the right templates and best-practices that avoid vulnerabilities. See security guidelines for further details.\nperformance\nis obtained by choosing the right products and proper configurations. While the actual implementation of the application matters for performance a proper design is important as it is the key to allow performance-optimizations (see e.g. caching).\nTechnology Stack\nThe technology stack of the devonfw is illustrated by the following table.\nTable 27. Technology Stack of devonfw\nTopic\nDetail\nStandard\nSuggested implementation\nruntime\nlanguage &amp; VM\nJava\nOracle JDK\nruntime\nservlet-container\nJEE\ntomcat\ncomponent management\ndependency injection\nJSR330 &amp; JSR250\nspring\nconfiguration\nframework\n-\nspring-boot\npersistence\nOR-mapper\nJPA\nhibernate\nbatch\nframework\nJSR352\nspring-batch\nservice\nSOAP services\nJAX-WS\nCXF\nservice\nREST services\nJAX-RS\nCXF\nlogging\nframework\nslf4j\nlogback\nvalidation\nframework\nbeanvalidation/JSR303\nhibernate-validator\nsecurity\nAuthentication &amp; Authorization\nJAAS\nspring-security\nmonitoring\nframework\nJMX\nspring\nmonitoring\nHTTP Bridge\nHTTP &amp; JSON\njolokia\nAOP\nframework\ndynamic proxies\nspring AOP\n"},{"id":57,"path":"../website/pages/docs/devon4j.asciidoc_architecture.html#guide-component.asciidoc","type":"docs","title":"Components","body":"8.4. Components\nFollowing separation-of-concerns we divide an application into components using our package-conventions and architecture-mapping.\nAs described by the architecture each component is divided into these layers:\nclient-layer with the dialogs to view and modify the component&#x2019;s data.\nservice-layer with the services to access the component&#x2019;s data remotely.\nlogic-layer with the component-facade providing the business-logic to manage the component&#x2019;s data.\ndataaccess-layer with the entities defining and the repositories (or DAOs) accessing the component&#x2019;s data.\nPlease note that only CRUD oriented components will have all four layers within the same component.\nSome types of applications may have completely different components for the client.\n"},{"id":58,"path":"../website/pages/docs/devon4j.asciidoc_architecture.html#guide-component.asciidoc_general-component","type":"docs","title":"General Component","body":"8.4.1. General Component\nCross-cutting aspects belong to the implicit component general. It contains technical configurations and very general code that is not business specific. Such code shall not have any dependencies to other components and therefore business related code.\n"},{"id":59,"path":"../website/pages/docs/devon4j.asciidoc_architecture.html#guide-component.asciidoc_business-component","type":"docs","title":"Business Component","body":"8.4.2. Business Component\nThe business-architecture defines the business components with their allowed dependencies. A small application (microservice) may just have one component and no dependencies making it simple while the same architecture can scale up to large and complex applications (from bigger microservice up to modulith).\nTailoring an business domain into applications and applications into components is a tricky task that needs the skills of an experienced architect.\nAlso, the tailoring should follow the business and not split by technical reasons or only by size.\nSize is only an indicator but not a driver of tailoring.\nWhatever hypes like microservices are telling you, never get misled in this regard:\nIf your system grows and reaches MAX+1 lines of code, it is not the right motivation to split it into two microservices of ~MAX/2 lines of code - such approaches will waste huge amounts of money and lead to chaos.\n"},{"id":60,"path":"../website/pages/docs/devon4j.asciidoc_architecture.html#guide-component.asciidoc_app-component","type":"docs","title":"App Component","body":"8.4.3. App Component\nOnly in case you need cross-cutting code that aggregates another component you may introduce the component app.\nIt is allowed to depend on all other components but no other component may depend on it.\nWith the modularity and flexibility of spring you typically do not need this.\nHowever, when you need to have a class that registers all services or component-facades using direct code dependencies, you can introduce this component.\n"},{"id":61,"path":"../website/pages/docs/devon4j.asciidoc_architecture.html#guide-component.asciidoc_component-example","type":"docs","title":"Component Example","body":"8.4.4. Component Example\nThe following class diagram illustrates an example of the business component Staffmanagement:\nIn this scheme, you can see the structure and flow from the service-layer (REST service call) via the logic-layer to the dataaccess-layer (and back).\n&#x2191;&#xA0;Up:&#xA0;devonfw for Java (devon4j)&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Coding Conventions&#xA0;&#x2192;\n"},{"id":62,"path":"../website/pages/docs/devon4j.asciidoc_coding-conventions.html#devon4j.asciidoc_coding-conventions","type":"docs","title":"Coding Conventions","body":"9. Coding Conventions\nThe code should follow general conventions for Java (see Oracle Naming Conventions, Google Java Style, etc.).We consider this as common sense and provide configurations for SonarQube and related tools such as Checkstyle instead of repeating this here.\n"},{"id":63,"path":"../website/pages/docs/devon4j.asciidoc_coding-conventions.html#coding-conventions.asciidoc_naming","type":"docs","title":"Naming","body":"9.1. Naming\nBesides general Java naming conventions, we follow the additional rules listed here explicitly:\nAlways use short but speaking names (for types, methods, fields, parameters, variables, constants, etc.).\nStrictly avoid special characters in technical names (for files, types, fields, methods, properties, variables, database tables, columns, constraints, etc.). In other words only use Latin alpahnumeric ASCII characters with the common allowed technical separators for the accordign context (e.g. underscore) for technical names (even excluding whitespaces).\nFor package segments and type names prefer singular forms (CustomerEntity instead of CustomersEntity). Only use plural forms when there is no singular or it is really semantically required (e.g. for a container that contains multiple of such objects).\nAvoid having duplicate type names. The name of a class, interface, enum or annotation should be unique within your project unless this is intentionally desired in a special and reasonable situation.\nAvoid artificial naming constructs such as prefixes (I*) or suffixes (*IF) for interfaces.\nUse CamelCase even for abbreviations (XmlUtil instead of XMLUtil)\nAvoid property/field names where the second character is upper-case at all (e.g. &apos;aBc&apos;). See #1095 for details.\nNames of Generics should be easy to understand. Where suitable follow the common rule E=Element, T=Type, K=Key, V=Value but feel free to use longer names for more specific cases such as ID, DTO or ENTITY. The capitalized naming helps to distinguish a generic type from a regular class.\n"},{"id":64,"path":"../website/pages/docs/devon4j.asciidoc_coding-conventions.html#coding-conventions.asciidoc_packages","type":"docs","title":"Packages","body":"9.2. Packages\nJava Packages are the most important element to structure your code. We use a strict packaging convention to map technical layers and business components (slices) to the code (See technical architecture for further details). By using the same names in documentation and code we create a strong link that gives orientation and makes it easy to find from business requirements, specifications or story tickets into the code and back.\nFor an devon4j based application we use the following Java-Package schema:\n&#xAB;rootpackage&#xBB;.&#xAB;application&#xBB;.&#xAB;component&#xBB;.&#xAB;layer&#xBB;.&#xAB;scope&#xBB;[.&#xAB;detail&#xBB;]*\nE.g. in our example application we find the Spring Data repositories for the ordermanagement component in the package com.devonfw.application.mtsj.ordermanagement.dataaccess.api.repo\nTable 28. Segments of package schema\nSegment\nDescription\nExample\n&#xAB;rootpackage&#xBB;\nIs the basic Java Package name-space of the organization or IT project owning the code following common Java Package conventions. Consists of multiple segments corresponding to the Internet domain of the organization.\ncom.devonfw.application.mtsj\n&#xAB;application&#xBB;\nThe name of the application build in this project.\ndevonfw\n&#xAB;component&#xBB;\nThe (business) component the code belongs to. It is defined by the business architecture and uses terms from the business domain. Use the implicit component general for code not belonging to a specific component (foundation code).\nsalesmanagement\n&#xAB;layer&#xBB;\nThe name of the technical layer (See technical architecture) which is one of the predefined layers (dataaccess, logic, service, batch, gui, client) or common for code not assigned to a technical layer (datatypes, cross-cutting concerns).\ndataaccess\n&#xAB;scope&#xBB;\nThe scope which is one of api (official API to be used by other layers or components),base (basic code to be reused by other implementations) and impl (implementation that should never be imported from outside)\napi\n&#xAB;detail&#xBB;\nHere you are free to further divide your code into sub-components and other concerns according to the size of your component part.\ndao\nPlease note that for library modules where we use com.devonfw.module as &#xAB;basepackage&#xBB; and the name of the module as &#xAB;component&#xBB;. E.g. the API of our beanmapping module can be found in the package com.devonfw.module.beanmapping.common.api.\n"},{"id":65,"path":"../website/pages/docs/devon4j.asciidoc_coding-conventions.html#coding-conventions.asciidoc_architecture-mapping","type":"docs","title":"Architecture Mapping","body":"9.3. Architecture Mapping\nWe combine the above naming and packaging conventions to map the entire architecture to the code.\nThis also allows tools such as CobiGen or sonar-devon4j-plugin to &quot;understand&quot; the code.\nAlso this helps developers going from one devon4j project to the next one to quickly understand the code-base.\nIf every developer knows where to find what, the project gets more efficient.\nA long time ago maven standardized the project structure with src/main/java, etc. and turned chaos into structure.\nWith devonfw we experienced the same for the codebase (what is inside src/main/java).\nListing 6. Architecture mapped to code\n&#xAB;rootpackage&#xBB;.&#xAB;application&#xBB;\n&#x251C;&#x2500;&#x2500;.&#xAB;component&#xBB;\n| &#x251C;&#x2500;&#x2500;.common\n| | &#x251C;&#x2500;&#x2500;.api[.&#xAB;detail&#xBB;]\n| | | &#x251C;&#x2500;&#x2500;.datatype\n| | | | &#x2514;&#x2500;&#x2500;.&#xAB;Datatype&#xBB; (api)\n| | | &#x2514;&#x2500;&#x2500;.&#xAB;BusinessObject&#xBB; (api)\n| | &#x2514;&#x2500;&#x2500;.impl[.&#xAB;detail&#xBB;]\n| | &#x251C;&#x2500;&#x2500;.&#xAB;Aspect&#xBB;ConfigProperties (core)\n| | &#x251C;&#x2500;&#x2500;.&#xAB;Datatype&#xBB;JsonSerializer (core)\n| | &#x2514;&#x2500;&#x2500;.&#xAB;Datatype&#xBB;JsonDeserializer (core)\n| &#x251C;&#x2500;&#x2500;.dataaccess\n| | &#x251C;&#x2500;&#x2500;.api[.&#xAB;detail&#xBB;]\n| | | &#x251C;&#x2500;&#x2500;.repo\n| | | | &#x2514;&#x2500;&#x2500;.&#xAB;BusinessObject&#xBB;Repository (core)\n| | | &#x251C;&#x2500;&#x2500;.dao (core) [alternative to repo]\n| | | | &#x2514;&#x2500;&#x2500;.&#xAB;BusinessObject&#xBB;Dao (core) [alternative to Repository]\n| | | &#x2514;&#x2500;&#x2500;.&#xAB;BusinessObject&#xBB;Entity (core)\n| | &#x2514;&#x2500;&#x2500;.impl[.&#xAB;detail&#xBB;]\n| | &#x251C;&#x2500;&#x2500;.dao (core) [alternative to repo]\n| | | &#x2514;&#x2500;&#x2500;.&#xAB;BusinessObject&#xBB;DaoImpl (core) [alternative to Repository]\n| | &#x2514;&#x2500;&#x2500;.&#xAB;Datatype&#xBB;AttributeConverter (core)\n| &#x251C;&#x2500;&#x2500;.logic\n| | &#x251C;&#x2500;&#x2500;.api\n| | | &#x251C;&#x2500;&#x2500;.[&#xAB;detail&#xBB;.]to\n| | | | &#x251C;&#x2500;&#x2500;.&#xAB;MyCustom&#xBB;&#xAB;To (api)\n| | | | &#x251C;&#x2500;&#x2500;.&#xAB;DataStructure&#xBB;Embeddable (api)\n| | | | &#x251C;&#x2500;&#x2500;.&#xAB;BusinessObject&#xBB;Eto (api)\n| | | | &#x2514;&#x2500;&#x2500;.&#xAB;BusinessObject&#xBB;&#xAB;Subset&#xBB;Cto (api)\n| | | &#x251C;&#x2500;&#x2500;.[&#xAB;detail&#xBB;.]usecase\n| | | | &#x251C;&#x2500;&#x2500;.UcFind&#xAB;BusinessObject&#xBB; (core)\n| | | | &#x251C;&#x2500;&#x2500;.UcManage&#xAB;BusinessObject&#xBB; (core)\n| | | | &#x2514;&#x2500;&#x2500;.Uc&#xAB;Operation&#xBB;&#xAB;BusinessObject&#xBB; (core)\n| | | &#x2514;&#x2500;&#x2500;.&#xAB;Component&#xBB; (core)\n| | &#x251C;&#x2500;&#x2500;.base\n| | | &#x2514;&#x2500;&#x2500;.[&#xAB;detail&#xBB;.]usecase\n| | | &#x2514;&#x2500;&#x2500;.Abstract&#xAB;BusinessObject&#xBB;Uc (core)\n| | &#x2514;&#x2500;&#x2500;.impl\n| | &#x251C;&#x2500;&#x2500;.[&#xAB;detail&#xBB;.]usecase\n| | | &#x251C;&#x2500;&#x2500;.UcFind&#xAB;BusinessObject&#xBB;Impl (core)\n| | | &#x251C;&#x2500;&#x2500;.UcManage&#xAB;BusinessObject&#xBB;Impl (core)\n| | | &#x2514;&#x2500;&#x2500;.Uc&#xAB;Operation&#xBB;&#xAB;BusinessObject&#xBB;Impl (core)\n| | &#x2514;&#x2500;&#x2500;.&#xAB;Component&#xBB;Impl (core)\n| &#x2514;&#x2500;&#x2500;.service\n| &#x251C;&#x2500;&#x2500;.api[.&#xAB;detail&#xBB;]\n| | &#x251C;&#x2500;&#x2500;.rest\n| | | &#x2514;&#x2500;&#x2500;.&#xAB;Component&#xBB;RestService (api)\n| | &#x2514;&#x2500;&#x2500;.ws\n| | &#x2514;&#x2500;&#x2500;.&#xAB;Component&#xBB;WebService (api)\n| &#x2514;&#x2500;&#x2500;.impl[.&#xAB;detail&#xBB;]\n| &#x251C;&#x2500;&#x2500;.jms\n| | &#x2514;&#x2500;&#x2500;.&#xAB;BusinessObject&#xBB;JmsListener (core)\n| &#x251C;&#x2500;&#x2500;.rest\n| | &#x2514;&#x2500;&#x2500;.&#xAB;Component&#xBB;RestServiceImpl (core)\n| &#x2514;&#x2500;&#x2500;.ws\n| &#x2514;&#x2500;&#x2500;.&#xAB;Component&#xBB;WebServiceImpl (core)\n&#x251C;&#x2500;&#x2500;.general\n&#x2502; &#x251C;&#x2500;&#x2500;.common\n&#x2502; | &#x251C;&#x2500;&#x2500;.api\n| | | &#x251C;&#x2500;&#x2500;.to\n| | | | &#x251C;&#x2500;&#x2500;.AbstractSearchCriteriaTo (api)\n| | | &#x2514;&#x2500;&#x2500;.ApplicationEntity\n&#x2502; | &#x251C;&#x2500;&#x2500;.base\n| | | &#x2514;&#x2500;&#x2500;.AbstractBeanMapperSupport (core)\n&#x2502; | &#x2514;&#x2500;&#x2500;.impl\n&#x2502; | &#x251C;&#x2500;&#x2500;.config\n&#x2502; | | &#x2514;&#x2500;&#x2500;.ApplicationObjectMapperFactory (core)\n&#x2502; | &#x2514;&#x2500;&#x2500;.security\n&#x2502; | &#x2514;&#x2500;&#x2500;.ApplicationWebSecurityConfig (core)\n&#x2502; &#x251C;&#x2500;&#x2500;.dataaccess\n&#x2502; | &#x2514;&#x2500;&#x2500;.api\n| | &#x2514;&#x2500;&#x2500;.ApplicationPersistenceEntity (core)\n&#x2502; &#x251C;&#x2500;&#x2500;.logic\n&#x2502; | &#x2514;&#x2500;&#x2500;.base\n| | &#x251C;&#x2500;&#x2500;.AbstractComponentFacade (core)\n| | &#x251C;&#x2500;&#x2500;.AbstractLogic (core)\n| | &#x2514;&#x2500;&#x2500;.AbstractUc (core)\n| &#x2514;&#x2500;&#x2500;.service\n| &#x2514;&#x2500;&#x2500;...\n&#x2514;&#x2500;&#x2500;.SpringBootApp (core)\n"},{"id":66,"path":"../website/pages/docs/devon4j.asciidoc_coding-conventions.html#coding-conventions.asciidoc_code-tasks","type":"docs","title":"Code Tasks","body":"9.4. Code Tasks\nCode spots that need some rework can be marked with the following tasks tags. These are already properly pre-configured in your development environment for auto completion and to view tasks you are responsible for. It is important to keep the number of code tasks low. Therefore, every member of the team should be responsible for the overall code quality. So if you change a piece of code and hit a code task that you can resolve in a reliable way, please do this as part of your change and remove the according tag.\n"},{"id":67,"path":"../website/pages/docs/devon4j.asciidoc_coding-conventions.html#coding-conventions.asciidoc_todo","type":"docs","title":"TODO","body":"9.4.1. TODO\nUsed to mark a piece of code that is not yet complete (typically because it can not be completed due to a dependency on something that is not ready).\n// TODO &#xAB;author&#xBB; &#xAB;description&#xBB;\nA TODO tag is added by the author of the code who is also responsible for completing this task.\n"},{"id":68,"path":"../website/pages/docs/devon4j.asciidoc_coding-conventions.html#coding-conventions.asciidoc_fixme","type":"docs","title":"FIXME","body":"9.4.2. FIXME\n// FIXME &#xAB;author&#xBB; &#xAB;description&#xBB;\nA FIXME tag is added by the author of the code or someone who found a bug he can not fix right now. The &#xAB;author&#xBB; who added the FIXME is also responsible for completing this task. This is very similar to a TODO but with a higher priority. FIXME tags indicate problems that should be resolved before a release is completed while TODO tags might have to stay for a longer time.\n"},{"id":69,"path":"../website/pages/docs/devon4j.asciidoc_coding-conventions.html#coding-conventions.asciidoc_review","type":"docs","title":"REVIEW","body":"9.4.3. REVIEW\n// REVIEW &#xAB;responsible&#xBB; (&#xAB;reviewer&#xBB;) &#xAB;description&#xBB;\nA REVIEW tag is added by a reviewer during a code review. Here the original author of the code is responsible to resolve the REVIEW tag and the reviewer is assigning this task to him. This is important for feedback and learning and has to be aligned with a review &quot;process&quot; where people talk to each other and get into discussion. In smaller or local teams a peer-review is preferable but this does not scale for large or even distributed teams.\n"},{"id":70,"path":"../website/pages/docs/devon4j.asciidoc_coding-conventions.html#coding-conventions.asciidoc_code-documentation","type":"docs","title":"Code-Documentation","body":"9.5. Code-Documentation\nAs a general goal, the code should be easy to read and understand. Besides, clear naming the documentation is important. We follow these rules:\nAPIs (especially component interfaces) are properly documented with JavaDoc.\nJavaDoc shall provide actual value - we do not write JavaDoc to satisfy tools such as checkstyle but to express information not already available in the signature.\nWe make use of {@link} tags in JavaDoc to make it more expressive.\nJavaDoc of APIs describes how to use the type or method and not how the implementation internally works.\nTo document implementation details, we use code comments (e.g. // we have to flush explicitly to ensure version is up-to-date). This is only needed for complex logic.\nAvoid the pointless {@inheritDoc} as since Java 1.5 there is the @Override annotation for overridden methods and your JavaDoc is inherited automatically even without any JavaDoc comment at all.\n"},{"id":71,"path":"../website/pages/docs/devon4j.asciidoc_coding-conventions.html#coding-conventions.asciidoc_code-style","type":"docs","title":"Code-Style","body":"9.6. Code-Style\nThis section gives you best practices to write better code and avoid pitfalls and mistakes.\n"},{"id":72,"path":"../website/pages/docs/devon4j.asciidoc_coding-conventions.html#coding-conventions.asciidoc_blobs","type":"docs","title":"BLOBs","body":"9.6.1. BLOBs\nAvoid using byte[] for BLOBs as this will load them entirely into your memory. This will cause performance issues or out of memory errors. Instead, use streams when dealing with BLOBs. For further details see BLOB support.\n"},{"id":73,"path":"../website/pages/docs/devon4j.asciidoc_coding-conventions.html#coding-conventions.asciidoc_closing-resources","type":"docs","title":"Closing Resources","body":"9.6.2. Closing Resources\nResources such as streams (InputStream, OutputStream, Reader, Writer) or transactions need to be handled properly. Therefore, it is important to follow these rules:\nEach resource has to be closed properly, otherwise you will get out of file handles, TX sessions, memory leaks or the like\nWhere possible avoid to deal with such resources manually. That is why we are recommending @Transactional for transactions in devonfw (see Transaction Handling).\nIn case you have to deal with resources manually (e.g. binary streams) ensure to close them properly. See the example below for details.\nClosing streams and other such resources is error prone. Have a look at the following example:\n// bad\ntry {\nInputStream in = new FileInputStream(file);\nreadData(in);\nin.close();\n} catch (IOException e) {\nthrow new IllegalStateException(&quot;Failed to read data.&quot;, e);\n}\nThe code above is wrong as in case of an IOException the InputStream is not properly closed. In a server application such mistakes can cause severe errors that typically will only occur in production. As such resources implement the AutoCloseable interface you can use the try-with-resource syntax to write correct code. The following code shows a correct version of the example:\n// fine\ntry (InputStream in = new FileInputStream(file)) {\nreadData(in);\n} catch (IOException e) {\nthrow new IllegalStateException(&quot;Failed to read data.&quot;, e);\n}\n"},{"id":74,"path":"../website/pages/docs/devon4j.asciidoc_coding-conventions.html#coding-conventions.asciidoc_catching-and-handling-exceptions","type":"docs","title":"Catching and handling Exceptions","body":"9.6.3. Catching and handling Exceptions\nWhen catching exceptions always ensure the following:\nNever call printStackTrace() method on an exception\nEither log or wrap and re-throw the entire catched exception. Be aware that the cause(s) of an exception is very valuable information. If you loose such information by improper exception-handling you may be unable to properly analyse production problems what can cause severe issues.\nIf you wrap and re-throw an exception ensure that the catched exception is passed as cause to the newly created and thrown exception.\nIf you log an exception ensure that the entire exception is passed as argument to the logger (and not only the result of getMessage() or toString() on the exception).\nSee exception handling\n"},{"id":75,"path":"../website/pages/docs/devon4j.asciidoc_coding-conventions.html#coding-conventions.asciidoc_lambdas-and-streams","type":"docs","title":"Lambdas and Streams","body":"9.6.4. Lambdas and Streams\nWith Java8 you have cool new features like lambdas and monads like (Stream, CompletableFuture, Optional, etc.).\nHowever, these new features can also be misused or led to code that is hard to read or debug. To avoid pain, we give you the following best practices:\nLearn how to use the new features properly before using. Developers are often keen on using cool new features. When you do your first experiments in your project code you will cause deep pain and might be ashamed afterwards. Please study the features properly. Even Java8 experts still write for loops to iterate over collections, so only use these features where it really makes sense.\nStreams shall only be used in fluent API calls as a Stream can not be forked or reused.\nEach stream has to have exactly one terminal operation.\nDo not write multiple statements into lambda code:\n// bad\ncollection.stream().map(x -&gt; {\nFoo foo = doSomething(x);\n...\nreturn foo;\n}).collect(Collectors.toList());\nThis style makes the code hard to read and debug. Never do that! Instead, extract the lambda body to a private method with a meaningful name:\n// fine\ncollection.stream().map(this::convertToFoo).collect(Collectors.toList());\nDo not use parallelStream() in general code (that will run on server side) unless you know exactly what you are doing and what is going on under the hood. Some developers might think that using parallel streams is a good idea as it will make the code faster. However, if you want to do performance optimizations talk to your technical lead (architect). Many features such as security and transactions will rely on contextual information that is associated with the current thread. Hence, using parallel streams will most probably cause serious bugs. Only use them for standalone (CLI) applications or for code that is just processing large amounts of data.\nDo not perform operations on a sub-stream inside a lambda:\nset.stream().flatMap(x -&gt; x.getChildren().stream().filter(this::isSpecial)).collect(Collectors.toList()); // bad\nset.stream().flatMap(x -&gt; x.getChildren().stream()).filter(this::isSpecial).collect(Collectors.toList()); // fine\nOnly use collect at the end of the stream:\nset.stream().collect(Collectors.toList()).forEach(...) // bad\nset.stream().peek(...).collect(Collectors.toList()) // fine\nLambda parameters with Types inference\n(String a, Float b, Byte[] c) -&gt; a.toString() + Float.toString(b) + Arrays.toString(c) // bad\n(a,b,c) -&gt; a.toString() + Float.toString(b) + Arrays.toString(c) // fine\nCollections.sort(personList, (Person p1, Person p2) -&gt; p1.getSurName().compareTo(p2.getSurName())); // bad\nCollections.sort(personList, (p1, p2) -&gt; p1.getSurName().compareTo(p2.getSurName())); // fine\nAvoid Return Braces and Statement\na -&gt; { return a.toString(); } // bad\na -&gt; a.toString(); // fine\nAvoid Parentheses with Single Parameter\n(a) -&gt; a.toString(); // bad\na -&gt; a.toString(); // fine\nAvoid if/else inside foreach method. Use Filter method &amp; comprehension\n// bad\nstatic public Iterator&lt;String&gt; TwitterHandles(Iterator&lt;Author&gt; authors, string company) {\nfinal List result = new ArrayList&lt;String&gt; ();\nforeach (Author a : authors) {\nif (a.Company.equals(company)) {\nString handle = a.TwitterHandle;\nif (handle != null)\nresult.Add(handle);\n}\n}\nreturn result;\n}\n// fine\npublic List&lt;String&gt; twitterHandles(List&lt;Author&gt; authors, String company) {\nreturn authors.stream()\n.filter(a -&gt; null != a &amp;&amp; a.getCompany().equals(company))\n.map(a -&gt; a.getTwitterHandle())\n.collect(toList());\n}\n"},{"id":76,"path":"../website/pages/docs/devon4j.asciidoc_coding-conventions.html#coding-conventions.asciidoc_optionals","type":"docs","title":"Optionals","body":"9.6.5. Optionals\nWith Optional you can wrap values to avoid a NullPointerException (NPE). However, it is not a good code-style to use Optional for every parameter or result to express that it may be null. For such case use @Nullable or even better instead annotate @NotNull where null is not acceptable.\nHowever, Optional can be used to prevent NPEs in fluent calls (due to the lack of the elvis operator):\nLong id;\nid = fooCto.getBar().getBar().getId(); // may cause NPE\nid = Optional.ofNullable(fooCto).map(FooCto::getBar).map(BarCto::getBar).map(BarEto::getId).orElse(null); // null-safe\n"},{"id":77,"path":"../website/pages/docs/devon4j.asciidoc_coding-conventions.html#coding-conventions.asciidoc_encoding","type":"docs","title":"Encoding","body":"9.6.6. Encoding\nEncoding (esp. Unicode with combining characters and surrogates) is a complex topic. Please study this topic if you have to deal with encodings and processing of special characters. For the basics follow these recommendations:\nWhen you have explicitly decided for an encoding always prefer Unicode (UTF-8 or better). This especially impacts your databases and has to be defined upfront as it typically can not be changed (easily) afterwards.\nDo not cast from byte to char (Unicode characters can be composed of multiple bytes, such cast may only work for ASCII characters)\nNever convert the case of a String using the default locale (esp. when writing generic code like in devonfw). E.g. if you do &quot;HI&quot;.toLowerCase() and your system locale is Turkish, then the output will be &quot;h&#x131;&quot; instead of &quot;hi&quot;, which can lead to wrong assumptions and serious problems. If you want to do a &quot;universal&quot; case conversion always use explicitly an according western locale (e.g. toLowerCase(Locale.US)). Consider using a library (https://github.com/m-m-m/util/blob/master/core/src/main/java/net/sf/mmm/util/lang/api/BasicHelper.java) or create your own little static utility for that in your project.\nWrite your code independent from the default encoding (system property file.encoding) - this will most likely differ in JUnit from production environment\nAlways provide an encoding when you create a String from byte[]: new String(bytes, encoding)\nAlways provide an encoding when you create a Reader or Writer : new InputStreamReader(inStream, encoding)\n"},{"id":78,"path":"../website/pages/docs/devon4j.asciidoc_coding-conventions.html#coding-conventions.asciidoc_prefer-general-api","type":"docs","title":"Prefer general API","body":"9.6.7. Prefer general API\nAvoid unnecessary strong bindings:\nDo not bind your code to implementations such as Vector or ArrayList instead of List\nIn APIs for input (=parameters) always consider to make little assumptions:\nprefer Collection over List or Set where the difference does not matter (e.g. only use Set when you require uniqueness or highly efficient contains)\nconsider preferring Collection&lt;? extends Foo&gt; over Collection&lt;Foo&gt; when Foo is an interface or super-class\n"},{"id":79,"path":"../website/pages/docs/devon4j.asciidoc_coding-conventions.html#coding-conventions.asciidoc_prefer-primitive-boolean","type":"docs","title":"Prefer primitive boolean","body":"9.6.8. Prefer primitive boolean\nUnless in rare cases where you need to allow a flag being null avoid using the object type Boolean.\n// bad\npublic Boolean isEmpty {\nreturn size() == 0;\n}\nInstead always use the primitive boolean type:\n// fine\npublic boolean isEmpty {\nreturn size() == 0;\n}\nThe only known excuse is for flags in embeddable types due to limitations of hibernate.\n&#x2190;&#xA0;Previous:&#xA0;Architecture&#xA0;| &#x2191;&#xA0;Up:&#xA0;devonfw for Java (devon4j)&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Project structure&#xA0;&#x2192;\n"},{"id":80,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#devon4j.asciidoc_guides","type":"docs","title":"Guides","body":"12. Guides\n"},{"id":81,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-dependency-injection.asciidoc","type":"docs","title":"Dependency Injection","body":"12.1. Dependency Injection\nDependency injection is one of the most important design patterns and is a key principle to a modular and component based architecture. The Java Standard for dependency injection is javax.inject (JSR330) that we use in combination with JSR250.\nThere are many frameworks which support this standard including all recent Java EE application servers. We recommend to use Spring (also known as springframework) that we use in our example application. However, the modules we provide typically just rely on JSR330 and can be used with any compliant container.\n"},{"id":82,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-dependency-injection.asciidoc_key-principles","type":"docs","title":"Key Principles","body":"12.1.1. Key Principles\nA Bean in CDI (Contexts and Dependency-Injection) or Spring is typically part of a larger component and encapsulates some piece of logic that should in general be replaceable. As an example we can think of a Use-Case, Data-Access-Object (DAO), etc. As best practice we use the following principles:\nSeparation of API and implementation\nWe create a self-contained API documented with JavaDoc. Then we create an implementation of this API that we annotate with @Named. This implementation is treated as secret. Code from other components that wants to use the implementation shall only rely on the API. Therefore we use dependency injection via the interface with the @Inject annotation.\nStateless implementation\nBy default implementations (CDI-Beans) shall always be stateless. If you store state information in member variables you can easily run into concurrency problems and nasty bugs. This is easy to avoid by using local variables and separate state classes for complex state-information. Try to avoid stateful CDI-Beans wherever possible. Only add state if you are fully aware of what you are doing and properly document this as a warning in your JavaDoc.\nUsage of JSR330\nWe use javax.inject (JSR330) and JSR250 as a common standard that makes our code portable (works in any modern Java EE environment). However, we recommend to use the springframework as container. But we never use proprietary annotations such as @Autowired instead of standardized annotations like @Inject. Generally we avoid proprietary annotations in business code (common and logic layer).\nSimple Injection-Style\nIn general you can choose between constructor, setter or field injection. For simplicity we recommend to do private field injection as it is very compact and easy to maintain. We believe that constructor injection is bad for maintenance especially in case of inheritance (if you change the dependencies you need to refactor all sub-classes). Private field injection and public setter injection are very similar but setter injection is much more verbose (often you are even forced to have javadoc for all public methods). If you are writing re-usable library code setter injection will make sense as it is more flexible. In a business application you typically do not need that and can save a lot of boiler-plate code if you use private field injection instead. Nowadays you are using container infrastructure also for your tests (see spring integration tests) so there is no need to inject manually (what would require a public setter).\nKISS\nTo follow the KISS (keep it small and simple) principle we avoid advanced features (e.g. AOP, non-singleton beans) and only use them where necessary.\n"},{"id":83,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-dependency-injection.asciidoc_example-bean","type":"docs","title":"Example Bean","body":"12.1.2. Example Bean\nHere you can see the implementation of an example bean using JSR330 and JSR250:\n@Named\npublic class MyBeanImpl implements MyBean {\n@Inject\nprivate MyOtherBean myOtherBean;\n@PostConstruct\npublic void init() {\n// initialization if required (otherwise omit this method)\n}\n@PreDestroy\npublic void dispose() {\n// shutdown bean, free resources if required (otherwise omit this method)\n}\n}\nIt depends on MyOtherBean that should be the interface of an other component that is injected into the field because of the @Inject annotation. To make this work there must be exactly one implementation of MyOtherBean in the container (in our case spring). In order to put a Bean into the container we use the @Named annotation so in our example we put MyBeanImpl into the container. Therefore it can be injected into all setters that take the interface MyBean as argument and are annotated with @Inject.\nIn some situations you may have an Interface that defines a kind of &quot;plugin&quot; where you can have multiple implementations in your container and want to have all of them. Then you can request a list with all instances of that interface as in the following example:\n@Inject\nprivate List&lt;MyConverter&gt; converters;\nPlease note that when writing library code instead of annotating implementation with @Named it is better to provide @Configuration classes that choose the implementation via @Bean methods (see @Bean documentation). This way you can better &quot;export&quot; specific features instead of relying library users to do a component-scan to your library code and loose control on upgrades.\n"},{"id":84,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-dependency-injection.asciidoc_bean-configuration","type":"docs","title":"Bean configuration","body":"12.1.3. Bean configuration\nWiring and Bean configuration can be found in configuration guide.\n"},{"id":85,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-configuration.asciidoc","type":"docs","title":"Configuration","body":"12.2. Configuration\nAn application needs to be configurable in order to allow internal setup (like CDI) but also to allow externalized configuration of a deployed package (e.g. integration into runtime environment). Using Spring Boot (must read: Spring Boot reference) we rely on a comprehensive configuration approach following a &quot;convention over configuration&quot; pattern. This guide adds on to this by detailed instructions and best-practices how to deal with configurations.\nIn general we distinguish the following kinds of configuration that are explained in the following sections:\nInternal Application configuration maintained by developers\nExternalized Environment configuration maintained by operators\nExternalized Business configuration maintained by business administrators\n"},{"id":86,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-configuration.asciidoc_internal-application-configuration","type":"docs","title":"Internal Application Configuration","body":"12.2.1. Internal Application Configuration\nThe application configuration contains all internal settings and wirings of the application (bean wiring, database mappings, etc.) and is maintained by the application developers at development time. There usually is a main configuration registered with main Spring Boot App, but differing configurations to support automated test of the application can be defined using profiles (not detailed in this guide).\nSpring Boot Application\nThe devonfw recommends using spring-boot to build web applications.\nFor a complete documentation see the Spring Boot Reference Guide.\nWith spring-boot you provide a simple main class (also called starter class) like this:\ncom.devonfw.mtsj.application\n@SpringBootApplication(exclude = { EndpointAutoConfiguration.class })\n@EntityScan(basePackages = { &quot;com.devonfw.mtsj.application&quot; }, basePackageClasses = { AdvancedRevisionEntity.class })\n@EnableGlobalMethodSecurity(jsr250Enabled = true)\n@ComponentScan(basePackages = { &quot;com.devonfw.mtsj.application.general&quot;, &quot;com.devonfw.mtsj.application&quot; })\npublic class SpringBootApp {\n/**\n* Entry point for spring-boot based app\n*\n* @param args - arguments\n*/\npublic static void main(String[] args) {\nSpringApplication.run(SpringBootApp.class, args);\n}\n}\nIn an devonfw application this main class is always located in the &lt;basepackage&gt; of the application package namespace (see package-conventions). This is because a spring boot application will automatically do a classpath scan for components (spring-beans) and entities in the package where the application main class is located including all sub-packages. You can use the @ComponentScan and @EntityScan annotations to customize this behaviour.\nIf you want to map spring configuration properties into your custom code please see configuration mapping.\nStandard beans configuration\nFor basic bean configuration we rely on spring boot using mainly configuration classes and only occasionally XML configuration files. Some key principle to understand Spring Boot auto-configuration features:\nSpring Boot auto-configuration attempts to automatically configure your Spring application based on the jar dependencies and annotated components found in your source code.\nAuto-configuration is non-invasive, at any point you can start to define your own configuration to replace specific parts of the auto-configuration by redefining your identically named bean (see also exclude attribute of @SpringBootApplication in example code above).\nBeans are configured via annotations in your java code (see dependency-injection).\nFor technical configuration you will typically write additional spring config classes annotated with @Configuration that provide bean implementations via methods annotated with @Bean. See spring @Bean documentation for further details. Like in XML you can also use @Import to make a @Configuration class include other configurations.\nMore specific configuration files (as required) reside in an adequately named subfolder of:\nsrc/main/resources/app\nBeanMapper Configuration\nIn case you are still using dozer, you will find further details in bean-mapper configuration.\nSecurity configuration\nThe abstract base class BaseWebSecurityConfig should be extended to configure web application security thoroughly.\nA basic and secure configuration is provided which can be overridden or extended by subclasses.\nSubclasses must use the @Profile annotation to further discriminate between beans used in production and testing scenarios. See the following example:\nListing 7. How to extend BaseWebSecurityConfig for Production and Test\n@Configuration\n@EnableWebSecurity\n@Profile(SpringProfileConstants.JUNIT)\npublic class TestWebSecurityConfig extends BaseWebSecurityConfig {...}\n@Configuration\n@EnableWebSecurity\n@Profile(SpringProfileConstants.NOT_JUNIT)\npublic class WebSecurityConfig extends BaseWebSecurityConfig {...}\nSee WebSecurityConfig.\nWebSocket configuration\nA websocket endpoint is configured within the business package as a Spring configuration class. The annotation @EnableWebSocketMessageBroker makes Spring Boot registering this endpoint.\npackage your.path.to.the.websocket.config;\n...\n@Configuration\n@EnableWebSocketMessageBroker\npublic class WebSocketConfig extends AbstractWebSocketMessageBrokerConfigurer {\n...\nDatabase Configuration\nTo choose database of your choice , set spring.profiles.active=XXX in src/main/resources/config/application.properties. Also, one has to set all the active spring profiles in this application.properties and not in any of the other application.properties.\n"},{"id":87,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-configuration.asciidoc_externalized-configuration","type":"docs","title":"Externalized Configuration","body":"12.2.2. Externalized Configuration\nExternalized configuration is a configuration that is provided separately to a deployment package and can be maintained undisturbed by re-deployments.\nEnvironment Configuration\nThe environment configuration contains configuration parameters (typically port numbers, host names, passwords, logins, timeouts, certificates, etc.) specific for the different environments. These are under the control of the operators responsible for the application.\nThe environment configuration is maintained in application.properties files, defining various properties (see common application properties for a list of properties defined by the spring framework).\nThese properties are explained in the corresponding configuration sections of the guides for each topic:\npersistence configuration\nservice configuration\nlogging guide\nFor a general understanding how spring-boot is loading and boostrapping your application.properties see spring-boot external configuration.\nThe following properties files are used in every devonfw application:\nsrc/main/resources/application.properties providing a default configuration - bundled and deployed with the application package. It further acts as a template to derive a tailored minimal environment-specific configuration.\nsrc/main/resources/config/application.properties providing additional properties only used at development time (for all local deployment scenarios). This property file is excluded from all packaging.\nsrc/test/resources/config/application.properties providing additional properties only used for testing (JUnits based on spring test).\nFor other environments where the software gets deployed such as test, acceptance and production you need to provide a tailored copy of application.properties. The location depends on the deployment strategy:\nstandalone run-able Spring Boot App using embedded tomcat: config/application.properties under the installation directory of the spring boot application.\ndedicated tomcat (one tomcat per app): $CATALINA_BASE/lib/config/application.properties\ntomcat serving a number of apps (requires expanding the wars): $CATALINA_BASE/webapps/&lt;app&gt;/WEB-INF/classes/config\nIn this application.properties you only define the minimum properties that are environment specific and inherit everything else from the bundled src/main/resources/application.properties. In any case, make very sure that the classloader will find the file.\nMake sure your properties are thoroughly documented by providing a comment to each property. This inline documentation is most valuable for your operating department.\nBusiness Configuration\nOften applications do not need business configuration. In case they do it should typically be editable by administrators via the GUI. The business configuration values should therefore be stored in the database in key/value pairs.\nTherefore we suggest to create a dedicated table with (at least) the following columns:\nID\nProperty name\nProperty type (Boolean, Integer, String)\nProperty value\nDescription\nAccording to the entries in this table, an administrative GUI may show a generic form to modify business configuration. Boolean values should be shown as checkboxes, integer and string values as text fields. The values should be validated according to their type so an error is raised if you try to save a string in an integer property for example.\nWe recommend the following base layout for the hierarchical business configuration:\ncomponent.[subcomponent].[subcomponent].propertyname\n"},{"id":88,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-configuration.asciidoc_security","type":"docs","title":"Security","body":"12.2.3. Security\nOften you need to have passwords (for databases, third-party services, etc.) as part of your configuration. These are typically environment specific (see above). However, with DevOps and continuous-deployment you might be tempted to commit such configurations into your version-control (e.g. git). Doing that with plain text passwords is a severe problem especially for production systems. Never do that! Instead we offer some suggestions how to deal with sensible configurations:\nPassword Encryption\nA simple but reasonable approach is to configure the passwords encrypted with a master-password. The master-password should be a strong secret that is specific for each environment. It must never be committed to version-control.\nIn order to support encrypted passwords in spring-boot application.properties all you need to do is to add jasypt-spring-boot as dependency in your pom.xml (please check for recent version here):\n&lt;dependency&gt;\n&lt;groupId&gt;com.github.ulisesbocchio&lt;/groupId&gt;\n&lt;artifactId&gt;jasypt-spring-boot-starter&lt;/artifactId&gt;\n&lt;version&gt;3.0.3&lt;/version&gt;\n&lt;/dependency&gt;\nThis will smoothly integrate jasypt into your spring-boot application. Read this HOWTO to learn how to encrypt and decrypt passwords using jasypt.\nNext, we give a simple example how to encypt and configure a secret value.\nWe use the algorithm PBEWITHHMACSHA512ANDAES_256 that provides strong encryption and is the default of jasypt-spring-boot-starter.\nHowever, different algorithms can be used if perferred (e.g. PBEWITHMD5ANDTRIPLEDES).\njava -cp ${M2_REPO}/org/jasypt/jasypt/1.9.3/jasypt-1.9.3.jar org.jasypt.intf.cli.JasyptPBEStringEncryptionCLI password=masterpassword algorithm=PBEWITHHMACSHA512ANDAES_256 input=secret ivGeneratorClassName=org.jasypt.iv.RandomIvGenerator\n----ENVIRONMENT-----------------\nRuntime: AdoptOpenJDK OpenJDK 64-Bit Server VM 11.0.5+10\n----ARGUMENTS-------------------\ninput: secret\npassword: masterpassword\nivGeneratorClassName: org.jasypt.iv.RandomIvGenerator\nalgorithm: PBEWITHHMACSHA512ANDAES_256\n----OUTPUT----------------------\nPoUxkNjY2juQMCyPu6ic5KJy1XfK+bX9vu2/mPj3pmcO4iydG6mhgZRZSw50z/oC\nOf course the master-password (masterpassword) and the actual password to encrypt (secret) are just examples.\nPlease replace them with reasonable strong passwords for your environment.\nFurther, if you are using devonfw-ide you can make your life much easier and just type:\ndevon jasypt encrypt\nSee jasypt commandlet for details.\nNow the entire line after the OUTPUT block is your encrypted secret.\nIt even contains some random salt so that multiple encryption invocations with the same parameters (ARGUMENTS) will produce a different OUTPUT.\nThe master-password can be configured on your target environment via the property jasypt.encryptor.password. As system properties given on the command-line are visible in the process list, we recommend to use an config/application.yml file only for this purpose (as we recommended to use application.properties for regular configs):\njasypt:\nencryptor:\npassword: masterpassword\nAgain masterpassword is just an example that your replace with your actual master password.\nNow you are able to put encrypted passwords into your application.properties and specify the algorithm.\nspring.datasource.password=ENC(PoUxkNjY2juQMCyPu6ic5KJy1XfK+bX9vu2/mPj3pmcO4iydG6mhgZRZSw50z/oC)\njasypt.encryptor.algorithm=PBEWITHHMACSHA512ANDAES_256\nThis application.properties file can be version controlled (git-opts) and without knowing the masterpassword nobody is able to decrypt this to get the actual secret back.\nTo prevent jasypt to throw an exception in dev or test scenarios you can simply put this in your local config (src/main/config/application.properties and same for test, see above for details):\njasypt.encryptor.password=none\nIs this Security by Obscurity?\nYes, from the point of view to protect the passwords on the target environment this is nothing but security by obscurity. If an attacker somehow got full access to the machine this will only cause him to spend some more time.\nNo, if someone only gets the configuration file. So all your developers might have access to the version-control where the config is stored. Others might have access to the software releases that include this configs. But without the master-password that should only be known to specific operators none else can decrypt the password (except with brute-force what will take a very long time, see jasypt for details).\n"},{"id":89,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-configuration-mapping.asciidoc","type":"docs","title":"Mapping configuration to your code","body":"12.2.4. Mapping configuration to your code\nIf you are using spring-boot as suggested by devon4j your application can be configured by application.properties file as described in configuration.\nTo get a single configuration option into your code for flexibility, you can use\n@Value(&quot;${my.property.name}&quot;)\nprivate String myConfigurableField;\nNow, in your application.properties you can add the property:\nmy.property.name=my-property-value\nYou may even use @Value(&quot;${my.property.name:my-default-value}&quot;) to make the property optional.\nNaming conventions for configuration properties\nAs a best practice your configruation properties should follow these naming conventions:\nbuild the property-name as a path of segments separated by the dot character (.)\nsegments should get more specific from left to right\na property-name should either be a leaf value or a tree node (prefix of other property-names) but never both! So never have something like foo.bar=value and foo.bar.child=value2.\nstart with a segment namespace unique to your context or application\na good example would be &#xAB;myapp&#xBB;.billing.service.email.sender for the sender address of billing service emails send by &#xAB;myapp&#xBB;.\nMapping advanced configuration\nHowever, in many scenarios you will have features that require more than just one property.\nInjecting those via @Value is not leading to good code quality.\nInstead we create a class with the suffix ConfigProperties containing all configuration properties for our aspect that is annotated with @ConfigurationProperties:\n@ConfigurationProperties(prefix = &quot;myapp.billing.service&quot;)\npublic class BillingServiceConfigProperties {\nprivate final Email email = new Email();\nprivate final Smtp smtp = new Smtp();\npublic Email getEmail() { return this.email; }\npublic Email getSmtp() { return this.smtp; }\npublic static class Email {\nprivate String sender;\nprivate String subject;\npublic String getSender() { return this.sender; }\npublic void setSender(String sender) { this.sender = sender; }\npublic String getSubject() { return this.subject; }\npublic void setSubject(String subject) { this.subject = subject; }\n}\npublic static class Smtp {\nprivate String host;\nprivate int port = 25;\npublic String getHost() { return this.host; }\npublic void setHost(String host) { this.host = host; }\npublic int getPort() { return this.port; }\npublic void setPort(int port) { this.port = port; }\n}\n}\nOf course this is just an example to demonstrate this feature of spring-boot.\nIn order to send emails you would typically use the existing spring-email feature.\nBut as you can see this allows us to define and access our configuration in a very structured and comfortable way.\nThe annotation @ConfigurationProperties(prefix = &quot;myapp.billing.service&quot;) will automatically map spring configuration properties starting with myapp.billing.service via the according getters and setters into our BillingServiceConfigProperties.\nWe can easily define defaults (e.g. 25 as default value for myapp.billing.service.smtp.port).\nAlso Email or Smtp could be top-level classes to be reused in multiple configurations.\nOf course you would also add helpful JavaDoc comments to the getters and classes to document your configuration options.\nFurther to access this configuration, we can use standard dependency-injection:\n@Inject\nprivate BillingServiceConfigProperties config;\nFor very generic cases you may also use Map&lt;String, String&gt; to map any kind of property in an untyped way.\nAn example for generic configuration from devon4j can be found in\nServiceConfigProperties.\nFor further details about this feature also consult Guide to @ConfigurationProperties in Spring Boot.\nGenerate configuration metadata\nYou should further add this dependency to your module containing the *ConfigProperties:\n&lt;dependency&gt;\n&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n&lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt;\n&lt;optional&gt;true&lt;/optional&gt;\n&lt;/dependency&gt;\nThis will generate configuration metadata so projects using your code can benefit from autocompletion and getting your JavaDoc as tooltip when editing application.properites what makes this approach very powerful.\nFor further details about this please read A Guide to Spring Boot Configuration Metadata.\n"},{"id":90,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-jpa.asciidoc","type":"docs","title":"Java Persistence API","body":"12.3. Java Persistence API\nFor mapping java objects to a relational database we use the Java Persistence API (JPA).\nAs JPA implementation we recommend to use hibernate. For general documentation about JPA and hibernate follow the links above as we will not replicate the documentation. Here you will only find guidelines and examples how we recommend to use it properly. The following examples show how to map the data of a database to an entity. As we use JPA we abstract from SQL here. However, you will still need a DDL script for your schema and during maintenance also database migrations. Please follow our SQL guide for such artifacts.\n"},{"id":91,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-jpa.asciidoc_entity","type":"docs","title":"Entity","body":"12.3.1. Entity\nEntities are part of the persistence layer and contain the actual data. They are POJOs (Plain Old Java Objects) on which the relational data of a database is mapped and vice versa. The mapping is configured via JPA annotations (javax.persistence). Usually an entity class corresponds to a table of a database and a property to a column of that table. A persistent entity instance then represents a row of the database table.\nA Simple Entity\nThe following listing shows a simple example:\n@Entity\n@Table(name=&quot;TEXTMESSAGE&quot;)\npublic class MessageEntity extends ApplicationPersistenceEntity implements Message {\nprivate String text;\npublic String getText() {\nreturn this.text;\n}\npublic void setText(String text) {\nthis.text = text;\n}\n}\nThe @Entity annotation defines that instances of this class will be entities which can be stored in the database. The @Table annotation is optional and can be used to define the name of the corresponding table in the database. If it is not specified, the simple name of the entity class is used instead.\nIn order to specify how to map the attributes to columns we annotate the corresponding getter methods (technically also private field annotation is also possible but approaches can not be mixed).\nThe @Id annotation specifies that a property should be used as primary key.\nWith the help of the @Column annotation it is possible to define the name of the column that an attribute is mapped to as well as other aspects such as nullable or unique. If no column name is specified, the name of the property is used as default.\nNote that every entity class needs a constructor with public or protected visibility that does not have any arguments. Moreover, neither the class nor its getters and setters may be final.\nEntities should be simple POJOs and not contain business logic.\nEntities and Datatypes\nStandard datatypes like Integer, BigDecimal, String, etc. are mapped automatically by JPA. Custom datatypes are mapped as serialized BLOB by default what is typically undesired.\nIn order to map atomic custom datatypes (implementations of`+SimpleDatatype`) we implement an AttributeConverter. ere is a simple example:\n@Converter(autoApply = true)\npublic class MoneyAttributeConverter implements AttributeConverter&lt;Money, BigDecimal&gt; {\npublic BigDecimal convertToDatabaseColumn(Money attribute) {\nreturn attribute.getValue();\n}\npublic Money convertToEntityAttribute(BigDecimal dbData) {\nreturn new Money(dbData);\n}\n}\nThe annotation @Converter is detected by the JPA vendor if the annotated class is in the packages to scan. Further, autoApply = true implies that the converter is automatically used for all properties of the handled datatype. Therefore all entities with properties of that datatype will automatically be mapped properly (in our example Money is mapped as BigDecimal).\nIn case you have a composite datatype that you need to map to multiple columns the JPA does not offer a real solution. As a workaround you can use a bean instead of a real datatype and declare it as @Embeddable. If you are using hibernate you can implement CompositeUserType. Via the @TypeDef annotation it can be registered to hibernate. If you want to annotate the CompositeUserType implementation itself you also need another annotation (e.g. MappedSuperclass tough not technically correct) so it is found by the scan.\nEnumerations\nBy default JPA maps Enums via their ordinal. Therefore the database will only contain the ordinals (0, 1, 2, etc.) . So , inside the database you can not easily understand their meaning. Using @Enumerated with EnumType.STRING allows to map the enum values to their name (Enum.name()). Both approaches are fragile when it comes to code changes and refactoring (if you change the order of the enum values or rename them) after the application is deployed to production. If you want to avoid this and get a robust mapping you can define a dedicated string in each enum value for database representation that you keep untouched. Then you treat the enum just like any other custom datatype.\nBLOB\nIf binary or character large objects (BLOB/CLOB) should be used to store the value of an attribute, e.g. to store an icon, the @Lob annotation should be used as shown in the following listing:\n@Lob\npublic byte[] getIcon() {\nreturn this.icon;\n}\nWarning\nUsing a byte array will cause problems if BLOBs get large because the entire BLOB is loaded into the RAM of the server and has to be processed by the garbage collector. For larger BLOBs the type Blob and streaming should be used.\npublic Blob getAttachment() {\nreturn this.attachment;\n}\nDate and Time\nTo store date and time related values, the temporal annotation can be used as shown in the listing below:\n@Temporal(TemporalType.TIMESTAMP)\npublic java.util.Date getStart() {\nreturn start;\n}\nUntil Java8 the java data type java.util.Date (or Jodatime) has to be used.\nTemporalType defines the granularity. In this case, a precision of nanoseconds is used. If this granularity is not wanted, TemporalType.DATE can be used instead, which only has a granularity of milliseconds.\nMixing these two granularities can cause problems when comparing one value to another. This is why we only use TemporalType.TIMESTAMP.\nQueryDSL and Custom Types\nUsing the Aliases API of QueryDSL might result in an InvalidDataAccessApiUsageException when using custom datatypes in entity properties. This can be circumvented in two steps:\nEnsure you have the following maven dependencies in your project (core module) to support custom types via the Aliases API:\n&lt;dependency&gt;\n&lt;groupId&gt;org.ow2.asm&lt;/groupId&gt;\n&lt;artifactId&gt;asm&lt;/artifactId&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n&lt;groupId&gt;cglib&lt;/groupId&gt;\n&lt;artifactId&gt;cglib&lt;/artifactId&gt;\n&lt;/dependency&gt;\nMake sure, that all your custom types used in entities provide a non-argument constructor with at least visibility level protected.\nPrimary Keys\nWe only use simple Long values as primary keys (IDs). By default it is auto generated (@GeneratedValue(strategy=GenerationType.AUTO)). This is already provided by the class com.devonfw.&lt;projectName&gt;.general.dataaccess.api.AbstractPersistenceEntity that you can extend.\nIn case you have business oriented keys (often as String), you can define an additional property for it and declare it as unique (@Column(unique=true)).\nBe sure to include &quot;AUTO_INCREMENT&quot; in your sql table field ID to be able to persist data (or similar for other databases).\n"},{"id":92,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-jpa.asciidoc_relationships","type":"docs","title":"Relationships","body":"12.3.2. Relationships\nn:1 and 1:1 Relationships\nEntities often do not exist independently but are in some relation to each other. For example, for every period of time one of the StaffMember&#x2019;s of the restaurant example has worked, which is represented by the class WorkingTime, there is a relationship to this StaffMember.\nThe following listing shows how this can be modeled using JPA:\n...\n@Entity\npublic class WorkingTimeEntity {\n...\nprivate StaffMemberEntity staffMember;\n@ManyToOne\n@JoinColumn(name=&quot;STAFFMEMBER&quot;)\npublic StaffMemberEntity getStaffMember() {\nreturn this.staffMember;\n}\npublic void setStaffMember(StaffMemberEntity staffMember) {\nthis.staffMember = staffMember;\n}\n}\nTo represent the relationship, an attribute of the type of the corresponding entity class that is referenced has been introduced. The relationship is a n:1 relationship, because every WorkingTime belongs to exactly one StaffMember, but a StaffMember usually worked more often than once.\nThis is why the @ManyToOne annotation is used here. For 1:1 relationships the @OneToOne annotation can be used which works basically the same way. To be able to save information about the relation in the database, an additional column in the corresponding table of WorkingTime is needed which contains the primary key of the referenced StaffMember. With the name element of the @JoinColumn annotation it is possible to specify the name of this column.\n1:n and n:m Relationships\nThe relationship of the example listed above is currently an unidirectional one, as there is a getter method for retrieving the StaffMember from the WorkingTime object, but not vice versa.\nTo make it a bidirectional one, the following code has to be added to StaffMember:\nprivate Set&lt;WorkingTimeEntity&gt; workingTimes;\n@OneToMany(mappedBy=&quot;staffMember&quot;)\npublic Set&lt;WorkingTimeEntity&gt; getWorkingTimes() {\nreturn this.workingTimes;\n}\npublic void setWorkingTimes(Set&lt;WorkingTimeEntity&gt; workingTimes) {\nthis.workingTimes = workingTimes;\n}\nTo make the relationship bidirectional, the tables in the database do not have to be changed. Instead the column that corresponds to the attribute staffMember in class WorkingTime is used, which is specified by the mappedBy element of the @OneToMany annotation. Hibernate will search for corresponding WorkingTime objects automatically when a StaffMember is loaded.\nThe problem with bidirectional relationships is that if a WorkingTime object is added to the set or list workingTimes in StaffMember, this does not have any effect in the database unless\nthe staffMember attribute of that WorkingTime object is set. That is why the devon4j advices not to use bidirectional relationships but to use queries instead. How to do this is shown here. If a bidirectional relationship should be used nevertheless, appropriate add and remove methods must be used.\nFor 1:n and n:m relations, the devon4j demands that (unordered) Sets and no other collection types are used, as shown in the listing above. The only exception is whenever an ordering is really needed, (sorted) lists can be used.\nFor example, if WorkingTime objects should be sorted by their start time, this could be done like this:\nprivate List&lt;WorkingTimeEntity&gt; workingTimes;\n@OneToMany(mappedBy = &quot;staffMember&quot;)\n@OrderBy(&quot;startTime asc&quot;)\npublic List&lt;WorkingTimeEntity&gt; getWorkingTimes() {\nreturn this.workingTimes;\n}\npublic void setWorkingTimes(List&lt;WorkingTimeEntity&gt; workingTimes) {\nthis.workingTimes = workingTimes;\n}\nThe value of the @OrderBy annotation consists of an attribute name of the class followed by asc (ascending) or desc (descending).\nTo store information about a n:m relationship, a separate table has to be used, as one column cannot store several values (at least if the database schema is in first normal form).\nFor example if one wanted to extend the example application so that all ingredients of one FoodDrink can be saved and to model the ingredients themselves as entities (e.g. to store additional information about them), this could be modeled as follows (extract of class FoodDrink):\nprivate Set&lt;IngredientEntity&gt; ingredients;\n@ManyToMany()\n@JoinTable\npublic Set&lt;IngredientEntity&gt; getIngredients() {\nreturn this.ingredients;\n}\npublic void setOrders(Set&lt;IngredientEntity&gt; ingredients) {\nthis.ingredients = ingredients;\n}\nInformation about the relation is stored in a table called BILL_ORDER that has to have two columns, one for referencing the Bill, the other one for referencing the Order. Note that the @JoinTable annotation is not needed in this case because a separate table is the default solution here (same for n:m relations) unless there is a mappedBy element specified.\nFor 1:n relationships this solution has the disadvantage that more joins (in the database system) are needed to get a Bill with all the Orders it refers to. This might have a negative impact on performance so that the solution to store a reference to the Bill row/entity in the Order&#x2019;s table is probably the better solution in most cases.\nNote that bidirectional n:m relationships are not allowed for applications based on devon4j. Instead a third entity has to be introduced, which &quot;represents&quot; the relationship (it has two n:1 relationships).\nEager vs. Lazy Loading\nUsing JPA it is possible to use either lazy or eager loading. Eager loading means that for entities retrieved from the database, other entities that are referenced by these entities are also retrieved, whereas lazy loading means that this is only done when they are actually needed, i.e. when the corresponding getter method is invoked.\nApplication based on devon4j are strongly advised to always use lazy loading. The JPA defaults are:\n@OneToMany: LAZY\n@ManyToMany: LAZY\n@ManyToOne: EAGER\n@OneToOne: EAGER\nSo at least for @ManyToOne and @OneToOne you always need to override the default by providing fetch = FetchType.LAZY.\nImportant\nPlease read the performance guide.\nCascading Relationships\nFor relations it is also possible to define whether operations are cascaded (like a recursion) to the related entity.\nBy default, nothing is done in these situations. This can be changed by using the cascade property of the annotation that specifies the relation type (@OneToOne, @ManyToOne, @OneToMany, @ManyToOne). This property accepts a CascadeType that offers the following options:\nPERSIST (for EntityManager.persist, relevant to inserted transient entities into DB)\nREMOVE (for EntityManager.remove to delete entity from DB)\nMERGE (for EntityManager.merge)\nREFRESH (for EntityManager.refresh)\nDETACH (for EntityManager.detach)\nALL (cascade all of the above operations)\nSee here for more information.\nTypesafe Foreign Keys using IdRef\nFor simple usage you can use Long for all your foreign keys.\nHowever, as an optional pattern for advanced and type-safe usage, we offer IdRef.\n"},{"id":93,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-jpa.asciidoc_embeddable","type":"docs","title":"Embeddable","body":"12.3.3. Embeddable\nAn embeddable Object is a way to group properties of an entity into a separate Java (child) object. Unlike with implement relationships the embeddable is not a separate entity and its properties are stored (embedded) in the same table together with the entity. This is helpful to structure and reuse groups of properties.\nThe following example shows an Address implemented as an embeddable class:\n@Embeddable\npublic class AddressEmbeddable {\nprivate String street;\nprivate String number;\nprivate Integer zipCode;\nprivate String city;\n@Column(name=&quot;STREETNUMBER&quot;)\npublic String getNumber() {\nreturn number;\n}\npublic void setNumber(String number) {\nthis.number = number;\n}\n... // other getter and setter methods, equals, hashCode\n}\nAs you can see an embeddable is similar to an entity class, but with an @Embeddable annotation instead of the @Entity annotation and without primary key or modification counter.\nAn Embeddable does not exist on its own but in the context of an entity.\nAs a simplification Embeddables do not require a separate interface and ETO as the bean-mapper will create a copy automatically when converting the owning entity to an ETO.\nHowever, in this case the embeddable becomes part of your api module that therefore needs a dependency on the JPA.\nIn addition to that the methods equals(Object) and hashCode() need to be implemented as this is required by Hibernate (it is not required for entities because they can be unambiguously identified by their primary key). For some hints on how to implement the hashCode() method please have a look here.\nUsing this AddressEmbeddable inside an entity class can be done like this:\nprivate AddressEmbeddable address;\n@Embedded\npublic AddressEmbeddable getAddress() {\nreturn this.address;\n}\npublic void setAddress(AddressEmbeddable address) {\nthis.address = address;\n}\n}\nThe @Embedded annotation needs to be used for embedded attributes. Note that if in all columns of the embeddable (here Address) are null, then the embeddable object itself is also null inside the entity. This has to be considered to avoid NullPointerException&#x2019;s. Further this causes some issues with primitive types in embeddable classes that can be avoided by only using object types instead.\n"},{"id":94,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-jpa.asciidoc_inheritance","type":"docs","title":"Inheritance","body":"12.3.4. Inheritance\nJust like normal java classes, entity classes can inherit from others. The only difference is that you need to specify how to map a class hierarchy to database tables. Generic abstract super-classes for entities can simply be annotated with @MappedSuperclass.\nFor all other cases the JPA offers the annotation @Inheritance with the property strategy talking an InheritanceType that has the following options:\nSINGLE_TABLE: This strategy uses a single table that contains all columns needed to store all entity-types of the entire inheritance hierarchy. If a column is not needed for an entity because of its type, there is a null value in this column. An additional column is introduced, which denotes the type of the entity (called dtype).\nTABLE_PER_CLASS: For each concrete entity class there is a table in the database that can store such an entity with all its attributes. An entity is only saved in the table corresponding to its most concrete type. To get all entities of a super type, joins are needed.\nJOINED: In this case there is a table for every entity class including abstract classes, which contains only the columns for the persistent properties of that particular class. Additionally there is a primary key column in every table. To get an entity of a class that is a subclass of another one, joins are needed.\nEach of the three approaches has its advantages and drawbacks, which are discussed in detail here. In most cases, the first one should be used, because it is usually the fastest way to do the mapping, as no joins are needed when retrieving, searching or persisting entities. Moreover it is rather simple and easy to understand.\nOne major disadvantage is that the first approach could lead to a table with a lot of null values, which might have a negative impact on the database size.\nThe inheritance strategy has to be annotated to the top-most entity of the class hierarchy (where `@MappedSuperclass`es are not considered) like in the following example:\n@Entity\n@Inheritance(strategy=InheritanceType.SINGLE_TABLE)\npublic abstract class MyParentEntity extends ApplicationPersistenceEntity implements MyParent {\n...\n}\n@Entity\npublic class MyChildEntity extends MyParentEntity implements MyChild {\n...\n}\n@Entity\npublic class MyOtherEntity extends MyParentEntity implements MyChild {\n...\n}\nAs a best practice we advise you to avoid entity hierarchies at all where possible and otherwise to keep the hierarchy as small as possible. In order to just ensure reuse or establish a common API you can consider a shared interface, a @MappedSuperclass or an @Embeddable instead of an entity hierarchy.\n"},{"id":95,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-jpa.asciidoc_repositories-and-daos","type":"docs","title":"Repositories and DAOs","body":"12.3.5. Repositories and DAOs\nFor each entity a code unit is created that groups all database operations for that entity. We recommend to use spring-data repositories for that as it is most efficient for developers. As an alternative there is still the classic approach using DAOs.\nConcurrency Control\nThe concurrency control defines the way concurrent access to the same data of a database is handled. When several users (or threads of application servers) concurrently access a database, anomalies may happen, e.g. a transaction is able to see changes from another transaction although that one did, not yet commit these changes. Most of these anomalies are automatically prevented by the database system, depending on the isolation level (property hibernate.connection.isolation in the jpa.xml, see here).\nAnother anomaly is when two stakeholders concurrently access a record, do some changes and write them back to the database. The JPA addresses this with different locking strategies (see here).\nAs a best practice we are using optimistic locking for regular end-user services (OLTP) and pessimistic locking for batches.\nOptimistic Locking\nThe class com.devonfw.module.jpa.persistence.api.AbstractPersistenceEntity already provides optimistic locking via a modificationCounter with the @Version annotation. Therefore JPA takes care of optimistic locking for you. When entities are transferred to clients, modified and sent back for update you need to ensure the modificationCounter is part of the game. If you follow our guides about transfer-objects and services this will also work out of the box.\nYou only have to care about two things:\nHow to deal with optimistic locking in relationships?\nAssume an entity A contains a collection of B entities. Should there be a locking conflict if one user modifies an instance of A while another user in parallel modifies an instance of B that is contained in the other instance? To address this , take a look at FeatureForceIncrementModificationCounter.\nWhat should happen in the UI if an OptimisticLockException occurred?\nAccording to KISS our recommendation is that the user gets an error displayed that tells him to do his change again on the recent data. Try to design your system and the work processing in a way to keep such conflicts rare and you are fine.\nPessimistic Locking\nFor back-end services and especially for batches optimistic locking is not suitable. A human user shall not cause a large batch process to fail because he was editing the same entity. Therefore such use-cases use pessimistic locking what gives them a kind of priority over the human users.\nIn your DAO implementation you can provide methods that do pessimistic locking via EntityManager operations that take a LockModeType. Here is a simple example:\ngetEntityManager().lock(entity, LockModeType.READ);\nWhen using the lock(Object, LockModeType) method with LockModeType.READ, Hibernate will issue a SELECT &#x2026;&#x200B; FOR UPDATE. This means that no one else can update the entity (see here for more information on the statement). If LockModeType.WRITE is specified, Hibernate issues a SELECT &#x2026;&#x200B; FOR UPDATE NOWAIT instead, which has has the same meaning as the statement above, but if there is already a lock, the program will not wait for this lock to be released. Instead, an exception is raised.\nUse one of the types if you want to modify the entity later on, for read only access no lock is required.\nAs you might have noticed, the behavior of Hibernate deviates from what one would expect by looking at the LockModeType (especially LockModeType.READ should not cause a SELECT &#x2026;&#x200B; FOR UPDATE to be issued). The framework actually deviates from what is specified in the JPA for unknown reasons.\n"},{"id":96,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-jpa.asciidoc_database-auditing","type":"docs","title":"Database Auditing","body":"12.3.6. Database Auditing\nSee auditing guide.\n"},{"id":97,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-jpa.asciidoc_testing-data-access","type":"docs","title":"Testing Data-Access","body":"12.3.7. Testing Data-Access\nFor testing of Entities and Repositories or DAOs see testing guide.\n"},{"id":98,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-jpa.asciidoc_principles","type":"docs","title":"Principles","body":"12.3.8. Principles\nWe strongly recommend these principles:\nUse the JPA where ever possible and use vendor (hibernate) specific features only for situations when JPA does not provide a solution. In the latter case consider first if you really need the feature.\nCreate your entities as simple POJOs and use JPA to annotate the getters in order to define the mapping.\nKeep your entities simple and avoid putting advanced logic into entity methods.\n"},{"id":99,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-jpa.asciidoc_database-configuration","type":"docs","title":"Database Configuration","body":"12.3.9. Database Configuration\nThe configuration for spring and hibernate is already provided by devonfw in our sample application and the application template. So you only need to worry about a few things to customize.\nDatabase System and Access\nObviously you need to configure which type of database you want to use as well as the location and credentials to access it. The defaults are configured in application-default.properties that is bundled and deployed with the release of the software. It should therefore contain the properties as in the given example:\ndatabase.url=jdbc:postgresql://database.enterprise.com/app\ndatabase.user.login=appuser01\ndatabase.hibernate.dialect = org.hibernate.dialect.PostgreSQLDialect\ndatabase.hibernate.hbm2ddl.auto=validate\nThe environment specific settings (especially passwords) are configured by the operators in application.properties. For further details consult the configuration guide. It can also override the default values. The relevant configuration properties can be seen by the following example for the development environment (located in src/test/resources):\ndatabase.url=jdbc:postgresql://localhost/app\ndatabase.user.password=************\ndatabase.hibernate.hbm2ddl.auto=create\nFor further details about database.hibernate.hbm2ddl.auto please see here. For production and acceptance environments we use the value validate that should be set as default. In case you want to use Oracle RDBMS you can find additional hints here.\nDatabase Migration\nSee database migration.\nDatabase Logging\nAdd the following properties to application.properties to enable logging of database queries for debugging purposes.\nspring.jpa.properties.hibernate.show_sql=true\nspring.jpa.properties.hibernate.use_sql_comments=true\nspring.jpa.properties.hibernate.format_sql=true\nPooling\nYou typically want to pool JDBC connections to boost performance by recycling previous connections. There are many libraries available to do connection pooling. We recommend to use HikariCP. For Oracle RDBMS see here.\n"},{"id":100,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-jpa.asciidoc_security","type":"docs","title":"Security","body":"12.3.10. Security\nSQL-Injection\nA common security threat is SQL-injection. Never build queries with string concatenation or your code might be vulnerable as in the following example:\nString query = &quot;Select op from OrderPosition op where op.comment = &quot; + userInput;\nreturn getEntityManager().createQuery(query).getResultList();\nVia the parameter userInput an attacker can inject SQL (JPQL) and execute arbitrary statements in the database causing extreme damage.\nIn order to prevent such injections you have to strictly follow our rules for queries:\nUse named queries for static queries.\nUse QueryDSL for dynamic queries.\nPlease also consult the SQL Injection Prevention Cheat Sheet.\nLimited Permissions for Application\nWe suggest that you operate your application with a database user that has limited permissions so he can not modify the SQL schema (e.g. drop tables). For initializing the schema (DDL) or to do schema migrations use a separate user that is not used by the application itself.\n"},{"id":101,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-jpa-query.asciidoc","type":"docs","title":"Queries","body":"12.3.11. Queries\nThe Java Persistence API (JPA) defines its own query language, the java persistence query language (JPQL) (see also JPQL tutorial), which is similar to SQL but operates on entities and their attributes instead of tables and columns.\nThe simplest CRUD-Queries (e.g. find an entity by its ID) are already build in the devonfw CRUD functionality (via Repository or DAO). For other cases you need to write your own query. We distinguish between static and dynamic queries. Static queries have a fixed JPQL query string that may only use parameters to customize the query at runtime. Instead, dynamic queries can change their clauses (WHERE, ORDER BY, JOIN, etc.) at runtime depending on the given search criteria.\nStatic Queries\nE.g. to find all DishEntries (from MTS sample app) that have a price not exceeding a given maxPrice we write the following JPQL query:\nSELECT dish FROM DishEntity dish WHERE dish.price &lt;= :maxPrice\nHere dish is used as alias (variable name) for our selected DishEntity (what refers to the simple name of the Java entity class). With dish.price we are referring to the Java property price (getPrice()/setPrice(&#x2026;&#x200B;)) in DishEntity. A named variable provided from outside (the search criteria at runtime) is specified with a colon (:) as prefix. Here with :maxPrice we reference to a variable that needs to be set via query.setParameter(&quot;maxPrice&quot;, maxPriceValue). JPQL also supports indexed parameters (?) but they are discouraged because they easily cause confusion and mistakes.\nUsing Queries to Avoid Bidirectional Relationships\nWith the usage of queries it is possible to avoid exposing relationships or modelling bidirectional relationships, which have some disadvantages (see relationships). This is especially desired for relationships between entities of different business components.\nSo for example to get all OrderLineEntities for a specific OrderEntity without using the orderLines relation from OrderEntity the following query could be used:\nSELECT line FROM OrderLineEntity line WHERE line.order.id = :orderId\nDynamic Queries\nFor dynamic queries we use QueryDSL. It allows to implement queries in a powerful but readable and type-safe way (unlike Criteria API). If you already know JPQL you will quickly be able to read and write QueryDSL code. It feels like JPQL but implemented in Java instead of plain text.\nPlease be aware that code-generation can be painful especially with large teams. We therefore recommend to use QueryDSL without code-generation. Here is an example from our sample application:\npublic List&lt;DishEntity&gt; findOrders(DishSearchCriteriaTo criteria) {\nDishEntity dish = Alias.alias(DishEntity.class);\nJPAQuery&lt;OrderEntity&gt; query = newDslQuery(alias); // new JPAQuery&lt;&gt;(getEntityManager()).from(Alias.$(dish));\nRange&lt;BigDecimal&gt; priceRange = criteria.getPriceRange();\nif (priceRange != null) {\nBigDecimal min = priceRange.getMin();\nif (min != null) {\nquery.where(Alias.$(order.getPrice()).ge(min));\n}\nBigDecimal max = priceRange.getMax();\nif (max != null) {\nquery.where(Alias.$(order.getPrice()).le(max));\n}\n}\nString name = criteria.getName();\nif ((name != null) &amp;&amp; (!name.isEmpty())) {\n// query.where(Alias.$(alias.getName()).eq(name));\nQueryUtil.get().whereString(query, Alias.$(alias.getName()), name, criteria.getNameOption());\n}\nreturn query.fetch();\n}\nUsing Wildcards\nFor flexible queries it is often required to allow wildcards (especially in dynamic queries). While users intuitively expect glob syntax the SQL and JPQL standards work different. Therefore a mapping is required. devonfw provides this on a lower level by LikePatternSyntax and on a high level by QueryUtil (see QueryHelper.newStringClause(&#x2026;&#x200B;)).\nPagination\ndevonfw provides pagination support. If you are using spring-data repositories you will get that directly from spring for static queries. Otherwise for dynamic or generally handwritten queries we provide this via QueryUtil.findPaginated(&#x2026;&#x200B;):\nboolean determineTotalHitCount = ...;\nreturn QueryUtil.get().findPaginated(criteria.getPageable(), query, determineTotalHitCount);\nPagination example\nFor the table entity we can make a search request by accessing the REST endpoint with pagination support like in the following examples:\nPOST mythaistar/services/rest/tablemanagement/v1/table/search\n{\n&quot;pagination&quot;: {\n&quot;size&quot;:2,\n&quot;total&quot;:true\n}\n}\n//Response\n{\n&quot;pagination&quot;: {\n&quot;size&quot;: 2,\n&quot;page&quot;: 1,\n&quot;total&quot;: 11\n},\n&quot;result&quot;: [\n{\n&quot;id&quot;: 101,\n&quot;modificationCounter&quot;: 1,\n&quot;revision&quot;: null,\n&quot;waiterId&quot;: null,\n&quot;number&quot;: 1,\n&quot;state&quot;: &quot;OCCUPIED&quot;\n},\n{\n&quot;id&quot;: 102,\n&quot;modificationCounter&quot;: 1,\n&quot;revision&quot;: null,\n&quot;waiterId&quot;: null,\n&quot;number&quot;: 2,\n&quot;state&quot;: &quot;FREE&quot;\n}\n]\n}\nNote\nAs we are requesting with the total property set to true the server responds with the total count of rows for the query.\nFor retrieving a concrete page, we provide the page attribute with the desired value. Here we also left out the total property so the server doesn&#x2019;t incur on the effort to calculate it:\nPOST mythaistar/services/rest/tablemanagement/v1/table/search\n{\n&quot;pagination&quot;: {\n&quot;size&quot;:2,\n&quot;page&quot;:2\n}\n}\n//Response\n{\n&quot;pagination&quot;: {\n&quot;size&quot;: 2,\n&quot;page&quot;: 2,\n&quot;total&quot;: null\n},\n&quot;result&quot;: [\n{\n&quot;id&quot;: 103,\n&quot;modificationCounter&quot;: 1,\n&quot;revision&quot;: null,\n&quot;waiterId&quot;: null,\n&quot;number&quot;: 3,\n&quot;state&quot;: &quot;FREE&quot;\n},\n{\n&quot;id&quot;: 104,\n&quot;modificationCounter&quot;: 1,\n&quot;revision&quot;: null,\n&quot;waiterId&quot;: null,\n&quot;number&quot;: 4,\n&quot;state&quot;: &quot;FREE&quot;\n}\n]\n}\nQuery Meta-Parameters\nQueries can have meta-parameters and that are provided via SearchCriteriaTo. Besides paging (see above) we also get timeout support.\nAdvanced Queries\nWriting queries can sometimes get rather complex. The current examples given above only showed very simple basics. Within this topic a lot of advanced features need to be considered like:\nJoins\nConstructor queries\nOrder By (Sorting)\nGrouping\nHaving\nUnions\nSub-Queries\nAggregation functions like e.g. count/avg/sum\nDistinct selections\nSQL Hints (see e.g. Oracle hints or SQL-Server hints) - only when required for ultimate performance tuning\nThis list is just containing the most important aspects. As we can not cover all these topics here, they are linked to external documentation that can help and guide you.\n"},{"id":102,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-repository.asciidoc","type":"docs","title":"Spring-Data","body":"12.3.12. Spring-Data\nIf you are using the Spring Framework and have no restrictions regarding that, we recommend to use spring-data-jpa via devon4j-starter-spring-data-jpa that brings advanced integration (esp. for QueryDSL).\nMotivation\nThe benefits of spring-data are (for examples and explanations see next sections):\nAll you need is one single repository interface for each entity. No need for a separate implementation or other code artifacts like XML descriptors, NamedQueries class, etc.\nYou have all information together in one place (the repository interface) that actually belong together (where as in the classic approach you have the static queries in an XML file, constants to them in NamedQueries class and referencing usages in DAO implementation classes).\nStatic queries are most simple to realize as you do not need to write any method body. This means you can develop faster.\nSupport for paging is already build-in. Again for static query method the is nothing you have to do except using the paging objects in the signature.\nStill you have the freedom to write custom implementations via default methods within the repository interface (e.g. for dynamic queries).\nRepository\nFor each entity &#xAB;Entity&#xBB;Entity an interface is created with the name &#xAB;Entity&#xBB;Repository extending DefaultRepository.\nSuch repository is the analogy to a Data-Access-Object (DAO) used in the classic approach or when spring-data is not an option.\nExample\nThe following example shows how to write such a repository:\npublic interface ExampleRepository extends DefaultRepository&lt;ExampleEntity&gt; {\n@Query(&quot;SELECT example FROM ExampleEntity example&quot; //\n+ &quot; WHERE example.name = :name&quot;)\nList&lt;ExampleEntity&gt; findByName(@Param(&quot;name&quot;) String name);\n@Query(&quot;SELECT example FROM ExampleEntity example&quot; //\n+ &quot; WHERE example.name = :name&quot;)\nPage&lt;ExampleEntity&gt; findByNamePaginated(@Param(&quot;name&quot;) String name, Pageable pageable);\ndefault Page&lt;ExampleEntity&gt; findByCriteria(ExampleSearchCriteriaTo criteria) {\nExampleEntity alias = newDslAlias();\nJPAQuery&lt;ExampleEntity&gt; query = newDslQuery(alias);\nString name = criteria.getName();\nif ((name != null) &amp;&amp; !name.isEmpty()) {\nQueryUtil.get().whereString(query, $(alias.getName()), name, criteria.getNameOption());\n}\nreturn QueryUtil.get().findPaginated(criteria.getPageable(), query, false);\n}\n}\nThis ExampleRepository has the following features:\nCRUD support from spring-data (see JavaDoc for details).\nSupport for QueryDSL integration, paging and more as well as locking via GenericRepository\nA static query method findByName to find all ExampleEntity instances from DB that have the given name. Please note the @Param annotation that links the method parameter with the variable inside the query (:name).\nThe same with pagination support via findByNamePaginated method.\nA dynamic query method findByCriteria showing the QueryDSL and paging integration into spring-data provided by devon.\nFurther examples\nYou can also read the JUnit test-case DefaultRepositoryTest that is testing an example\nFooRepository.\nAuditing\nIn case you need auditing, you only need to extend DefaultRevisionedRepository instead of DefaultRepository. The auditing methods can be found in GenericRevisionedRepository.\nDependency\nIn case you want to switch to or add spring-data support to your devon application all you need is this maven dependency:\n&lt;!-- Starter for consuming REST services --&gt;\n&lt;dependency&gt;\n&lt;groupId&gt;com.devonfw.java.starters&lt;/groupId&gt;\n&lt;artifactId&gt;devon4j-starter-spring-data-jpa&lt;/artifactId&gt;\n&lt;/dependency&gt;\nDrawbacks\nSpring-data also has some drawbacks:\nSome kind of magic behind the scenes that are not so easy to understand. So in case you want to extend all your repositories without providing the implementation via a default method in a parent repository interface you need to deep-dive into spring-data. We assume that you do not need that and hope what spring-data and devon already provides out-of-the-box is already sufficient.\nThe spring-data magic also includes guessing the query from the method name. This is not easy to understand and especially to debug. Our suggestion is not to use this feature at all and either provide a @Query annotation or an implementation via default method.\n"},{"id":103,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-dao.asciidoc","type":"docs","title":"Data Access Object","body":"12.3.13. Data Access Object\nThe Data Access Objects (DAOs) are part of the persistence layer.\nThey are responsible for a specific entity and should be named &#xAB;Entity&#xBB;Dao and &#xAB;Entity&#xBB;DaoImpl.\nThe DAO offers the so called CRUD-functionalities (create, retrieve, update, delete) for the corresponding entity.\nAdditionally a DAO may offer advanced operations such as query or locking methods.\nDAO Interface\nFor each DAO there is an interface named &#xAB;Entity&#xBB;Dao that defines the API. For CRUD support and common naming we derive it from the ApplicationDao interface that comes with the devon application template:\npublic interface MyEntityDao extends ApplicationDao&lt;MyEntity&gt; {\nList&lt;MyEntity&gt; findByCriteria(MyEntitySearchCriteria criteria);\n}\nAll CRUD operations are inherited from ApplicationDao so you only have to declare the additional methods.\nDAO Implementation\nImplementing a DAO is quite simple. We create a class named &#xAB;Entity&#xBB;DaoImpl that extends ApplicationDaoImpl and implements your &#xAB;Entity&#xBB;Dao interface:\npublic class MyEntityDaoImpl extends ApplicationDaoImpl&lt;MyEntity&gt; implements MyEntityDao {\npublic List&lt;MyEntity&gt; findByCriteria(MyEntitySearchCriteria criteria) {\nTypedQuery&lt;MyEntity&gt; query = createQuery(criteria, getEntityManager());\nreturn query.getResultList();\n}\n...\n}\nAgain you only need to implement the additional non-CRUD methods that you have declared in your &#xAB;Entity&#xBB;Dao interface.\nIn the DAO implementation you can use the method getEntityManager() to access the EntityManager from the JPA. You will need the EntityManager to create and execute queries.\nStatic queries for DAO Implementation\nAll static queries are declared in the file src\\main\\resources\\META-INF\\orm.xml:\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;\n&lt;entity-mappings version=&quot;1.0&quot; xmlns=&quot;http://java.sun.com/xml/ns/persistence/orm&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;\nxsi:schemaLocation=&quot;http://java.sun.com/xml/ns/persistence/orm http://java.sun.com/xml/ns/persistence/orm_1_0.xsd&quot;&gt;\n&lt;named-query name=&quot;find.dish.with.max.price&quot;&gt;\n&lt;query&gt;&lt;![SELECT dish FROM DishEntity dish WHERE dish.price &lt;= :maxPrice]]&gt;&lt;/query&gt;\n&lt;/named-query&gt;\n...\n&lt;/hibernate-mapping&gt;\nWhen your application is started, all these static queries will be created as prepared statements. This allows better performance and also ensures that you get errors for invalid JPQL queries when you start your app rather than later when the query is used.\nTo avoid redundant occurrences of the query name (get.open.order.positions.for.order) we define a constant for each named query:\npublic class NamedQueries {\npublic static final String FIND_DISH_WITH_MAX_PRICE = &quot;find.dish.with.max.price&quot;;\n}\nNote that changing the name of the java constant (FIND_DISH_WITH_MAX_PRICE) can be done easily with refactoring. Further you can trace where the query is used by searching the references of the constant.\nThe following listing shows how to use this query:\npublic List&lt;DishEntity&gt; findDishByMaxPrice(BigDecimal maxPrice) {\nQuery query = getEntityManager().createNamedQuery(NamedQueries.FIND_DISH_WITH_MAX_PRICE);\nquery.setParameter(&quot;maxPrice&quot;, maxPrice);\nreturn query.getResultList();\n}\nVia EntityManager.createNamedQuery(String) we create an instance of Query for our predefined static query.\nNext we use setParameter(String, Object) to provide a parameter (maxPrice) to the query. This has to be done for all parameters of the query.\nNote that using the createQuery(String) method, which takes the entire query as string (that may already contain the parameter) is not allowed to avoid SQL injection vulnerabilities.\nWhen the method getResultList() is invoked, the query is executed and the result is delivered as List. As an alternative, there is a method called getSingleResult(), which returns the entity if the query returned exactly one and throws an exception otherwise.\n"},{"id":104,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-jpa-performance.asciidoc","type":"docs","title":"JPA Performance","body":"12.3.14. JPA Performance\nWhen using JPA the developer sometimes does not see or understand where and when statements to the database are triggered.\nEstablishing expectations Developers shouldn&#x2019;t expect to sprinkle magic pixie dust on POJOs in hopes they will become persistent.\n&#x2014; Dan Allen\nhttps://epdf.tips/seam-in-action.html\nSo in case you do not understand what is going on under the hood of JPA, you will easily run into performance issues due to lazy loading and other effects.\nN plus 1 Problem\nThe most prominent phenomena is call the N+1 Problem.\nWe use entities from our MTS demo app as an example to explain the problem.\nThere is a DishEntity that has a @ManyToMany relation to\nIngredientEntity.\nNow we assume that we want to iterate all ingredients for a dish like this:\nDishEntity dish = dao.findDishById(dishId);\nBigDecimal priceWithAllExtras = dish.getPrice();\nfor (IngredientEntity ingredient : dish.getExtras()) {\npriceWithAllExtras = priceWithAllExtras.add(ingredient.getPrice());\n}\nNow dish.getExtras() is loaded lazy. Therefore the JPA vendor will provide a list with lazy initialized instances of IngredientEntity that only contain the ID of that entity. Now with every call of ingredient.getPrice() we technically trigger an SQL query statement to load the specific IngredientEntity by its ID from the database.\nNow findDishById caused 1 initial query statement and for any number N of ingredients we are causing an additional query statement. This makes a total of N+1 statements. As causing statements to the database is an expensive operation with a lot of overhead (creating connection, etc.) this ends in bad performance and is therefore a problem (the N+1 Problem).\nSolving N plus 1 Problem\nTo solve the N+1 Problem you need to change your code to only trigger a single statement instead. This can be archived in various ways. The most universal solution is to use FETCH JOIN in order to pre-load the nested N child entities into the first level cache of the JPA vendor implementation. This will behave very similar as if the @ManyToMany relation to IngredientEntity was having FetchType.EAGER but only for the specific query and not in general. Because changing @ManyToMany to FetchType.EAGER would cause bad performance for other usecases where only the dish but not its extra ingredients are needed. For this reason all relations, including @OneToOne should always be FetchType.LAZY. Back to our example we simply replace dao.findDishById(dishId) with dao.findDishWithExtrasById(dishId) that we implement by the following JPQL query:\nSELECT dish FROM DishEntity dish\nLEFT JOIN FETCH dish.extras\nWHERE dish.id = :dishId\nThe rest of the code does not have to be changed but now dish.getExtras() will get the IngredientEntity from the first level cache where is was fetched by the initial query above.\nPlease note that if you only need the sum of the prices from the extras you can also create a query using an aggregator function:\nSELECT sum(dish.extras.price) FROM DishEntity dish\nAs you can see you need to understand the concepts in order to get good performance.\nThere are many advanced topics such as creating database indexes or calculating statistics for the query optimizer to get the best performance. For such advanced topics we recommend to have a database expert in your team that cares about such things. However, understanding the N+1 Problem and its solutions is something that every Java developer in the team needs to understand.\n"},{"id":105,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-jpa-idref.asciidoc","type":"docs","title":"IdRef","body":"12.3.15. IdRef\nIdRef can be used to reference other entities in TOs in order to make them type-safe and semantically more expressive.\nIt is an optional concept in devon4j for more complex applications that make intensive use of relations and foreign keys.\nMotivation\nAssuming you have a method signature like the following:\nLong approve(Long cId, Long cuId);\nSo what are the paremeters? What is returned?\nIdRef is just a wrapper for a Long used as foreign key. This makes our signature much more expressive and self-explanatory:\nIdRef&lt;Contract&gt; approve(IdRef&lt;Contract&gt; cId, IdRef&lt;Customer&gt; cuId);\nNow we can easily see, that the result and the parameters are foreign-keys and which entity they are referring to via their generic type.\nWe can read the javadoc of these entities from the generic type and understand the context.\nFinally, when passing IdRef objects to such methods, we get compile errors in case we accidentally place parameters in the wrong order.\nIdRef and Mapping\nIn order to easily map relations from entities to transfer-objects and back, we can easily also put according getters and setters into our entities:\npublic class ContractEntity extends ApplicationPersistenceEntity implements Contract {\nprivate CustomerEntity customer;\n...\n@ManyToOne(fetch = FetchType.LAZY)\n@JoinColumn(name = &quot;CUSTOMER_ID&quot;)\npublic CustomerEntity getCustomer() {\nreturn this.customer;\n}\npublic void setCustomer(CustomerEntity customer) {\nthis.customer = customer;\n}\n@Transient\npublic IdRef&lt;Customer&gt; getCustomerId() {\nreturn IdRef.of(this.customer);\n}\npublic void setCustomerId(IdRef&lt;Customer&gt; customerId) {\nthis.customer = JpaHelper.asEntity(customerId, CustomerEntity.class);\n}\n}\nNow, ensure that you have the same getters and setters for customerId in your Eto:\npublic class ContractEto extends AbstractEto implements Contract {\nprivate IdRef&lt;Customer&gt; customerId;\n...\npublic IdRef&lt;Customer&gt; getCustomerId() {\nreturn this.customerId;\n}\npublic void setCustomerId(IdRef&lt;Customer&gt; customerId) {\nthis.customerId = customerId;\n}\n}\nThis way the bean-mapper can automatically map from your entity (ContractEntity) to your Eto (ContractEto) and vice-versa.\nJpaHelper and EntityManager access\nIn the above example we used JpaHelper.asEntity to convert the foreign key (IdRef&lt;Customer&gt;) to the according entity (CustomerEntity).\nThis will internally use EntityManager.getReference to properly create a JPA entity.\nThe alternative &quot;solution&quot; that may be used with Long instead of IdRef is typically:\npublic void setCustomerId(IdRef&lt;Customer&gt; customerId) {\nLong id = null;\nif (customerId != null) {\nid = customerId.getId();\n}\nif (id == null) {\nthis.customer = null;\n} else {\nthis.customer = new CustomerEntity();\nthis.customer.setId(id);\n}\n}\nWhile this &quot;solution&quot; works is most cases, we discovered some more complex cases, where it fails with very strange hibernate exceptions.\nWhen cleanly creating the entity via EntityManager.getReference instead it is working in all cases.\nSo how can JpaHelper.asEntity as a static method access the EntityManager?\nTherefore we need to initialize this as otherwise you may see this exception:\njava.lang.IllegalStateException: EntityManager has not yet been initialized!\nat com.devonfw.module.jpa.dataaccess.api.JpaEntityManagerAccess.getEntityManager(JpaEntityManagerAccess.java:38)\nat com.devonfw.module.jpa.dataaccess.api.JpaHelper.asEntity(JpaHelper.java:49)\nFor main usage in your application we assume that there is only one instance of EntityManager.\nTherefore we can initialize this instance during the spring boot setup.\nThis is what we provide for you in JpaInitializer for you\nwhen creating a devon4j app.\nJpaHelper and spring-test\nFurther, you also want your code to work in integration tests.\nSpring-test provides a lot of magic under the hood to make integration testing easy for you.\nTo boost the performance when running multiple tests, spring is smart and avoids creating the same spring-context multiple times.\nTherefore it stores these contexts so that if a test-case is executed with a specific spring-configuration that has already been setup before,\nthe same spring-context can be reused instead of creating it again.\nHowever, your tests may have multiple spring configurations leading to multiple spring-contexts.\nEven worse these tests can run in any order leading to switching between spring-contexts forth and back.\nTherefore, a static initializer during the spring boot setup can lead to strange errors as you can get the wrong EntityManager instance.\nIn order to fix such problems, we provide a solution pattern via DbTest ensuring for every test,\nthat the proper instance of EntityManager is initialized.\nTherefore you should derive directly or indirectly (e.g. via ComponentDbTest and SubsystemDbTest) from DbTesT or adopt your own way to apply this pattern to your tests, when using JpaHelper.\nThis already happens if you are extending ApplicationComponentTest or ApplicationSubsystemTest.\n"},{"id":106,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-auditing.asciidoc","type":"docs","title":"Auditing","body":"12.4. Auditing\nFor database auditing we use hibernate envers. If you want to use auditing ensure you have the following dependency in your pom.xml:\n&lt;dependency&gt;\n&lt;groupId&gt;com.devonfw.java.modules&lt;/groupId&gt;\n&lt;artifactId&gt;devon4j-jpa-envers&lt;/artifactId&gt;\n&lt;/dependency&gt;\nMake sure that entity manager also scans the package from the devon4j-jpa[-envers] module in order to work properly. And make sure that correct Repository Factory Bean Class is chosen.\n@EntityScan(basePackages = { &quot;&#xAB;my.base.package&#xBB;&quot; }, basePackageClasses = { AdvancedRevisionEntity.class })\n...\n@EnableJpaRepositories(repositoryFactoryBeanClass = GenericRevisionedRepositoryFactoryBean.class)\n...\npublic class SpringBootApp {\n...\n}\nNow let your [Entity]Repository extend from DefaultRevisionedRepository instead of DefaultRepository.\nThe repository now has a method getRevisionHistoryMetadata(id) and getRevisionHistoryMetadata(id, boolean lazy) available to get a list of revisions for a given entity and a method find(id, revision) to load a specific revision of an entity with the given ID or getLastRevisionHistoryMetadata(id) to load last revision.\nTo enable auditing for a entity simply place the @Audited annotation to your entity and all entity classes it extends from.\n@Entity(name = &quot;Drink&quot;)\n@Audited\npublic class DrinkEntity extends ProductEntity implements Drink {\n...\nWhen auditing is enabled for an entity an additional database table is used to store all changes to the entity table and a corresponding revision number. This table is called &lt;ENTITY_NAME&gt;_AUD per default. Another table called REVINFO is used to store all revisions. Make sure that these tables are available. They can be generated by hibernate with the following property (only for development environments).\ndatabase.hibernate.hbm2ddl.auto=create\nAnother possibility is to put them in your database migration scripts like so.\nCREATE CACHED TABLE PUBLIC.REVINFO(\nid BIGINT NOT NULL generated by default as identity (start with 1),\ntimestamp BIGINT NOT NULL,\nuser VARCHAR(255)\n);\n...\nCREATE CACHED TABLE PUBLIC.&lt;TABLE_NAME&gt;_AUD(\n&lt;ALL_TABLE_ATTRIBUTES&gt;,\nrevtype TINYINT,\nrev BIGINT NOT NULL\n);\n"},{"id":107,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-transactions.asciidoc","type":"docs","title":"Transaction Handling","body":"12.5. Transaction Handling\nTransactions are technically processed by the data access layer. However, the transaction control has to be performed in upper layers. To avoid dependencies on persistence layer and technical code in upper layers, we use AOP to add transaction control via annotations as aspect.\nWe recommend using the @Transactional annotation (the JEE standard javax.transaction.Transactional rather than org.springframework.transaction.annotation.Transactional). We use this annotation in the logic layer to annotate business methods that participate in transactions (what typically applies to most up to all business components):\n@Transactional\npublic MyDataTo getData(MyCriteriaTo criteria) {\n...\n}\nIn case a service operation should invoke multiple use-cases, you would end up with multiple transactions what is undesired (what if the first TX succeeds and then the second TX fails?). Therefore you would then also annotate the service operation. This is not proposed as a pattern in any case as in some rare cases you need to handle constraint-violations from the database to create a specific business exception (with specified message). In such case you have to surround the transaction with a try {} catch statement what is not working if that method itself is @Transactional.\n"},{"id":108,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-transactions.asciidoc_batches","type":"docs","title":"Batches","body":"12.5.1. Batches\nTransaction control for batches is a lot more complicated and is described in the batch layer.\n"},{"id":109,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-sql.asciidoc","type":"docs","title":"SQL","body":"12.6. SQL\nFor general guides on dealing or avoiding SQL, preventing SQL-injection, etc. you should study data-access layer.\n"},{"id":110,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-sql.asciidoc_naming-conventions","type":"docs","title":"Naming Conventions","body":"12.6.1. Naming Conventions\nHere we define naming conventions that you should follow whenever you write SQL files:\nAll SQL-Keywords in UPPER CASE\nIndentation should be 2 spaces as suggested by devonfw for every format.\nDDL\nThe naming conventions for database constructs (tables, columns, triggers, constraints, etc.) should be aligned with your database product and their operators.\nHowever, when you have the freedom of choice and a modern case-sensitive database, you can simply use your code conventions also for database constructs to avoid explicitly mapping each and every property (e.g. RestaurantTable vs. RESTAURANT_TABLE).\nDefine columns and constraints inline in the statement to create the table\nIndent column types so they all start in the same text column\nConstraints should be named explicitly (to get a reasonable hint error messages) with:\nPK_&#xAB;table&#xBB; for primary key (name optional here as PK constraint are fundamental)\nFK_&#xAB;table&#xBB;_&#xAB;property&#xBB; for foreign keys (&#xAB;table&#xBB; and &#xAB;property&#xBB; are both on the source where the foreign key is defined)\nUC_&#xAB;table&#xBB;_&#xAB;property&#xBB;[_&#xAB;propertyN&#xBB;]* for unique constraints\nCK_&#xAB;table&#xBB;_&#xAB;check&#xBB; for check constraints (&#xAB;check&#xBB; describes the check, if it is defined on a single property it should start with the property).\nOld RDBMS had hard limitations for names (e.g. 30 characters). Please note that recent databases have overcome this very low length limitations. However, keep your names short but precise and try to define common abbreviations in your project for according (business) terms. Especially do not just truncate the names at the limit.\nIf possible add comments on table and columns to help DBAs understanding your schema. This is also honored by many tools (not only DBA-tools).\nHere is a brief example of a DDL:\nCREATE SEQUENCE HIBERNATE_SEQUENCE START WITH 1000000;\n-- *** Table ***\nCREATE TABLE RESTAURANT_TABLE (\nID NUMBER(19) NOT NULL,\nMODIFICATION_COUNTER INTEGER NOT NULL,\nSEATS INTEGER NOT NULL,\nCONSTRAINT PK_TABLE PRIMARY KEY(ID)\n);\nCOMMENT ON TABLE RESTAURANT_TABLE IS &apos;The physical tables inside the restaurant.&apos;;\n-- *** Order ***\nCREATE TABLE RESTAURANT_ORDER (\nID NUMBER(19) NOT NULL,\nMODIFICATION_COUNTER INTEGER NOT NULL,\nTABLE_ID NUMBER(19) NOT NULL,\nTOTAL DECIMAL(5, 2) NOT NULL,\nCREATION_DATE TIMESTAMP NOT NULL,\nPAYMENT_DATE TIMESTAMP,\nSTATUS VARCHAR2(10 CHAR) NOT NULL,\nCONSTRAINT PK_ORDER PRIMARY KEY(ID),\nCONSTRAINT FK_ORDER_TABLE_ID FOREIGN KEY(TABLE_ID) REFERENCES RESTAURANT_TABLE(ID)\n);\nCOMMENT ON TABLE RESTAURANT_ORDER IS &apos;An order and bill at the restaurant.&apos;;\n...\nATTENTION: Please note that TABLE and ORDER are reserved keywords in SQL and you should avoid using such keywords to prevent problems.\nData\nFor insert, update, delete, etc. of data SQL scripts should additionally follow these guidelines:\nInserts always with the same order of columns in blocks for each table.\nInsert column values always starting with ID, MODIFICATION_COUNTER, [DTYPE, ] &#x2026;&#x200B;\nList columns with fixed length values (boolean, number, enums, etc.) before columns with free text to support alignment of multiple insert statements\nPro Tip: Get familiar with column mode of advanced editors such as notepad++ when editing large blocks of similar insert statements.\nINSERT INTO RESTAURANT_TABLE(ID, MODIFICATION_COUNTER, SEATS) VALUES (0, 1, 4);\nINSERT INTO RESTAURANT_TABLE(ID, MODIFICATION_COUNTER, SEATS) VALUES (1, 1, 4);\nINSERT INTO RESTAURANT_TABLE(ID, MODIFICATION_COUNTER, SEATS) VALUES (2, 1, 4);\nINSERT INTO RESTAURANT_TABLE(ID, MODIFICATION_COUNTER, SEATS) VALUES (3, 1, 4);\nINSERT INTO RESTAURANT_TABLE(ID, MODIFICATION_COUNTER, SEATS) VALUES (4, 1, 6);\nINSERT INTO RESTAURANT_TABLE(ID, MODIFICATION_COUNTER, SEATS) VALUES (5, 1, 6);\nINSERT INTO RESTAURANT_TABLE(ID, MODIFICATION_COUNTER, SEATS) VALUES (6, 1, 6);\nINSERT INTO RESTAURANT_TABLE(ID, MODIFICATION_COUNTER, SEATS) VALUES (7, 1, 8);\nINSERT INTO RESTAURANT_TABLE(ID, MODIFICATION_COUNTER, SEATS) VALUES (8, 1, 8);\n...\nSee also Database Migrations.\n"},{"id":111,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-database-migration.asciidoc","type":"docs","title":"Database Migration","body":"12.7. Database Migration\nFor database migrations we use Flyway.\nAs illustrated here database migrations have three advantages:\nRecreate a database from scratch\nMake it clear at all times what state a database is in\nMigrate in a deterministic way from your current version of the database to a newer one\nFlyway can be used standalone or can be integrated via its API to make sure the database migration takes place on startup.\n"},{"id":112,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-database-migration.asciidoc_organizational-advice","type":"docs","title":"Organizational Advice","body":"12.7.1. Organizational Advice\nA few considerations with respect to project organization will help to implement maintainable Flyway migrations.\nAt first, testing and production environments must be clearly and consistently distinguished. Use the following directory structure to achieve this distinction:\nsrc/main/resources/db\nsrc/test/resources/db\nAlthough this structure introduces redundancies, the benefit outweighs this disadvantage.\nAn even more fine-grained production directory structure which contains one sub folder per release should be implemented:\nsrc/main/resources/db/migration/releases/X.Y/x.sql\nEmphasizing that migration scripts below the current version must never be changed will aid the second advantage of migrations: it will always be clearly reproducible in which state the database currently is.\nHere, it is important to mention that, if test data is required, it must be managed separately from the migration data in the following directory:\nsrc/test/resources/db/migration/\nThe migration directory is added to aid easy usage of Flyway defaults.\nOf course, test data should also be managed per release as like production data.\nWith regard to content, separation of concerns (SoC) is an important goal. SoC can be achieved by distinguishing and writing multiple scripts with respect to business components/use cases (or database tables in case of large volumes of master data [1]. Comprehensible file names aid this separation.\nIt is important to have clear responsibilities regarding the database, the persistence layer (JPA), and migrations. Therefore a dedicated database expert should be in charge of any migrations performed or she should at least be informed before any change to any of the mentioned parts is applied.\n"},{"id":113,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-database-migration.asciidoc_technical-configuration","type":"docs","title":"Technical Configuration","body":"12.7.2. Technical Configuration\nDatabase migrations can be SQL based or Java based.\nTo enable auto migration on startup (not recommended for productive environment) set the following property in the application.properties file for an environment.\nflyway.enabled=true\nflyway.clean-on-validation-error=false\nFor development environment it is helpful to set both properties to true in order to simplify development. For regular environments flyway.clean-on-validation-error should be false.\nIf you want to use Flyway set the following property in any case to prevent Hibernate from doing changes on the database (pre-configured by default in devonfw):\nspring.jpa.hibernate.ddl-auto=validate\nThe setting must be communicated to and coordinated with the customer and their needs.\nIn acceptance testing the same configuration as for the production environment should be enabled.\nSince migration scripts will also be versioned the end-of-line (EOL) style must be fixated according to this issue. This is however solved in flyway 4.0+ and the latest devonfw release.\nAlso, the version numbers of migration scripts should not consist of simple ascending integer numbers like V0001&#x2026;&#x200B;, V0002&#x2026;&#x200B;, &#x2026;&#x200B; This naming may lead to problems when merging branches. Instead the usage of timestamps as version numbers will help to avoid such problems.\n"},{"id":114,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-database-migration.asciidoc_naming-conventions","type":"docs","title":"Naming Conventions","body":"12.7.3. Naming Conventions\nDatabase migrations should follow this naming convention:\nV&lt;version&gt;__&lt;description&gt; (e.g.: V12345__Add_new_table.sql).\nIt is also possible to use Flyway for test data. To do so place your test data migrations in src/main/resources/db/testdata/ and set property\nflyway.locations=classpath:db/migration/releases,classpath:db/migration/testdata\nThen Flyway scans the additional location for migrations and applies all in the order specified by their version. If migrations V0001__... and V0002__... exist and a test data migration should be applied in between you can name it V0001_1__....\n"},{"id":115,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-logging.asciidoc","type":"docs","title":"Logging","body":"12.8. Logging\nWe use SLF4J as API for logging. The recommended implementation is Logback for which we provide additional value such as configuration templates and an appender that prevents log-forging and reformatting of stack-traces for operational optimizations.\n"},{"id":116,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-logging.asciidoc_usage","type":"docs","title":"Usage","body":"12.8.1. Usage\nMaven Integration\nIn the pom.xml of your application add this dependency (that also adds transitive dependencies to SLF4J and logback):\n&lt;dependency&gt;\n&lt;groupId&gt;com.devonfw.java&lt;/groupId&gt;\n&lt;artifactId&gt;devon4j-logging&lt;/artifactId&gt;\n&lt;/dependency&gt;\nConfiguration\nThe configuration file is logback.xml and is to put in the directory src/main/resources of your main application. For details consult the logback configuration manual. devon4j provides a production ready configuration here. Simply copy this configuration into your application in order to benefit from the provided operational and security aspects. We do not include the configuration into the devon4j-logging module to give you the freedom of customizations (e.g. tune log levels for components and integrated products and libraries of your application).\nThe provided logback.xml is configured to use variables defined on the config/application.properties file. On our example, the log files path point to ../logs/ in order to log to tomcat log directory when starting tomcat on the bin folder. Change it according to your custom needs.\nListing 8. config/application.properties\nlog.dir=../logs/\nLogger Access\nThe general pattern for accessing loggers from your code is a static logger instance per class. We pre-configured the development environment so you can just type LOG and hit [ctrl][space] (and then [arrow up]) to insert the code pattern line into your class:\npublic class MyClass {\nprivate static final Logger LOG = LoggerFactory.getLogger(MyClass.class);\n...\n}\nPlease note that in this case we are not using injection pattern but use the convenient static alternative. This is already a common solution and also has performance benefits.\nHow to log\nWe use a common understanding of the log-levels as illustrated by the following table. This helps for better maintenance and operation of the systems by combining both views.\nTable 30. Log-levels\nLog-level\nDescription\nImpact\nActive Environments\nFATAL\nOnly used for fatal errors that prevent the application to work at all (e.g. startup fails or shutdown/restart required)\nOperator has to react immediately\nall\nERROR\nAn abnormal error indicating that the processing failed due to technical problems.\nOperator should check for known issue and otherwise inform development\nall\nWARNING\nA situation where something worked not as expected. E.g. a business exception or user validation failure occurred.\nNo direct reaction required. Used for problem analysis.\nall\nINFO\nImportant information such as context, duration, success/failure of request or process\nNo direct reaction required. Used for analysis.\nall\nDEBUG\nDevelopment information that provides additional context for debugging problems.\nNo direct reaction required. Used for analysis.\ndevelopment and testing\nTRACE\nLike DEBUG but exhaustive information and for code that is run very frequently. Will typically cause large log-files.\nNo direct reaction required. Used for problem analysis.\nnone (turned off by default)\nExceptions (with their stacktrace) should only be logged on FATAL or ERROR level. For business exceptions typically a WARNING including the message of the exception is sufficient.\n"},{"id":117,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-logging.asciidoc_operations","type":"docs","title":"Operations","body":"12.8.2. Operations\nLog Files\nWe always use the following log files:\nError Log: Includes log entries to detect errors.\nInfo Log: Used to analyze system status and to detect bottlenecks.\nDebug Log: Detailed information for error detection.\nThe log file name pattern is as follows:\n&#xAB;LOGTYPE&#xBB;_log_&#xAB;HOST&#xBB;_&#xAB;APPLICATION&#xBB;_&#xAB;TIMESTAMP&#xBB;.log\nTable 31. Segments of Logfilename\nElement\nValue\nDescription\n&#xAB;LOGTYPE&#xBB;\ninfo, error, debug\nType of log file\n&#xAB;HOST&#xBB;\ne.g. mywebserver01\nName of server, where logs are generated\n&#xAB;APPLICATION&#xBB;\ne.g. myapp\nName of application, which causes logs\n&#xAB;TIMESTAMP&#xBB;\nYYYY-MM-DD_HH00\ndate of log file\nExample:\nerror_log_mywebserver01_myapp_2013-09-16_0900.log\nError log from mywebserver01 at application myapp at 16th September 2013 9pm.\nOutput format\nWe use the following output format for all log entries to ensure that searching and filtering of log entries work consistent for all logfiles:\n[D: &#xAB;timestamp&#xBB;] [P: &#xAB;priority&#xBB;] [C: &#xAB;NDC&#xBB;][T: &#xAB;thread&#xBB;][L: &#xAB;logger&#xBB;]-[M: &#xAB;message&#xBB;]\nD: Date (Timestamp in ISO8601 format e.g. 2013-09-05 16:40:36,464)\nP: Priority (the log level)\nC: Correlation ID (ID to identify users across multiple systems, needed when application is distributed)\nT: Thread (Name of thread)\nL: Logger name (use class name)\nM: Message (log message)\nExample:\n[D: 2013-09-05 16:40:36,464] [P: DEBUG] [C: 12345] [T: main] [L: my.package.MyClass]-[M: My message...]\n"},{"id":118,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-logging.asciidoc_security","type":"docs","title":"Security","body":"12.8.3. Security\nIn order to prevent log forging attacks we provide a special appender for logback in devon4j-logging. If you use it (see configuration) you are safe from such attacks.\n"},{"id":119,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-logging.asciidoc_correlation-id","type":"docs","title":"Correlation ID","body":"12.8.4. Correlation ID\nIn order to correlate separate HTTP requests to services belonging to the same user / session, we provide a servlet filter called DiagnosticContextFilter. This filter takes a provided correlation ID from the HTTP header X-Correlation-Id. If none was found, it will generate a new correlation id as UUID. This correlation ID is added as MDC to the logger. Therefore, it will then be included to any log message of the current request (thread). Further concepts such as service invocations will pass this correlation ID to subsequent calls in the application landscape. Hence you can find all log messages related to an initial request simply via the correlation ID even in highly distributed systems.\n"},{"id":120,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-logging.asciidoc_monitoring","type":"docs","title":"Monitoring","body":"12.8.5. Monitoring\nIn highly distributed systems (from clustering up to microservices) it might get tedious to search for problems and details in log files. Therefore, we recommend to setup a central log and analysis server for your application landscape. Then you feed the logs from all your applications (using logstash) into that central server that adds them to a search index to allow fast searches (using elasticsearch). This should be completed with a UI that allows dashboards and reports based on data aggregated from all the logs.\nThis is addressed by ELK or Graylog.\nAdding custom values to JSON log\nWhen you use a external system for gathering distrubited logs, we strongly suggest that you use a JSON based log format (e.g. by using the provided logback.xml, see above).\nIn that case it might be useful to log customs field to the produced JSON. This is fully supported by slf4j together with logstash. The trick is to use the class net.logstash.logback.argument.StructuredArguments for adding the arguments to you log message, e.g.\nimport static net.logstash.logback.argument.StructuredArguments.v;\n...\npublic void processMessage(MyMessage msg) {\nLOG.info(&quot;Processing message with {}&quot;, v(&quot;msgId&quot;, msg.getId());\n...\n}\nThis will produce something like:\n{ &quot;timestamp&quot;:&quot;2018-11-06T18:36:37.638+00:00&quot;,\n&quot;@version&quot;:&quot;1&quot;,\n&quot;message&quot;:&quot;Processing message with msgId=MSG-999-000&quot;,\n&quot;msgId&quot;:&quot;MSG-999-000&quot;,\n&quot;logger_name&quot;:&quot;com.myapplication...Processor&quot;,\n&quot;thread_name&quot;:&quot;http-nio-8081-exec-6&quot;,\n&quot;level&quot;:&quot;INFO&quot;,\n&quot;level_value&quot;:20000,\n&quot;appname&quot;:&quot;basic&quot;,}\n"},{"id":121,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-security.asciidoc","type":"docs","title":"Security","body":"12.9. Security\nSecurity is todays most important cross-cutting concern of an application and an enterprise IT-landscape. We seriously care about security and give you detailed guides to prevent pitfalls, vulnerabilities, and other disasters. While many mistakes can be avoided by following our guidelines you still have to consider security and think about it in your design and implementation. The security guide will not only automatically prevent you from any harm, but will provide you hints and best practices already used in different software products.\nAn important aspect of security is proper authentication and authorization as described in access-control. In the following we discuss about potential vulnerabilities and protection to prevent them.\n"},{"id":122,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-security.asciidoc_vulnerabilities-and-protection","type":"docs","title":"Vulnerabilities and Protection","body":"12.9.1. Vulnerabilities and Protection\nIndependent from classical authentication and authorization mechanisms there are many common pitfalls that can lead to vulnerabilities and security issues in your application such as XSS, CSRF, SQL-injection, log-forging, etc. A good source of information about this is the OWASP.\nWe address these common threats individually in security sections of our technological guides as a concrete solution to prevent an attack typically depends on the according technology. The following table illustrates common threats and contains links to the solutions and protection-mechanisms provided by the devonfw:\nTable 32. Security threats and protection-mechanisms\nThreat\nProtection\nLink to details\nA1 Injection\nvalidate input, escape output, use proper frameworks\nSQL Injection\nA2 Broken Authentication\nencrypt all channels, use a central identity management with strong password-policy\nAuthentication\nA3 Sensitive Data Exposure\nUse secured exception facade, design your data model accordingly\nREST exception handling\nA4 XML External Entities\nPrefer JSON over XML, ensure FSP when parsing (external) XML\nXML guide\nA5 Broken Access Control\nEnsure proper authorization for all use-cases, use @DenyAll as default to enforce\nAccess-control guide especially method authorization\nA6 Security Misconfiguration\nUse devon4j application template and guides to avoid\ntutorial-newapp and sensitive configuration\nA7 Cross-Site Scripting\nprevent injection (see A1) for HTML, JavaScript and CSS and understand same-origin-policy\nclient-layer\nA8 Insecure Deserialization\nUse simple and established serialization formats such as JSON, prevent generic deserialization (for polymorphic types)\nJSON guide especially inheritence, XML guide\nA9 Using Components with Known Vulnerabilities\nsubscribe to security newsletters, recheck products and their versions continuously, use devonfw dependency management\nCVE newsletter and dependency check\nA10 Insufficient_Logging &amp; Monitoring\nEnsure to log all security related events (login, logout, errors), establish effective monitoring\nLogging guide and monitoring guide\nInsecure Direct Object References\nUsing direct object references (IDs) only with appropriate authorization\nlogic-layer\nCross-Site Request Forgery (CSRF)\nsecure mutable service operations with an explicit CSRF security token sent in HTTP header and verified on the server\nCSRF guide\nLog-Forging\nEscape newlines in log messages\nlogging security\nUnvalidated Redirects and Forwards\nAvoid using redirects and forwards, in case you need them do a security audit on the solution.\ndevonfw proposes to use rich-clients (SPA/RIA). We only use redirects for login in a safe way.\n"},{"id":123,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-security.asciidoc_advanced-security","type":"docs","title":"Advanced Security","body":"12.9.2. Advanced Security\nWhile OWASP Top 10 covers the basic aspects of application security, there are advanced standards such as AVS.\nIn devonfw we address this in the \nApplication Security Quick Solution Guide.\n"},{"id":124,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-security.asciidoc_tools","type":"docs","title":"Tools","body":"12.9.3. Tools\nDependency Check\nTo address the thread Using Components with Known Vulnerabilities we integrated OWASP dependency check into the devon4j maven build. If you build an devon4j application (sample or any app created from our app-template) you can activate dependency check with the security profile:\nmvn clean install -P security\nThis does not run by default as it causes some overhead for the build performance. However, consider to build this in your CI at least nightly.\nAfter the dependency check is performed, you will find the results in target/dependency-check-report.html of each module. The report will also be generated when the site is build (mvn site) even without the profile.\nPenetration Testing\nFor penetration testing (testing for vulnerabilities) of your web application, we recommend the following tools:\nZAP (OWASP Zed Attack Proxy Project)\nsqlmap (or HQLmap)\nnmap\nSee the marvelous presentation Toolbox of a security professional from Christian Schneider.\n"},{"id":125,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-access-control.asciidoc","type":"docs","title":"Access-Control","body":"12.10. Access-Control\nAccess-Control is a central and important aspect of Security. It consists of two major aspects:\nAuthentication (Who tries to access?)\nAuthorization (Is the one accessing allowed to do what he wants to do?)\n"},{"id":126,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-access-control.asciidoc_authentication","type":"docs","title":"Authentication","body":"12.10.1. Authentication\nDefinition:\nAuthentication is the verification that somebody interacting with the system is the actual subject for whom he claims to be.\nThe one authenticated is properly called subject or principal. However, for simplicity we use the common term user even though it may not be a human (e.g. in case of a service call from an external system).\nTo prove his authenticity the user provides some secret called credentials. The most simple form of credentials is a password.\nNote\nPlease never implement your own authentication mechanism or credential store. You have to be aware of implicit demands such as salting and hashing credentials, password life-cycle with recovery, expiry, and renewal including email notification confirmation tokens, central password policies, etc. This is the domain of access managers and identity management systems. In a business context you will typically already find a system for this purpose that you have to integrate (e.g. via LDAP). Otherwise you should consider establishing such a system e.g. using keycloak.\nWe use spring-security as a framework for authentication purposes.\nTherefore you need to provide an implementation of WebSecurityConfigurerAdapter:\n@Configuration\n@EnableWebSecurity\npublic class MyWebSecurityConfig extends WebSecurityConfigurerAdapter {\n@Inject\nprivate UserDetailsService userDetailsService;\n...\npublic void configure(HttpSecurity http) throws Exception {\nhttp.userDetailsService(this.userDetailsService)\n.authorizeRequests().antMatchers(&quot;/public/**&quot;).permitAll()\n.anyRequest().authenticated().and()\n...\n}\n}\nAs you can see spring-security offers a fluent API for easy configuration. You can simply add invocations like formLogin().loginPage(&quot;/public/login&quot;) or httpBasic().realmName(&quot;MyApp&quot;). Also CSRF protection can be configured by invoking csrf().\nFor further details see spring Java-config for HTTP security.\nFurther, you need to provide an implementation of the UserDetailsService interface.\nA good starting point comes with our application template.\nPreserve original request anchors after form login redirect\nSpring Security will automatically redirect any unauthorized access to the defined login-page. After successful login, the user will be redirected to the original requested URL. The only pitfall is, that anchors in the request URL will not be transmitted to server and thus cannot be restored after successful login. Therefore the devon4j-security module provides the RetainAnchorFilter, which is able to inject javascript code to the source page and to the target page of any redirection. Using javascript this filter is able to retrieve the requested anchors and store them into a cookie. Heading the target URL this cookie will be used to restore the original anchors again.\nTo enable this mechanism you have to integrate the RetainAnchorFilter as follows:\nFirst, declare the filter with\nstoreUrlPattern: an regular expression matching the URL, where anchors should be stored\nrestoreUrlPattern: an regular expression matching the URL, where anchors should be restored\ncookieName: the name of the cookie to save the anchors in the intermediate time\nYou can easily configure this as code in your WebSecurityConfig as following:\nRetainAnchorFilter filter = new RetainAnchorFilter();\nfilter.setStoreUrlPattern(&quot;http://[^/]+/[^/]+/login.*&quot;);\nfilter.setRestoreUrlPattern(&quot;http://[^/]+/[^/]+/.*&quot;);\nfilter.setCookieName(&quot;TARGETANCHOR&quot;);\nhttp.addFilterBefore(filter, UsernamePasswordAuthenticationFilter.class);\nUsers vs. Systems\nIf we are talking about authentication we have to distinguish two forms of principals:\nhuman users\nautonomous systems\nWhile e.g. a Kerberos/SPNEGO Single-Sign-On makes sense for human users it is pointless for authenticating autonomous systems. So always keep this in mind when you design your authentication mechanisms and separate access for human users from access for systems.\nUsing JWT\nFor authentication via JSON Web Token (JWT) see JWT guide.\nMixed Authentication\nIn rare cases you might need to mix multiple authentication mechanisms (form based, basic-auth, SAMLv2, OAuth, etc.) within the same app (for different URLs). For KISS this should be avoided where possible. However, when needed, you can find a solution\nhere.\n"},{"id":127,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-access-control.asciidoc_authorization","type":"docs","title":"Authorization","body":"12.10.2. Authorization\nDefinition:\nAuthorization is the verification that an authenticated user is allowed to perform the operation he intends to invoke.\nClarification of terms\nFor clarification we also want to give a common understanding of related terms that have no unique definition and consistent usage in the wild.\nTable 33. Security terms related to authorization\nTerm\nMeaning and comment\nPermission\nA permission is an object that allows a principal to perform an operation in the system. This permission can be granted (give) or revoked (taken away). Sometimes people also use the term right what is actually wrong as a right (such as the right to be free) can not be revoked.\nGroup\nWe use the term group in this context for an object that contains permissions. A group may also contain other groups. Then the group represents the set of all recursively contained permissions.\nRole\nWe consider a role as a specific form of group that also contains permissions. A role identifies a specific function of a principal. A user can act in a role.\nFor simple scenarios a principal has a single role associated. In more complex situations a principal can have multiple roles but has only one active role at a time that he can choose out of his assigned roles. For KISS it is sometimes sufficient to avoid this by creating multiple accounts for the few users with multiple roles. Otherwise at least avoid switching roles at run-time in clients as this may cause problems with related states. Simply restart the client with the new role as parameter in case the user wants to switch his role.\nAccess Control\nAny permission, group, role, etc., which declares a control for access management.\nSuggestions on the access model\nFor the access model we give the following suggestions:\nEach Access Control (permission, group, role, &#x2026;&#x200B;) is uniquely identified by a human readable string.\nWe create a unique permission for each use-case.\nWe define groups that combine permissions to typical and useful sets for the users.\nWe define roles as specific groups as required by our business demands.\nWe allow to associate users with a list of Access Controls.\nFor authorization of an implemented use case we determine the required permission. Furthermore, we determine the current user and verify that the required permission is contained in the tree spanned by all his associated Access Controls. If the user does not have the permission we throw a security exception and thus abort the operation and transaction.\nWe avoid negative permissions, that is a user has no permission by default and only those granted to him explicitly give him additional permission for specific things. Permissions granted can not be reduced by other permissions.\nTechnically we consider permissions as a secret of the application. Administrators shall not fiddle with individual permissions but grant them via groups. So the access management provides a list of strings identifying the Access Controls of a user. The individual application itself contains these Access Controls in a structured way, whereas each group forms a permission tree.\nNaming conventions\nAs stated above each Access Control is uniquely identified by a human readable string. This string should follow the naming convention:\n&#xAB;app-id&#xBB;.&#xAB;local-name&#xBB;\nFor Access Control Permissions the &#xAB;local-name&#xBB; again follows the convention:\n&#xAB;verb&#xBB;&#xAB;object&#xBB;\nThe segments are defined by the following table:\nTable 34. Segments of Access Control Permission ID\nSegment\nDescription\nExample\n&#xAB;app-id&#xBB;\nIs a unique technical but human readable string of the application (or microservice). It shall not contain special characters and especially no dot or whitespace. We recommend to use lower-train-case-ascii-syntax. The identity and access management should be organized on enterprise level rather than application level. Therefore permissions of different apps might easily clash (e.g. two apps might both define a group ReadMasterData but some user shall get this group for only one of these two apps). Using the &#xAB;app-id&#xBB;. prefix is a simple but powerful namespacing concept that allows you to scale and grow. You may also reserve specific &#xAB;app-id&#xBB;s for cross-cutting concerns that do not actually reflect a single app e.g to grant access to a geographic region.\nshop\n&#xAB;verb&#xBB;\nThe action that is to be performed on &#xAB;object&#xBB;. We use Find for searching and reading data. Save shall be used both for create and update. Only if you really have demands to separate these two you may use Create in addition to Save. Finally, Delete is used for deletions. For non CRUD actions you are free to use additional verbs such as Approve or Reject.\nFind\n&#xAB;object&#xBB;\nThe affected object or entity. Shall be named according to your data-model\nProduct\nSo as an example shop.FindProduct will reflect the permission to search and retrieve a Product in the shop application. The group shop.ReadMasterData may combine all permissions to read master-data from the shop. However, also a group shop.Admin may exist for the Admin role of the shop application. Here the &#xAB;local-name&#xBB; is Admin that does not follow the &#xAB;verb&#xBB;&#xAB;object&#xBB; schema.\ndevon4j-security\nThe module devon4j-security provides ready-to-use code based on spring-security that makes your life a lot easier.\nFigure 6. devon4j Security Model\nThe diagram shows the model of devon4j-security that separates two different aspects:\nThe Identity- and Access-Management is provided by according products and typically already available in the enterprise landscape (e.g. an active directory). It provides a hierarchy of primary access control objects (roles and groups) of a user. An administrator can grant and revoke permissions (indirectly) via this way.\nThe application security defines a hierarchy of secondary access control objects (groups and permissions). This is done by configuration owned by the application (see following section). The &quot;API&quot; is defined by the IDs of the primary access control objects that will be referenced from the Identity- and Access-Management.\nAccess Control Config\nIn your application simply extend AccessControlConfig to configure your access control objects as code and reference it from your use-cases. An example config may look like this:\n@Named\npublic class ApplicationAccessControlConfig extends AccessControlConfig {\npublic static final String APP_ID = &quot;MyApp&quot;;\nprivate static final String PREFIX = APP_ID + &quot;.&quot;;\npublic static final String PERMISSION_FIND_OFFER = PREFIX + &quot;FindOffer&quot;;\npublic static final String PERMISSION_SAVE_OFFER = PREFIX + &quot;SaveOffer&quot;;\npublic static final String PERMISSION_DELETE_OFFER = PREFIX + &quot;DeleteOffer&quot;;\npublic static final String PERMISSION_FIND_PRODUCT = PREFIX + &quot;FindProduct&quot;;\npublic static final String PERMISSION_SAVE_PRODUCT = PREFIX + &quot;SaveProduct&quot;;\npublic static final String PERMISSION_DELETE_PRODUCT = PREFIX + &quot;DeleteProduct&quot;;\npublic static final String GROUP_READ_MASTER_DATA = PREFIX + &quot;ReadMasterData&quot;;\npublic static final String GROUP_MANAGER = PREFIX + &quot;Manager&quot;;\npublic static final String GROUP_ADMIN = PREFIX + &quot;Admin&quot;;\npublic ApplicationAccessControlConfig() {\nsuper();\nAccessControlGroup readMasterData = group(GROUP_READ_MASTER_DATA, PERMISSION_FIND_OFFER, PERMISSION_FIND_PRODUCT);\nAccessControlGroup manager = group(GROUP_MANAGER, readMasterData, PERMISSION_SAVE_OFFER, PERMISSION_SAVE_PRODUCT);\nAccessControlGroup admin = group(GROUP_ADMIN, manager, PERMISSION_DELETE_OFFER, PERMISSION_DELETE_PRODUCT);\n}\n}\nConfiguration on Java Method level\nIn your use-case you can now reference a permission like this:\n@Named\npublic class UcSafeOfferImpl extends ApplicationUc implements UcSafeOffer {\n@Override\n@RolesAllowed(ApplicationAccessControlConfig.PERMISSION_SAVE_OFFER)\npublic OfferEto save(OfferEto offer) { ... }\n...\n}\nCheck Data-Permissions\nSee data permissions\nAccess Control Schema (deprecated)\nThe access-control-schema.xml approach is deprecated. The documentation can still be found in access control schema.\n"},{"id":128,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-access-control-schema.asciidoc","type":"docs","title":"Access Control Schema","body":"12.11. Access Control Schema\nWith release 3.0.0 the access-control-schema.xml has been deprecated. You may still use it and find the documentation in this section. However, for new devonfw applications always start with the new approach described in access control config.\n"},{"id":129,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-access-control-schema.asciidoc_legacy-access-control-schema-documentation","type":"docs","title":"Legacy Access Control Schema Documentation","body":"12.11.1. Legacy Access Control Schema Documentation\nThe file access-control-schema.xml is used to define the mapping from groups to permissions (see example from sample app). The general terms discussed above can be mapped to the implementation as follows:\nTable 35. General security terms related to devon4j access control schema\nTerm\ndevon4j-security implementation\nComment\nPermission\nAccessControlPermission\nGroup\nAccessControlGroup\nWhen considering different levels of groups of different meanings, declare type attribute, e.g. as &quot;group&quot;.\nRole\nAccessControlGroup\nWith type=&quot;role&quot;.\nAccess Control\nAccessControl\nSuper type that represents a tree of AccessControlGroups and AccessControlPermissions. If a principal &quot;has&quot; a AccessControl he also &quot;has&quot; all AccessControls with according permissions in the spanned sub-tree.\nListing 9. Example access-control-schema.xml\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;\n&lt;access-control-schema&gt;\n&lt;group id=&quot;ReadMasterData&quot; type=&quot;group&quot;&gt;\n&lt;permissions&gt;\n&lt;permission id=&quot;OfferManagement_GetOffer&quot;/&gt;\n&lt;permission id=&quot;OfferManagement_GetProduct&quot;/&gt;\n&lt;permission id=&quot;TableManagement_GetTable&quot;/&gt;\n&lt;permission id=&quot;StaffManagement_GetStaffMember&quot;/&gt;\n&lt;/permissions&gt;\n&lt;/group&gt;\n&lt;group id=&quot;Waiter&quot; type=&quot;role&quot;&gt;\n&lt;inherits&gt;\n&lt;group-ref&gt;Barkeeper&lt;/group-ref&gt;\n&lt;/inherits&gt;\n&lt;permissions&gt;\n&lt;permission id=&quot;TableManagement_ChangeTable&quot;/&gt;\n&lt;/permissions&gt;\n&lt;/group&gt;\n...\n&lt;/access-control-schema&gt;\nThis example access-control-schema.xml declares\na group named ReadMasterData, which grants four different permissions, e.g., OfferManagement_GetOffer\na group named Waiter, which\nalso grants all permissions from the group Barkeeper\nin addition grants the permission TableManagement_ChangeTable\nis marked to be a role for further application needs.\nThe devon4j-security module automatically validates the schema configuration and will throw an exception if invalid.\nUnfortunately, Spring Security does not provide differentiated interfaces for authentication and authorization. Thus we have to provide an AuthenticationProvider, which is provided from Spring Security as an interface for authentication and authorization simultaneously.\nTo integrate the devon4j-security provided access control schema, you can simply inherit your own implementation from the devon4j-security provided abstract class AbstractAccessControlBasedAuthenticationProvider and register your ApplicationAuthenticationProvider as an AuthenticationManager. Doing so, you also have to declare the two Beans AccessControlProvider and AccessControlSchemaProvider, which are precondition for the AbstractAccessControlBasedAuthenticationProvider.\nAs state of the art devon4j will focus on role-based authorization to cope with authorization for executing use case of an application.\nWe will use the JSR250 annotations, mainly @RolesAllowed, for authorizing method calls against the permissions defined in the annotation body. This has to be done for each use-case method in logic layer. Here is an example:\npublic class OrdermanagementImpl extends AbstractComponentFacade implements Ordermanagement {\n@RolesAllowed(Roles.WAITER)\npublic PaginatedListTo&lt;OrderCto&gt; findOrdersByPost(OrderSearchCriteriaTo criteria) {\nreturn findOrderCtos(criteria);\n}\n}\nNow this method can only be called if a user is logged-in that has the permission FIND_TABLE.\n"},{"id":130,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-data-permission.asciidoc","type":"docs","title":"Data-permissions","body":"12.11.2. Data-permissions\nIn some projects there are demands for permissions and authorization that is dependent on the processed data. E.g. a user may only be allowed to read or write data for a specific region. This is adding some additional complexity to your authorization. If you can avoid this it is always best to keep things simple. However, in various cases this is a requirement. Therefore the following sections give you guidance and patterns how to solve this properly.\nStructuring your data\nFor all your business objects (entities) that have to be secured regarding to data permissions we recommend that you create a separate interface that provides access to the relevant data required to decide about the permission. Here is a simple example:\npublic interface SecurityDataPermissionCountry {\n/**\n* @return the 2-letter ISO code of the country this object is associated with. Users need\n* a data-permission for this country in order to read and write this object.\n*/\nString getCountry();\n}\nNow related business objects (entities) can implement this interface. Often such data-permissions have to be applied to an entire object-hierarchy. For security reasons we recommend that also all child-objects implement this interface. For performance reasons we recommend that the child-objects redundantly store the data-permission properties (such as country in the example above) and this gets simply propagated from the parent, when a child object is created.\nPermissions for processing data\nWhen saving or processing objects with a data-permission, we recommend to provide dedicated methods to verify the permission in an abstract base-class such as AbstractUc and simply call this explicitly from your business code. This makes it easy to understand and debug the code. Here is a simple example:\nprotected void verifyPermission(SecurityDataPermissionCountry entity) throws AccessDeniedException;\nBeware of AOP\nFor simple but cross-cutting data-permissions you may also use AOP. This leads to programming aspects that reflectively scan method arguments and magically decide what to do. Be aware that this quickly gets tricky:\nWhat if multiple of your method arguments have data-permissions (e.g. implement SecurityDataPermission*)?\nWhat if the object to authorize is only provided as reference (e.g. Long or IdRef) and only loaded and processed inside the implementation where the AOP aspect does not apply?\nHow to express advanced data-permissions in annotations?\nWhat we have learned is that annotations like @PreAuthorize from spring-security easily lead to the &quot;programming in string literals&quot; anti-pattern. We strongly discourage to use this anti-pattern. In such case writing your own verifyPermission methods that you manually call in the right places of your business-logic is much better to understand, debug and maintain.\nPermissions for reading data\nWhen it comes to restrictions on the data to read it becomes even more tricky. In the context of a user only entities shall be loaded from the database he is permitted to read. This is simple for loading a single entity (e.g. by its ID) as you can load it and then if not permitted throw an exception to secure your code. But what if the user is performing a search query to find many entities? For performance reasons we should only find data the user is permitted to read and filter all the rest already via the database query. But what if this is not a requirement for a single query but needs to be applied cross-cutting to tons of queries? Therefore we have the following pattern that solves your problem:\nFor each data-permission attribute (or set of such) we create an abstract base entity:\n@MappedSuperclass\n@EntityListeners(PermissionCheckListener.class)\n@FilterDef(name = &quot;country&quot;, parameters = {@ParamDef(name = &quot;countries&quot;, type = &quot;string&quot;)})\n@Filter(name = &quot;country&quot;, condition = &quot;country in (:countries)&quot;)\npublic abstract class SecurityDataPermissionCountryEntity extends ApplicationPersistenceEntity\nimplements SecurityDataPermissionCountry {\nprivate String country;\n@Override\npublic String getCountry() {\nreturn this.country;\n}\npublic void setCountry(String country) {\nthis.country = country;\n}\n}\nThere are some special hibernate annotations @EntityListeners, @FilterDef, and @Filter used here allowing to apply a filter on the country for any (non-native) query performed by hibernate. The entity listener may look like this:\npublic class PermissionCheckListener {\n@PostLoad\npublic void read(SecurityDataPermissionCountryEntity entity) {\nPermissionChecker.getInstance().requireReadPermission(entity);\n}\n@PrePersist\n@PreUpdate\npublic void write(SecurityDataPermissionCountryEntity entity) {\nPermissionChecker.getInstance().requireWritePermission(entity);\n}\n}\nThis will ensure that hibernate implicitly will call these checks for every such entity when it is read from or written to the database. Further to avoid reading entities from the database the user is not permitted to (and ending up with exceptions), we create an AOP aspect that automatically activates the above declared hibernate filter:\n@Named\npublic class PermissionCheckerAdvice implements MethodBeforeAdvice {\n@Inject\nprivate PermissionChecker permissionChecker;\n@PersistenceContext\nprivate EntityManager entityManager;\n@Override\npublic void before(Method method, Object[] args, Object target) {\nCollection&lt;String&gt; permittedCountries = this.permissionChecker.getPermittedCountriesForReading();\nif (permittedCountries != null) { // null is returned for admins that may access all countries\nif (permittedCountries.isEmpty()) {\nthrow new AccessDeniedException(&quot;Not permitted for any country!&quot;);\n}\nSession session = this.entityManager.unwrap(Session.class);\nsession.enableFilter(&quot;country&quot;).setParameterList(&quot;countries&quot;, permittedCountries.toArray());\n}\n}\n}\nFinally to apply this aspect to all Repositories (can easily be changed to DAOs) implement the following advisor:\n@Named\npublic class PermissionCheckerAdvisor implements PointcutAdvisor, Pointcut, ClassFilter, MethodMatcher {\n@Inject\nprivate PermissionCheckerAdvice advice;\n@Override\npublic Advice getAdvice() {\nreturn this.advice;\n}\n@Override\npublic boolean isPerInstance() {\nreturn false;\n}\n@Override\npublic Pointcut getPointcut() {\nreturn this;\n}\n@Override\npublic ClassFilter getClassFilter() {\nreturn this;\n}\n@Override\npublic MethodMatcher getMethodMatcher() {\nreturn this;\n}\n@Override\npublic boolean matches(Method method, Class&lt;?&gt; targetClass) {\nreturn true; // apply to all methods\n}\n@Override\npublic boolean isRuntime() {\nreturn false;\n}\n@Override\npublic boolean matches(Method method, Class&lt;?&gt; targetClass, Object... args) {\nthrow new IllegalStateException(&quot;isRuntime()==false&quot;);\n}\n@Override\npublic boolean matches(Class&lt;?&gt; clazz) {\n// when using DAOs simply change to some class like ApplicationDao\nreturn DefaultRepository.class.isAssignableFrom(clazz);\n}\n}\nManaging and granting the data-permissions\nFollowing our authorization guide we can simply create a permission for each country. We might simply reserve a prefix (as virtual &#xAB;app-id&#xBB;) for each data-permission to allow granting data-permissions to end-users across all applications of the IT landscape. In our example we could create access controls country.DE, country.US, country.ES, etc. and assign those to the users. The method permissionChecker.getPermittedCountriesForReading() would then scan for these access controls and only return the 2-letter country code from it.\nCaution\nBefore you make your decisions how to design your access controls please clarify the following questions:\nDo you need to separate data-permissions independent of the functional permissions? E.g. may it be required to express that a user can read data from the countries ES and PL but is only permitted to modify data from PL? In such case a single assignment of &quot;country-permissions&quot; to users is insufficient.\nDo you want to grant data-permissions individually for each application (higher flexibility and complexity) or for the entire application landscape (simplicity, better maintenance for administrators)? In case of the first approach you would rather have access controls like app1.country.GB and app2.country.GB.\nDo your data-permissions depend on objects that can be created dynamically inside your application?\nIf you want to grant data-permissions on other business objects (entities), how do you want to reference them (primary keys, business keys, etc.)? What reference is most stable? Which is most readable?\n"},{"id":131,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-jwt.asciidoc","type":"docs","title":"JSON Web Token(JWT)","body":"12.12. JSON Web Token(JWT)\nJWT is an open standard (RFC 7519) for creating Json based access token that assert some number of claims.\nFor more information about JWT click here\n"},{"id":132,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-jwt.asciidoc_keystore","type":"docs","title":"Keystore","body":"12.12.1. Keystore\nA KeyStore is a repository of certificates and keys (public key, private key, or secret key). They can be used for TSL transportation, for encryption and decryption as well as for signing.\nFor demonstration you might create a keystore with openssl, with the following commands:\nopenssl req -x509 -newkey rsa:4096 -keyout key.pem -out cert.pem -days 365\nopenssl pkcs12 -export -in cert.pem -inkey key.pem -out example.p12\nFor Java tooling you may also try the following instead:\nkeytool -genkeypair -alias devonfw -keypass &quot;password&quot; -storetype PKCS12 -keyalg RSA -keysize 4096 -storepass &quot;password&quot; -keystore keystore.pkcs\nNote\nPlease use reasonable passwords instead of password what should be obvious. Also for the alias the value devonfw is just an example.\n"},{"id":133,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-jwt.asciidoc_dependency","type":"docs","title":"Dependency","body":"12.12.2. Dependency\nTo use JWT support from devon4j you have to add following required dependency.\n&lt;dependency&gt;\n&lt;groupId&gt;com.devonfw.java.starters&lt;/groupId&gt;\n&lt;artifactId&gt;devon4j-starter-security-jwt&lt;/artifactId&gt;\n&lt;/dependency&gt;\n"},{"id":134,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-jwt.asciidoc_configuration","type":"docs","title":"Configuration","body":"12.12.3. Configuration\nThe following properties need to be configured in your application.properties file:\n# location of the keystore file, can be any spring resource (such as file or classpath URIs)\nsecurity.keystore.location=classpath:config/keystore.pkcs\n# type of keystore e.g. &quot;PKCS12&quot; (recommended), &quot;JKS&quot;, or &quot;JCEKS&quot;\nsecurity.keystore.type=PKCS12\n# password the keystore is secured with. Consider using password encryption as described in devon4j configuration guide\nsecurity.keystore.password=password\n# the algorithm for encryption/decryption and signing - see io.jsonwebtoken.SignatureAlgorithm\nsecurity.authentication.jwt.algorithm=RS256\n# alias of public/private key in keystore (for validation only public key is used, for creation private key is required)\nsecurity.authentication.jwt.alias=devonfw\n# the following properties are used if you are validating JWTs (e.g. via JwtAuthenticationFilter)\nsecurity.authentication.jwt.validation.expiration-required=false\nsecurity.authentication.jwt.validation.max-validity=42h\nsecurity.authentication.jwt.validation.not-before-required=false\n# the following properties are only used if you are issuing JWTs (e.g. via JwtLoginFilter)\nsecurity.authentication.jwt.creation.add-issued-at=true\nsecurity.authentication.jwt.creation.validity=4h\nsecurity.authentication.jwt.creation.not-before-delay=1m\n# the following properties enable backward compatiblity for devon4j &lt;= 2021.04.002\n# after microprofile JWT is used by default since 2021.04.003\n#security.authentication.jwt.claims.access-controls-name=roles\n#security.authentication.jwt.claims.access-controls-array=false\nSee also JwtConfigProperties for details about configuration.\n"},{"id":135,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-jwt.asciidoc_authentication-with-jwt-via-oauth","type":"docs","title":"Authentication with JWT via OAuth","body":"12.12.4. Authentication with JWT via OAuth\nThe authentication with JWT via OAuth (HTTP header), will happen via JwtAuthenticationFilter that is automatically added by devon4j-starter-security-jwt via JwtAutoConfiguration.\nWith the starter and auto-configuration we want to make it as easy as possible for you.\nIn case you would like to build a server app that e.g. wants to issue JWTs but does not allow authentication via JWT itself, you can use devon4j-security-jwt as dependency instead of the starter and do the spring config yourself (pick and choose from JwtAutoConfiguration).\nTo do this, you need to add the following changes in your BaseWebSecurityConfig:\n@Bean\npublic JwtAuthenticationFilter getJwtAuthenticationFilter() {\nreturn new JwtAuthenticationFilter();\n}\n@Override\npublic void configure(HttpSecurity http) throws Exception {\n// ...\n// add this line to the end of this existing method\nhttp.addFilterBefore(getJwtAuthenticationFilter(), UsernamePasswordAuthenticationFilter.class);\n}\n"},{"id":136,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-jwt.asciidoc_login-with-username-and-password-to-get-jwt","type":"docs","title":"Login with Username and Password to get JWT","body":"12.12.5. Login with Username and Password to get JWT\nTo allow a client to login with username and password to get a JWT for sub-sequent requests, you need to do the following changes in your BaseWebSecurityConfig:\n@Bean\npublic JwtLoginFilter getJwtLoginFilter() throws Exception {\nJwtLoginFilter jwtLoginFilter = new JwtLoginFilter(&quot;/login&quot;);\njwtLoginFilter.setAuthenticationManager(authenticationManager());\njwtLoginFilter.setUserDetailsService(this.userDetailsService);\nreturn jwtLoginFilter;\n}\n@Override\npublic void configure(HttpSecurity http) throws Exception {\n// ...\n// add this line to the end of this existing method\nhttp.addFilterBefore(getJwtLoginFilter(), UsernamePasswordAuthenticationFilter.class);\n}\n"},{"id":137,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-jwt.asciidoc_authentication-with-kafka","type":"docs","title":"Authentication with Kafka","body":"12.12.6. Authentication with Kafka\nAuthentication with JWT and Kafka is explained in the Kafka guide.\n"},{"id":138,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-csrf.asciidoc","type":"docs","title":"Cross-site request forgery (CSRF)","body":"12.13. Cross-site request forgery (CSRF)\nCSRF is a type of malicious exploit of a web application that allows an attacker to induce users to perform actions that they do not intend to perform.\nMore details about csrf can be found at https://owasp.org/www-community/attacks/csrf.\n"},{"id":139,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-csrf.asciidoc_secure-devon4j-server-against-csrf","type":"docs","title":"Secure devon4j server against CSRF","body":"12.13.1. Secure devon4j server against CSRF\nIn case your devon4j server application is not accessed by browsers or the web-client is using JWT based authentication, you are already safe according to CSRF.\nHowever, if your application is accessed from a browser and you are using form based authentication (with session coockie) or basic authentication, you need to enable CSRF protection.\nThis guide will tell you how to do this.\nDependency\nTo secure your devon4j application against CSRF attacks, you only need to add the following dependency:\n&lt;dependency&gt;\n&lt;groupId&gt;com.devonfw.java.starters&lt;/groupId&gt;\n&lt;artifactId&gt;devon4j-starter-security-csrf&lt;/artifactId&gt;\n&lt;/dependency&gt;\nStarting with devon4j version 2020.12.001 application template, this is all you need to do.\nHowever, if you have started from an older version or you want to understand more, please read on.\nPluggable web-security\nTo enable pluggable security via devon4j security starters you need to apply WebSecurityConfigurer to your BaseWebSecurityConfig (your class extending spring-boot&#x2019;s WebSecurityConfigurerAdapter) as following:\n@Inject\nprivate WebSecurityConfigurer webSecurityConfigurer;\npublic void configure(HttpSecurity http) throws Exception {\n// disable CSRF protection by default, use csrf starter to override.\nhttp = http.csrf().disable();\n// apply pluggable web-security from devon4j security starters\nhttp = this.webSecurityConfigurer.configure(http);\n.....\n}\nCustom CsrfRequestMatcher\nIf you want to customize which HTTP requests will require a CSRF token, you can implement your own CsrfRequestMatcher and provide it to the devon4j CSRF protection via qualified injection as following:\n@Named(&quot;CsrfRequestMatcher&quot;)\npublic class CsrfRequestMatcher implements RequestMatcher {\n@Override\npublic boolean matches(HttpServletRequest request) {\n.....\n}\n}\nPlease note that the exact name (@Named(&quot;CsrfRequestMatcher&quot;)) is required here to ensure your custom implementation will be injected properly.\nCsrfRestService\nWith the devon4j-starter-security-csrf the CsrfRestService gets integrated into your app.\nIt provides an operation to get the CSRF token via an HTTP GET request.\nThe URL path to retrieve this CSRF token is services/rest/csrf/v1/token.\nAs a result you will get a JSON like the following:\n{\n&quot;token&quot;:&quot;3a8a5f66-c9eb-4494-81e1-7cc58bc3a519&quot;,\n&quot;parameterName&quot;:&quot;_csrf&quot;,\n&quot;headerName&quot;:&quot;X-CSRF-TOKEN&quot;\n}\nThe token value is a strong random value that will differ for each user session.\nIt has to be send with subsequent HTTP requests (when method is other than GET) in the specified header (X-CSRF-TOKEN).\nHow it works\nPutting it all together, a browser client should call the CsrfRestService after successfull login to receive the current CSRF token.\nWith every subsequent HTTP request (other than GET) the client has to send this token in the according HTTP header.\nOtherwise the server will reject the request to prevent CSRF attacks.\nTherefore, an attacker might make your browser perform HTTP requests towards your devon4j application backend via &lt;image&gt; elements, &lt;iframes&gt;, etc.\nYour browser will then still include your session coockie if you are already logged in (e.g. from another tab).\nHowever, in case he wants to trigger DELETE or POST requests trying your browser to make changes in the application (delete or update data, etc.) this will fail without CSRF token.\nThe attacker may make your browser retrieve the CSRF token but he will not be able to retrieve the result and put it into the header of other requests due to the same-origin-policy.\nThis way your application will be secured against CSRF attacks.\n"},{"id":140,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-csrf.asciidoc_configure-devon4ng-client-for-csrf","type":"docs","title":"Configure devon4ng client for CSRF","body":"12.13.2. Configure devon4ng client for CSRF\nDevon4ng client configuration for CSRF is described here\n"},{"id":141,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-validation.asciidoc","type":"docs","title":"Validation","body":"12.14. Validation\nValidation is about checking syntax and semantics of input data. Invalid data is rejected by the application.\nTherefore validation is required in multiple places of an application. E.g. the GUI will do validation for usability reasons to assist the user, early feedback and to prevent unnecessary server requests.\nOn the server-side validation has to be done for consistency and security.\nIn general we distinguish these forms of validation:\nstateless validation will produce the same result for given input at any time (for the same code/release).\nstateful validation is dependent on other states and can consider the same input data as valid in once case and as invalid in another.\n"},{"id":142,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-validation.asciidoc_stateless-validation","type":"docs","title":"Stateless Validation","body":"12.14.1. Stateless Validation\nFor regular, stateless validation we use the JSR303 standard that is also called bean validation (BV).\nDetails can be found in the specification.\nAs implementation we recommend hibernate-validator.\nExample\nA description of how to enable BV can be found in the relevant Spring documentation. For a quick summary follow these steps:\nMake sure that hibernate-validator is located in the classpath by adding a dependency to the pom.xml.\n&lt;dependency&gt;\n&lt;groupId&gt;org.hibernate&lt;/groupId&gt;\n&lt;artifactId&gt;hibernate-validator&lt;/artifactId&gt;\n&lt;/dependency&gt;\nAdd the @Validated annotation to the implementation (spring bean) to be validated. The standard use case is to annotate the logic layer implementation, i.e. the use case implementation or component facade in case of simple logic layer pattern. Thus, the validation will be executed for service requests as well as batch processing. For methods to validate go to their declaration and add constraint annotations to the method parameters.\n@Valid annotation to the arguments to validate (if that class itself is annotated with constraints to check).\n@NotNull for required arguments.\nOther constraints (e.g. @Size) for generic arguments (e.g. of type String or Integer). However, consider to create custom datatypes and avoid adding too much validation logic (especially redundant in multiple places).\n.BookingmanagementRestServiceImpl.java\n@Validated\npublic class BookingmanagementRestServiceImpl implements BookingmanagementRestService {\n...\npublic BookingEto saveBooking(@Valid BookingCto booking) {\n...\nFinally add appropriate validation constraint annotations to the fields of the ETO class.\n.BookingCto.java\n@Valid\nprivate BookingEto booking;\nListing 10. BookingEto.java\n@NotNull\n@Future\nprivate Timestamp bookingDate;\nA list with all bean validation constraint annotations available for hibernate-validator can be found here. In addition it is possible to configure custom constraints. Therefore it is necessary to implement a annotation and a corresponding validator. A description can also be found in the Spring documentation or with more details in the hibernate documentation.\nNote\nBean Validation in Wildfly &gt;v8: Wildfly v8 is the first version of Wildfly implementing the JEE7 specification. It comes with bean validation based on hibernate-validator out of the box. In case someone is running Spring in Wildfly for whatever reasons, the spring based annotation @Validated would duplicate bean validation at runtime and thus should be omitted.\nGUI-Integration\nTODO\nCross-Field Validation\nBV has poor support for this. Best practice is to create and use beans for ranges, etc. that solve this. A bean for a range could look like so:\npublic class Range&lt;V extends Comparable&lt;V&gt;&gt; {\nprivate V min;\nprivate V max;\npublic Range(V min, V max) {\nsuper();\nif ((min != null) &amp;&amp; (max != null)) {\nint delta = min.compareTo(max);\nif (delta &gt; 0) {\nthrow new ValueOutOfRangeException(null, min, min, max);\n}\n}\nthis.min = min;\nthis.max = max;\n}\npublic V getMin() ...\npublic V getMax() ...\n"},{"id":143,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-validation.asciidoc_stateful-validation","type":"docs","title":"Stateful Validation","body":"12.14.2. Stateful Validation\nFor complex and stateful business validations we do not use BV (possible with groups and context, etc.) but follow KISS and just implement this on the server in a straight forward manner.\nAn example is the deletion of a table in the example application. Here the state of the table must be checked first:\nBookingmanagementImpl.java\nprivate void sendConfirmationEmails(BookingEntity booking) {\nif (!booking.getInvitedGuests().isEmpty()) {\nfor (InvitedGuestEntity guest : booking.getInvitedGuests()) {\nsendInviteEmailToGuest(guest, booking);\n}\n}\nsendConfirmationEmailToHost(booking);\n}\nImplementing this small check with BV would be a lot more effort.\n"},{"id":144,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-aop.asciidoc","type":"docs","title":"Aspect Oriented Programming (AOP)","body":"12.15. Aspect Oriented Programming (AOP)\nAOP is a powerful feature for cross-cutting concerns. However, if used extensive and for the wrong things an application can get unmaintainable. Therefore we give you the best practices where and how to use AOP properly.\n"},{"id":145,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-aop.asciidoc_aop-key-principles","type":"docs","title":"AOP Key Principles","body":"12.15.1. AOP Key Principles\nWe follow these principles:\nWe use spring AOP based on dynamic proxies (and fallback to cglib).\nWe avoid AspectJ and other mighty and complex AOP frameworks whenever possible\nWe only use AOP where we consider it as necessary (see below).\n"},{"id":146,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-aop.asciidoc_aop-usage","type":"docs","title":"AOP Usage","body":"12.15.2. AOP Usage\nWe recommend to use AOP with care but we consider it established for the following cross cutting concerns:\nTransaction-Handling\nAuthorization\nValidation\nTrace-Logging (for testing and debugging)\nException facades for services but only if no other solution is possible (use alternatives such as JAX-RS provider instead).\n"},{"id":147,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-aop.asciidoc_aop-debugging","type":"docs","title":"AOP Debugging","body":"12.15.3. AOP Debugging\nWhen using AOP with dynamic proxies the debugging of your code can get nasty. As you can see by the red boxes in the call stack in the debugger there is a lot of magic happening while you often just want to step directly into the implementation skipping all the AOP clutter. When using Eclipse this can easily be archived by enabling step filters. Therefore you have to enable the feature in the Eclipse tool bar (highlighted in read).\nIn order to properly make this work you need to ensure that the step filters are properly configured:\nEnsure you have at least the following step-filters configured and active:\nch.qos.logback.*\ncom.devonfw.module.security.*\njava.lang.reflect.*\njava.security.*\njavax.persistence.*\norg.apache.commons.logging.*\norg.apache.cxf.jaxrs.client.*\norg.apache.tomcat.*\norg.h2.*\norg.springframework.*\n"},{"id":148,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-exceptions.asciidoc","type":"docs","title":"Exception Handling","body":"12.16. Exception Handling\n"},{"id":149,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-exceptions.asciidoc_exception-principles","type":"docs","title":"Exception Principles","body":"12.16.1. Exception Principles\nFor exceptions we follow these principles:\nWe only use exceptions for exceptional situations and not for programming control flows, etc. Creating an exception in Java is expensive and hence you should not do it just for testing if something is present, valid or permitted. In the latter case design your API to return this as a regular result.\nWe use unchecked exceptions (RuntimeException) [2]\nWe distinguish internal exceptions and user exceptions:\nInternal exceptions have technical reasons. For unexpected and exotic situations it is sufficient to throw existing exceptions such as IllegalStateException. For common scenarios a own exception class is reasonable.\nUser exceptions contain a message explaining the problem for end users. Therefore we always define our own exception classes with a clear, brief but detailed message.\nOur own exceptions derive from an exception base class supporting\nunique ID per instance\nError code per class\nmessage templating (see I18N)\ndistinguish between user exceptions and internal exceptions\nAll this is offered by mmm-util-core that we propose as solution.\n"},{"id":150,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-exceptions.asciidoc_exception-example","type":"docs","title":"Exception Example","body":"12.16.2. Exception Example\nHere is an exception class from our sample application:\npublic class IllegalEntityStateException extends ApplicationBusinessException {\nprivate static final long serialVersionUID = 1L;\npublic IllegalEntityStateException(Object entity, Object state) {\nthis((Throwable) null, entity, state);\n}\npublic IllegalEntityStateException(Object entity, Object currentState, Object newState) {\nthis(null, entity, currentState, newState);\n}\npublic IllegalEntityStateException(Throwable cause, Object entity, Object state) {\nsuper(cause, createBundle(NlsBundleApplicationRoot.class).errorIllegalEntityState(entity, state));\n}\npublic IllegalEntityStateException(Throwable cause, Object entity, Object currentState, Object newState) {\nsuper(cause, createBundle(NlsBundleApplicationRoot.class).errorIllegalEntityStateChange(entity, currentState,\nnewState));\n}\n}\nThe message templates are defined in the interface NlsBundleRestaurantRoot as following:\npublic interface NlsBundleApplicationRoot extends NlsBundle {\n@NlsBundleMessage(&quot;The entity {entity} is in state {state}!&quot;)\nNlsMessage errorIllegalEntityState(@Named(&quot;entity&quot;) Object entity, @Named(&quot;state&quot;) Object state);\n@NlsBundleMessage(&quot;The entity {entity} in state {currentState} can not be changed to state {newState}!&quot;)\nNlsMessage errorIllegalEntityStateChange(@Named(&quot;entity&quot;) Object entity, @Named(&quot;currentState&quot;) Object currentState,\n@Named(&quot;newState&quot;) Object newState);\n@NlsBundleMessage(&quot;The property {property} of object {object} can not be changed!&quot;)\nNlsMessage errorIllegalPropertyChange(@Named(&quot;object&quot;) Object object, @Named(&quot;property&quot;) Object property);\n@NlsBundleMessage(&quot;There is currently no user logged in&quot;)\nNlsMessage errorNoActiveUser();\n"},{"id":151,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-exceptions.asciidoc_handling-exceptions","type":"docs","title":"Handling Exceptions","body":"12.16.3. Handling Exceptions\nFor catching and handling exceptions we follow these rules:\nWe do not catch exceptions just to wrap or to re-throw them.\nIf we catch an exception and throw a new one, we always have to provide the original exception as cause to the constructor of the new exception.\nAt the entry points of the application (e.g. a service operation) we have to catch and handle all throwables. This is done via the exception-facade-pattern via an explicit facade or aspect. The devon4j-rest module already provides ready-to-use implementations for this such as RestServiceExceptionFacade. The exception facade has to &#x2026;&#x200B;\nlog all errors (user errors on info and technical errors on error level)\nensure the entire exception is passed to the logger (not only the message) so that the logger can capture the entire stacktrace and the root cause is not lost.\nconvert the error to a result appropriable for the client and secure for Sensitive Data Exposure. Especially for security exceptions only a generic security error code or message may be revealed but the details shall only be logged but not be exposed to the client. All internal exceptions are converted to a generic error with a message like:\nAn unexpected technical error has occurred. We apologize any inconvenience. Please try again later.\n"},{"id":152,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-exceptions.asciidoc_common-errors","type":"docs","title":"Common Errors","body":"12.16.4. Common Errors\nThe following errors may occur in any devon application:\nTable 36. Common Exceptions\nCode\nMessage\nLink\nTechnicalError\nAn unexpected error has occurred! We apologize any inconvenience. Please try again later.\nTechnicalErrorUserException.java\nServiceInvoke\n&#xAB;original message of the cause&#xBB;\nServiceInvocationFailedException.java\n"},{"id":153,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-i18n.asciidoc","type":"docs","title":"Internationalization","body":"12.17. Internationalization\nInternationalization (I18N) is about writing code independent from locale-specific information.\nFor I18N of text messages we are suggesting\nmmm native-language-support.\nIn devonfw we have developed a solution to manage text internationalization. devonfw solution comes into two aspects:\nBind locale information to the user.\nGet the messages in the current user locale.\n"},{"id":154,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-i18n.asciidoc_binding-locale-information-to-the-user","type":"docs","title":"Binding locale information to the user","body":"12.17.1. Binding locale information to the user\nWe have defined two different points to bind locale information to user, depending on user is authenticated or not.\nUser not authenticated: devonfw intercepts unsecured request and extract locale from it. At first, we try to extract a language parameter from the request and if it is not possible, we extract locale from &#xC0;ccept-language` header.\nUser authenticated. During login process, applications developers are responsible to fill language parameter in the UserProfile class. This language parameter could be obtain from DB, LDAP, request, etc. In devonfw sample we get the locale information from database.\nThis image shows the entire process:\n"},{"id":155,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-i18n.asciidoc_getting-internationalizated-messages","type":"docs","title":"Getting internationalizated messages","body":"12.17.2. Getting internationalizated messages\ndevonfw has a bean that manage i18n message resolution, the ApplicationLocaleResolver. This bean is responsible to get the current user and extract locale information from it and read the correct properties file to get the message.\nThe i18n properties file must be called ApplicationMessages_la_CO.properties where la=language and CO=country. This is an example of a i18n properties file for English language to translate devonfw sample user roles:\nApplicationMessages_en_US.properties\nadmin=Admin\nYou should define an ApplicationMessages_la_CO.properties file for every language that your application needs.\nApplicationLocaleResolver bean is injected in AbstractComponentFacade class so you have available this bean in logic layer so you only need to put this code to get an internationalized message:\nString msg = getApplicationLocaleResolver().getMessage(&quot;mymessage&quot;);\n"},{"id":156,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-xml.asciidoc","type":"docs","title":"XML","body":"12.18. XML\nXML (Extensible Markup Language) is a W3C standard format for structured information. It has a large eco-system of additional standards and tools.\nIn Java there are many different APIs and frameworks for accessing, producing and processing XML. For the devonfw we recommend to use JAXB for mapping Java objects to XML and vice-versa. Further there is the popular DOM API for reading and writing smaller XML documents directly. When processing large XML documents StAX is the right choice.\n"},{"id":157,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-xml.asciidoc_jaxb","type":"docs","title":"JAXB","body":"12.18.1. JAXB\nWe use JAXB to serialize Java objects to XML or vice-versa.\nJAXB and Inheritance\nUse @XmlSeeAlso annotation to provide sub-classes.\nSee section &quot;Collective Polymorphism&quot; described here.\nJAXB Custom Mapping\nIn order to map custom datatypes or other types that do not follow the Java bean conventions, you need to define a custom mapping. If you create dedicated objects for the XML mapping you can easily avoid such situations. When this is not suitable use @XmlJavaTypeAdapter and provide an XmlAdapter implementation that handles the mapping.\nFor details see here.\n"},{"id":158,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-xml.asciidoc_security","type":"docs","title":"Security","body":"12.18.2. Security\nTo prevent XML External Entity attacks, follow JAXP Security Guide and enable FSP.\n"},{"id":159,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-json.asciidoc","type":"docs","title":"JSON","body":"12.19. JSON\nJSON (JavaScript Object Notation) is a popular format to represent and exchange data especially for modern web-clients. For mapping Java objects to JSON and vice-versa there is no official standard API. We use the established and powerful open-source solution Jackson.\nDue to problems with the wiki of fasterxml you should try this alternative link: Jackson/AltLink.\n"},{"id":160,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-json.asciidoc_configure-json-mapping","type":"docs","title":"Configure JSON Mapping","body":"12.19.1. Configure JSON Mapping\nIn order to avoid polluting business objects with proprietary Jackson annotations (e.g. @JsonTypeInfo, @JsonSubTypes, @JsonProperty) we propose to create a separate configuration class. Every devonfw application (sample or any app created from our app-template) therefore has a class called ApplicationObjectMapperFactory that extends ObjectMapperFactory from the devon4j-rest module. It looks like this:\n@Named(&quot;ApplicationObjectMapperFactory&quot;)\npublic class ApplicationObjectMapperFactory extends ObjectMapperFactory {\npublic RestaurantObjectMapperFactory() {\nsuper();\n// JSON configuration code goes here\n}\n}\n"},{"id":161,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-json.asciidoc_json-and-inheritance","type":"docs","title":"JSON and Inheritance","body":"12.19.2. JSON and Inheritance\nIf you are using inheritance for your objects mapped to JSON then polymorphism can not be supported out-of-the box. So in general avoid polymorphic objects in JSON mapping. However, this is not always possible.\nHave a look at the following example from our sample application:\nFigure 7. Transfer-Objects using Inheritance\nNow assume you have a REST service operation as Java method that takes a ProductEto as argument. As this is an abstract class the server needs to know the actual sub-class to instantiate.\nWe typically do not want to specify the classname in the JSON as this should be an implementation detail and not part of the public JSON format (e.g. in case of a service interface). Therefore we use a symbolic name for each polymorphic subtype that is provided as virtual attribute @type within the JSON data of the object:\n{ &quot;@type&quot;: &quot;Drink&quot;, ... }\nTherefore you add configuration code to the constructor of ApplicationObjectMapperFactory. Here you can see an example from the sample application:\nsetBaseClasses(ProductEto.class);\naddSubtypes(new NamedType(MealEto.class, &quot;Meal&quot;), new NamedType(DrinkEto.class, &quot;Drink&quot;),\nnew NamedType(SideDishEto.class, &quot;SideDish&quot;));\nWe use setBaseClasses to register all top-level classes of polymorphic objects. Further we declare all concrete polymorphic sub-classes together with their symbolic name for the JSON format via addSubtypes.\n"},{"id":162,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-json.asciidoc_custom-mapping","type":"docs","title":"Custom Mapping","body":"12.19.3. Custom Mapping\nIn order to map custom datatypes or other types that do not follow the Java bean conventions, you need to define a custom mapping. If you create objects dedicated for the JSON mapping you can easily avoid such situations. When this is not suitable follow these instructions to define the mapping:\nAs an example, the use of JSR354 (javax.money) is appreciated in order to process monetary amounts properly. However, without custom mapping, the default mapping of Jackson will produce the following JSON for a MonetaryAmount:\n&quot;currency&quot;: {&quot;defaultFractionDigits&quot;:2, &quot;numericCode&quot;:978, &quot;currencyCode&quot;:&quot;EUR&quot;},\n&quot;monetaryContext&quot;: {...},\n&quot;number&quot;:6.99,\n&quot;factory&quot;: {...}\nAs clearly can be seen, the JSON contains too much information and reveals implementation secrets that do not belong here. Instead the JSON output expected and desired would be:\n&quot;currency&quot;:&quot;EUR&quot;,&quot;amount&quot;:&quot;6.99&quot;\nEven worse, when we send the JSON data to the server, Jackson will see that MonetaryAmount is an interface and does not know how to instantiate it so the request will fail.\nTherefore we need a customized Serializer.\nWe implement MonetaryAmountJsonSerializer to define how a MonetaryAmount is serialized to JSON:\npublic final class MonetaryAmountJsonSerializer extends JsonSerializer&lt;MonetaryAmount&gt; {\npublic static final String NUMBER = &quot;amount&quot;;\npublic static final String CURRENCY = &quot;currency&quot;;\npublic void serialize(MonetaryAmount value, JsonGenerator jgen, SerializerProvider provider) throws ... {\nif (value != null) {\njgen.writeStartObject();\njgen.writeFieldName(MonetaryAmountJsonSerializer.CURRENCY);\njgen.writeString(value.getCurrency().getCurrencyCode());\njgen.writeFieldName(MonetaryAmountJsonSerializer.NUMBER);\njgen.writeString(value.getNumber().toString());\njgen.writeEndObject();\n}\n}\nFor composite datatypes it is important to wrap the info as an object (writeStartObject() and writeEndObject()). MonetaryAmount provides the information we need by the getCurrency() and getNumber(). So that we can easily write them into the JSON data.\nNext, we implement MonetaryAmountJsonDeserializer to define how a MonetaryAmount is deserialized back as Java object from JSON:\npublic final class MonetaryAmountJsonDeserializer extends AbstractJsonDeserializer&lt;MonetaryAmount&gt; {\nprotected MonetaryAmount deserializeNode(JsonNode node) {\nBigDecimal number = getRequiredValue(node, MonetaryAmountJsonSerializer.NUMBER, BigDecimal.class);\nString currencyCode = getRequiredValue(node, MonetaryAmountJsonSerializer.CURRENCY, String.class);\nMonetaryAmount monetaryAmount =\nMonetaryAmounts.getAmountFactory().setNumber(number).setCurrency(currencyCode).create();\nreturn monetaryAmount;\n}\n}\nFor composite datatypes we extend from AbstractJsonDeserializer as this makes our task easier. So we already get a JsonNode with the parsed payload of our datatype. Based on this API it is easy to retrieve individual fields from the payload without taking care of their order, etc.\nAbstractJsonDeserializer also provides methods such as getRequiredValue to read required fields and get them converted to the desired basis datatype. So we can easily read the amount and currency and construct an instance of MonetaryAmount via the official factory API.\nFinally we need to register our custom (de)serializers with the following configuration code in the constructor of ApplicationObjectMapperFactory:+\nSimpleModule module = getExtensionModule();\nmodule.addDeserializer(MonetaryAmount.class, new MonetaryAmountJsonDeserializer());\nmodule.addSerializer(MonetaryAmount.class, new MonetaryAmountJsonSerializer());\nNow we can read and write MonetaryAmount from and to JSON as expected.\n"},{"id":163,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-rest.asciidoc","type":"docs","title":"REST","body":"12.20. REST\nREST (REpresentational State Transfer) is an inter-operable protocol for services that is more lightweight than SOAP.\nHowever, it is no real standard and can cause confusion. Therefore we define best practices here to guide you.\nATTENTION:\nREST and RESTful often implies very strict and specific rules and conventions. However different people will often have different opinions of such rules. We learned that this leads to &quot;religious discussions&quot; (starting from PUT vs. POST and IDs in path vs. payload up to Hypermedia and HATEOAS). These &quot;religious discussions&quot; waste a lot of time and money without adding real value in case of common business applications (if you publish your API on the internet to billions of users this is a different story). Therefore we give best practices that lead to simple, easy and pragmatic &quot;HTTP APIs&quot; (to avoid the term &quot;REST services&quot; and end &quot;religious discussions&quot;). Please also note that we do not want to assault anybody nor force anyone to follow our guidelines. Please read the following best practices carefully and be aware that they might slightly differ from what your first hit on the web will say about REST (see e.g. RESTful cookbook).\n"},{"id":164,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-rest.asciidoc_urls","type":"docs","title":"URLs","body":"12.20.1. URLs\nURLs are not case sensitive. Hence, we follow the best practice to use only lower-case-letters-with-hyphen-to-separate-words.\nFor operations in REST we distinguish the following types of URLs:\nA collection URL is build from the rest service URL by appending the name of a collection. This is typically the name of an entity. Such URI identifies the entire collection of all elements of this type. Example: https://mydomain.com/myapp/services/rest/mycomponent/v1/myentity\nAn element URL is build from a collection URL by appending an element ID. It identifies a single element (entity) within the collection. Example: https://mydomain.com/myapp/services/rest/mycomponent/v1/myentity/42\nA search URL is build from a collection URL by appending the segment search. The search criteria is send as POST. Example: https://mydomain.com/myapp/services/rest/mycomponent/v1/myentity/search\nThis fits perfect for CRUD operations. For business operations (processing, calculation, etc.) we simply create a collection URL with the name of the business operation instead of the entity name (use a clear naming convention to avoid collisions). Then we can POST the input for the business operation and get the result back.\nIf you want to provide an entity with a different structure do not append further details to an element URL but create a separate collection URL as base.\nSo use https://mydomain.com/myapp/services/rest/mycomponent/v1/myentity-with-details/42 instead of https://mydomain.com/myapp/services/rest/mycomponent/v1/myentity/42/with-details.\nFor offering a CTO simply append -cto to the collection URL (e.g. &#x2026;&#x200B;/myentity-cto/).\n"},{"id":165,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-rest.asciidoc_http-methods","type":"docs","title":"HTTP Methods","body":"12.20.2. HTTP Methods\nWhile REST was designed as a pragmatical approach it sometimes leads to &quot;religious discussions&quot; e.g. about using PUT vs. POST (see ATTENTION notice above).\nAs the devonfw has a string focus on usual business applications it proposes a more &quot;pragmatic&quot; approach to REST services.\nOn the next table we compare the main differences between the &quot;canonical&quot; REST approach (or RESTful) and the devonfw proposal.\nTable 37. Usage of HTTP methods\nHTTP Method\nRESTful Meaning\ndevonfw\nGET\nRead single element.\nSearch on an entity (with parametrized url)\nRead a single element.\nPUT\nReplace entity data.\nReplace entire collection (typically not supported)\nNot used\nPOST\nCreate a new element in the collection\nCreate or update an element in the collection.\nSearch on an entity (parametrized post body)\nBulk deletion.\nDELETE\nDelete an entity.\nDelete an entire collection (typically not supported)\nDelete an entity.\nDelete an entire collection (typically not supported)\nPlease consider these guidelines and rationales:\nWe use POST on the collection URL to save an entity (create if no ID provided in payload otherwise update). This avoids pointless discussions in distinctions between PUT and POST and what to do if a create contains an ID in the payload or if an update is missing the ID property or contains a different ID in payload than in URL.\nHence, we do NOT use PUT but always use POST for write operations. As we always have a technical ID for each entity, we can simply distinguish create and update by the presence of the ID property.\nPlease also note that for (large) bulk deletions you may be forced to used POST instead of DELETE as according to the HTTP standard DELETE must not have payload and URLs are limited in length.\n"},{"id":166,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-rest.asciidoc_http-status-codes","type":"docs","title":"HTTP Status Codes","body":"12.20.3. HTTP Status Codes\nFurther we define how to use the HTTP status codes for REST services properly. In general the 4xx codes correspond to an error on the client side and the 5xx codes to an error on the server side.\nTable 38. Usage of HTTP status codes\nHTTP Code\nMeaning\nResponse\nComment\n200\nOK\nrequested result\nResult of successful GET\n204\nNo Content\nnone\nResult of successful POST, DELETE, or PUT (void return)\n400\nBad Request\nerror details\nThe HTTP request is invalid (parse error, validation failed)\n401\nUnauthorized\nnone (security)\nAuthentication failed\n403\nForbidden\nnone (security)\nAuthorization failed\n404\nNot found\nnone\nEither the service URL is wrong or the requested resource does not exist\n500\nServer Error\nerror code, UUID\nInternal server error occurred (used for all technical exceptions)\n"},{"id":167,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-rest.asciidoc_metadata","type":"docs","title":"Metadata","body":"12.20.4. Metadata\ndevonfw has support for the following metadata in REST service invocations:\nName\nDescription\nFurther information\nX-Correlation-Id\nHTTP header for a correlation ID that is a unique identifier to associate different requests belonging to the same session / action\nLogging guide\nValidation errors\nStandardized format for a service to communicate validation errors to the client\nServer-side validation is documented in the Validation guide.\nThe protocol to communicate these validation errors is described in REST exception handling.\nPagination\nStandardized format for a service to offer paginated access to a list of entities\nServer-side support for pagination is documented in the Repository Guide.\n"},{"id":168,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-rest.asciidoc_jax-rs","type":"docs","title":"JAX-RS","body":"12.20.5. JAX-RS\nFor implementing REST services we use the JAX-RS standard. As an implementation we recommend CXF. For JSON bindings we use Jackson while XML binding works out-of-the-box with JAXB.\nTo implement a service you write an interface with JAX-RS annotations for the API and a regular implementation class annotated with @Named to make it a spring-bean. Here is a simple example:\n@Path(&quot;/imagemanagement/v1&quot;)\n@Consumes(MediaType.APPLICATION_JSON)\n@Produces(MediaType.APPLICATION_JSON)\npublic interface ImagemanagementRestService {\n@GET\n@Path(&quot;/image/{id}/&quot;)\npublic ImageEto getImage(@PathParam(&quot;id&quot;) long id);\n}\n@Named(&quot;ImagemanagementRestService&quot;)\npublic class ImagemanagementRestServiceImpl implements ImagemanagementRestService {\n@Inject\nprivate Imagemanagement imagemanagement;\n@Override\npublic ImageEto getImage(long id) {\nreturn this.imagemanagement.findImage(id);\n}\n}\nHere we can see a REST service for the business component imagemanagement. The method getImage can be accessed via HTTP GET (see @GET) under the URL path imagemanagement/image/{id} (see @Path annotations) where {id} is the ID of the requested table and will be extracted from the URL and provided as parameter id to the method getImage. It will return its result (ImageEto) as JSON (see @Produces - should already be defined as defaults in RestService marker interface). As you can see it delegates to the logic component imagemanagement that contains the actual business logic while the service itself only exposes this logic via HTTP. The REST service implementation is a regular CDI bean that can use dependency injection.\nThe separation of the API as a Java interface allows to use it for service client calls.\nNote\nWith JAX-RS it is important to make sure that each service method is annotated with the proper HTTP method (@GET,@POST,etc.) to avoid unnecessary debugging. So you should take care not to forget to specify one of these annotations.\nJAX-RS Configuration\nStarting from CXF 3.0.0 it is possible to enable the auto-discovery of JAX-RS roots.\nWhen the jaxrs server is instantiated all the scanned root and provider beans (beans annotated with javax.ws.rs.Path and javax.ws.rs.ext.Provider) are configured.\n"},{"id":169,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-rest.asciidoc_rest-exception-handling","type":"docs","title":"REST Exception Handling","body":"12.20.6. REST Exception Handling\nFor exceptions a service needs to have an exception fa&#xE7;ade that catches all exceptions and handles them by writing proper log messages and mapping them to a HTTP response with an according HTTP status code. Therefore the devonfw provides a generic solution via RestServiceExceptionFacade. You need to follow the exception guide so that it works out of the box because the fa&#xE7;ade needs to be able to distinguish between business and technical exceptions.\nNow your service may throw exceptions but the fa&#xE7;ade with automatically handle them for you.\n"},{"id":170,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-rest.asciidoc_recommendations-for-rest-requests-and-responses","type":"docs","title":"Recommendations for REST requests and responses","body":"12.20.7. Recommendations for REST requests and responses\nThe devonfw proposes, for simplicity, a deviation from the common REST pattern:\nUsing POST for updates (instead of PUT)\nUsing the payload for addressing resources on POST (instead of identifier on the URL)\nUsing parametrized POST for searches\nThis use of REST will lead to simpler code both on client and on server. We discuss this use on the next points.\nThe following table specifies how to use the HTTP methods (verbs) for collection and element URIs properly (see wikipedia).\nUnparameterized loading of a single resource\nHTTP Method: GET\nURL example: /services/rest/productmanagement/v1/product/123\nFor loading of a single resource, embed the identifier (e.g. 123) of the resource in the URL.\nThe response contains the resource in JSON format, using a JSON object at the top-level, for example:\n{\n&quot;id&quot;: 123,\n&quot;name&quot;: &quot;Steak&quot;,\n&quot;color&quot;: &quot;brown&quot;\n}\nUnparameterized loading of a collection of resources\nHTTP Method: GET\nURL example: /services/rest/productmanagement/v1/product\nFor loading of a collection of resources, make sure that the size of the collection can never exceed a reasonable maximum size. For parameterized loading (searching, pagination), see below.\nThe response contains the collection in JSON format, using a JSON object at the top-level, and the actual collection underneath a result key, for example:\n{\n&quot;result&quot;: [\n{\n&quot;id&quot;: 123,\n&quot;name&quot;: &quot;Steak&quot;,\n&quot;color&quot;: &quot;brown&quot;\n},\n{\n&quot;id&quot;: 124,\n&quot;name&quot;: &quot;Broccoli&quot;,\n&quot;color&quot;: &quot;green&quot;\n}\n]\n}\nSaving a resource\nHTTP Method: POST\nURL example: /services/rest/productmanagement/v1/product\nThe resource will be passed via JSON in the request body. If updating an existing resource, include the resource&#x2019;s identifier in the JSON and not in the URL, in order to avoid ambiguity.\nIf saving was successful, the updated product (e.g. with assigned ID or updated modification counter) is returned.\nIf saving was unsuccessful, refer below for the format to return errors to the client.\nParameterized loading of a resource\nHTTP Method: POST\nURL example: /services/rest/productmanagement/v1/product/search\nIn order to differentiate from an unparameterized load, a special subpath (for example search) is introduced. The parameters are passed via JSON in the request body. An example of a simple, paginated search would be:\n{\n&quot;status&quot;: &quot;OPEN&quot;,\n&quot;pagination&quot;: {\n&quot;page&quot;: 2,\n&quot;size&quot;: 25\n}\n}\nThe response contains the requested page of the collection in JSON format, using a JSON object at the top-level, the actual page underneath a result key, and additional pagination information underneath a pagination key, for example:\n{\n&quot;pagination&quot;: {\n&quot;page&quot;: 2,\n&quot;size&quot;: 25,\n&quot;total&quot;: null\n},\n&quot;result&quot;: [\n{\n&quot;id&quot;: 123,\n&quot;name&quot;: &quot;Steak&quot;,\n&quot;color&quot;: &quot;brown&quot;\n},\n{\n&quot;id&quot;: 124,\n&quot;name&quot;: &quot;Broccoli&quot;,\n&quot;color&quot;: &quot;green&quot;\n}\n]\n}\nCompare the code needed on server side to accept this request:\n@Path(&quot;/category/search&quot;)\n@POST\npublic PaginatedListTo&lt;CategoryEto&gt; findCategorysByPost(CategorySearchCriteriaTo searchCriteriaTo) {\nreturn this.dishmanagement.findCategoryEtos(searchCriteriaTo);\n}\nWith the equivalent code required if doing it the RESTful way by issuing a GET request:\n@Path(&quot;/category/search&quot;)\n@POST @Path(&quot;/order&quot;)\n@GET\npublic PaginatedListTo&lt;CategoryEto&gt; findCategorysByPost( @Context UriInfo info) {\nRequestParameters parameters = RequestParameters.fromQuery(info);\nCategorySearchCriteriaTo criteria = new CategorySearchCriteriaTo();\ncriteria.setName(parameters.get(&quot;name&quot;, Long.class, false));\ncriteria.setDescription(parameters.get(&quot;description&quot;, OrderState.class, false));\ncriteria.setShowOrder(parameters.get(&quot;showOrder&quot;, OrderState.class, false));\nreturn this.dishmanagement.findCategoryEtos(criteria);\n}\nPagination details\nThe client can choose to request a count of the total size of the collection, for example to calculate the total number of available pages. It does so, by specifying the pagination.total property with a value of true.\nThe service is free to honour this request. If it chooses to do so, it returns the total count as the pagination.total property in the response.\nDeletion of a resource\nHTTP Method: DELETE\nURL example: /services/rest/productmanagement/v1/product/123\nFor deletion of a single resource, embed the identifier of the resource in the URL.\nError results\nThe general format for returning an error to the client is as follows:\n{\n&quot;message&quot;: &quot;A human-readable message describing the error&quot;,\n&quot;code&quot;: &quot;A code identifying the concrete error&quot;,\n&quot;uuid&quot;: &quot;An identifier (generally the correlation id) to help identify corresponding requests in logs&quot;\n}\nIf the error is caused by a failed validation of the entity, the above format is extended to also include the list of individual validation errors:\n{\n&quot;message&quot;: &quot;A human-readable message describing the error&quot;,\n&quot;code&quot;: &quot;A code identifying the concrete error&quot;,\n&quot;uuid&quot;: &quot;An identifier (generally the correlation id) to help identify corresponding requests in logs&quot;,\n&quot;errors&quot;: {\n&quot;property failing validation&quot;: [\n&quot;First error message on this property&quot;,\n&quot;Second error message on this property&quot;\n],\n// ....\n}\n}\n"},{"id":171,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-rest.asciidoc_rest-media-types","type":"docs","title":"REST Media Types","body":"12.20.8. REST Media Types\nThe payload of a REST service can be in any format as REST by itself does not specify this. The most established ones that the devonfw recommends are XML and JSON. Follow these links for further details and guidance how to use them properly. JAX-RS and CXF properly support these formats (MediaType.APPLICATION_JSON and MediaType.APPLICATION_XML can be specified for @Produces or @Consumes). Try to decide for a single format for all services if possible and NEVER mix different formats in a service.\n"},{"id":172,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-rest.asciidoc_rest-testing","type":"docs","title":"REST Testing","body":"12.20.9. REST Testing\nFor testing REST services in general consult the testing guide.\nFor manual testing REST services there are browser plugins:\nFirefox: rested\nChrome: postman (advanced-rest-client)\n"},{"id":173,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-rest.asciidoc_security","type":"docs","title":"Security","body":"12.20.10. Security\nYour services are the major entry point to your application. Hence security considerations are important here.\nCSRF\nA common security threat is CSRF for REST services. Therefore all REST operations that are performing modifications (PUT, POST, DELETE, etc. - all except GET) have to be secured against CSRF attacks. See CSRF how to do this.\nJSON top-level arrays\nOWASP earlier suggested to never return JSON arrays at the top-level, to prevent attacks without rationale.\nWe digged deep and found anatomy-of-a-subtle-json-vulnerability.\nTo sum it up the attack is many years old and does not work in any recent or relevant browser.\nHence it is fine to use arrays as top-level result in a JSON REST service (means you can return List&lt;Foo&gt; in a Java JAX-RS service).\n"},{"id":174,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-soap.asciidoc","type":"docs","title":"SOAP","body":"12.21. SOAP\nSOAP is a common protocol for services that is rather complex and heavy. It allows to build inter-operable and well specified services (see WSDL). SOAP is transport neutral what is not only an advantage. We strongly recommend to use HTTPS transport and ignore additional complex standards like WS-Security and use established HTTP-Standards such as RFC2617 (and RFC5280).\n"},{"id":175,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-soap.asciidoc_jax-ws","type":"docs","title":"JAX-WS","body":"12.21.1. JAX-WS\nFor building web-services with Java we use the JAX-WS standard.\nThere are two approaches:\ncode first\ncontract first\nHere is an example in case you define a code-first service.\nWeb-Service Interface\nWe define a regular interface to define the API of the service and annotate it with JAX-WS annotations:\n@WebService\npublic interface TablemanagmentWebService {\n@WebMethod\n@WebResult(name = &quot;message&quot;)\nTableEto getTable(@WebParam(name = &quot;id&quot;) String id);\n}\nWeb-Service Implementation\nAnd here is a simple implementation of the service:\n@Named\n@WebService(endpointInterface = &quot;com.devonfw.application.mtsj.tablemanagement.service.api.ws.TablemanagmentWebService&quot;)\npublic class TablemanagementWebServiceImpl implements TablemanagmentWebService {\nprivate Tablemanagement tableManagement;\n@Override\npublic TableEto getTable(String id) {\nreturn this.tableManagement.findTable(id);\n}\n"},{"id":176,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-soap.asciidoc_soap-custom-mapping","type":"docs","title":"SOAP Custom Mapping","body":"12.21.2. SOAP Custom Mapping\nIn order to map custom datatypes or other types that do not follow the Java bean conventions, you need to write adapters for JAXB (see XML).\n"},{"id":177,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-soap.asciidoc_soap-testing","type":"docs","title":"SOAP Testing","body":"12.21.3. SOAP Testing\nFor testing SOAP services in general consult the testing guide.\nFor testing SOAP services manually we strongly recommend SoapUI.\n"},{"id":178,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-service-client.asciidoc","type":"docs","title":"Service Client","body":"12.22. Service Client\nThis guide is about consuming (calling) services from other applications (micro-services). For providing services see the Service-Layer Guide. Services can be consumed in the client or the server. As the client is typically not written in Java you should consult the according guide for your client technology. In case you want to call a service within your Java code this guide is the right place to get help.\n"},{"id":179,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-service-client.asciidoc_motivation","type":"docs","title":"Motivation","body":"12.22.1. Motivation\nVarious solutions already exist for calling services such as RestTemplate from spring or the JAX-RS client API. Further each and every service framework offers its own API as well. These solutions might be suitable for very small and simple projects (with one or two such invocations). However, with the trend of microservices the invocation of a service becomes a very common use-case that occurs all over the place. You typically need a solution that is very easy to use but supports flexible configuration, adding headers for authentication, mapping of errors from server, logging success/errors with duration for performance analysis, support for synchronous and asynchronous invocations, etc. This is exactly what this devon4j service-client solution brings for you.\n"},{"id":180,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-service-client.asciidoc_dependency","type":"docs","title":"Dependency","body":"12.22.2. Dependency\nYou need to add (at least one of) these dependencies to your application:\n&lt;!-- Starter for asynchronous consuming REST services via Jaca HTTP Client (Java11+) --&gt;\n&lt;dependency&gt;\n&lt;groupId&gt;com.devonfw.java.starters&lt;/groupId&gt;\n&lt;artifactId&gt;devon4j-starter-http-client-rest-async&lt;/artifactId&gt;\n&lt;/dependency&gt;\n&lt;!-- Starter for synchronous consuming REST services via Jaca HTTP Client (Java11+) --&gt;\n&lt;dependency&gt;\n&lt;groupId&gt;com.devonfw.java.starters&lt;/groupId&gt;\n&lt;artifactId&gt;devon4j-starter-http-client-rest-sync&lt;/artifactId&gt;\n&lt;/dependency&gt;\n&lt;!-- Starter for synchronous consuming REST services via Apache CXF (Java8+)\nNOTE: This is an alternative to devon4j-starter-http-client-rest-sync\n--&gt;\n&lt;!--\n&lt;dependency&gt;\n&lt;groupId&gt;com.devonfw.java.starters&lt;/groupId&gt;\n&lt;artifactId&gt;devon4j-starter-cxf-client-rest&lt;/artifactId&gt;\n&lt;/dependency&gt;\n--&gt;\n&lt;!-- Starter for synchronous consuming SOAP services via Apache CXF (Java8+) --&gt;\n&lt;dependency&gt;\n&lt;groupId&gt;com.devonfw.java.starters&lt;/groupId&gt;\n&lt;artifactId&gt;devon4j-starter-cxf-client-ws&lt;/artifactId&gt;\n&lt;/dependency&gt;\n"},{"id":181,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-service-client.asciidoc_features","type":"docs","title":"Features","body":"12.22.3. Features\nWhen invoking a service you need to consider many cross-cutting aspects. You might not think about them in the very first place and you do not want to implement them multiple times redundantly. Therefore you should consider using this approach. The following sub-sections list the covered features and aspects:\nSimple usage\nAssuming you already have a Java interface MyService of the service you want to invoke:\npackage com.company.department.foo.mycomponent.service.api.rest;\n...\n@Path(&quot;/myservice&quot;)\npublic interface MyService extends RestService {\n@POST\n@Path(&quot;/getresult&quot;)\nMyResult getResult(MyArgs myArgs);\n@DELETE\n@Path(&quot;/entity/{id}&quot;)\nvoid deleteEntity(@PathParam(&quot;id&quot;) long id);\n}\nThen all you need to do is this:\n@Named\npublic class UcMyUseCaseImpl extends MyUseCaseBase implements UcMyUseCase {\n@Inject\nprivate ServiceClientFactory serviceClientFactory;\n...\nprivate void callSynchronous(MyArgs myArgs) {\nMyService myService = this.serviceClientFactory.create(MyService.class);\n// call of service over the wire, synchronously blocking until result is received or error occurred\nMyResult myResult = myService.myMethod(myArgs);\nhandleResult(myResult);\n}\nprivate void callAsynchronous(MyArgs myArgs) {\nAsyncServiceClient&lt;MyService&gt; client = this.serviceClientFactory.createAsync(MyService.class);\n// call of service over the wire, will return when request is send and invoke handleResult asynchronously\nclient.call(client.get().myMethod(myArgs), this::handleResult);\n}\nprivate void handleResult(MyResult myResult) {\n...\n}\n...\n}\nAs you can see both synchronous and asynchronous invocation of a service is very simple and type-safe. Still it is very flexible and powerful (see following features). The actual call of myMethod will technically call the remote service over the wire (e.g. via HTTP) including marshaling the arguments (e.g. converting myArgs to JSON) and unmarshalling the result (e.g. converting the received JSON to myResult).\nAsynchronous Invocation of void Methods\nIf you want to call a service method with void as return type, the type-safe call method can not be used as void methods do not return a result. Therefore you can use the callVoid method as following:\nprivate void callAsynchronousVoid(long id) {\nAsyncServiceClient&lt;MyService&gt; client = this.serviceClientFactory.createAsync(MyService.class);\n// call of service over the wire, will return when request is send and invoke resultHandler asynchronously\nConsumer&lt;Void&gt; resultHandler = r -&gt; { System.out.println(&quot;Response received&quot;)};\nclient.callVoid(() -&gt; { client.get().deleteEntity(id);}, resultHandler);\n}\nYou may also provide null as resultHandler for &quot;fire and forget&quot;. However, this will lead to the result being ignored so even in case of an error you will not be notified.\nConfiguration\nThis solution allows a very flexible configuration on the following levels:\nGlobal configuration (defaults)\nConfiguration per remote service application (microservice)\nConfiguration per invocation.\nA configuration on a deeper level (e.g. 3) overrides the configuration from a higher level (e.g. 1).\nThe configuration on Level 1 and 2 are configured via application.properties\n(see configuration guide).\nFor Level 1 the prefix service.client.default. is used for properties.\nFurther, for level 2. the prefix service.client.app.&#xAB;application&#xBB;. is used where &#xAB;application&#xBB; is the\ntechnical name of the application providing the service. This name will automatically be derived from\nthe java package of the service interface (e.g. foo in MyService interface before) following our\npackaging conventions.\nIn case these conventions are not met it will fallback to the fully qualified name of the service interface.\nConfiguration on Level 3 has to be provided as Map argument to the method\nServiceClientFactory.create(Class&lt;S&gt; serviceInterface, Map&lt;String, String&gt; config).\nThe keys of this Map will not use prefixes (such as the ones above). For common configuration\nparameters a type-safe builder is offered to create such map via ServiceClientConfigBuilder.\nE.g. for testing you may want to do:\nthis.serviceClientFactory.create(MyService.class,\nnew ServiceClientConfigBuilder().authBasic().userLogin(login).userPassword(password).buildMap());\nHere is an example of a configuration block for your application.properties:\nservice.client.default.url=https://api.company.com/services/${type}\nservice.client.default.timeout.connection=120\nservice.client.default.timeout.response=3600\nservice.client.app.bar.url=https://bar.company.com:8080/services/rest\nservice.client.app.bar.auth=basic\nservice.client.app.bar.user.login=user4711\nservice.client.app.bar.user.password=ENC(jd5ZREpBqxuN9ok0IhnXabgw7V3EoG2p)\nservice.client.app.foo.url=https://foo.company.com:8443/services/rest\n# authForward: simply forward Authorization header (e.g. with JWT) to remote service\nservice.client.app.bar.auth=authForward\nService Discovery\nYou do not want to hardwire service URLs in your code, right? Therefore different strategies might apply\nto discover the URL of the invoked service. This is done internally by an implementation of the interface\nServiceDiscoverer. The default implementation simply reads the base URL from the configuration.\nSo you can simply add this to your application.properties as in the above configuration example.\nAssuming your service interface would have the fully qualified name\ncom.company.department.foo.mycomponent.service.api.rest.MyService then the URL would be resolved to\nhttps://foo.company.com:8443/services/rest as the &#xAB;application&#xBB; is foo.\nAdditionally, the URL might use the following variables that will automatically be resolved:\n${app} to &#xAB;application&#xBB; (useful for default URL)\n${type} to the type of the service. E.g. rest in case of a REST service and ws for a SOAP service.\n${local.server.port} for the port of your current Java servlet container running the JVM. Should only used for testing with spring-boot random port mechanism (technically spring can not resolve this variable but we do it for you here).\nTherefore, the default URL may also be configured as:\nservice.client.default.url=https://api.company.com/${app}/services/${type}\nAs you can use any implementation of ServiceDiscoverer, you can also easily use eureka (or anything else) instead to discover your services.\nHowever, we recommend to use istio instead as described below.\nHeaders\nA very common demand is to tweak (HTTP) headers in the request to invoke the service. May it be for security (authentication data) or for other cross-cutting concerns (such as the Correlation ID). This is done internally by implementations of the interface ServiceHeaderCustomizer.\nWe already provide several implementations such as:\nServiceHeaderCustomizerBasicAuth for basic authentication (auth=basic).\nServiceHeaderCustomizerOAuth for OAuth: passes a security token from security context such as a JWT via OAuth (auth=oauth).\nServiceHeaderCustomizerAuthForward forwards the Authorization HTTP header from the running request to the request to the remote serivce as is (auth=authForward). Be careful to avoid security pitfals by misconfiguring this feature as it may also sensitive credentials (e.g. basic auth) to the remote service. Never use as default.\nServiceHeaderCustomizerCorrelationId passed the Correlation ID to the service request.\nAdditionally, you can add further custom implementations of ServiceHeaderCustomizer for your individual requirements and additional headers.\nTimeouts\nYou can configure timeouts in a very flexible way. First of all you can configure timeouts to establish the connection (timeout.connection) and to wait for the response (timeout.response) separately. These timeouts can be configured on all three levels as described in the configuration section above.\nError Handling\nWhilst invoking a remote service an error may occur. This solution will automatically handle such errors and map them to a higher level ServiceInvocationFailedException. In general we separate two different types of errors:\nNetwork error\nIn such case (host not found, connection refused, time out, etc.) there is not even a response from the server. However, in advance to a low-level exception you will get a wrapped ServiceInvocationFailedException (with code ServiceInvoke) with a readable message containing the service that could not be invoked.\nService error\nIn case the service failed on the server-side the error result will be parsed and thrown as a ServiceInvocationFailedException with the received message and code.\nThis allows to catch and handle errors when a service-invocation failed. You can even distinguish business errors from the server-side from technical errors and implement retry strategies or the like.\nFurther the created exception contains detailed contextual information about the serivce that failed (service interface class, method, URL) what makes it much easier to trace down errors. Here is an example from our tests:\nWhile invoking the service com.devonfw.test.app.myexample.service.api.rest.MyExampleRestService#businessError[http://localhost:50178/app/services/rest/my-example/v1/business-error] the following error occurred: Test of business error. Probably the service is temporary unavailable. Please try again later. If the problem persists contact your system administrator.\n2f43b03e-685b-45c0-9aae-23ff4b220c85:BusinessErrorCode\nYou may even provide your own implementation of ServiceClientErrorFactory instead to provide an own exception class for this purpose.\nHandling Erros\nIn case of a synchronous service invocation an error will be immediately thrown so you can sourround the call with a regular try-catch block:\nprivate void callSynchronous(MyArgs myArgs) {\nMyService myService = this.serviceClientFactory.create(MyService.class);\n// call of service over the wire, synchronously blocking until result is received or error occurred\ntry {\nMyResult myResult = myService.myMethod(myArgs);\nhandleResult(myResult);\n} catch (ServiceInvocationFailedException e) {\nif (e.isTechnical()) {\nhandleTechnicalError(e);\n} else {\n// error code you defined in the exception on the server side of the service\nString errorCode = e.getCode();\nhandleBusinessError(e, errorCode;\n}\n} catch (Throwable e) { // you may not handle this explicitly here...\nhandleTechnicalError(e);\n}\n}\nIf you are using asynchronous service invocation an error can occurr in a separate thread. Therefore you may and should define a custom error handler:\nprivate void callAsynchronous(MyArgs myArgs) {\nAsyncServiceClient&lt;MyService&gt; client = this.serviceClientFactory.createAsync(MyService.class);\nConsumer&lt;Throwalbe&gt; errorHandler = this::handleError;\nclient.setErrorHandler(errorHandler);\n// call of service over the wire, will return when request is send and invoke handleResult asynchronously\nclient.call(client.get().myMethod(myArgs), this::handleResult);\n}\nprivate void handleError(Throwalbe error) {\n...\n}\n}\nThe error handler consumes Throwable and not only RuntimeException so you can get notified even in case of an unexpected OutOfMemoryError, NoClassDefFoundError, or other technical problems. Please note that the error handler may also be called from the thread calling the service (e.g. if already creating the request fails). The default error handler used if no custom handler is set will only log the error and do nothing else.\nLogging\nBy default this solution will log all invocations including the URL of the invoked service, success or error status flag and the duration in seconds (with decimal nano precision as available). Therefore you can easily monitor the status and performance of the service invocations. Here is an example from our tests:\nInvoking service com.devonfw.test.app.myexample.service.api.rest.MyExampleRestService#greet[http://localhost:50178/app/services/rest/my-example/v1/greet/John%20Doe%20%26%20%3F%23] took PT20.309756622S (20309756622ns) and succeded with status 200.\nResilience\nResilience adds a lot of complexity and that typically means that addressing this here would most probably result in not being up-to-date and not meeting all requirements. Therefore we recommend something completely different: the sidecar approach (based on sidecar pattern). This means that you use a generic proxy app that runs as a separate process on the same host, VM, or container of your actual application. Then in your app you are calling the service via the sidecar proxy on localhost (service discovery URL is e.g. http://localhost:8081/${app}/services/${type}) that then acts as proxy to the actual remote service. Now aspects such as resilience with circuit breaking and the actual service discovery can be configured in the sidecar proxy app and independent of your actual application. Therefore, you can even share and reuse configuration and experience with such a sidecar proxy app even across different technologies (Java, .NET/C#, Node.JS, etc.). Further, you do not pollute the technology stack of your actual app with the infrastructure for resilience, throttling, etc. and can update the app and the side-card independently when security-fixes are available.\nVarious implementations of such sidecar proxy apps are available as free open source software.\nOur recommendation in devonfw is to use istio. This not only provides such a side-car but also an entire management solution for service-mesh making administration and maintenance much easier. Platforms like OpenShift support this out of the box.\nHowever, if you are looking for details about side-car implementations for services you can have a look at the following links:\nNetflix Sidecar - see Spring Cloud Netflix docs\nEnvoy - see Microservices Patterns With Envoy Sidecar Proxy\nPrana - see Prana: A Sidecar for your Netflix PaaS based Applications and Services &#x2190; Not updated as it&#x2019;s not used internally by Netflix\nKeycloak - see Protecting Jaeger UI with a sidecar security proxy\n"},{"id":182,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-testing.asciidoc","type":"docs","title":"Testing","body":"12.23. Testing\n"},{"id":183,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-testing.asciidoc_general-best-practices","type":"docs","title":"General best practices","body":"12.23.1. General best practices\nFor testing please follow our general best practices:\nTests should have a clear goal that should also be documented.\nTests have to be classified into different integration levels.\nTests should follow a clear naming convention.\nAutomated tests need to properly assert the result of the tested operation(s) in a reliable way. E.g. avoid stuff like assertThat(service.getAllEntities()).hasSize(42) or even worse tests that have no assertion at all.\nTests need to be independent of each other. Never write test-cases or tests (in Java @Test methods) that depend on another test to be executed before.\nUse AssertJ to write good readable and maintainable tests that also provide valuable feedback in case a test fails. Do not use legacy JUnit methods like assertEquals anymore!\nFor easy understanding divide your test in three commented sections:\n//given\n//when\n//then\nPlan your tests and test data management properly before implementing.\nInstead of having a too strong focus on test coverage better ensure you have covered your critical core functionality properly and review the code including tests.\nTest code shall NOT be seen as second class code. You shall consider design, architecture and code-style also for your test code but do not over-engineer it.\nTest automation is good but should be considered in relation to cost per use. Creating full coverage via automated system tests can cause a massive amount of test-code that can turn out as a huge maintenance hell. Always consider all aspects including product life-cycle, criticality of use-cases to test, and variability of the aspect to test (e.g. UI, test-data).\nUse continuous integration and establish that the entire team wants to have clean builds and running tests.\nPrefer delegation over inheritance for cross-cutting testing functionality. Good places to put this kind of code can be realized and reused via the JUnit @Rule mechanism.\n"},{"id":184,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-testing.asciidoc_test-automation-technology-stack","type":"docs","title":"Test Automation Technology Stack","body":"12.23.2. Test Automation Technology Stack\nFor test automation we use JUnit. However, we are strictly doing all assertions with AssertJ. For mocking we use mockito.\nIn order to mock remote connections we use wiremock.\nFor testing entire components or sub-systems we recommend to use spring-boot-starter-test as lightweight and fast testing infrastructure that is already shipped with devon4j-test.\nIn case you have to use a full blown JEE application server, we recommend to use arquillian. To get started with arquillian, look here.\n"},{"id":185,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-testing.asciidoc_test-doubles","type":"docs","title":"Test Doubles","body":"12.23.3. Test Doubles\nWe use test doubles as generic term for mocks, stubs, fakes, dummies, or spys to avoid confusion. Here is a short summary from stubs VS mocks:\nDummy objects specifying no logic at all. May declare data in a POJO style to be used as boiler plate code to parameter lists or even influence the control flow towards the test&#x2019;s needs.\nFake objects actually have working implementations, but usually take some shortcut which makes them not suitable for production (an in memory database is a good example).\nStubs provide canned answers to calls made during the test, usually not responding at all to anything outside what&#x2019;s programmed in for the test. Stubs may also record information about calls, such as an email gateway stub that remembers the messages it &apos;sent&apos;, or maybe only how many messages it &apos;sent&apos;.\nMocks are objects pre-programmed with expectations, which form a specification of the calls they are expected to receive.\nWe try to give some examples, which should make it somehow clearer:\nStubs\nBest Practices for applications:\nA good way to replace small to medium large boundary systems, whose impact (e.g. latency) should be ignored during load and performance tests of the application under development.\nAs stub implementation will rely on state-based verification, there is the threat, that test developers will partially reimplement the state transitions based on the replaced code. This will immediately lead to a black maintenance whole, so better use mocks to assure the certain behavior on interface level.\nDo NOT use stubs as basis of a large amount of test cases as due to state-based verification of stubs, test developers will enrich the stub implementation to become a large monster with its own hunger after maintenance efforts.\nMocks\nBest Practices for applications:\nReplace not-needed dependencies of your system-under-test (SUT) to minimize the application context to start of your component framework.\nReplace dependencies of your SUT to impact the control flow under test without establishing all the context parameters needed to match the control flow.\nRemember: Not everything has to be mocked! Especially on lower levels of tests like isolated module tests you can be betrayed into a mocking delusion, where you end up in a hundred lines of code mocking the whole context and five lines executing the test and verifying the mocks behavior. Always keep in mind the benefit-cost ratio, when implementing tests using mocks.\nWiremock\nIf you need to mock remote connections such as HTTP-Servers, wiremock offers easy to use functionality. For a full description see the homepage or the github repository. Wiremock can be used either as a JUnit Rule, in Java outside of JUnit or as a standalone process. The mocked server can be configured to respond to specific requests in a given way via a fluent Java API, JSON files and JSON over HTTP. An example as an integration to JUnit can look as follows.\nimport static com.github.tomakehurst.wiremock.core.WireMockConfiguration.wireMockConfig;\nimport com.github.tomakehurst.wiremock.junit.WireMockRule;\npublic class WireMockOfferImport{\n@Rule\npublic WireMockRule mockServer = new WireMockRule(wireMockConfig().dynamicPort());\n@Test\npublic void requestDataTest() throws Exception {\nint port = this.mockServer.port();\n...}\nThis creates a server on a randomly chosen free port on the running machine. You can also specify the port to be used if wanted. Other than that there are several options to further configure the server. This includes HTTPs, proxy settings, file locations, logging and extensions.\n@Test\npublic void requestDataTest() throws Exception {\nthis.mockServer.stubFor(get(urlEqualTo(&quot;/new/offers&quot;)).withHeader(&quot;Accept&quot;, equalTo(&quot;application/json&quot;))\n.withHeader(&quot;Authorization&quot;, containing(&quot;Basic&quot;)).willReturn(aResponse().withStatus(200).withFixedDelay(1000)\n.withHeader(&quot;Content-Type&quot;, &quot;application/json&quot;).withBodyFile(&quot;/wireMockTest/jsonBodyFile.json&quot;)));\n}\nThis will stub the URL localhost:port/new/offers to respond with a status 200 message containing a header (Content-Type: application/json) and a body with content given in jsonBodyFile.json if the request matches several conditions.\nIt has to be a GET request to ../new/offers with the two given header properties.\nNote that by default files are located in src/test/resources/__files/. When using only one WireMock server one can omit the this.mockServer in before the stubFor call (static method).\nYou can also add a fixed delay to the response or processing delay with WireMock.addRequestProcessingDelay(time) in order to test for timeouts.\nWireMock can also respond with different corrupted messages to simulate faulty behaviour.\n@Test(expected = ResourceAccessException.class)\npublic void faultTest() {\nthis.mockServer.stubFor(get(urlEqualTo(&quot;/fault&quot;)).willReturn(aResponse()\n.withFault(Fault.MALFORMED_RESPONSE_CHUNK)));\n...}\nA GET request to ../fault returns an OK status header, then garbage, and then closes the connection.\n"},{"id":186,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-testing.asciidoc_integration-levels","type":"docs","title":"Integration Levels","body":"12.23.4. Integration Levels\nThere are many discussions about the right level of integration for test automation. Sometimes it is better to focus on small, isolated modules of the system - whatever a &quot;module&quot; may be. In other cases it makes more sense to test integrated groups of modules. Because there is no universal answer to this question, devonfw only defines a common terminology for what could be tested. Each project must make its own decision where to put the focus of test automation. There is no worldwide accepted terminology for the integration levels of testing. In general we consider ISTQB. However, with a technical focus on test automation we want to get more precise.\nThe following picture shows a simplified view of an application based on the devonfw reference architecture. We define four integration levels that are explained in detail below.\nThe boxes in the picture contain parenthesized numbers. These numbers depict the lowest integration level, a box belongs to. Higher integration levels also contain all boxes of lower integration levels. When writing tests for a given integration level, related boxes with a lower integration level must be replaced by test doubles or drivers.\nThe main difference between the integration levels is the amount of infrastructure needed to test them. The more infrastructure you need, the more bugs you will find, but the more instable and the slower your tests will be. So each project has to make a trade-off between pros and contras of including much infrastructure in tests and has to select the integration levels that fit best to the project.\nConsider, that more infrastructure does not automatically lead to a better bug-detection. There may be bugs in your software that are masked by bugs in the infrastructure. The best way to find those bugs is to test with very few infrastructure.\nExternal systems do not belong to any of the integration levels defined here. devonfw does not recommend involving real external systems in test automation. This means, they have to be replaced by test doubles in automated tests. An exception may be external systems that are fully under control of the own development team.\nThe following chapters describe the four integration levels.\nLevel 1 Module Test\nThe goal of a isolated module test is to provide fast feedback to the developer. Consequently, isolated module tests must not have any interaction with the client, the database, the file system, the network, etc.\nAn isolated module test is testing a single classes or at least a small set of classes in isolation. If such classes depend on other components or external resources, etc. these shall be replaced with a test double.\npublic class MyClassTest extends ModuleTest {\n@Test\npublic void testMyClass() {\n// given\nMyClass myClass = new MyClass();\n// when\nString value = myClass.doSomething();\n// then\nassertThat(value).isEqualTo(&quot;expected value&quot;);\n}\n}\nFor an advanced example see here.\nLevel 2 Component Test\nA component test aims to test components or component parts as a unit.\nThese tests typically run with a (light-weight) infrastructure such as spring-boot-starter-test and can access resources such as a database (e.g. for DAO tests).\nFurther, no remote communication is intended here. Access to external systems shall be replaced by a test double.\nWith devon4j and spring you can write a component-test as easy as illustrated in the following example:\n@SpringBootTest(classes = { MySpringBootApp.class }, webEnvironment = WebEnvironment.NONE)\npublic class UcFindCountryTest extends ComponentTest {\n@Inject\nprivate UcFindCountry ucFindCountry;\n@Test\npublic void testFindCountry() {\n// given\nString countryCode = &quot;de&quot;;\n// when\nTestUtil.login(&quot;user&quot;, MyAccessControlConfig.FIND_COUNTRY);\nCountryEto country = this.ucFindCountry.findCountry(countryCode);\n// then\nassertThat(country).isNotNull();\nassertThat(country.getCountryCode()).isEqualTo(countryCode);\nassertThat(country.getName()).isEqualTo(&quot;Germany&quot;);\n}\n}\nThis test will start the entire spring-context of your app (MySpringBootApp). Within the test spring will inject according spring-beans into all your fields annotated with @Inject. In the test methods you can use these spring-beans and perform your actual tests. This pattern can be used for testing DAOs/Repositories, Use-Cases, or any other spring-bean with its entire configuration including database and transactions.\nWhen you are testing use-cases your authorization will also be in place. Therefore, you have to simulate a logon in advance what is done via the login method in the above example. The test-infrastructure will automatically do a logout for you after each test method in doTearDown.\nLevel 3 Subsystem Test\nA subsystem test runs against the external interfaces (e.g. HTTP service) of the integrated subsystem. Subsystem tests of the client subsystem are described in the devon4ng testing guide. In devon4j the server (JEE application) is the subsystem under test. The tests act as a client (e.g. service consumer) and the server has to be integrated and started in a container.\nWith devon4j and spring you can write a subsystem-test as easy as illustrated in the following example:\n@SpringBootTest(classes = { MySpringBootApp.class }, webEnvironment = WebEnvironment.RANDOM_PORT)\npublic class CountryRestServiceTest extends SubsystemTest {\n@Inject\nprivate ServiceClientFactory serviceClientFactory;\n@Test\npublic void testFindCountry() {\n// given\nString countryCode = &quot;de&quot;;\n// when\nCountryRestService service = this.serviceClientFactory.create(CountryRestService.class);\nCountryEto country = service.findCountry(countryCode);\n// then\nassertThat(country).isNotNull();\nassertThat(country.getCountryCode()).isEqualTo(countryCode);\nassertThat(country.getName()).isEqualTo(&quot;Germany&quot;);\n}\n}\nEven though not obvious on the first look this test will start your entire application as a server on a free random port (so that it works in CI with parallel builds for different branches) and tests the invocation of a (REST) service including (un)marshalling of data (e.g. as JSON) and transport via HTTP (all in the invocation of the findCountry method).\nDo not confuse a subsystem test with a system integration test. A system integration test validates the interaction of several systems where we do not recommend test automation.\nLevel 4 System Test\nA system test has the goal to test the system as a whole against its official interfaces such as its UI or batches. The system itself runs as a separate process in a way close to a regular deployment. Only external systems are simulated by test doubles.\nThe devonfw only gives advice for automated system test (TODO see allure testing framework). In nearly every project there must be manual system tests, too. This manual system tests are out of scope here.\nClassifying Integration-Levels\ndevon4j defines Category-Interfaces that shall be used as JUnit Categories.\nAlso devon4j provides abstract base classes that you may extend in your test-cases if you like.\ndevon4j further pre-configures the maven build to only run integration levels 1-2 by default (e.g. for fast feedback in continuous integration). It offers the profiles subsystemtest (1-3) and systemtest (1-4). In your nightly build you can simply add -Psystemtest to run all tests.\n"},{"id":187,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-testing.asciidoc_implementation","type":"docs","title":"Implementation","body":"12.23.5. Implementation\nThis section introduces how to implement tests on the different levels with the given devonfw infrastructure and the proposed frameworks.\nModule Test\nIn devon4j you can extend the abstract class ModuleTest to basically get access to assertions. In order to test classes embedded in dependencies and external services one needs to provide mocks for that. As the technology stack recommends we use the Mockito framework to offer this functionality. The following example shows how to implement Mockito into a JUnit test.\nimport static org.mockito.Mockito.when;\nimport static org.mockito.Mockito.mock;\n...\npublic class StaffmanagementImplTest extends ModuleTest {\n@Rule\npublic MockitoRule rule = MockitoJUnit.rule();\n@Test\npublic void testFindStaffMember() {\n...}\n}\nNote that the test class does not use the @SpringApplicationConfiguration annotation. In a module test one does not use the whole application.\nThe JUnit rule is the best solution to use in order to get all needed functionality of Mockito. Static imports are a convenient option to enhance readability within Mockito tests.\nYou can define mocks with the @Mock annotation or the mock(*.class) call. To inject the mocked objects into your class under test you can use the @InjectMocks annotation. This automatically uses the setters of StaffmanagementImpl to inject the defined mocks into the class under test (CUT) when there is a setter available. In this case the beanMapper and the staffMemberDao are injected. Of course it is possible to do this manually if you need more control.\n@Mock\nprivate BeanMapper beanMapper;\n@Mock\nprivate StaffMemberEntity staffMemberEntity;\n@Mock\nprivate StaffMemberEto staffMemberEto;\n@Mock\nprivate StaffMemberDao staffMemberDao;\n@InjectMocks\nStaffmanagementImpl staffmanagementImpl = new StaffmanagementImpl();\nThe mocked objects do not provide any functionality at the time being. To define what happens on a method call on a mocked dependency in the CUT one can use when(condition).thenReturn(result). In this case we want to test findStaffMember(Long id) in the StaffmanagementImpl.\npublic StaffMemberEto findStaffMember(Long id) {\nreturn getBeanMapper().map(getStaffMemberDao().find(id), StaffMemberEto.class);\n}\nIn this simple example one has to stub two calls on the CUT as you can see below. For example the method call of the CUT staffMemberDao.find(id) is stubbed for returning a mock object staffMemberEntity that is also defined as mock.\nSubsystem Test\ndevon4j provides a simple test infrastructure to aid with the implementation of subsystem tests. It becomes available by simply subclassing AbstractRestServiceTest.java.\n//given\nlong id = 1L;\nClass&lt;StaffMemberEto&gt; targetClass = StaffMemberEto.class;\nwhen(this.staffMemberDao.find(id)).thenReturn(this.staffMemberEntity);\nwhen(this.beanMapper.map(this.staffMemberEntity, targetClass)).thenReturn(this.staffMemberEto);\n//when\nStaffMemberEto resultEto = this.staffmanagementImpl.findStaffMember(id);\n//then\nassertThat(resultEto).isNotNull();\nassertThat(resultEto).isEqualTo(this.staffMemberEto);\nAfter the test method call one can verify the expected results. Mockito can check whether a mocked method call was indeed called. This can be done using Mockito verify. Note that it does not generate any value if you check for method calls that are needed to reach the asserted result anyway. Call verification can be useful e.g. when you want to assure that statistics are written out without actually testing them.\n"},{"id":188,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-testing.asciidoc_regression-testing","type":"docs","title":"Regression testing","body":"12.23.6. Regression testing\nWhen it comes to complex output (even binary) that you want to regression test by comparing with an expected result, you sould consider Approval Tests using ApprovalTests.Java.\nIf applied for the right problems, it can be very helpful.\n"},{"id":189,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-testing.asciidoc_deployment-pipeline","type":"docs","title":"Deployment Pipeline","body":"12.23.7. Deployment Pipeline\nA deployment pipeline is a semi-automated process that gets software-changes from version control into production. It contains several validation steps, e.g. automated tests of all integration levels.\nBecause devon4j should fit to different project types - from agile to waterfall - it does not define a standard deployment pipeline. But we recommend to define such a deployment pipeline explicitly for each project and to find the right place in it for each type of test.\nFor that purpose, it is advisable to have fast running test suite that gives as much confidence as possible without needing too much time and too much infrastructure. This test suite should run in an early stage of your deployment pipeline. Maybe the developer should run it even before he/she checked in the code. Usually lower integration levels are more suitable for this test suite than higher integration levels.\nNote, that the deployment pipeline always should contain manual validation steps, at least manual acceptance testing. There also may be manual validation steps that have to be executed for special changes only, e.g. usability testing. Management and execution processes of those manual validation steps are currently not in the scope of devonfw.\n"},{"id":190,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-testing.asciidoc_test-coverage","type":"docs","title":"Test Coverage","body":"12.23.8. Test Coverage\nWe are using tools (SonarQube/Jacoco) to measure the coverage of the tests. Please always keep in mind that the only reliable message of a code coverage of X% is that (100-X)% of the code is entirely untested. It does not say anything about the quality of the tests or the software though it often relates to it.\n"},{"id":191,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-testing.asciidoc_test-configuration","type":"docs","title":"Test Configuration","body":"12.23.9. Test Configuration\nThis section covers test configuration in general without focusing on integration levels as in the first chapter.\nConfigure Test Specific Beans\nSometimes it can become handy to provide other or differently configured bean implementations via CDI than those available in production. For example, when creating beans using @Bean-annotated methods they are usually configured within those methods. WebSecurityBeansConfig shows an example of such methods.\n@Configuration\npublic class WebSecurityBeansConfig {\n//...\n@Bean\npublic AccessControlSchemaProvider accessControlSchemaProvider() {\n// actually no additional configuration is shown here\nreturn new AccessControlSchemaProviderImpl();\n}\n//...\n}\nAccessControlSchemaProvider allows to programmatically access data defined in some XML file, e.g. access-control-schema.xml. Now, one can imagine that it would be helpful if AccessControlSchemaProvider would point to some other file than the default within a test class. That file could provide content that differs from the default.\nThe question is: how can I change resource path of AccessControlSchemaProviderImpl within a test?\nOne very helpful solution is to use static inner classes.\nStatic inner classes can contain @Bean -annotated methods, and by placing them in the classes parameter in @SpringBootTest(classes = { /* place class here*/ }) annotation the beans returned by these methods are placed in the application context during test execution. Combining this feature with inheritance allows to override methods defined in other configuration classes as shown in the following listing where TempWebSecurityConfig extends WebSecurityBeansConfig. This relationship allows to override public AccessControlSchemaProvider accessControlSchemaProvider(). Here we are able to configure the instance of type AccessControlSchemaProviderImpl before returning it (and, of course, we could also have used a completely different implementation of the AccessControlSchemaProvider interface). By overriding the method the implementation of the super class is ignored, hence, only the new implementation is called at runtime. Other methods defined in WebSecurityBeansConfig which are not overridden by the subclass are still dispatched to WebSecurityBeansConfig.\n//... Other testing related annotations\n@SpringBootTest(classes = { TempWebSecurityConfig.class })\npublic class SomeTestClass {\npublic static class TempWebSecurityConfig extends WebSecurityBeansConfig {\n@Override\n@Bean\npublic AccessControlSchemaProvider accessControlSchemaProvider() {\nClassPathResource resource = new ClassPathResource(locationPrefix + &quot;access-control-schema3.xml&quot;);\nAccessControlSchemaProviderImpl accessControlSchemaProvider = new AccessControlSchemaProviderImpl();\naccessControlSchemaProvider.setAccessControlSchema(resource);\nreturn accessControlSchemaProvider;\n}\n}\n}\nThe following chapter of the Spring framework documentation explains issue, but uses a slightly different way to obtain the configuration.\nTest Data\nIt is possible to obtain test data in two different ways depending on your test&#x2019;s integration level.\n"},{"id":192,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-testing.asciidoc_debugging-tests","type":"docs","title":"Debugging Tests","body":"12.23.10. Debugging Tests\nThe following two sections describe two debugging approaches for tests. Tests are either run from within the IDE or from the command line using Maven.\nDebugging with the IDE\nDebugging with the IDE is as easy as always. Even if you want to execute a SubsystemTest which needs a Spring context and a server infrastructure to run properly, you just set your breakpoints and click on Debug As &#x2192; JUnit Test. The test infrastructure will take care of initializing the necessary infrastructure - if everything is configured properly.\nDebugging with Maven\nPlease refer to the following two links to find a guide for debugging tests when running them from Maven.\nhttp://maven.apache.org/surefire/maven-surefire-plugin/examples/debugging.html\nhttps://www.eclipse.org/jetty/documentation/9.3.x/debugging-with-eclipse.html\nIn essence, you first have to start execute a test using the command line. Maven will halt just before the test execution and wait for your IDE to connect to the process. When receiving a connection the test will start and then pause at any breakpoint set in advance.\nThe first link states that tests are started through the following command:\nmvn -Dmaven.surefire.debug test\nAlthough this is correct, it will run every test class in your project and - which is time consuming and mostly unnecessary - halt before each of these tests.\nTo counter this problem you can simply execute a single test class through the following command (here we execute the TablemanagementRestServiceTest from the restaurant sample application):\nmvn test -Dmaven.surefire.debug test -Dtest=TablemanagementRestServiceTest\nIt is important to notice that you first have to execute the Maven command in the according submodule, e.g. to execute the TablemanagementRestServiceTest you have first to navigate to the core module&#x2019;s directory.\n"},{"id":193,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-transferobject.asciidoc","type":"docs","title":"Transfer-Objects","body":"12.24. Transfer-Objects\nThe technical data model is defined in form of persistent entities.\nHowever, passing persistent entities via call-by-reference across the entire application will soon cause problems:\nChanges to a persistent entity are directly written back to the persistent store when the transaction is committed. When the entity is send across the application also changes tend to take place in multiple places endangering data sovereignty and leading to inconsistency.\nYou want to send and receive data via services across the network and have to define what section of your data is actually transferred. If you have relations in your technical model you quickly end up loading and transferring way too much data.\nModifications to your technical data model shall not automatically have impact on your external services causing incompatibilities.\nTo prevent such problems transfer-objects are used leading to a call-by-value model and decoupling changes to persistent entities.\nIn the following sections the different types of transfer-objects are explained.\nYou will find all according naming-conventions in the architecture-mapping\n"},{"id":194,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-transferobject.asciidoc_eto","type":"docs","title":"ETO","body":"12.24.1. ETO\nFor each persistent entity &#xAB;BusinessObject&#xBB;Entity we create or generate a corresponding entity transfer object (ETO) named &#xAB;BusinessObject&#xBB;Eto. It has the same properties except for relations.\n"},{"id":195,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-transferobject.asciidoc_bo","type":"docs","title":"BO","body":"12.24.2. BO\nIn order to centralize the properties (getters and setters with their javadoc) we create a common interface &#xAB;BusinessObject&#xBB; implemented both by the entity and its ETO. This also gives us compile-time safety that\nbean-mapper can properly map all properties between entity and ETO.\n"},{"id":196,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-transferobject.asciidoc_cto","type":"docs","title":"CTO","body":"12.24.3. CTO\nIf we need to pass an entity with its relation(s) we create a corresponding composite transfer object (CTO) named &#xAB;BusinessObject&#xBB;&#xAB;Subset&#xBB;Cto that only contains other transfer-objects or collections of them. Here &#xAB;Subset&#xBB; is empty for the canonical CTO that holds the ETO together with all its relations.\nThis is what can be generated automatically with CobiGen.\nHowever, be careful to generate CTOs without thinking and considering design.\nIf there are no relations at all a CTO is pointless and shall be omitted.\nHowever, if there are multiple relations you typically need multiple CTOs for the same &#xAB;BusinessObject&#xBB; that define different subsets of the related data.\nThese will typically be designed and implemented by hand.\nE.g. you may have CustomerWithAddressCto and CustomerWithContractCto. Most CTOs correspond to a specific &#xAB;BusinessObject&#xBB; and therefore contain a &#xAB;BusinessObject&#xBB;Eto. Such CTOs should inherit from MasterCto.\nThis pattern with entities, ETOs and CTOs is illustrated by the following UML diagram from our sample application.\nFigure 8. ETOs and CTOs\n"},{"id":197,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-transferobject.asciidoc_to","type":"docs","title":"TO","body":"12.24.4. TO\nFinally, there are typically transfer-objects for data that is never persistent.\nFor very generic cases these just carry the suffix To.\n"},{"id":198,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-transferobject.asciidoc_searchcriteriato","type":"docs","title":"SearchCriteriaTo","body":"12.24.5. SearchCriteriaTo\nFor searching we create or generate a &#xAB;BusinessObject&#xBB;SearchCriteriaTo representing a query to find instances of &#xAB;BusinessObject&#xBB;.\n"},{"id":199,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-transferobject.asciidoc_sto","type":"docs","title":"STO","body":"12.24.6. STO\nWe can potentially create separate service transfer objects (STO) (if possible named &#xAB;BusinessObject&#xBB;Sto) to keep the service API stable and independent of the actual data-model.\nHowever, we usually do not need this and want to keep our architecture simple.\nOnly create STOs if you need service versioning and support previous APIs or to provide legacy service technologies that require their own isolated data-model.\nIn such case you also need beanmapping between STOs and ETOs what means extra effort and complexity that should be avoided.\n"},{"id":200,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-beanmapping.asciidoc","type":"docs","title":"Bean-Mapping","body":"12.25. Bean-Mapping\nFor decoupling you sometimes need to create separate objects (beans) for a different view. E.g. for an external service you will use a transfer-object instead of the persistence entity so internal changes to the entity do not implicitly change or break the service.\nTherefore you have the need to map similar objects what creates a copy. This also has the benefit that modifications to the copy have no side-effect on the original source object. However, to implement such mapping code by hand is very tedious and error-prone (if new properties are added to beans but not to mapping code):\npublic UserEto mapUser(UserEntity source) {\nUserEto target = new UserEto();\ntarget.setUsername(source.getUsername());\ntarget.setEmail(source.getEmail());\n...\nreturn target;\n}\nTherefore we are using a BeanMapper for this purpose that makes our lives a lot easier.\n"},{"id":201,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-beanmapping.asciidoc_bean-mapper-dependency","type":"docs","title":"Bean-Mapper Dependency","body":"12.25.1. Bean-Mapper Dependency\nTo get access to the BeanMapper we have to use either of below dependency in our POM:\nWe started with dozer.sourceforge.net/[dozer] in devon4j and still support it. However, we now recommend orika (for new projects) as it is much faster (see Performance of Java Mapping Frameworks).\n&lt;dependency&gt;\n&lt;groupId&gt;com.devonfw.java&lt;/groupId&gt;\n&lt;artifactId&gt;devon4j-beanmapping-orika&lt;/artifactId&gt;\n&lt;/dependency&gt;\nor\n&lt;dependency&gt;\n&lt;groupId&gt;com.devonfw.java&lt;/groupId&gt;\n&lt;artifactId&gt;devon4j-beanmapping-dozer&lt;/artifactId&gt;\n&lt;/dependency&gt;\n"},{"id":202,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-beanmapping.asciidoc_bean-mapper-configuration-using-dozer","type":"docs","title":"Bean-Mapper Configuration using Dozer","body":"12.25.2. Bean-Mapper Configuration using Dozer\nThe BeanMapper implementation is based on an existing open-source bean mapping framework.\nIn case of Dozer the mapping is configured src/main/resources/config/app/common/dozer-mapping.xml.\nSee the my-thai-star dozer-mapping.xml as an example.\nImportant is that you configure all your custom datatypes as &lt;copy-by-reference&gt; tags and have the mapping from PersistenceEntity (ApplicationPersistenceEntity) to AbstractEto configured properly:\n&lt;mapping type=&quot;one-way&quot;&gt;\n&lt;class-a&gt;com.devonfw.module.basic.common.api.entity.PersistenceEntity&lt;/class-a&gt;\n&lt;class-b&gt;com.devonfw.module.basic.common.api.to.AbstractEto&lt;/class-b&gt;\n&lt;field custom-converter=&quot;com.devonfw.module.beanmapping.common.impl.dozer.IdentityConverter&quot;&gt;\n&lt;a&gt;this&lt;/a&gt;\n&lt;b is-accessible=&quot;true&quot;&gt;persistentEntity&lt;/b&gt;\n&lt;/field&gt;\n&lt;/mapping&gt;\n"},{"id":203,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-beanmapping.asciidoc_bean-mapper-usage","type":"docs","title":"Bean-Mapper Usage","body":"12.25.3. Bean-Mapper Usage\nThen we can get the BeanMapper via dependency-injection what we typically already provide by an abstract base class (e.g. AbstractUc). Now we can solve our problem very easy:\n...\nUserEntity resultEntity = ...;\n...\nreturn getBeanMapper().map(resultEntity, UserEto.class);\nThere is also additional support for mapping entire collections.\n"},{"id":204,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-datatype.asciidoc","type":"docs","title":"Datatypes","body":"12.26. Datatypes\nA datatype is an object representing a value of a specific type with the following aspects:\nIt has a technical or business specific semantic.\nIts JavaDoc explains the meaning and semantic of the value.\nIt is immutable and therefore stateless (its value assigned at construction time and can not be modified).\nIt is serializable.\nIt properly implements #equals(Object) and #hashCode() (two different instances with the same value are equal and have the same hash).\nIt shall ensure syntactical validation so it is NOT possible to create an instance with an invalid value.\nIt is responsible for formatting its value to a string representation suitable for sinks such as UI, loggers, etc. Also consider cases like a Datatype representing a password where toString() should return something like &quot;**&quot; instead of the actual password to prevent security accidents.\nIt is responsible for parsing the value from other representations such as a string (as needed).\nIt shall provide required logical operations on the value to prevent redundancies. Due to the immutable attribute all manipulative operations have to return a new Datatype instance (see e.g. BigDecimal.add(java.math.BigDecimal)).\nIt should implement Comparable if a natural order is defined.\nBased on the Datatype a presentation layer can decide how to view and how to edit the value. Therefore a structured data model should make use of custom datatypes in order to be expressive.\nCommon generic datatypes are String, Boolean, Number and its subclasses, Currency, etc.\nPlease note that both Date and Calendar are mutable and have very confusing APIs. Therefore, use JSR-310 or jodatime instead.\nEven if a datatype is technically nothing but a String or a Number but logically something special it is worth to define it as a dedicated datatype class already for the purpose of having a central javadoc to explain it. On the other side avoid to introduce technical datatypes like String32 for a String with a maximum length of 32 characters as this is not adding value in the sense of a real Datatype.\nIt is suitable and in most cases also recommended to use the class implementing the datatype as API omitting a dedicated interface.\n&#x2014; mmm project\ndatatype javadoc\nSee mmm datatype javadoc.\n"},{"id":205,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-datatype.asciidoc_datatype-packaging","type":"docs","title":"Datatype Packaging","body":"12.26.1. Datatype Packaging\nFor the devonfw we use a common packaging schema.\nThe specifics for datatypes are as following:\nSegment\nValue\nExplanation\n&lt;component&gt;\n*\nHere we use the (business) component defining the datatype or general for generic datatypes.\n&lt;layer&gt;\ncommon\nDatatypes are used across all layers and are not assigned to a dedicated layer.\n&lt;scope&gt;\napi\nDatatypes are always used directly as API even tough they may contain (simple) implementation logic. Most datatypes are simple wrappers for generic Java types (e.g. String) but make these explicit and might add some validation.\n"},{"id":206,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-datatype.asciidoc_technical-concerns","type":"docs","title":"Technical Concerns","body":"12.26.2. Technical Concerns\nMany technologies like Dozer and QueryDSL&#x2019;s (alias API) are heavily based on reflection. For them to work properly with custom datatypes, the frameworks must be able to instantiate custom datatypes with no-argument constructors. It is therefore recommended to implement a no-argument constructor for each datatype of at least protected visibility.\n"},{"id":207,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-datatype.asciidoc_datatypes-in-entities","type":"docs","title":"Datatypes in Entities","body":"12.26.3. Datatypes in Entities\nThe usage of custom datatypes in entities is explained in the persistence layer guide.\n"},{"id":208,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-datatype.asciidoc_datatypes-in-transfer-objects","type":"docs","title":"Datatypes in Transfer-Objects","body":"12.26.4. Datatypes in Transfer-Objects\nXML\nFor mapping datatypes with JAXB see XML guide.\nJSON\nFor mapping datatypes from and to JSON see JSON custom mapping.\n"},{"id":209,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-cors-support.asciidoc","type":"docs","title":"CORS support","body":"12.27. CORS support\nWhen you are developing Javascript client and server application separately, you have to deal with cross domain issues. We have to request from a origin domain distinct to target domain and browser does not allow this.\nSo , we need to prepare server side to accept request from other domains. We need to cover the following points:\nAccept request from other domains.\nAccept devonfw used headers like X-CSRF-TOKEN or correlationId.\nBe prepared to receive secured request (cookies).\nIt is important to note that if you are using security in your request (sending cookies) you have to set withCredentials flag to true in your client side request and deal with special IE8 characteristics.\n"},{"id":210,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-cors-support.asciidoc_configuring-cors-support","type":"docs","title":"Configuring CORS support","body":"12.27.1. Configuring CORS support\nDependency\nTo enable the CORS support from the server side add the below dependency.\n&lt;dependency&gt;\n&lt;groupId&gt;com.devonfw.java.starters&lt;/groupId&gt;\n&lt;artifactId&gt;devon4j-starter-security-cors&lt;/artifactId&gt;\n&lt;/dependency&gt;\nConfiguration\nAdd the below properties in your application.properties file.\n#CORS support\nsecurity.cors.spring.allowCredentials=true\nsecurity.cors.spring.allowedOriginPatterns=*\nsecurity.cors.spring.allowedHeaders=*\nsecurity.cors.spring.allowedMethods=OPTIONS,HEAD,GET,PUT,POST,DELETE,PATCH\nsecurity.cors.pathPattern=/**\nAttribute\nDescription\nHTTP Header\nallowCredentials\nDecides the browser should include any cookies associated with the request (true if cookies should be included).\nAccess-Control-Allow-Credentials\nallowedOrigins\nList of allowed origins (use * to allow all orgins).\nAccess-Control-Allow-Origin\nallowedMethods\nList of allowed HTTP request methods (OPTIONS, HEAD, GET, PUT, POST, DELETE, PATCH, etc.).\n-\nallowedHeaders\nList of allowed headers that can be used during the request (use * to allow all headers requested by the client)\nAccess-Control-Allow-Headers\npathPattern\nAnt-style pattern for the URL paths where to apply CORS. Use &quot;/**&quot; to match all URL paths.\nMore information about the CORS headers can be found here\n"},{"id":211,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-blob-support.asciidoc","type":"docs","title":"BLOB support","body":"12.28. BLOB support\nBLOB stands for Binary Large Object. A BLOB may be an image, an office document, ZIP archive or any other multimedia object.\nOften these BLOBs are large. if this is the case you need to take care, that you do not copy all the blob data into you application heap, e.g. when providing them via a REST service.\nThis could easily lead to performance problems or out of memory errors.\nAs solution for that problem is &quot;streaming&quot; those BLOBs directly from the database to the client. To demonstrate how this can be accomplished, devonfw provides a example.\n"},{"id":212,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-blob-support.asciidoc_further-reading","type":"docs","title":"Further Reading","body":"12.28.1. Further Reading\nBLOBs and the Data Access Layer\nSecurity Vulnerability Unrestricted File Upload\n"},{"id":213,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-jdk.asciidoc","type":"docs","title":"Java Development Kit","body":"12.29. Java Development Kit\nThe Java Development Kit is an implementation of the Java platform. It provides the Java Virtual Machine (JVM) and the Java Runtime Environment (JRE).\n"},{"id":214,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-jdk.asciidoc_editions","type":"docs","title":"Editions","body":"12.29.1. Editions\nThe JDK exists in different editions:\nOpenJDK is a free and open-source edition of the JDK.\nOracleJDK is a commercial edition of the JDK.\nVarious alternative JDK editions either commercial (e.g. IBM&#x2019;s JVM) or open-source.\nAs Java is evolving and also complex maintaining a JVM requires a lot of energy.\nTherefore many alternative JDK editions are unable to cope with this and support latest Java versions and according compatibility.\nUnfortunately OpenJDK only maintains a specific version of Java for a relative short period of time before moving to the next major version.\nIn the end, this technically means that OpenJDK is continuous beta and can not be used in production for reasonable software projects.\nAs OracleJDK changed its licensing model and can not be used for commercial usage even during development, things can get tricky.\nYou may want to use OpenJDK for development and OracleJDK only in production.\nHowever, e.g. OpenJDK 11 never released a version that is stable enough for reasonable development (e.g. javadoc tool is broken and fixes are not available of OpenJDK 11 - fixed in 11.0.3 what is only available as OracleJDK 11 or you need to go to OpenJDK 12+, what has other bugs) so in the end there is no working release of OpenJDK 11.\nThis more or less forces you to use OracleJDK what requires you to buy a subscription so you can use it for commercial development.\nHowever, there is AdoptOpenJDK that provides forked releases of OpenJDK with bug-fixes what might be an option.\nAnyhow, as you want to have your development environment close to production, the productively used JDK (most likely OracleJDK) should be preferred also for development.\n"},{"id":215,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-jdk.asciidoc_upgrading","type":"docs","title":"Upgrading","body":"12.29.2. Upgrading\nUntil Java 8 compatibility was one of the key aspects for Java version updates (after the mess on the Swing updates with Java2 many years ago).\nHowever, Java 9 introduced a lot of breaking changes.\nThis documentation wants to share the experience we collected in devonfw when upgrading from Java 8 to newer versions.\nFirst of all we separate runtime changes that you need if you want to build your software with JDK 8 but such that it can also run on newer versions (e.g. JRE 11)\nfrom changes required to also build your software with more recent JDKs (e.g. JDK 11 or 12).\nRuntime Changes\nThis section describes required changes to your software in order to make it run also with versions newer than Java 8.\nClasses removed from JDK\nThe first thing that most users hit when running their software with newer Java versions is a ClassNotFoundException like this:\nCaused by: java.lang.ClassNotFoundException: javax.xml.bind.JAXBException\nAs Java 9 introduced a module system with Jigsaw, the JDK that has been a monolithic mess is now a well-defined set of structured modules.\nSome of the classes that used to come with the JDK moved to modules that where not available by default in Java 9 and have even been removed entirely in later versions of Java.\nTherefore you should simply treat such code just like any other 3rd party component that you can add as a (maven) dependency.\nThe following table gives you the required hints to make your software work even with such classes / modules removed from the JDK (please note that the specified version is just a suggestion that worked, feel free to pick a more recent or more appropriate version):\nTable 39. Dependencies for classes removed from Java 8 since 9+\nClass\nGroupId\nArtifactId\nVersion\njavax.xml.bind.*\njavax.xml.bind\njaxb-api\n2.3.1\ncom.sun.xml.bind.*\norg.glassfish.jaxb\njaxb-runtime\n2.3.1\njava.activation.*\njavax.activation\njavax.activation-api\n1.2.0\njava.transaction.*\njavax.transaction\njavax.transaction-api\n1.2\njava.xml.ws.*\njavax.xml.ws\njaxws-api\n2.3.1\njavax.jws.*\njavax.jws\njavax.jws-api\n1.1\njavax.annotation.*\njavax.annotation\njavax.annotation-api\n1.3.2\n3rd Party Updates\nFurther, internal and inofficial APIs (e.g. sun.misc.Unsafe) have been removed.\nThese are typically not used by your software directly but by low-level 3rd party libraries like asm that need to be updated.\nAlso simple things like the Java version have changed (from 1.8.x to 9.x, 10.x, 11.x, 12.x, etc.).\nSome 3rd party libraries were parsing the Java version in a very naive way making them unable to be used with Java 9+:\nCaused by: java.lang.NullPointerException\nat org.apache.maven.surefire.shade.org.apache.commons.lang3.SystemUtils.isJavaVersionAtLeast (SystemUtils.java:1626)\nTherefore the following table gives an overview of common 3rd party libraries that have been affected by such breaking changes and need to be updated to at least the specified version:\nTable 40. Minimum recommended versions of common 3rd party for Java 9+\nGroupId\nArtifactId\nVersion\nIssue\norg.apache.commons\ncommons-lang3\n3.7\nLANG-1365\ncglib\ncglib\n3.2.9\n102, 93, 133\norg.ow2.asm\nasm\n7.1\n2941\norg.javassist\njavassist\n3.25.0-GA\n194, 228, 246, 171\nResourceBundles\nFor internationalization (i18n) and localization (l10n) ResourceBundle is used for language and country specific texts and configurations as properties (e.g. MyResourceBundle_de.properties). With Java modules there are changes and impacts you need to know to get things working. The most important change is documented in the JavaDoc of ResourceBundle. However, instead of using ResourceBundleProvider and refactoring your entire code causing incompatibilities, you can simply put the resource bundles in a regular JAR on the classpath rather than a named module (or into the lauching app).\nIf you want to implement (new) Java modules with i18n support, you can have a look at mmm-nls.\nBuildtime Changes\nIf you also want to change your build to work with a recent JDK you also need to ensure that test frameworks and maven plugins properly support this.\nFindbugs\nFindbugs does not work with Java 9+ and is actually a dead project.\nThe new findbugs is SpotBugs.\nFor maven the new solution is spotbugs-maven-plugin:\n&lt;plugin&gt;\n&lt;groupId&gt;com.github.spotbugs&lt;/groupId&gt;\n&lt;artifactId&gt;spotbugs-maven-plugin&lt;/artifactId&gt;\n&lt;version&gt;3.1.11&lt;/version&gt;\n&lt;/plugin&gt;\nTest Frameworks\nTable 41. Minimum recommended versions of common 3rd party test frameworks for Java 9+\nGroupId\nArtifactId\nVersion\nIssue\norg.mockito\nmockito-core\n2.23.4\n1419, 1696, 1607, 1594, 1577, 1482\nMaven Plugins\nTable 42. Minimum recommended versions of common maven plugins for Java 9+\nGroupId\nArtifactId\n(min.) Version\nIssue\norg.apache.maven.plugins\nmaven-compiler-plugin\n3.8.1\nx\norg.apache.maven.plugins\nmaven-surefire-plugin\n2.22.2\nSUREFIRE-1439\norg.apache.maven.plugins\nmaven-surefire-report-plugin\n2.22.2\nSUREFIRE-1439\norg.apache.maven.plugins\nmaven-archetype-plugin\n3.1.0\nx\norg.apache.maven.plugins\nmaven-javadoc-plugin\n3.1.0\nx\norg.jacoco\njacoco-maven-plugin\n0.8.3\n663\nMaven Usage\nWith Java modules you can not run Javadoc standalone anymore or you will get this error when running mvn javadoc:javadoc:\n[ERROR] Failed to execute goal org.apache.maven.plugins:maven-javadoc-plugin:3.1.1:javadoc (default-cli) on project mmm-base: An error has occurred in Javadoc report generation:\n[ERROR] Exit code: 1 - error: module not found: io.github.mmm.base\n[ERROR]\n[ERROR] Command line was: /projects/mmm/software/java/bin/javadoc @options @packages @argfile\nAs a solution or workaround you need to include the compile goal into your build lifecycle so the module-path is properly configured:\nmvn compile javadoc:javadoc\n"},{"id":216,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-jdk.asciidoc_sources-and-links","type":"docs","title":"Sources and Links","body":"12.29.3. Sources and Links\nWe want to give credits and say thanks to the following articles that have been there before and helped us on our way:\nJava 9 Migration Guide: The Seven Most Common Challenges\nIt&#x2019;s time! Migrating to Java 11\nMigrate Maven Projects to Java 11\nJAXB on Java 9, 10, 11 and beyond\nJAXB Artifacts\n"},{"id":217,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-microservice.asciidoc","type":"docs","title":"Microservices in devonfw","body":"12.30. Microservices in devonfw\nThe Microservices architecture is an approach for application development based on a series of small services grouped under a business domain. Each individual service runs autonomously and communicating with each other through their APIs. That independence between the different services allows to manage (upgrade, fix, deploy, etc.) each one without affecting the rest of the system&#x2019;s services. In addition to that the microservices architecture allows to scale specific services when facing an increment of the requests, so the applications based on microservices are more flexible and stable, and can be adapted quickly to demand changes.\nHowever, this new approach, developing apps based on microservices, presents some downsides.\nLet&#x2019;s see the main challenges when working with microservices:\nHaving the applications divided in different services we will need a component (router) to redirect each request to the related microservice. These redirection rules must implement filters to guarantee a proper functionality.\nIn order to manage correctly the routing process, the application will also need a catalog with all the microservices and its details: IPs and ports of each of the deployed instances of each microservice, the state of each instance and some other related information. This catalog is called Service Discovery.\nWith all the information of the Service Discovery the application will need to calculate and select between all the available instances of a microservice which is the suitable one. This will be figured out by the library Client Side Load Balancer.\nThe different microservices will be likely interconnected with each other, that means that in case of failure of one of the microservices involved in a process, the application must implement a mechanism to avoid the error propagation through the rest of the services and provide an alternative as a process result. To solve this, the pattern Circuit Breaker can be implemented in the calls between microservices.\nAs we have mentioned, the microservices will exchange calls and information with each other so our applications will need to provide a secured context to avoid not allowed operations or intrusions. In addition, since microservices must be able to operate in an isolated way, it is not recommended to maintain a session. To meet this need without using Spring sessions, a token-based authentication is used that exchanges information using the json web token (JWT) protocol.\nIn addition to all of this we will find other issues related to this particular architecture that we will address fitting the requirements of each project.\nDistributed data bases: each instance of a microservice should have only one data base.\nCentralized logs: each instance of a microservice creates a log and a trace that should be centralized to allow an easier way to read all that information.\nCentralized configuration: each microservice has its own configuration, so our applications should group all those configurations in only one place to ease the configuration management.\nAutomatized deployments: as we are managing several components (microservices, catalogs, balancers, etc.) the deployment should be automatized to avoid errors and ease this process.\nTo address the above, devonfw microservices has an alternative approach Microservices based on Netflix-Tools.\n"},{"id":218,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-apm.asciidoc","type":"docs","title":"Application Performance Management","body":"12.31. Application Performance Management\nThis guide gives hints how to manage, monitor and analyse performance of Java applications.\n"},{"id":219,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-apm.asciidoc_temporary-analysis","type":"docs","title":"Temporary Analysis","body":"12.31.1. Temporary Analysis\nIf you are facing performance issues and want to do a punctual analysis we recommend you to use glowroot. It is ideal in cases where monitoring in your local development environment is suitable. However, it is also possible to use it in your test environment. It is entirely free and open-source. Still it is very powerful and helps to trace down bottlenecks. To get a first impression of the tool take a look at the demo.\nJEE/WTP\nIn case you are forced to use an JEE application server and want to do a temporary analysis you can double click your server instance from the servers view in Eclipse and click on the link Open launch configuration in order to add the -javaagent JVM option.\n"},{"id":220,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-apm.asciidoc_regular-analysis","type":"docs","title":"Regular Analysis","body":"12.31.2. Regular Analysis\nIn case you want to manage application performance regularly we recommend to use JavaMelody that can be integrated into your application. More information on javamelody is available on the JavaMelody Wiki\n"},{"id":221,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-apm.asciidoc_alternatives","type":"docs","title":"Alternatives","body":"12.31.3. Alternatives\nPinPoint\nOpenAPM\nAppDynamics\nZabbix\n"},{"id":222,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-caching.asciidoc","type":"docs","title":"Caching","body":"12.32. Caching\nCaching is a technical approach to improve performance. While it may appear easy on the first sight it is an advanced topic. In general, try to use caching only when required for performance reasons. If you come to the point that you need caching first think about:\nWhat to cache?\nBe sure about what you want to cache. Is it static data? How often will it change? What will happen if the data changes but due to caching you might receive &quot;old&quot; values? Can this be tolerated? For how long? This is not a technical question but a business requirement.\nWhere to cache?\nWill you cache data on client or server? Where exactly?\nHow to cache?\nIs a local cache sufficient or do you need a shared cache?\n"},{"id":223,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-caching.asciidoc_local-cache","type":"docs","title":"Local Cache","body":"12.32.1. Local Cache\n"},{"id":224,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-caching.asciidoc_shared-cache","type":"docs","title":"Shared Cache","body":"12.32.2. Shared Cache\nDistributed Cache\n"},{"id":225,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-caching.asciidoc_products","type":"docs","title":"Products","body":"12.32.3. Products\nhttp://ehcache.org/\nhttp://hazelcast.org/\nhttp://terracotta.org/\nhttp://memcached.org/\n"},{"id":226,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-caching.asciidoc_caching-of-web-resources","type":"docs","title":"Caching of Web-Resources","body":"12.32.4. Caching of Web-Resources\nhttp://www.mobify.com/blog/beginners-guide-to-http-cache-headers/\nhttp://en.wikipedia.org/wiki/Web_cache#Cache_control\nhttp://en.wikipedia.org/wiki/List_of_HTTP_header_fields#Avoiding_caching\n"},{"id":227,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-feature-toggle.asciidoc","type":"docs","title":"Feature-Toggles","body":"12.33. Feature-Toggles\nThe most software developing teams use Feature-Branching to be able to work in parallel and maintain a stable main branch in the VCS. However Feature-Branching might not be the ideal tool in every case because of big merges and isolation between development groups. In many cases, Feature-Toggles can avoid some of these problems, so these should definitely be considered to be used in the collaborative software development.\n"},{"id":228,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-feature-toggle.asciidoc_implementation-with-the-devonfw","type":"docs","title":"Implementation with the devonfw","body":"12.33.1. Implementation with the devonfw\nTo use Feature-Toggles with the devonfw, use the Framework Togglz because it has all the features generally needed and provides a great documentation.\nFor a pretty minimal working example, also see this fork.\nPreparation\nThe following example takes place in the oasp-sample-core project, so the necessary dependencies have to be added to the according pom.xml file. Required are the main Togglz project including Spring support, the Togglz console to graphically change the feature state and the Spring security package to handle authentication for the Togglz console.\n&lt;!-- Feature-Toggle-Framework togglz --&gt;\n&lt;dependency&gt;\n&lt;groupId&gt;org.togglz&lt;/groupId&gt;\n&lt;artifactId&gt;togglz-spring-boot-starter&lt;/artifactId&gt;\n&lt;version&gt;2.3.0.RC2&lt;/version&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n&lt;groupId&gt;org.togglz&lt;/groupId&gt;\n&lt;artifactId&gt;togglz-console&lt;/artifactId&gt;\n&lt;version&gt;2.3.0.RC2&lt;/version&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n&lt;groupId&gt;org.togglz&lt;/groupId&gt;\n&lt;artifactId&gt;togglz-spring-security&lt;/artifactId&gt;\n&lt;version&gt;2.3.0.RC2&lt;/version&gt;\n&lt;/dependency&gt;\nIn addition to that, the following lines have to be included in the spring configuration file application.properties\n# configuration for the togglz Feature-Toggle-Framework\ntogglz.enabled=true\ntogglz.console.secured=false\nSmall features\nFor small features, a simple query of the toggle state is often enough to achieve the desired functionality. To illustrate this, a simple example follows, which implements a toggle to limit the page size returned by the staffmanagement. See here for further details.\nThis is the current implementation to toggle the feature:\n// Uncomment next line in order to limit the maximum page size for the staff member search\n// criteria.limitMaximumPageSize(MAXIMUM_HIT_LIMIT);\nTo realise this more elegantly with Togglz, first an enum is required to configure the feature-toggle.\npublic enum StaffmanagementFeatures implements Feature {\n@Label(&quot;Limit the maximum page size for the staff members&quot;)\nLIMIT_STAFF_PAGE_SIZE;\npublic boolean isActive() {\nreturn FeatureContext.getFeatureManager().isActive(this);\n}\n}\nTo familiarize the Spring framework with the enum, add the following entry to the application.properties file.\ntogglz.feature-enums=io.oasp.gastronomy.restaurant.staffmanagement.featuremanager.StaffmanagementFeatures\nAfter that, the toggle can be used easily by calling the isActive() method of the enum.\nif (StaffmanagementFeatures.LIMIT_STAFF_PAGE_SIZE.isActive()) {\ncriteria.limitMaximumPageSize(MAXIMUM_HIT_LIMIT);\n}\nThis way, you can easily switch the feature on or off by using the administration console at http://localhost:8081/devon4j-sample-server/togglz-console. If you are getting redirected to the login page, just sign in with any valid user (eg. admin).\nExtensive features\nWhen implementing extensive features, you might want to consider using the strategy design pattern to maintain the overview of your software. The following example is an implementation of a feature which adds a 25% discount to all products managed by the offermanagement.\nTherefore there are two strategies needed:\nReturn the offers with the normal price\nReturn the offers with a 25% discount\nThe implementation is pretty straight forward so use this as a reference. Compare this for further details.\n@Override\n@RolesAllowed(PermissionConstants.FIND_OFFER)\npublic PaginatedListTo&lt;OfferEto&gt; findOfferEtos(OfferSearchCriteriaTo criteria) {\ncriteria.limitMaximumPageSize(MAXIMUM_HIT_LIMIT);\nPaginatedListTo&lt;OfferEntity&gt; offers = getOfferDao().findOffers(criteria);\nif (OffermanagementFeatures.DISCOUNT.isActive()) {\nreturn getOfferEtosDiscount(offers);\n} else {\nreturn getOfferEtosNormalPrice(offers);\n}\n}\n// Strategy 1: Return the OfferEtos with the normal price\nprivate PaginatedListTo&lt;OfferEto&gt; getOfferEtosNormalPrice(PaginatedListTo&lt;OfferEntity&gt; offers) {\nreturn mapPaginatedEntityList(offers, OfferEto.class);\n}\n// Strategy 2: Return the OfferEtos with the new, discounted price\nprivate PaginatedListTo&lt;OfferEto&gt; getOfferEtosDiscount(PaginatedListTo&lt;OfferEntity&gt; offers) {\noffers = addDiscountToOffers(offers);\nreturn mapPaginatedEntityList(offers, OfferEto.class);\n}\nprivate PaginatedListTo&lt;OfferEntity&gt; addDiscountToOffers(PaginatedListTo&lt;OfferEntity&gt; offers) {\nfor (OfferEntity oe : offers.getResult()) {\nDouble oldPrice = oe.getPrice().getValue().doubleValue();\n// calculate the new price and round it to two decimal places\nBigDecimal newPrice = new BigDecimal(oldPrice * 0.75);\nnewPrice = newPrice.setScale(2, RoundingMode.HALF_UP);\noe.setPrice(new Money(newPrice));\n}\nreturn offers;\n}\n"},{"id":229,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-feature-toggle.asciidoc_guidelines-for-a-successful-use-of-feature-toggles","type":"docs","title":"Guidelines for a successful use of feature-toggles","body":"12.33.2. Guidelines for a successful use of feature-toggles\nThe use of feature-toggles requires a specified set of guidelines to maintain the overview on the software. The following is a collection of considerations and examples for conventions that are reasonable to use.\nMinimize the number of toggles\nWhen using too many toggles at the same time, it is hard to maintain a good overview of the system and things like finding bugs are getting much harder. Additionally, the management of toggles in the configuration interface gets more difficult due to the amount of toggles.\nTo prevent toggles from piling up during development, a toggle and the associated obsolete source code should be removed after the completion of the corresponding feature. In addition to that, the existing toggles should be revisited periodically to verify that these are still needed and therefore remove legacy toggles.\nConsistent naming scheme\nA consistent naming scheme is the key to a structured and easily maintainable set of features. This should include the naming of toggles in the source code and the appropriate naming of commit messages in the VCS. The following section contains an example for a useful naming scheme including a small example.\nEvery Feature-Toggle in the system has to get its own unique name without repeating any names of features, which were removed from the system. The chosen names should be descriptive names to simplify the association between toggles and their purpose. If the feature should be split into multiple sub-features, you might want to name the feature like the parent feature with a describing addition. If for example you want to split the DISCOUNT feature into the logic and the UI part, you might want to name the sub-features DISCOUNT_LOGIC and DISCOUNT_UI.\nThe entry in the togglz configuration enum should be named identically to the aforementioned feature name. The explicitness of feature names prevents a confusion between toggles due to using multiple enums.\nCommit messages are very important for the use of feature-toggles and also should follow a predefined naming scheme. You might want to state the feature name at the beginning of the message, followed by the actual message, describing what the commit changes to the feature. An example commit message could look like the following:\nDISCOUNT: Add the feature-toggle to the offermanagement implementation.\nMentioning the feature name in the commit message has the advantage, that you can search your git log for the feature name and get every commit belonging to the feature. An example for this using the tool grep could look like this.\n$ git log | grep -C 4 DISCOUNT\ncommit 034669a48208cb946cc6ba8a258bdab586929dd9\nAuthor: Florian Luediger &lt;florian.luediger@somemail.com&gt;\nDate: Thu Jul 7 13:04:37 2016 +0100\nDISCOUNT: Add the feature-toggle to the offermanagement implementation.\nTo keep track of all the features in your software system, a platform like GitHub offers issues. When creating an issue for every feature, you can retrace, who created the feature and who is assigned to completing its development. When referencing the issue from commits, you also have links to all the relevant commits from the issue view.\nPlacement of toggle points\nTo maintain a clean codebase, you definitely want to avoid using the same toggle in different places in the software. There should be one single query of the toggle which should be able to toggle the whole functionality of the feature. If one single toggle point is not enough to switch the whole feature on or off, you might want to think about splitting the feature into multiple ones.\nUse of fine-grained features\nBigger features in general should be split into multiple sub-features to maintain the overview on the codebase. These sub-features get their own feature-toggle and get implemented independently.\n"},{"id":230,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-accessibility.asciidoc","type":"docs","title":"Accessibility","body":"12.34. Accessibility\nTODO\nhttp://www.w3.org/TR/WCAG20/\nhttp://www.w3.org/WAI/intro/aria\nhttp://www.einfach-fuer-alle.de/artikel/bitv/\nhttp://www.banu.bund.de\nhttp://www.de.capgemini.com/public-sector/igov\n"},{"id":231,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-jee.asciidoc","type":"docs","title":"JEE","body":"12.35. JEE\nThis section is about Java Enterprise Edition (JEE). Regarding to our key principles we focus on open standards. For Java this means that we consider official standards from Java Standard and Enterprise Edition as first choice for considerations. Therefore we also decided to recommend JAX-RS over SpringMVC as the latter is proprietary. Only if an existing Java standard is not suitable for current demands such as Java Server Faces (JSF), we do not officially recommend it (while you are still free to use it if you have good reasons to do so). In all other cases we officially suggest the according standard and use it in our guides, code-samples, sample application, modules, templates, etc. Examples for such standards are JPA, JAX-RS, JAX-WS, JSR330, JSR250, JAX-B, etc.\n"},{"id":232,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-jee.asciidoc_application-server","type":"docs","title":"Application-Server","body":"12.35.1. Application-Server\nWe designed everything based on standards to work with different technology stacks and servlet containers. However, we strongly encourage to use spring and spring-boot. You are free to decide for something else but here is a list of good reasons for our decision:\nUp-to-date\nWith spring you easily keep up to date with evolving technologies (microservices, reactive, NoSQL, etc.). Most application servers put you in a jail with old legacy technology. In many cases you are even forced to use a totally outdated version of java (JVM/JDK). This may even cause severe IT-Security vulnerabilities but with expensive support you might get updates. Also with spring and open-source you need to be aware that for IT-security you need to update recently what can cost quite a lot of additional maintenance effort.\nDevelopment speed\nWith spring-boot you can implement and especially test your individual logic very fast. Starting the app in your IDE is very easy, fast, and realistic (close to production). You can easily write JUnit tests that startup your server application to e.g. test calls to your remote services via HTTP fast and easy. For application servers you need to bundle and deploy your app what takes more time and limits you in various ways. We are aware that this has improved in the past but also spring continuously improves and is always way ahead in this area. Further, with spring you have your configurations bundled together with the code in version control (still with ability to handle different environments) while with application servers these are configured externally and can not be easily tested during development.\nDocumentation\nSpring has an extremely open and active community. There is documentation for everything available for free on the web. You will find solutions to almost any problem on platforms like stackoverflow. If you have a problem you are only a google search away from your solution. This is very much different for proprietary application server products.\nHelpful Exception Messages\nSpring is really great for developers on exception messages. If you do something wrong you get detailed and helpful messages that guide you to the problem or even the solution. This is not as great in application servers.\nFuture-proof\nSpring has evolved really awesome over time. Since its 1.0 release in 2004 spring has continuously been improved and always caught up with important trends and innovations. Even in critical situations, when the company behind it (interface21) was sold, spring went on perfectly.\nJEE went through a lot of trouble and crisis. Just look at the EJB pain stories. This happened often in the past and also recent. See JEE 8 in crisis.\nFree\nSpring and its ecosystem is free and open-source. It still perfectly integrates with commercial solutions for specific needs. Most application servers are commercial and cost a lot of money. As of today the ROI for this is of question.\nFun\nIf you go to conferences or ask developers you will see that spring is popular and fun. If new developers are forced to use an old application server product they will be less motivated or even get frustrated. Especially in today&#x2019;s agile projects this is a very important aspect. In the end you will get into trouble with maintenance on the long run if you rely on a proprietary application server.\nOf course the vendors of application servers will tell you a different story. This is simply because they still make a lot of money from their products. We do not get paid from application servers nor from spring. We are just developers who love to build great systems. A good reason for application servers is that they combine a set of solutions to particular aspects to one product that helps to standardize your IT. However, devonfw fills exactly this gap for the spring ecosystem in a very open and flexible way. However, there is one important aspect that you need to understand and be aware of:\nSome big companies decided for a specific application server as their IT strategy. They may have hundreds of apps running with this application server. All their operators and developers have learned a lot of specific skills for this product and are familiar with it. If you are implementing yet another (small) app in this context it can make sense to stick with this application server. However, also they have to be aware that with every additional app they increase their technical debt.\n"},{"id":233,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-kafka.asciidoc","type":"docs","title":"Messaging Services","body":"12.36. Messaging Services\nMessaging Services provide an asynchronous communication mechanism between applications. Technically this is\nimplemented using Apache Kafka .\nDevonfw uses Spring-Kafka as kafka framework.\nThis guide explains how Spring kafka is used in devonfw applications. It focuses on aspects which are special to devonfw if you want to learn about spring-kafka you should adhere to springs references documentation.\nThere is an example of simple kafka implementation in the devon4j-kafka-employeeapp.\nThe devon4j-kafka library consist of:\nCustom message processor with retry pattern\nMonitoring support\nTracing support\nLogging support\nConfiguration support for Kafka Producers, Consumers, brave tracer and message retry processing including defaults\n"},{"id":234,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-kafka.asciidoc_how-to-use","type":"docs","title":"How to use?","body":"12.36.1. How to use?\nTo use devon4j-kafka you have to add required starter dependencies which is &quot;starter-kafka-sender&quot; or &quot;starter-kafka-receiver&quot; from devon4j. These 2 starters are responsible for taking care of the required spring configuration. If you only want to produce messages &quot;starter-kafka-sender&quot; is enough. For consuming messages you need &quot;starter-kafka-receiver&quot; which also includes &quot;starter-kafka-sender&quot;.\nTo use devon4j-kafka message sender add the below dependency:\n&lt;dependency&gt;\n&lt;groupId&gt;com.devonfw.java.starters&lt;/groupId&gt;\n&lt;artifactId&gt;devon4j-starter-kafka-sender&lt;/artifactId&gt;\n&lt;/dependency&gt;\nIt includes the Tracer implementations from Spring cloud sleuth.\nTo use the devon4j-kafka message receiver configurations , loggers and message retry processor for processing message, add the below dependency:\n&lt;dependency&gt;\n&lt;groupId&gt;com.devonfw.java.starters&lt;/groupId&gt;\n&lt;artifactId&gt;devon4j-starter-kafka-receiver&lt;/artifactId&gt;\n&lt;/dependency&gt;\n"},{"id":235,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-kafka.asciidoc_-property-parameters","type":"docs","title":"Property Parameters","body":"12.36.2. Property Parameters\nAs written before kafka-producer and listener-specific configuration is done via properties classes. These classes provide useful defaults, at a minimum the following parameters have to be configured:\nmessaging.kafka.common.bootstrap-servers=kafka-broker:9092\nmessaging.kafka.consumer.group-id=&lt;e.g. application name&gt;\nmessaging.kafka.listener.container.concurrency=&lt;Number of listener threads for each listener container&gt;\nAll the configuration beans for devon4j-kafka are annotated with @ConfigurationProperties and use common prefixes to read the property values from application.properties or application.yml.\nExample:\n@Bean\n@ConfigurationProperties(prefix = &quot;messaging.kafka.producer&quot;)\npublic KafkaProducerProperties messageKafkaProducerProperties() {\nreturn new KafkaProducerProperties();\n}\nFor producer and consumer the prefixes are messaging.kafka.producer&#x2026;&#x200B; and `message.kafka.consumer&#x2026;&#x200B; and for retry the prefix is `messaging.retry&#x2026;&#x200B;\nSee devon4j-kafka-employeeapp&#x2019;s application.properties file for an example.\nWe use the same properties defined by Apache Kafka or Spring Kafka. They are simply &quot;mapped&quot; to the above prefixes to allow easy access from your application properties. The java docs provided in each of the devon4j-kafka property classes which explains their use and what value has to be passed.\nThe Devon4j-Kafka-Producer properties are defined from kafka prodcuer config.\nThe Devon4j-Kafka-Consumer properties are defined from kafka consumer config.\nThe Devon4j-Kafka-Listener container properties are defined from Spring kafka listener properties.\n"},{"id":236,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-kafka.asciidoc_naming-convention-for-topics","type":"docs","title":"Naming convention for topics","body":"12.36.3. Naming convention for topics\nFor better managing of several Kafka topics in your application portfolio we devon strongly advice to introduce a naming scheme for your topics. The schema may depend on the actual usage pattern of kafka. For context where kafka is used\nin a 1-to-1-communication-scheme (not publish/subscribe) the following schema as been proven useful in practice:\n&lt;application name&gt;-&lt;service name&gt;-&lt;version&gt;-&lt;service-operation&gt;\nTo keep thing easy and prevent problems we suggest to use only small letters, hyphens but no other special characters.\n"},{"id":237,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-kafka.asciidoc_send-messages","type":"docs","title":"Send Messages","body":"12.36.4. Send Messages\nAs mentioned above the &apos;starter-kafka-sender&apos; is required to be added as dependency to use MessageSender from kafka.\n&lt;dependency&gt;\n&lt;groupId&gt;com.devonfw.java.starters&lt;/groupId&gt;\n&lt;artifactId&gt;devon4j-starter-kafka-sender&lt;/artifactId&gt;\n&lt;/dependency&gt;\nThe following example shows how to use MessageSender and its method to send message to kafka broker:\nExample:\n@Inject\nprivate MessageSender messageSender;\nprivate ProducerRecord&lt;K,V&gt; producerRecord;\npublic void sendMessageToKafka(){\nproducerRecord=new ProducerRecord&lt;&gt;(&quot;topic-name&quot;,&quot;message&quot;);\nmessageSender.sendMessage(this.producerRecord);\n//Alternative\nmessageSender.sendMessageAndWait(this.producerRecord,10);\n}\nThere are multiple methods available from MessageSender of devon4j-kafka. The ProducerListener will log the message sent tot he kafka broker.\n"},{"id":238,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-kafka.asciidoc_receive-messages","type":"docs","title":"Receive Messages","body":"12.36.5. Receive Messages\nTo receive messages you have to define a listener. The listener is normally part of the service layer.\nFigure 9. Architecture for Kafka services\nImport the following starter-kafka-receiver dependency to use the listener configurations and loggers from devon4j-kafka.\n&lt;dependency&gt;\n&lt;groupId&gt;com.devonfw.java.starters&lt;/groupId&gt;\n&lt;artifactId&gt;devon4j-starter-kafka-receiver&lt;/artifactId&gt;\n&lt;/dependency&gt;\nThe listener\nis defined by implementing and annotating a method like in the following example:\n@KafkaListener(topics = &quot;employeeapp-employee-v1-delete&quot;, groupId = &quot;${messaging.kafka.consumer.groupId}&quot;, containerFactory = &quot;kafkaListenerContainerFactory&quot;)\npublic void consumer(ConsumerRecord&lt;Object, Object&gt; consumerRecord, Acknowledgment acknowledgment) {\n//user operation\n//To acknowledge listener after processing\nacknowledgement.acknowledge();\n}\nThe group id can be mentioned in application.properties as listener properties.\nmessaging.kafka.consumer.groupId=default\nif there are multiple topics and multiple listeners then we suggest to specify the topic names directly on each listeners instead reading from the property file.\nThe container factory mentioned in the @KafkaListener is provided in the KafkaListenerContainerProperties.java to create default container factory with acknowledgement.\nThe default ack-mode is manual_immediate . It can be overridden by below example:\nmessaging.kafka.listener.container.ackMode=&lt;ack-mode&gt;\nThe other ack-mode values can be referred from\nhere.\n"},{"id":239,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-kafka.asciidoc_retry","type":"docs","title":"Retry","body":"12.36.6. Retry\nThe retry pattern in devon4j-kafka is invoked when a particular exception(described by user in application.properties file) is thrown while processing the consumed message and it is configured in application.properties file. Then general idea is to separate messages which could not be processed into dedicated retry-topics to allow fine control on how processing of the messages is retried and to not block newly arriving messages.\nLet us see more about handling retry in the below topics.\nHandling retry in devon4j-kafka\nThe retry pattern is included in the starter dependency of &quot;starter-kafka-receiver&quot;.\nThe retryPattern method is used by calling the method processMessageWithRetry(ConsumerRecord&lt;K, V&gt; consumerRecord,MessageProcessor&lt;K, V&gt; processor). Please find the below Example:\n@Inject\nprivate MessageRetryOperations&lt;K, V&gt; messageRetryOperations;\n@Inject\nprivate DeleteEmployeeMessageProcessor&lt;K, V&gt; deleteEmployeeMessageProcessor;\n@KafkaListener(topics = &quot;employeeapp-employee-v1-delete&quot;, groupId = &quot;${messaging.kafka.consumer.groupId}&quot;,containerFactory = &quot;kafkaListenerContainerFactory&quot;)\npublic void consumer(ConsumerRecord&lt;K, V&gt; consumerRecord, Acknowledgment acknowledgment) {\nthis.messageRetryOperations.processMessageWithRetry(consumerRecord, this.deleteEmployeeMessageProcessor);\n// Acknowledge the listener.\nacknowledgment.acknowledge();\n}\nThe implementation for MessageProcessor from devon4j-kafka is required to provide the implementation to process the ConsumedRecord from kafka broker. The implementation for MessageProcessor interface can look as below example:\nimport com.devonfw.module.kafka.common.messaging.retry.api.client.MessageProcessor;\n@Named\npublic class DeleteEmployeeMessageProcessor&lt;K, V&gt; implements MessageProcessor&lt;K, V&gt; {\n@Override\npublic void processMessage(ConsumerRecord&lt;K, V&gt; message) {\n//process message\n}\n}\nIt works as follows:\n* The application gets a message from the topic.\n* During processing of the message an error occurs, the message will be written to the redelivery topic.\n* The message is acknowledged in the topic.\n* The message will be processed from the re-delivery topic after a delay.\n* Processing of the message fails again. It retires until the retry count gets over.\n* When the retry fails in all the retry then the message is logged and payload in the ProducerRecord is deleted for log\ncompaction which is explained below.\nRetry configuration and naming convention of redelivery topics.\nThe following properties should be added in the application.properties or application.yml file.\nThe retry pattern in devon4j-kafka will perform for specific topic of a message. So its mandatory to specify the properties for each topic. Below properties are example,\n# Back off policy properties for employeeapp-employee-v1-delete\nmessaging.retry.back-off-policy.retryReEnqueueDelay.employeeapp-employee-v1-delete=1000\nmessaging.retry.back-off-policy.retryDelay.employeeapp-employee-v1-delete=600000\nmessaging.retry.back-off-policy.retryDelayMultiplier.employeeapp-employee-v1-delete=1.0\nmessaging.retry.back-off-policy.retryMaxDelay.employeeapp-employee-v1-delete=600000\nmessaging.retry.back-off-policy.retryCount.employeeapp-employee-v1-delete=2\n# Retry policy properties for employeeapp-employee-v1-delete\nmessaging.retry.retry-policy.retryPeriod.employeeapp-employee-v1-delete=1800\nmessaging.retry.retry-policy.retryableExceptions.employeeapp-employee-v1-delete=&lt;Class names of exceptions for which a retry should be performed&gt;\nmessaging.retry.retry-policy.retryableExceptionsTraverseCauses.employeeapp-employee-v1-delete=true\n# Back off policy properties for employeeapp-employee-v1-add\nmessaging.retry.back-off-policy.retryReEnqueueDelay.employeeapp-employee-v1-add=1000\nmessaging.retry.back-off-policy.retryDelay.employeeapp-employee-v1-add=600000\nmessaging.retry.back-off-policy.retryDelayMultiplier.employeeapp-employee-v1-add=2.0\nmessaging.retry.back-off-policy.retryMaxDelay.employeeapp-employee-v1-add=600000\nmessaging.retry.back-off-policy.retryCount.employeeapp-employee-v1-add=4\n# Retry policy properties for employeeapp-employee-v1-add\nmessaging.retry.retry-policy.retryPeriod.employeeapp-employee-v1-add=3000\nmessaging.retry.retry-policy.retryableExceptions.employeeapp-employee-v1-add=&lt;Class names of exceptions for which a retry should be performed&gt;\nmessaging.retry.retry-policy.retryableExceptionsTraverseCauses.employeeapp-employee-v1-add=true\nIf you notice the above properties, the retry-policy and back-off policy properties are repeated twice as i have 2 topics for the retry to be performed with different level of values. The topic name should be added at the last of attribute.\nSo, the retry will be performed for each topic according to their configuration values.\nIf you want to provide same/default values for all the topics, then its required to add default in the place of topic on the above properties example.\nFor example,\n# Default back off policy properties\nmessaging.retry.back-off-policy.retryReEnqueueDelay.default=1000\nmessaging.retry.back-off-policy.retryDelay.default=600000\nmessaging.retry.back-off-policy.retryDelayMultiplier.default=1.0\nmessaging.retry.back-off-policy.retryMaxDelay.default=600000\nmessaging.retry.back-off-policy.retryCount.default=2\n# Default retry policy properties\nmessaging.retry.retry-policy.retryPeriod.default=1800\nmessaging.retry.retry-policy.retryableExceptions.default=&lt;Class names of exceptions for which a retry should be performed&gt;\nmessaging.retry.retry-policy.retryableExceptionsTraverseCauses.default=true\nBy giving properties like above , the same values will be passed for all the topics and the way of processing retry for all the topics are same.\nAll these above property values are mapped to the classes DefaultBackOffPolicyProperties.java and DefaultRetryPolicyProperties.java and configured by the class MessageDefaultRetryConfig.java.\nThe MessageRetryContext in devon kafka is used to perform the retry pattern with the properties from DefaultBackOffPolicyProperties and DefaultRetryPolicyProperties.\nThe 2 main properties of MessageRetryContext is nextRetry and retryUntil which is a Instant date format and it is calculated internally using the properties given in DefaultBackOffPolicyProperties and DefaultRetryPolicyProperties.\nYou may change the behavior of this date calculation by providing your own implementation classes for MessageBackOffPolicy.java and MessageRetryPolicy.java.\nThe naming convention for retry topic is the same topic name which you have given to publish the message and we add suffix -retry to it once it is consumed and given to process with retry.\nIf there is no topic found in the consumed record the default retry topic will be added which is default-message-retry.\nRetry topics\nDevon4j-kafka uses a separate retry topic for each topic where retries occur. By default this topic is named &lt;topic name&gt;-retry. You may change this behavior by providing your own implementation for DefaultKafkaRecordSupport which is an default implementation from devon4j-kafka for KafkaRecordSupport.\nDevon4-kafka enqueues a new message for each retry attempt. It is very important to configure your retry tropics with log compaction enabled. More or less simplified, if log compaction is enabled Kafka keeps only one message per message key. Since each retry message has the same key, in fact only one message per retry attempt is stored. After the last retry attempt the message payload is removed from the message so, you do not keep unnecessary data in your topics.\nHandling retry finally failed\nPer default when the retry fails with final attempt we just log the message and delete the payload of ProducerRecord which comes to proceed the retry pattern.\nYou can change this behavior by providing the implementation class for the interface MessageRetryHandler.java\nwhich has two method retryTimeout and retryFailedFinal.\n"},{"id":240,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-kafka.asciidoc_tracer","type":"docs","title":"Tracer","body":"12.36.7. Tracer\nWe leverage Spring Cloud Sleuth for tracing in devon4j-kafka\nThis is used to trace the asynchronous process of kafka producing and consuming. In an asynchronous process it is important to maintain a id which will be same for all asynchronous process.\nHowever, devon uses its own correlation-id(UUID) to track the process. But devon4j-kafka uses additional tracing protocol which is Brave Tracer.\nThis is a part of both starter dependencies starter-kafka-receiver and starter-kafka-sender.\nThere are 2 important properties which will be automatically logged which is trace-id and spain-id.\nThe trace-id is same for all the asynchronous process and span-id is unique for each asynchronous process.\nHow devon4j-kafka handles tracer ?\nWe inject the trace-id and span-id in to the ProducerRecord headers which comes to publish into the kafka broker.\nIts injected in the headers with the key traceId for trace-id and spanId for span-id.\nAlong with these, the correlation-id(UUID) is also injected in the headers of record with the key correlationId.\nSo, when you consume record from kafka broker, these values can be found in the consumed record&#x2019;s headers with these keys.\nSo, it is very helpful to track the asynchronous process of consuming the messages.\n"},{"id":241,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-kafka.asciidoc_logging","type":"docs","title":"Logging","body":"12.36.8. Logging\ndevon4j-kafka provides multiples support classes to log the published message and the consumed message.\n* The class ProducerLoggingListener which implements ProducerListener&lt;K,V&gt; from spring kafka uses to log the message as soon as it is published in the kafka broker.\nThe aspect class MessageListenerLoggingAspect which is annotated with @Aspect and has a method logMessageprocessing which is annotated with @Around(&quot;@annotation(org.springframework.kafka.annotation.KafkaListener)&amp;&amp;args(kafkaRecord,..)&quot;)\nused to listen to the classes which is annotated with @KafkaListener and logs the message as soon as it is consumed.\nThe class MessageLoggingSupport has multiple methods to log different type of events like MessageReceived, MessageSent, MessageProcessed, MessageNotProcessed.\nThe class LoggingErrorHandler which implements ErrorHandler from spring-kafka which logs the message when an error occurred while consuming message. You may change this behavior by creating your own implementation class for the ErrorHandler.\n"},{"id":242,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-kafka.asciidoc_kafka-health-check-using-spring-acutator","type":"docs","title":"Kafka Health check using Spring acutator","body":"12.36.9. Kafka Health check using Spring acutator\nThe spring config class MessageCommonConfig automatically provides a spring health indicator bean for kafka if\nthe property endpoints. The health indicator will check for all topics listed in messaging.kafka.health.topics-tocheck\nif a leader is available. If this property is missing only the broker connection will be checked. The timeout for\nthe check (default 60s) maybe changed via the property messaging.kafka.health.timeout.\nIf an application uses multiple broker(-clusters) for each broker(-cluster) a dedicated health indicator bean has to be\nconfigured in the spring config.\nThe properties for the devon kafka health check should be given like below example:\nmanagement.endpoint.health.enabled=&lt;true or false&gt;\nmessaging.kafka.health.timeout=&lt;the health check timeout seconds&gt;\nmessaging.kafka.health.topicsToCheck=employeeapp-employee-v1-delete,employeeapp-employee-v1-add\nThese properties are provided with default values except the topicsToCheck and health check will do happen only when the property is management.endpoint.health.enabled=true.\n"},{"id":243,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-kafka.asciidoc_authentication","type":"docs","title":"Authentication","body":"12.36.10. Authentication\nJSON Web Token (JWT)\ndevon4j-kafka supports authentication via JSON Web Tokens (JWT) out-of-the-box.\nTo use it add a dependency to the devon4j-starter-security-jwt:\n&lt;dependency&gt;\n&lt;groupId&gt;com.devonfw.java.starters&lt;/groupId&gt;\n&lt;artifactId&gt;devon4j-starter-security-jwt&lt;/artifactId&gt;\n&lt;/dependency&gt;\nThe authentication via JWT needs some configuration, e.g. a keystore to verify the token signature. This is explained in the JWT documentation.\nTo secure a message listener with jwt add the @JwtAuthentication:\n@JwtAuthentication\n@KafkaListener(topics = &quot;employeeapp-employee-v1-delete&quot;, groupId = &quot;${messaging.kafka.consumer.groupId}&quot;)\npublic void consumer(ConsumerRecord&lt;K, V&gt; consumerRecord, Acknowledgment acknowledgment) {\n...\n}\n}\nWith this annotation in-place each message will be checked for a valid JWT in a message header with the name Authorization. If a valid annotation is found the spring security context will be initialized with the user roles and &quot;normal&quot; authorization e.g. with @RolesAllowed may be used. This is also demonstrated in the kafka sample application.\n"},{"id":244,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-kafka.asciidoc_using-kafka-for-internal-parallel-processing","type":"docs","title":"Using Kafka for internal parallel processing","body":"12.36.11. Using Kafka for internal parallel processing\nApart from the use of Kafka as &quot;communication channel&quot; it sometimes helpful to use Kafka internally to do parallel processing:\nFigure 10. Architecture for internal parallel processing with Kafka\nThis examples shows a payment service which allows a to submit a list of receipt IDs for payment.\nWe assume that the payment it self takes a long time and should be done asynchronously and in parallel.\nThe general idea is to put a message for each receipt to pay into a topic. This is done in the use case implementation in a first step, if a rest call arrives.\nAlso part of the use case is a listener which consumes the messages. For each message (e.g. payment to do) a processor is called, which actually does the payment via the use case.\nSince Kafka supports concurrency for the listeners easily the payment will also be done in parallel.\nAll features of devon4j-kafka, like retry handling could also be used.\n"},{"id":245,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-jms.asciidoc","type":"docs","title":"Messaging","body":"12.37. Messaging\nMessaging in Java is done using the JMS standard from JEE.\n"},{"id":246,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-jms.asciidoc_products","type":"docs","title":"Products","body":"12.37.1. Products\nFor messaging you need to choose a JMS provider such as:\nRabbitMQ\nActiveMQ\nOracle Advanced Queuing (esp. if you already use Oracle RDBMS)\n"},{"id":247,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-jms.asciidoc_receiver","type":"docs","title":"Receiver","body":"12.37.2. Receiver\nAs a receiver of messages is receiving data from other systems it is located in the service-layer.\nJMS Listener\nA JmsListener is a class listening and consuming JMS messages. It should carry the suffix JmsListener and implement the MessageListener interface or have its listener method annotated with @JmsListener. This is illustrated by the following example:\n@Named\n@Transactional\npublic class BookingJmsListener /* implements MessageListener */ {\n@Inject\nprivate Bookingmanagement bookingmanagement;\n@Inject\nprivate MessageConverter messageConverter;\n@JmsListener(destination = &quot;BOOKING_QUEUE&quot;, containerFactory = &quot;jmsListenerContainerFactory&quot;)\npublic void onMessage(Message message) {\ntry {\nBookingTo bookingTo = (BookingTo) this.messageConverter.fromMessage(message);\nthis.bookingmanagement.importBooking(bookingTo);\n} catch (MessageConversionException | JMSException e) {\nthrow new InvalidMessageException(message);\n}\n}\n}\n"},{"id":248,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-jms.asciidoc_sender","type":"docs","title":"Sender","body":"12.37.3. Sender\nThe sending of JMS messages is considered as any other sending of data like kafka messages or RPC calls via REST using service-client, gRPC, etc.\nThis will typically happen directly from a use-case in the logic-layer.\nHowever, the technical complexity of the communication and protocols itself shall be hidden from the use-case and not be part of the logic layer.\nWith spring we can simply use JmsTemplate to do that.\n"},{"id":249,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-monitoring.asciidoc","type":"docs","title":"Monitoring","body":"12.38. Monitoring\nMonitoring is a very comprehensive topic. For devon4j we focus on selected core topics which are most important when developing production-ready applications.\nOn a high level view we strongly suggest to separate the application to be monitored from the monitoring system itself.\nThe monitoring system covers aspects like\nCollect monitoring information\nAggregate, process and visualizate data, e.g. in dashboards\nProvide alarms\n&#x2026;&#x200B;\nIn distributed systems it is crucial that a monitoring system provides a central overview over all applications in your application landscape. So it is not feasible to provide a monitoring system as part of your application. Your application is responsible for providing information to the monitoring system.\n"},{"id":250,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-monitoring.asciidoc_how-to-provide-monitoring-information","type":"docs","title":"How to provide monitoring information","body":"12.38.1. How to provide monitoring information\nJava Management Extensions (JMX)\nJMX is the official java monitoring solution. It is part of the JDK. Your application may provide monitoring information or receive monitoring related commands via MBeans. There is a huge amount of information about JMX available. A good starting point might be JMX on wikipedia.\nTraditionally JMX uses RMI for communication. In many environments HTTP(S) is preferred, so be careful on deciding if JMX is the right solution.\nAlternativly your application could provide a monitoring API via REST.\nREST APIs\nSince REST APIs are very popular it is quite natural to provide monitoring information via REST. If your application already uses REST and there is no JMX/RMI based monitoring solution in place, it is often a better approach to provide monitoring APIs via REST than introducing a new protocol with JMX.\nLogging\nSome aspects of monitoring are covered by &quot;logging&quot;. A typical case might be the requirement to &quot;monitor&quot; the application REST APIs. For that it is perfectly fine to log the perfomance of all (or some) request and ship this information to a logging system like Graylog. So please carefully read the logging guide. To allow efficient processing of those logs you should use JSON based logs.\n"},{"id":251,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-monitoring.asciidoc_which-monitoring-informaton-to-provide","type":"docs","title":"Which monitoring informaton to provide?","body":"12.38.2. Which monitoring informaton to provide?\nIt is not possible to provide a final list of which monitoring information is exactly required for your application. But we give you a general advice what type of information your application should provide at a minimum.\nGeneral information\nIt is often useful if your application provides basic information about itself. This should cover\nThe name of the application\nThe version (or buildno., or commit-id, &#x2026;&#x200B;) of the application\nThis is espicially useful in complex environments, e.g. to very that deployments went correctly.\nMetrics\nMetric means providing key figures about your applications like\nperformance key figures\nrequest duration\nqueue lengths\nduration of database queries\n..\nbusiness related information\nnumber of successful / unsuccesful requests\nsize of result sets\nworth of shopping baskets\n..\nTechnical key figures\nJVM heap usage\ncache sizes\n(database) pool usage\n&#x2026;&#x200B;\n&#x2026;&#x200B;\nRemember that processing of this data should be done mainly in the monitoring system. You might have noticed that there are different types of metrics: those that represent current values (like JVM heap usage, queue length, &#x2026;&#x200B;), others base on (timed) events like (duration of requests). Handling of different types of metrics might be different.\nFor handling events you may:\nWrite log statements for each (or a sample of) event. These logs must then be shipped to your monitoring systems.\nSend data for the event via an API of your monitoring system\nProvide a REST API (or JMX MBeans) with pre-aggregated key figures, which is periodically polled by your monitoring system. This solution is a bit inferior since the aggregation is part of your application and might not fit to the desired visualization in your monitoring systems.\nFor actual values you may:\nWrite them perodically to your log. These logs must then be shipped to your monitoring systems.\nSend them peridocally via an API of your monitoring systems\nProvide a REST API (or JMX MBeans) which is periodically polled by your monitoring system.\nHealth (Watchdog)\nFor monitoring a complex application landscape it is crucial to have an exact overview if all applications are up and running. So your application should offer an API for the monitoring system which allows to easily check if the application is alive. Often this alive information is polled by the monitoring system with a kind of watchdog.\nThe health check should include checks if the application is working &quot;correctly&quot;. For that we suggest to check if all required neighbour systems and infrastructure components are usable:\nCheck if your database can be queried (with a dummy query)\nCheck if you can reach your messaging system\nCheck if you can reach all your neighbour system, e.g. by querying their info-endpoint\nYou should be very careful to not cascade those requests, e.g. your system should only test their direct neighbours. This test should not lead to additional tests in these systems.\nThe healthcheck should return a simple OK/NOK result for use in dashboards, but addtionally include detailed results for each check.\n"},{"id":252,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-monitoring.asciidoc_implementation-with-spring-boot-actuator","type":"docs","title":"Implementation with Spring Boot Actuator","body":"12.38.3. Implementation with Spring Boot Actuator\nTo implement a monitoring API for your systems we suggest to use Spring Boot Actuator. Actuator offers APIs which provide monitoring information including metrics via HTTP and JMX. It also contains a framework to implement health checks.\nPlease consult the original documentation for information about how to use it.\nBasically to use it, add the following dependency to the pom.xml of your application core:\n&lt;dependencies&gt;\n&lt;dependency&gt;\n&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n&lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;\n&lt;/dependency&gt;\n&lt;/dependencies&gt;\nThere will be several endpoints with monitoring information available out-of-the-box.\nWe strongly advice to check carefully which information is required in your context, normally this is &#xEC;nfo, health and metrics. Be careful not to expose any security related information via this mechanismen (e.g. by exposing those endpoints externally).\nTo make the info-endpoint useful you need to provide information to actuactor. A good way to achive this is by using the provided maven module.\nFor first steps it might be useful to deactive security for the actuator endpoints (this is just for testing, never release it!). This can be accomblished by implementing the following class:\n@Configuration\n@EnableWebSecurity\n@Profile(SpringProfileConstants.NOT_JUNIT)\npublic class WebSecurityConfig extends BaseWebSecurityConfig {\n@Override\npublic void configure(WebSecurity web) throws Exception {\nsuper.configure(web);\nweb.ignoring().requestMatchers(EndpointRequest.toAnyEndpoint());\n}\n}\nDevonfw additions\nDevonfw includes the following additions for Spring boot actuator:\nKafka Health Check in devon4j-kafka (WIP)\n"},{"id":253,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-monitoring.asciidoc_integration-of-monitoring-information","type":"docs","title":"Integration of monitoring information","body":"12.38.4. Integration of monitoring information\nLoadbalancers\nTo loadbalance HTTP requests the loadbalancers needs to know which instances of the desired application are available and functioning. Often loadbalancers support reacting on the HTTP status code of an HTTP request to the service. The loadbalancer will periodically poll the service to find out if is available or not.\nTo configure this you may use the healthcheck of the service to find out if the instance is functioning correctly or not.\nDocker\nDocker supports a healtcheck. You may use a simple local curl to your application here to find out if the service is healthy or not. But be careful often unhealthy containers are automatically restarted. If you use the health information of your application this may lead to undesired effects. Since the health checks relies on querying all neighbour systems and infrastucure components, applications often become unhealthy because a 3rd system has problems. Restarting the application itself will not heal the problem and be inexpedient. So generally it is better you query the info endpoint of your application to just check if the service itself is up and running.\n"},{"id":254,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-text-search.asciidoc","type":"docs","title":"Full Text Search","body":"12.39. Full Text Search\nIf you want to all your users fast and simple searches with just a single search field (like in google), you need full text indexing and search support.\n"},{"id":255,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-text-search.asciidoc_solutions","type":"docs","title":"Solutions","body":"12.39.1. Solutions\nLucene\nNGram\nSolr\nelastic-search\nMaybe you also want to use native features of your database\nSAP Hana Fuzzy Search\nOracle Text\n"},{"id":256,"path":"../website/pages/docs/devon4j.asciidoc_guides.html#guide-text-search.asciidoc_best-practices","type":"docs","title":"Best Practices","body":"12.39.2. Best Practices\nTODO\n&#x2190;&#xA0;Previous:&#xA0;Layers&#xA0;| &#x2191;&#xA0;Up:&#xA0;devonfw for Java (devon4j)&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Tutorials&#xA0;&#x2192;\n"},{"id":257,"path":"../website/pages/docs/devon4j.asciidoc_layers.html#devon4j.asciidoc_layers","type":"docs","title":"Layers","body":"11. Layers\n"},{"id":258,"path":"../website/pages/docs/devon4j.asciidoc_layers.html#guide-client-layer.asciidoc","type":"docs","title":"Client Layer","body":"11.1. Client Layer\nThere are various technical approaches to building GUI clients. The devonfw proposes rich clients that connect to the server via data-oriented services (e.g. using REST with JSON).\nIn general, we have to distinguish among the following types of clients:\nweb clients\nnative desktop clients\n(native) mobile clients\nOur main focus is on web-clients. In our sample application my-thai-star we offer a responsive web-client based on Angular following devon4ng that integrates seamlessly with the back ends of my-thai-star available for Java using devon4j as well as .NET/C# using devon4net. For building angular clients read the separate devon4ng guide.\n"},{"id":259,"path":"../website/pages/docs/devon4j.asciidoc_layers.html#guide-client-layer.asciidoc_javascript-for-java-developers","type":"docs","title":"JavaScript for Java Developers","body":"11.1.1. JavaScript for Java Developers\nIn order to get started with client development as a Java developer we give you some hints to get started. Also if you are an experienced JavaScript developer and want to learn Java this can be helpful. First, you need to understand that the JavaScript ecosystem is as large as the Java ecosystem and developing a modern web client requires a lot of knowledge. The following table helps you as experienced developer to get an overview of the tools, configuration-files, and other related aspects from the new world to learn. Also it helps you to map concepts between the ecosystems. Please note that we list the tools recommended by devonfw here (and we know that there are alternatives not listed here such as gradle, grunt, bower, etc.).\nTable 29. Aspects in JavaScript and Java ecosystem\nTopic\nAspect\nJavaScript\nJava\nProgramming\nLanguage\nTypeScript (extends JavaScript)\nJava\nRuntime\nVM\nnodejs (or web-browser)\njvm\nBuild- &amp; Dependency-Management\nTool\nnpm or yarn\nmaven\nConfig\npackage.json\npom.xml\nRepository\nnpm repo\nmaven central (repo search)\nBuild cmd\nng build or npm run build (goals are not standardized in npm)\nmvn install (see lifecycle)\nTest cmd\nng test\nmvn test\nTesting\nTest-Tool\njasmine\njunit\nTest-Runner\nkarma\njunit / surefire\nE2E Testing\nProtractor\nSelenium\nCode Analysis\nCode Coverage\nng test --no-watch --code-coverage\nJaCoCo\nDevelopment\nIDE\nMS VS Code or IntelliJ\nEclipse or IntelliJ\nFramework\nAngular (etc.)\nSpring or Quarkus\n"},{"id":260,"path":"../website/pages/docs/devon4j.asciidoc_layers.html#guide-service-layer.asciidoc","type":"docs","title":"Service Layer","body":"11.2. Service Layer\nThe service layer is responsible for exposing functionality made available by the logical layer to external consumers over a network via technical protocols.\n"},{"id":261,"path":"../website/pages/docs/devon4j.asciidoc_layers.html#guide-service-layer.asciidoc_types-of-services","type":"docs","title":"Types of Services","body":"11.2.1. Types of Services\nBefore you start creating your services you should consider some general design aspects:\nDo you want to create a RPC service?\nOr is your problem better addressed by messaging or eventing?\nWho will consume your service?\nDo you have one or multiple consumers?\nDo web-browsers have to use your service?\nWill apps from other vendors or parties have to consume your service that you can not influence if the service may have to change or be extended?\nFor RPC a common choice is REST but there are also interesting alternatives like gRPC. We also have a guide for SOAP but this technology should rather be considered as legacy and is not recommended for new services.\nWhen it comes to messaging in Java the typical answer will be JMS. However, a very promising alternative is Kafka.\n"},{"id":262,"path":"../website/pages/docs/devon4j.asciidoc_layers.html#guide-service-layer.asciidoc_versioning","type":"docs","title":"Versioning","body":"11.2.2. Versioning\nFor RPC services consumed by other applications we use versioning to prevent incompatibilities between applications when deploying updates. This is done by the following conventions:\nWe define a version number and prefix it with v (e.g. v1).\nIf we support previous versions we use that version numbers as part of the Java package defining the service API (e.g. com.foo.application.component.service.api.v1)\nWe use the version number as part of the service name in the remote URL (e.g. https://application.foo.com/services/rest/component/v1/resource)\nWhenever breaking changes are made to the API, create a separate version of the service and increment the version (e.g. v1 &#x2192; v2) . The implementations of the different versions of the service contain compatibility code and delegate to the same unversioned use-case of the logic layer whenever possible.\nFor maintenance and simplicity, avoid keeping more than one previous version.\n"},{"id":263,"path":"../website/pages/docs/devon4j.asciidoc_layers.html#guide-service-layer.asciidoc_interoperability","type":"docs","title":"Interoperability","body":"11.2.3. Interoperability\nFor services that are consumed by clients with different technology, interoperability is required. This is addressed by selecting the right protocol, following protocol-specific best practices and following our considerations especially simplicity.\n"},{"id":264,"path":"../website/pages/docs/devon4j.asciidoc_layers.html#guide-service-layer.asciidoc_service-considerations","type":"docs","title":"Service Considerations","body":"11.2.4. Service Considerations\nThe term service is quite generic and therefore easily misunderstood. It is a unit exposing coherent functionality via a well-defined interface over a network. For the design of a service, we consider the following aspects:\nself-contained\nThe entire API of the service shall be self-contained and have no dependencies on other parts of the application (other services, implementations, etc.).\nidempotence\nE.g. creation of the same master-data entity has no effect (no error)\nloosely coupled\nService consumers have minimum knowledge and dependencies on the service provider.\nnormalized\nComplete, no redundancy, minimal\ncoarse-grained\nService provides rather large operations (save entire entity or set of entities rather than individual attributes)\natomic\nProcess individual entities (for processing large sets of data, use a batch instead of a service)\nsimplicity\nAvoid polymorphism, RPC methods with unique name per signature and no overloading, avoid attachments (consider separate download service), etc.\n"},{"id":265,"path":"../website/pages/docs/devon4j.asciidoc_layers.html#guide-service-layer.asciidoc_security","type":"docs","title":"Security","body":"11.2.5. Security\nYour services are the major entry point to your application. Hence, security considerations are important here.\nSee REST Security.\n"},{"id":266,"path":"../website/pages/docs/devon4j.asciidoc_layers.html#guide-service-versioning.asciidoc","type":"docs","title":"Service-Versioning","body":"11.3. Service-Versioning\nThis guide describes the aspect and details about versioning of services\n"},{"id":267,"path":"../website/pages/docs/devon4j.asciidoc_layers.html#guide-service-versioning.asciidoc_motivation","type":"docs","title":"Motivation","body":"11.3.1. Motivation\nWhy versioning of services? First of all, you should only care about this topic if you really have to. Service versioning is complex and requires effort (time and budget). The best way to avoid this is to be smart in the first place when designing the service API.\nFurther, if you are creating services where the only consumer is e.g. the web-client that you deploy together with the consumed services then you can change your service without the overhead to create new service versions and keeping old service versions for compatibility.\nHowever, if the following indicators are given you typically need to do service versioning:\nYour service is part of a complex and distributed IT landscape\nYour service requires incompatible changes\nThere are many consumers or there is at least one (relevant) consumer that can not be updated at the same time or is entirely out of control (unknown or totally different party/company)\nWhat are incompatible changes?\nAlmost any change when SOAP is used (as it changes the WSDL and breaks the contract). Therefore, we recommend to use REST instead. Then, only the following changes are critical.\nA change where existing properties (attributes) have to change their name\nA change where existing features (properties, operations, etc.) have to change their semantics (meaning)\nWhat changes do not cause incompatibilities?\nAdding new service operations is entirely uncritical with REST.\nAdding new properties is only a problem in the following cases:\nAdding new mandatory properties to the input of a service is causing incompatibilities. This problem can be avoided by contract-design.\nIf a consumer is using a service to read data, modify it and then save it back via a service and a property is added to the data, then this property might be lost. This is not a problem with dynamic languages such as JavaScript/TypeScript but with strictly typed languages such as Java. In Java you will typically use structured typed transfer-objects (and not Map&lt;String, Object&gt;) so new properties that have been added but are not known to the consumer can not be mapped to the transfer-object and will be lost. When saving that transfer-object later the property will be gone. It might be impossible to determine the difference between a lost property and a property that was removed on purpose. This is a general problem that you need to be aware of and that you have to consider by your design in such situations.\nEven if you hit an indicator for incompatible changes you can still think about adding a new service operation instead of changing an existing one (and deprecating the old one). Be creative to simplify and avoid extra effort.\n"},{"id":268,"path":"../website/pages/docs/devon4j.asciidoc_layers.html#guide-service-versioning.asciidoc_procedure","type":"docs","title":"Procedure","body":"11.3.2. Procedure\nThe procedure when rolling out incompatible changes is illustrated by the following example:\n+------+ +------+\n| App1 | | App2 |\n+---+--+ +--+---+\n| |\n+---+----+\n|\n+-------+--------+\n| Sv1 |\n| |\n| App3 |\n+----------------+\nSo, here we see a simple example where App3 provides a Service S in Version v1 that is consumed both by App1 and App2.\nNow for some reason the service S has to be changed in an incompatible way to make it future-proof for demands. However, upgrading all 3 applications at the same time is not possible in this case for whatever reason. Therefore, service versioning is applied for the changes of S.\n+------+ +------+\n| App1 | | App2 |\n+---+--+ +--+---+\n| |\n+--------+\n|\n+---+------------+\n| Sv1 | Sv2 |\n| |\n| App3* |\n+----------------+\nNow, App3 has been upgraded and the new release was deployed. A new version v2 of S has been added while v1 is still kept for compatibility reasons and that version is still used by App1 and App2.\n+------+ +------+\n| App1 | | App2*|\n+---+--+ +--+---+\n| |\n| |\n| |\n+---+--------+---+\n| Sv1 | Sv2 |\n| |\n| App3 |\n+----------------+\nNow, App2 has been updated and deployed and it is using the new version v2 of S.\n+------+ +------+\n| App1*| | App2 |\n+---+--+ +--+---+\n| |\n+--------+\n|\n+------------+---+\n| Sv1 | Sv2 |\n| |\n| App3 |\n+----------------+\nNow, also App1 has been updated and deployed and it is using the new version v2 of S. The version v1 of S is not used anymore. This can be verified via logging and monitoring.\n+------+ +------+\n| App1 | | App2 |\n+---+--+ +--+---+\n| |\n+--------+\n|\n+------------+---+\n| Sv2 |\n| |\n| App3* |\n+----------------+\nFinally, version v1 of the service S was removed from App3 and the new release has been deployed.\n"},{"id":269,"path":"../website/pages/docs/devon4j.asciidoc_layers.html#guide-service-versioning.asciidoc_versioning-schema","type":"docs","title":"Versioning Schema","body":"11.3.3. Versioning Schema\nIn general anything can be used to differentiate versions of a service. Possibilities are:\nCode names (e.g. Strawberry, Blueberry, Grapefruit)\nTimestamps (YYYYMMDD-HHmmSS)\nSequential version numbers (e.g. v1, v2, v3)\nComposed version numbers (e.g. 1.0.48-pre-alpha-3-20171231-235959-Strawberry)\nAs we are following the KISS principle (see key principles) we propose to use sequential version numbers. These are short, clear, and easy while still allowing to see what version is after another one. Especially composed version numbers (even 1.1 vs. 2.0) lead to decisions and discussions that easily waste more time than adding value. It is still very easy to maintain an Excel sheet or release-notes document that is explaining the changes for each version (v1, v2, v3) of a particular service.\nWe suggest to always add the version schema to the service URL to be prepared for service versioning even if service versioning is not (yet) actively used. For simplicity it is explicitly stated that you may even do incompatible changes to the current version (typically v1) of your service if you can update the according consumers within the same deployment.\n"},{"id":270,"path":"../website/pages/docs/devon4j.asciidoc_layers.html#guide-service-versioning.asciidoc_practice","type":"docs","title":"Practice","body":"11.3.4. Practice\nSo assuming you know that you have to do service versioning, the question is how to do it practically in the code.\nThe approach for your devon4j project in case of code-first should be as described below:\nDetermine which types in the code need to be changed. It is likely to be the API and implementation of the according service but it may also impact transfer objects and potentially even datatypes.\nCreate new packages for all these concerned types containing the current version number (e.g. v1).\nCopy all these types to that new packages.\nRename these copies so they carry the version number as suffix (e.g. V1).\nIncrease the version of the service in the unversioned package (e.g. from v1 to v2).\nNow you have two versions of the same service (e.g. v1 and v2) but so far they behave exactly the same.\nYou start with your actual changes and modify the original files that have been copied before.\nYou will also ensure the links (import statements) of the copied types point to the copies with the version number\nThis will cause incompatibilities (and compile errors) in the copied service. Therefore, you need to fix that service implementation to map from the old API to the new API and behavior. In some cases, this may be easy (e.g. mapping x.y.z.v1.FooTo to x.y.z.FooTo using bean-mapping with some custom mapping for the incompatible changes), in other cases this can get very complex. Be aware of this complexity from the start before you make your decision about service versioning.\nAs far as possible this mapping should be done in the service-layer, not to pollute your business code in the core-layer with versioning-aspects. If there is no way to handle it in the service layer, e.g. you need some data from the persistence-layer, implement the &quot;mapping&quot; in the core-layer then, but don&#x2019;t forget to remove this code, when removing the old service version.\nFinally, ensure that both the old service behaves as before as well as the new service works as planned.\nModularization\nFor modularization, we also follow the KISS principle (see key principles):\nwe suggest to have one api module per application that will contain the most recent version of your service and get released with every release-version of the application. The compatibility code with the versioned packages will be added to the core module and therefore is not exposed via the api module (because it has already been exposed in the previous release of the app). This way, you can always determine for sure which version of a service is used by another application just by its maven dependencies.\nThe KISS approach with only a single module that may contain multiple services (e.g. one for each business component) will cause problems when you want to have mixed usages of service versions: You can not use an old version of one service and a new version of another service from the same APP as then you would need to have its API module twice as a dependency on different versions, which is not possible. However, to avoid complicated overhead we always suggest to follow this easy approach. Only if you come to the point that you really need this complexity you can still solve it (even afterwards by publishing another maven artefact). As we are all on our way to build more but smaller applications (SOA, microservices, etc.) we should always start simple and only add complexity when really needed.\nThe following example gives an idea of the structure:\n/&#xAB;my-app&#xBB;\n&#x251C;&#x2500;&#x2500;/api\n| &#x2514;&#x2500;&#x2500;/src/main/java/\n| &#x2514;&#x2500;&#x2500;/&#xAB;rootpackage&#xBB;/&#xAB;application&#xBB;/&#xAB;component&#xBB;\n| &#x251C;&#x2500;&#x2500;/common/api/to\n| | &#x2514;&#x2500;&#x2500;FooTo\n| &#x2514;&#x2500;&#x2500;/service/api/rest\n| &#x2514;&#x2500;&#x2500;FooRestService\n&#x2514;&#x2500;&#x2500;/core\n&#x2514;&#x2500;&#x2500;/src/main/java/\n&#x2514;&#x2500;&#x2500;&#xAB;rootpackage&#xBB;/&#xAB;application&#xBB;/&#xAB;component&#xBB;\n&#x251C;&#x2500;&#x2500;/common/api/to/v1\n| &#x2514;&#x2500;&#x2500;FooToV1\n&#x2514;&#x2500;&#x2500;/service\n&#x251C;&#x2500;&#x2500;/api/rest/v1\n| &#x2514;&#x2500;&#x2500;FooRestServiceV1\n&#x2514;&#x2500;&#x2500;impl/rest\n&#x251C;&#x2500;&#x2500;/v1\n| &#x2514;&#x2500;&#x2500; FooRestServiceImplV1\n&#x2514;&#x2500;&#x2500;FooRestServiceImpl\n"},{"id":271,"path":"../website/pages/docs/devon4j.asciidoc_layers.html#guide-logic-layer.asciidoc","type":"docs","title":"Logic Layer","body":"11.4. Logic Layer\nThe logic layer is the heart of the application and contains the main business logic.\nAccording to our business architecture, we divide an application into components.\nFor each component, the logic layer defines a component-facade.\nAccording to the complexity, you can further divide this into individual use-cases.\nIt is very important that you follow the links to understand the concept of component-facade and use-case in order to properly implement your business logic.\n"},{"id":272,"path":"../website/pages/docs/devon4j.asciidoc_layers.html#guide-logic-layer.asciidoc_responsibility","type":"docs","title":"Responsibility","body":"11.4.1. Responsibility\nThe logic layer is responsible to implement the business logic according to the specified functional demands and requirements.\nTherefore, it creates the actual value of the application. The logic layer is responsible for invoking business logic in external systems.\nThe following additional aspects are also included in its responsibility:\nvalidation\nauthorization\ntransaction-handling (in addition to service layer).\n"},{"id":273,"path":"../website/pages/docs/devon4j.asciidoc_layers.html#guide-logic-layer.asciidoc_security","type":"docs","title":"Security","body":"11.4.2. Security\nThe logic layer is the heart of the application. It is also responsible for authorization and hence security is important in this current case. Every method exposed in an interface needs to be annotated with an authorization check, stating what role(s) a caller must provide in order to be allowed to make the call. The authorization concept is described here.\nDirect Object References\nA security threat are Insecure Direct Object References. This simply gives you two options:\navoid direct object references\nensure that direct object references are secure\nEspecially when using REST, direct object references via technical IDs are common sense. This implies that you have a proper authorization in place. This is especially tricky when your authorization does not only rely on the type of the data and according to static permissions but also on the data itself. Vulnerabilities for this threat can easily happen by design flaws and inadvertence. Here is an example from our sample application:\nWe have a generic use-case to manage BLOBs. In the first place, it makes sense to write a generic REST service to load and save these BLOBs. However, the permission to read or even update such BLOB depends on the business object hosting the BLOB. Therefore, such a generic REST service would open the door for this OWASP A4 vulnerability. To solve this in a secure way, you need individual services for each hosting business object to manage the linked BLOB and have to check permissions based on the parent business object. In this example the ID of the BLOB would be the direct object reference and the ID of the business object (and a BLOB property indicator) would be the indirect object reference.\n"},{"id":274,"path":"../website/pages/docs/devon4j.asciidoc_layers.html#guide-component-facade.asciidoc","type":"docs","title":"Component Facade","body":"11.4.3. Component Facade\nFor each component of the application, the logic layer defines a component facade.\nThis is an interface defining all business operations of the component.\nIt carries the name of the component (&#xAB;Component&#xBB;) and has an implementation named &#xAB;Component&#xBB;Impl (see implementation).\nAPI\nThe component facade interface defines the logic API of the component and has to be business oriented.\nThis means that all parameters and return types of all methods from this API have to be business transfer-objects, datatypes (String, Integer, MyCustomerNumber, etc.), or collections of these.\nThe API may also only access objects of other business components listed in the (transitive) dependencies of the business-architecture.\nHere is an example how such an API may look like:\npublic interface Bookingmanagement {\nBookingEto findBooking(Long id);\nBookingCto findBookingCto(Long id);\nPage&lt;BookingEto&gt; findBookingEtos(BookingSearchCriteriaTo criteria);\nvoid approveBooking(BookingEto booking);\n}\nImplementation\nThe implementation of an interface from the logic layer (a component facade or a use-case) carries the name of that interface with the suffix Impl and is annotated with @Named.\nAn implementation typically needs access to the persistent data.\nThis is done by injecting the corresponding repository (or DAO).\nAccording to data-sovereignty, only repositories of the same business component may be accessed directly.\nFor accessing data from other components the implementation has to use the corresponding API of the logic layer (the component facade). Further, it shall not expose persistent entities from the dataaccess layer and has to map them to transfer objects using the bean-mapper.\n@Named\n@Transactional\npublic class BookingmanagementImpl extends AbstractComponentFacade implements Bookingmanagement {\n@Inject\nprivate BookingRepository bookingRepository;\n@Override\npublic BookingEto findBooking(Long id) {\nLOG.debug(&quot;Get Booking with id {} from database.&quot;, id);\nBookingEntity entity = this.bookingRepository.findOne(id);\nreturn getBeanMapper().map(entity, BookingEto.class));\n}\n}\nAs you can see, entities (BookingEntity) are mapped to corresponding ETOs (BookingEto).\nFurther details about this can be found in bean-mapping.\nFor complex applications, the component facade consisting of many different methods.\nFor better maintainability in such case it is recommended to split it into separate use-cases that are then only aggregated by the component facade.\n"},{"id":275,"path":"../website/pages/docs/devon4j.asciidoc_layers.html#guide-usecase.asciidoc","type":"docs","title":"UseCase","body":"11.4.4. UseCase\nA use-case is a small unit of the logic layer responsible for an operation on a particular entity (business object).\nIt is defined by an interface (API) with its according implementation.\nFollowing our architecture-mapping, use-cases are named Uc&#xAB;Operation&#xBB;&#xAB;BusinessObject&#xBB;[Impl]. The prefix Uc stands for use-case and allows to easily find and identify them in your IDE. The &#xAB;Operation&#xBB; stands for a verb that is operated on the entity identified by &#xAB;BusinessObject&#xBB;.\nFor CRUD we use the standard operations Find and Manage that can be generated by CobiGen. This also separates read and write operations (e.g. if you want to do CQSR, or to configure read-only transactions for read operations).\nFind\nThe UcFind&#xAB;BusinessObject&#xBB; defines all read operations to retrieve and search the &#xAB;BusinessObject&#xBB;.\nHere is an example:\npublic interface UcFindBooking {\nBookingEto findBooking(Long id);\nBookingCto findBookingCto(Long id);\nPage&lt;BookingEto&gt; findBookingEtos(BookingSearchCriteriaTo criteria);\nPage&lt;BookingCto&gt; findBookingCtos(BookingSearchCriteriaTo criteria);\n}\nManage\nThe UcManage&#xAB;BusinessObject&#xBB; defines all CRUD write operations (create, update and delete) for the &#xAB;BusinessObject&#xBB;.\nHere is an example:\npublic interface UcManageBooking {\nBookingEto saveBooking(BookingEto booking);\nboolean deleteBooking(Long id);\n}\nCustom\nAny other non CRUD operation Uc&#xAB;Operation&#xBB;&#xAB;BusinessObject&#xBB; uses any other custom verb for &#xAB;Operation&#xBB;.\nTypically, such custom use-cases only define a single method.\nHere is an example:\npublic interface UcApproveBooking {\nvoid approveBooking(BookingEto booking);\n}\nImplementation\nFor the implementation of a use-cas, the same rules that are described for the component-facade implementation.\n.\nHowever, when following the use-case approach, your component facade simply changes to:\npublic interface Bookingmanagement extends UcFindBooking, UcManageBooking, UcApproveBooking {\n}\nWhere the implementation only delegates to the use-cases and gets entirely generated by CobiGen:\npublic class BookingmanagementImpl implements {\n@Inject\nprivate UcFindBooking ucFindBooking;\n@Inject\nprivate UcManageBooking ucManageBooking;\n@Inject\nprivate UcApproveBooking ucApproveBooking;\n@Override\npublic BookingEto findBooking(Long id) {\nreturn this.ucFindBooking.findBooking(id);\n}\n@Override\npublic Page&lt;BookingEto&gt; findBookingEtos(BookingSearchCriteriaTo criteria) {\nreturn this.ucFindBooking.findBookingEtos(criteria);\n}\n@Override\npublic BookingEto saveBooking(BookingEto booking) {\nreturn this.ucManageBooking.saveBooking(booking);\n}\n@Override\npublic boolean deleteBooking(Long id) {\nreturn this.ucManageBooking.deleteBooking(booking);\n}\n@Override\npublic void approveBooking(BookingEto booking) {\nthis.ucApproveBooking.approveBooking(booking);\n}\n...\n}\nThis approach is also illustrated by the following UML diagram:\nInternal use case\nSometimes, a component with multiple related entities and many use-cases needs to reuse business logic internally.\nOf course, this can be exposed as an official use-case API but this will imply using transfer-objects (ETOs) instead of entities. In some cases, this is undesired e.g. for better performance to prevent unnecessary mapping of entire collections of entities.\nIn the first place, you should try to use abstract base implementations providing reusable methods the actual use-case implementations can inherit from.\nIf your business logic is even more complex and you have multiple aspects of business logic to share and reuse but also run into multi-inheritance issues, you may also just create use-cases that have their interface located in the impl scope package right next to the implementation (or you may just skip the interface). In such a case, you may define methods that directly take or return entity objects.\nTo avoid confusion with regular use-cases, we recommend to add the Internal suffix to the type name leading to Uc&#xAB;Operation&#xBB;&#xAB;BusinessObject&#xBB;Internal[Impl].\nInjection issues\nTechnically, now you have two implementations of your use-case:\nthe direct implementation of the use-case (Uc*Impl)\nthe component facade implementation (&#xAB;Component&#xBB;Impl)\nWhen injecting a use-case interface this could cause ambiguities.\nThis is addressed as following:\nIn the component facade implementation (&#xAB;Component&#xBB;Impl) spring is smart enough to resolve the ambiguity as it assumes that a spring bean never wants to inject itself (it can already be an access via this).\nTherefore, only the proper use-case implementation remains as a candidate and injection works as expected.\nIn all other places, simply always inject the component facade interface instead of the use-case.\nIn case you might have the lucky occasion to hit this nice exception:\norg.springframework.beans.factory.BeanCurrentlyInCreationException: Error creating bean with name &apos;uc...Impl&apos;: Bean with name &apos;uc...Impl&apos; has been injected into other beans [...Impl] in its raw version as part of a circular reference, but has eventually been wrapped. This means that said other beans do not use the final version of the bean. This is often the result of over-eager type matching - consider using &apos;getBeanNamesOfType&apos; with the &apos;allowEagerInit&apos; flag turned off, for example.\nTo get rid of such an error you need to annotate your according implementation also with @Lazy in addition to @Named.\n"},{"id":276,"path":"../website/pages/docs/devon4j.asciidoc_layers.html#guide-dataaccess-layer.asciidoc","type":"docs","title":"Data-Access Layer","body":"11.5. Data-Access Layer\nThe data-access layer is responsible for all outgoing connections to access and process data. This is mainly about accessing data from a persistent data-store. External system could also be accessed from the data-access layer if they match this definition, e.g. a mongo-db via rest services.\n"},{"id":277,"path":"../website/pages/docs/devon4j.asciidoc_layers.html#guide-dataaccess-layer.asciidoc_database","type":"docs","title":"Database","body":"11.5.1. Database\nYou need to make your choice for a database. Options are documented here.\nThe classical approach is to use a Relational Database Management System (RDMS). In such a case, we strongly recommend to follow our JPA Guide. Some NoSQL databases are supported by spring-data so you can consider the repository guide.\n"},{"id":278,"path":"../website/pages/docs/devon4j.asciidoc_layers.html#guide-batch-layer.asciidoc","type":"docs","title":"Batch Layer","body":"11.6. Batch Layer\nWe understand batch processing as a bulk-oriented, non-interactive, typically long running execution of tasks. For simplicity, we use the term &quot;batch&quot; or &quot;batch job&quot; for such tasks in the following documentation.\ndevonfw uses Spring Batch as a batch framework.\nThis guide explains how Spring Batch is used in devonfw applications. It focuses on aspects which are special to devonfw. If you want to learn about spring-batch you should adhere to springs references documentation.\nThere is an example of a simple batch implementation in the my-thai-star batch module.\nIn this chapter, we will describe the overall architecture (especially concerning layering) and how to administer batches.\n"},{"id":279,"path":"../website/pages/docs/devon4j.asciidoc_layers.html#guide-batch-layer.asciidoc_layering","type":"docs","title":"Layering","body":"11.6.1. Layering\nBatches are implemented in the batch layer. The batch layer is responsible for batch processes, whereas the business logic is implemented in the logic layer. Compared to the service layer, you may understand the batch layer just as a different way of accessing the business logic.\nFrom a component point of view, each batch is implemented as a subcomponent in the corresponding business component.\nThe business component is defined by the business architecture.\nLet&#x2019;s make an example for that. The sample application implements a batch for exporting ingredients. This ingredientExportJob belongs to the dishmanagement business component.\nSo the ingredientExportJob is implemented in the following package:\n&lt;basepackage&gt;.dishmanagement.batch.impl.*\nBatches should invoke use cases in the logic layer for doing their work.\nOnly &quot;batch specific&quot; technical aspects should be implemented in the batch layer.\nExample:\nFor a batch, which imports product data from a CSV file, this means that all code for actually reading and parsing the CSV input file is implemented in the batch layer.\nThe batch calls the use case &quot;create product&quot; in the logic layer for actually creating the products for each line read from the CSV input file.\nDirectly accessing data access layer\nIn practice, it is not always appropriate to create use cases for every bit of work a batch should do. Instead, the data access layer can be used directly.\nAn example for that is a typical batch for data retention which deletes out-of-time data.\nOften deleting, out-dated data is done by invoking a single SQL statement. It is appropriate to implement that SQL in a Repository or DAO method and call this method directly from the batch.\nBut be careful: this pattern is a simplification which could lead to business logic cluttered in different layers, which reduces the maintainability of your application.\nIt is a typical design decision you have to make when designing your specific batches.\n"},{"id":280,"path":"../website/pages/docs/devon4j.asciidoc_layers.html#guide-batch-layer.asciidoc_project-structure-and-packaging","type":"docs","title":"Project structure and packaging","body":"11.6.2. Project structure and packaging\nBatches will be implemented in a separate Maven module to keep the application core free of batch dependencies. The batch module includes a dependency on the application core-module to allow the reuse of the use cases, DAOs etc.\nAdditionally the batch module has dependencies on the required spring batch jars:\n&lt;dependencies&gt;\n&lt;dependency&gt;\n&lt;groupId&gt;${project.groupId}&lt;/groupId&gt;\n&lt;artifactId&gt;mtsj-core&lt;/artifactId&gt;\n&lt;version&gt;dev-SNAPSHOT&lt;/version&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n&lt;artifactId&gt;spring-boot-starter-batch&lt;/artifactId&gt;\n&lt;/dependency&gt;\n&lt;/dependencies&gt;\nTo allow an easy start of the batches from the command line it is advised to create a bootified jar for the batch module by adding the following to the pom.xml of the batch module:\n&lt;build&gt;\n&lt;resources&gt;\n&lt;resource&gt;\n&lt;directory&gt;src/main/resources&lt;/directory&gt;\n&lt;filtering&gt;true&lt;/filtering&gt;\n&lt;/resource&gt;\n&lt;/resources&gt;\n&lt;plugins&gt;\n&lt;plugin&gt;\n&lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\n&lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt;\n&lt;configuration&gt;\n&lt;excludes&gt;\n&lt;exclude&gt;config/application.properties&lt;/exclude&gt;\n&lt;/excludes&gt;\n&lt;/configuration&gt;\n&lt;/plugin&gt;\n&lt;!-- Create bootified jar for batch execution via command line.\nYour applications spring boot app is used as main-class.\n--&gt;\n&lt;plugin&gt;\n&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n&lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;\n&lt;configuration&gt;\n&lt;mainClass&gt;com.devonfw.application.mtsj.SpringBootApp&lt;/mainClass&gt;\n&lt;classifier&gt;bootified&lt;/classifier&gt;\n&lt;/configuration&gt;\n&lt;executions&gt;\n&lt;execution&gt;\n&lt;goals&gt;\n&lt;goal&gt;repackage&lt;/goal&gt;\n&lt;/goals&gt;\n&lt;/execution&gt;\n&lt;/executions&gt;\n&lt;/plugin&gt;\n&lt;/plugins&gt;\n&lt;/build&gt;\n"},{"id":281,"path":"../website/pages/docs/devon4j.asciidoc_layers.html#guide-batch-layer.asciidoc_implementation","type":"docs","title":"Implementation","body":"11.6.3. Implementation\nMost of the details about implementation of batches is described in the spring batch documentation.\nThere is nothing special about implementing batches in devonfw. You will find an easy example in my-thai-star.\n"},{"id":282,"path":"../website/pages/docs/devon4j.asciidoc_layers.html#guide-batch-layer.asciidoc_starting-from-command-line","type":"docs","title":"Starting from command line","body":"11.6.4. Starting from command line\nDevonfw advises to start batches via command line. This is most common to many ops teams and allows easy integration in existing schedulers. In general batches are started with the following command:\njava -jar &lt;app&gt;-batch-&lt;version&gt;-bootified.jar --spring.main.web-application-type=none --spring.batch.job.enabled=true --spring.batch.job.names=&lt;myJob&gt; &lt;params&gt;\nParameter\nExplanation\n--spring.main.web-application-type=none\nThis disables the web app (e.g. Tomcat)\n--spring.batch.job.names=&lt;myJob&gt;\nThis specifies the name of the job to run. If you leave this out ALL jobs will be executed. Which probably does not make to much sense.\n&lt;params&gt;\n(Optional) additional parameters which are passed to your job\nThis will launch your normal spring boot app, disables the web application part and runs the designated job via Spring Boots org.springframework.boot.autoconfigure.batch.JobLauncherCommandLineRunner.\n"},{"id":283,"path":"../website/pages/docs/devon4j.asciidoc_layers.html#guide-batch-layer.asciidoc_scheduling","type":"docs","title":"Scheduling","body":"Scheduling\nIn real world scheduling of batches is not as simple as it first might look like.\nMultiple batches have to be executed in order to achieve complex tasks. If one of those batches fails the further execution has to be stopped and operations should be notified for example.\nInput files or those created by batches have to be copied from one node to another.\nScheduling batch executing could get complex easily (quarterly jobs, run job on first workday of a month, &#x2026;&#x200B;)\nFor devonfw we propose the batches themselves should not mess around with details of scheduling.\nLikewise your application should not do so. This complexity should be externalized to a dedicated batch administration service or scheduler.\nThis service could be a complex product or a simple tool like cron. We propose Rundeck as an open source job scheduler.\nThis gives full control to operations to choose the solution which fits best into existing administration procedures.\n"},{"id":284,"path":"../website/pages/docs/devon4j.asciidoc_layers.html#guide-batch-layer.asciidoc_handling-restarts","type":"docs","title":"Handling restarts","body":"11.6.5. Handling restarts\nIf you start a job with the same parameters set after a failed run (BatchStatus.FAILED) a restart will occur.\nIn many cases your batch should then not reprocess all items it processed in the previous runs.\nFor that you need some logic to start at the desired offset. There different ways to implement such logic:\nMarking processed items in the database in a dedicated column\nWrite all IDs of items to process in a separate table as an initialization step of your batch. You can then delete IDs of already processed items from that table during the batch execution.\nStoring restart information in springs ExecutionContext (see below)\nUsing spring batch ExecutionContext for restarts\nBy implementing the ItemStream interface in your ItemReader or ItemWriter you may store information about the batch progress in the ExecutionContext. You will find an example for that in the CountJob in My Thai Star.\nAdditional hint: It is important that bean definition method of your ItemReader/ItemWriter return types implementing ItemStream(and not just ItemReader or ItemWriter alone). For that the ItemStreamReader and ItemStreamWriter interfaces are provided.\n"},{"id":285,"path":"../website/pages/docs/devon4j.asciidoc_layers.html#guide-batch-layer.asciidoc_exit-codes","type":"docs","title":"Exit codes","body":"11.6.6. Exit codes\nYour batches should create a meaningful exit code to allow reaction to batch errors e.g. in a scheduler.\nFor that spring batch automatically registers an org.springframework.boot.autoconfigure.batch.JobExecutionExitCodeGenerator. To make this mechanism work your spring boot app main class as to populate this exit code to the JVM:\n@SpringBootApplication\npublic class SpringBootApp {\npublic static void main(String[] args) {\nif (Arrays.stream(args).anyMatch((String e) -&gt; e.contains(&quot;--spring.batch.job.names&quot;))) {\n// if executing batch job, explicitly exit jvm to report error code from batch\nSystem.exit(SpringApplication.exit(SpringApplication.run(SpringBootApp.class, args)));\n} else {\n// normal web application start\nSpringApplication.run(SpringBootApp.class, args);\n}\n}\n}\n"},{"id":286,"path":"../website/pages/docs/devon4j.asciidoc_layers.html#guide-batch-layer.asciidoc_stop-batches-and-manage-batch-status","type":"docs","title":"Stop batches and manage batch status","body":"11.6.7. Stop batches and manage batch status\nSpring batch uses several database tables to store the status of batch executions.\nEach execution may have different status.\nYou may use this mechanism to gracefully stop batches.\nAdditionally in some edge cases (batch process crashed) the execution status may be in an undesired state.\nE.g. the state will be running, despite the process crashed sometime ago.\nFor that cases you have to change the status of the execution in the database.\nCLI-Tool\nDevonfw provides a easy to use cli-tool to manage the executing status of your jobs.\nThe tool is implemented in the devonfw module devon4j-batch-tool. It will provide a runnable jar, which may be used as follows:\nList names of all previous executed jobs\njava -D&apos;spring.datasource.url=jdbc:h2:~/mts;AUTO_SERVER=TRUE&apos; -jar devon4j-batch-tool.jar jobs list\nStop job named &apos;countJob&apos;\njava -D&apos;spring.datasource.url=jdbc:h2:~/mts;AUTO_SERVER=TRUE&apos; -jar devon4j-batch-tool.jar jobs stop countJob\nShow help\njava -D&apos;spring.datasource.url=jdbc:h2:~/mts;AUTO_SERVER=TRUE&apos; -jar devon4j-batch-tool.jar\nAs you can the each invocation includes the JDBC connection string to your database.\nThis means that you have to make sure that the corresponding DB driver is in the classpath (the prepared jar only contains H2).\n"},{"id":287,"path":"../website/pages/docs/devon4j.asciidoc_layers.html#guide-batch-layer.asciidoc_authentication","type":"docs","title":"Authentication","body":"11.6.8. Authentication\nMost business application incorporate authentication and authorization.\nYour spring boot application will implement some kind of security, e.g. integrated login with username+password or in many cases authentication via an existing IAM.\nFor security reasons your batch should also implement an authentication mechanism and obey the authorization implemented in your application (e.g. via @RolesAllowed).\nSince there are many different authentication mechanism we cannot provide an out-of-the-box solution in devonfw, but we describe a pattern how this can be implemented in devonfw batches.\nWe suggest to implement the authentication in a Spring Batch tasklet, which runs as the first step in your batch. This tasklet will do all of the work which is required to authenticate the batch. A simple example which authenticates the batch &quot;locally&quot; via username and password could be implemented like this:\n@Named\npublic class SimpleAuthenticationTasklet implements Tasklet {\n@Override\npublic RepeatStatus execute(StepContribution contribution, ChunkContext chunkContext) throws Exception {\nString username = chunkContext.getStepContext().getStepExecution().getJobParameters().getString(&quot;username&quot;);\nString password = chunkContext.getStepContext().getStepExecution().getJobParameters().getString(&quot;password&quot;);\nAuthentication authentication = new UsernamePasswordAuthenticationToken(username, password);\nSecurityContextHolder.getContext().setAuthentication(authentication);\nreturn RepeatStatus.FINISHED;\n}\n}\nThe username and password have to be supplied via two cli parameters -username and -password. This implementation creates an &quot;authenticated&quot; Authentication and sets in the Spring Security context. This is just for demonstration normally you should not provide passwords via command line. The actual authentication will be done automatically via Spring Security as in your &quot;normal&quot; application.\nIf you have a more complex authentication mechanism in your application e.g. via OpenID connect just call this in the tasklet. Naturally you may read authentication parameters (e.g. secrets) from the command line or more securely from a configuration file.\nIn your Job Configuration set this tasklet as the first step:\n@Configuration\n@EnableBatchProcessing\npublic class BookingsExportBatchConfig {\n@Inject\nprivate JobBuilderFactory jobBuilderFactory;\n@Inject\nprivate StepBuilderFactory stepBuilderFactory;\n@Bean\npublic Job myBatchJob() {\nreturn this.jobBuilderFactory.get(&quot;myJob&quot;).start(myAuthenticationStep()).next(...).build();\n}\n@Bean\npublic Step myAuthenticationStep() {\nreturn this.stepBuilderFactory.get(&quot;myAuthenticationStep&quot;).tasklet(myAuthenticatonTasklet()).build();\n}\n@Bean\npublic Tasklet myAuthenticatonTasklet() {\nreturn new SimpleAuthenticationTasklet();\n}\n...\n"},{"id":288,"path":"../website/pages/docs/devon4j.asciidoc_layers.html#guide-batch-layer.asciidoc_tipps--tricks","type":"docs","title":"Tipps &amp; tricks","body":"11.6.9. Tipps &amp; tricks\nIdentifying job parameters\nSpring uses a jobs parameters to identify job executions. Parameters starting with &quot;-&quot; are not considered for identifying a job execution.\n&#x2190;&#xA0;Previous:&#xA0;Project structure&#xA0;| &#x2191;&#xA0;Up:&#xA0;devonfw for Java (devon4j)&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Guides&#xA0;&#x2192;\n"},{"id":289,"path":"../website/pages/docs/devon4j.asciidoc_tutorials.html#devon4j.asciidoc_tutorials","type":"docs","title":"Tutorials","body":"13. Tutorials\n"},{"id":290,"path":"../website/pages/docs/devon4j.asciidoc_tutorials.html#tutorial-newapp.asciidoc","type":"docs","title":"Creating a new application","body":"13.1. Creating a new application\n"},{"id":291,"path":"../website/pages/docs/devon4j.asciidoc_tutorials.html#tutorial-newapp.asciidoc_running-the-archetype","type":"docs","title":"Running the archetype","body":"13.1.1. Running the archetype\nIn order to create a new application you must use the archetype provided by devon4j which uses the maven archetype functionality.\nTo create a new application, you should have installed devonfw IDE. Follow the devon ide documentation to install\nthe same.\nYou can choose between 2 alternatives, create it from command line or, in more visual manner, within eclipse.\nFrom command Line\nTo create a new devon4j application from command line, you can simply run the following command:\ndevon java create com.example.application.sampleapp\nFor low-level creation you can also manually call this command:\nmvn -DarchetypeVersion=${devon4j.version} -DarchetypeGroupId=com.devonfw.java.templates -DarchetypeArtifactId=devon4j-template-server archetype:generate -DgroupId=com.example.application -DartifactId=sampleapp -Dversion=1.0.0-SNAPSHOT -Dpackage=com.devonfw.application.sampleapp\nAttention: The archetypeVersion (first argument) should be set to the latest version of devon4j. You can easily determine the version from this badge:\nFurther providing additional properties (using -D parameter) you can customize the generated app:\nTable 43. Options for app template\nproperty\ncomment\nexample\ndbType\nChoose the type of RDBMS to use (hana, oracle, mssql, postgresql, mariadb, mysql, etc.)\n-DdbTpye=postgresql\nbatch\nOption to add an batch module\n-Dbatch=batch\nFrom Eclipse\nAfter that, you should follow this Eclipse steps to create your application:\nCreate a new Maven Project.\nChoose the devon4j-template-server archetype, just like the image.\nFill the Group Id, Artifact Id, Version and Package for your project.\nFinish the Eclipse assistant and you are ready to start your project.\n"},{"id":292,"path":"../website/pages/docs/devon4j.asciidoc_tutorials.html#tutorial-newapp.asciidoc_what-is-generated","type":"docs","title":"What is generated","body":"13.1.2. What is generated\nThe application template (archetype) generates a Maven multi-module project. It has the following modules:\napi: module with the API (REST service interfaces, transferobjects, datatypes, etc.) to be imported by other apps as a maven dependency in order to invoke and consume the offered (micro)services.\ncore: maven module containing the core of the application.\nbatch: optional module for batch(es)\nserver: module that bundles the entire app (core with optional batch) as a WAR file.\nThe toplevel pom.xml of the generated project has the following features:\nProperties definition: Spring-boot version, Java version, etc.\nModules definition for the modules (described above)\nDependency management: define versions for dependencies of the technology stack that are recommended and work together in a compatible way.\nMaven plugins with desired versions and configuration\nProfiles for test stages\n"},{"id":293,"path":"../website/pages/docs/devon4j.asciidoc_tutorials.html#tutorial-newapp.asciidoc_how-to-run-your-app","type":"docs","title":"How to run your app","body":"13.1.3. How to run your app\nRun app from IDE\nTo run your application from your favourite IDE, simply launch SpringBootApp as java application.\nRun app as bootified jar or war\nMore details are available here.\n&#x2190;&#xA0;Previous:&#xA0;Guides&#xA0;| &#x2191;&#xA0;Up:&#xA0;devonfw for Java (devon4j)&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;devon4ng&#xA0;&#x2192;\n"},{"id":294,"path":"../website/pages/docs/devon4node-architecture.asciidoc.html#devon4node-architecture.asciidoc","type":"docs","title":"devon4node Architecture","body":"32. devon4node Architecture\nAs we have mentioned in the introduction, devon4node is based on NestJS. Nest (NestJS) is a framework for building efficient, scalable Node.js server-side applications.\n"},{"id":295,"path":"../website/pages/docs/devon4node-architecture.asciidoc.html#devon4node-architecture.asciidoc_http-layer","type":"docs","title":"HTTP layer","body":"32.1. HTTP layer\nBy using NestJS, devon4node is a platform-agnostic framework. NestJS focuses only on the logical layer, and delegates the transport layer to another framework, such as ExpressJS. You can see it in the following diagram:\nAs you can see, NestJS do not listen directly for incoming request. It has an adapter to communicate with ExpressJS and ExpressJS is the responsible for that. ExpressJS is only one of the frameworks that NestJS can work with. We have also another adapter available out-of-the-box: the Fastify adapter. With that, you can replace ExpressJS for Fastify But you can still use all your NestJS components. You can also create your own adapter to make NestJS work with other HTTP framework.\nAt this point, you may think: why is NestJS (and devon4node) using ExpressJS by default instead of Fastify? Because, as you can see in the previous diagram, there is a component that is dependent on the HTTP framework: the middleware. As ExpressJS is the most widely used framework, there exists a lot of middleware for it, so, in order to reuse them in our NestJS applications, NestJS use ExpressJS by default. Anyway, you may think which HTTP framework best fits your requirements.\n"},{"id":296,"path":"../website/pages/docs/devon4node-architecture.asciidoc.html#devon4node-architecture.asciidoc_devon4node-layers","type":"docs","title":"devon4node layers","body":"32.2. devon4node layers\nAs other devonfw technologies, devon4node separates the application into layers.\nThose layers are:\nController layer\nService layer\nData Access layer\n"},{"id":297,"path":"../website/pages/docs/devon4node-architecture.asciidoc.html#devon4node-architecture.asciidoc_devon4node-application-structure","type":"docs","title":"devon4node application structure","body":"32.3. devon4node application structure\nAlthough there are many frameworks to create backend applications in NodeJS, none of them effectively solve the main problem of - Architecture. This is the main reason we have chosen NestJS for the devon4node applications. Besides, NestJS is highly inspired by Angular, therefore a developer who knows Angular can use his already acquired knowledge to write devon4node applications.\nNestJS adopts various Angular concepts, such as dependency injection, piping, interceptors and modularity, among others. By using modularity we can reuse some of our modules between applications. One example that devon4node provide is the mailer module.\n"},{"id":298,"path":"../website/pages/docs/devon4node-architecture.asciidoc.html#devon4node-architecture.asciidoc_modules","type":"docs","title":"Modules","body":"32.3.1. Modules\nCreate a application module is simple, you only need to create an empty class with the decorator Module:\n@Module({})\nexport class AppModule {}\nIn the module you can define:\nImports: the list of imported modules that export the providers which are required in this module\nControllers: the set of controllers defined in this module which have to be instantiated\nProviders: the providers that will be instantiated by the Nest injector and that may be shared at least across this module\nExports: the subset of providers that are provided by this module and should be available in other modules which import this module\nThe main difference between Angular and NestJS is NestJS modules encapsulates providers by default. This means that it&#x2019;s impossible to inject providers that are neither directly part of the current module nor exported from the imported modules. Thus, you may consider the exported providers from a module as the module&#x2019;s public interface, or API. Example of modules graph:\nIn devon4node we three different kind of modules:\nAppModule: this is the root module. Everything that our application need must be imported here.\nGlobal Modules: this is a special kind of modules. When you make a module global, it&#x2019;s accessible for every module in your application. Your can see it in the next diagram. It&#x2019;s the same as the previous one, but now the CoreModule is global:\nOne example of global module is the CoreModule. In the CoreModule you must import every module which have providers that needs to be accessible in all modules of you application\nFeature (or application) modules: modules which contains the logic of our application. We must import it in the AppModule.\nFor more information about modules, see NestJS documentation page\n"},{"id":299,"path":"../website/pages/docs/devon4node-architecture.asciidoc.html#devon4node-architecture.asciidoc_folder-structure","type":"docs","title":"Folder structure","body":"32.3.2. Folder structure\ndevon4node defines a folder structure that every devon4node application must follow. The folder structure is:\n&#x251C;&#x2500;&#x2500;&#x2500;src\n&#x2502; &#x251C;&#x2500;&#x2500;&#x2500;app\n&#x2502; &#x2502; &#x251C;&#x2500;&#x2500;&#x2500;core\n&#x2502; &#x2502; &#x2502; &#x251C;&#x2500;&#x2500;&#x2500;auth\n&#x2502; &#x2502; &#x2502; &#x251C;&#x2500;&#x2500;&#x2500;configuration\n&#x2502; &#x2502; &#x2502; &#x251C;&#x2500;&#x2500;&#x2500;user\n&#x2502; &#x2502; &#x2502; &#x2514;&#x2500;&#x2500;&#x2500;core.module.ts\n&#x2502; &#x2502; &#x251C;&#x2500;&#x2500;&#x2500;shared\n&#x2502; &#x2502; &#x2514;&#x2500;&#x2500;&#x2500;feature\n&#x2502; &#x2502; &#x251C;&#x2500;&#x2500;&#x2500;sub-module\n&#x2502; &#x2502; &#x2502; &#x251C;&#x2500;&#x2500;&#x2500;controllers\n&#x2502; &#x2502; &#x2502; &#x251C;&#x2500;&#x2500;&#x2500;...\n&#x2502; &#x2502; &#x2502; &#x251C;&#x2500;&#x2500;&#x2500;services\n&#x2502; &#x2502; &#x2502; &#x2514;&#x2500;&#x2500;&#x2500;sub-module.module.ts\n&#x2502; &#x2502; &#x251C;&#x2500;&#x2500;&#x2500;controllers\n&#x2502; &#x2502; &#x251C;&#x2500;&#x2500;&#x2500;interceptors\n&#x2502; &#x2502; &#x251C;&#x2500;&#x2500;&#x2500;pipes\n&#x2502; &#x2502; &#x251C;&#x2500;&#x2500;&#x2500;guards\n&#x2502; &#x2502; &#x251C;&#x2500;&#x2500;&#x2500;filters\n&#x2502; &#x2502; &#x251C;&#x2500;&#x2500;&#x2500;middlewares\n&#x2502; &#x2502; &#x251C;&#x2500;&#x2500;&#x2500;model\n&#x2502; &#x2502; &#x2502; &#x251C;&#x2500;&#x2500;&#x2500;dto\n&#x2502; &#x2502; &#x2502; &#x2514;&#x2500;&#x2500;&#x2500;entities\n&#x2502; &#x2502; &#x251C;&#x2500;&#x2500;&#x2500;services\n&#x2502; &#x2502; &#x2514;&#x2500;&#x2500;&#x2500;feature.module.ts\n&#x2502; &#x251C;&#x2500;&#x2500;&#x2500;config\n&#x2502; &#x2514;&#x2500;&#x2500;&#x2500;migration\n&#x251C;&#x2500;&#x2500;&#x2500;test\n&#x2514;&#x2500;&#x2500;&#x2500;package.json\ndevon4node schematics ensures this folder structure so, please, do not create files by your own, use the devon4node schematics.\n"},{"id":300,"path":"../website/pages/docs/devon4node-architecture.asciidoc.html#devon4node-architecture.asciidoc_nestjs-components","type":"docs","title":"NestJS components","body":"32.3.3. NestJS components\nNestJS provides several components that you can use in your application:\nControllers\nProviders\nMiddleware\nGuards\nInterceptors\nPipes\nException filters\nIn the NestJS documentation you can find all information about each component. But, something that is missing in the documentation is the execution order. Every component can be defined in different levels: globally, in the controller or in the handler. As middleware is part of the HTTP server we can define it in a different way: globally or in the module.\nIt is not necessary to have defined components in every level. For example, you can have defined a interceptor globally but you do not have any other in the controller or handler level. If nothing is defined in some level, the request will continue to the next component.\nAs you can see in the previous image, the first component which receive the request is the global defined middleware. Then, it send the request to the module middleware. Each of them can return a response to the client, without passing the request to the next level.\nThen, the request continue to the guards: first the global guard, next to controller guard and finally to the handler guard. At this point, we can throw an exception in all components and the exception filter will catch it and send a proper error message to the client. We do not paint the filters in the graphic in order to simplify it.\nAfter the guards, is time to interceptors: global interceptors, controller interceptors and handler interceptors. And last, before arrive to the handler inside the controller, the request pass through the pipes.\nWhen the handler has the response ready to send to the client, it does not go directly to the client. It come again to the interceptors, so we can also intercept the response. The order this time is the reverse: handler interceptors, controller interceptors and global interceptors. After that, we can finally send the response to the client.\nNow, with this in mind, you are able to create the components in a better way.\n&#x2191;&#xA0;Up:&#xA0;devon4node&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Layers&#xA0;&#x2192;\n"},{"id":301,"path":"../website/pages/docs/devonfw-ide-advanced.asciidoc.html#devonfw-ide-advanced.asciidoc","type":"docs","title":"Advanced Features","body":"6. Advanced Features\n"},{"id":302,"path":"../website/pages/docs/devonfw-ide-advanced.asciidoc.html#advanced-tooling-generic.asciidoc","type":"docs","title":"Cross-Plattform Tooling","body":"6.1. Cross-Plattform Tooling\n"},{"id":303,"path":"../website/pages/docs/devonfw-ide-advanced.asciidoc.html#advanced-tooling-generic.asciidoc_git-client","type":"docs","title":"Git Client","body":"6.1.1. Git Client\nIf you are looking for a git client that works cross-platform we recommend to use Fork.\n"},{"id":304,"path":"../website/pages/docs/devonfw-ide-advanced.asciidoc.html#advanced-tooling-generic.asciidoc_draw-diagrams","type":"docs","title":"Draw Diagrams","body":"6.1.2. Draw Diagrams\nTo draw diagrams for your project or for blueprints in devonfw, we recommend the following cross-plattform tools:\ndraw.io is a powerful generic vector painting program (similar to visio). You can get a free open-source edition for your desktop from here.\nObjectAid is a nice and easy to use eclipse plugin that you can use to quickly create UML diagrams from existing code. While class-diagrams are supported for free, you need to buy a license if you want to use the other diagram types.\nPlantUML is a great tool that can render UML diagrams from simple markup that can be easily managed in git or other version-control systems together with your code. Its simplicity allows branching and merging unlike other greedy binary UML data-formats.\n"},{"id":305,"path":"../website/pages/docs/devonfw-ide-advanced.asciidoc.html#advanced-tooling-generic.asciidoc_browser-plugins","type":"docs","title":"Browser Plugins","body":"6.1.3. Browser Plugins\nThere are tons of helpful browser plugins out there and it might be a matter of personal taste what you like to have installed. However, as we are heavily using github we want to promote octotree.\nIn case you also work with ZenHub you might want to install the Zenhub Browser Extension.\n"},{"id":306,"path":"../website/pages/docs/devonfw-ide-advanced.asciidoc.html#advanced-tooling-windows.asciidoc","type":"docs","title":"Windows Tooling","body":"6.2. Windows Tooling\n"},{"id":307,"path":"../website/pages/docs/devonfw-ide-advanced.asciidoc.html#advanced-tooling-windows.asciidoc_integration-into-windows-explorer","type":"docs","title":"Integration into Windows-Explorer","body":"6.2.1. Integration into Windows-Explorer\nAfter you have set up your devonfw-ide on a windows machine,\nyou already have windows-explorer integration out-of-the-box.\nJust right-click on the folder you would like to open in a terminal and choose from the context menu:\nGit Bash\nOpen devonfw CMD shell here\nOpen devonfw PowerShell here\nOpen devonfw Cygwin Bash Here (only if cygwin was installed during setup)\n"},{"id":308,"path":"../website/pages/docs/devonfw-ide-advanced.asciidoc.html#advanced-tooling-windows.asciidoc_tabs-everywhere","type":"docs","title":"Tabs everywhere","body":"6.2.2. Tabs everywhere\nMany people got used to tabs that have been introduced by all major browsers:\nFigure 1. Tabs in Firefox\nThis nice feature can be added to many other tools.\nTabs for Windows Explorer\nIf you want to have tabs for windows explorer simply install Clover\nFigure 2. Tabs in Windows Explorer\nTabs for SSH\nIf you want to have tabs for your SSH client Putty (or even better Kitty that comes with WinSCP integration) you simply install SuperPutty\nBTW: Windows 10 has already an SSH client included.\nFigure 3. Tabs for SSH\nTabs for CMD\nIf you want to have tabs for your windows command-line you simply install ConEmu. Here you can also add other shells like Putty.\nAlso you should have a look at the new Windows Terminal which also supports tabs.\nFigure 4. Tabs for CMD\nSee integration to make ConEmu work flawless with devonfw-ide.\n"},{"id":309,"path":"../website/pages/docs/devonfw-ide-advanced.asciidoc.html#advanced-tooling-windows.asciidoc_windows-helpers","type":"docs","title":"Windows Helpers","body":"6.2.3. Windows Helpers\nHandle passwords\nDo you want complex passwords that differ for each account for security? Do you only want to remember a single password for simplicity? Do you want to have both? Then, you need to install KeePass right now.\nReal text editor\nA real developer needs a real text editor and not windows build in notepad.\nThe most common choice is Notepad++.\nReal compression tool\nDo you need to deal with ZIP files, TGZ, dpkg, etc.? Just install 7zip and forget about windows build-in ZIP support (that is buggy with long file paths, etc.).\nSmarter clipboard\nDo you want to paste something from the clipboard but meanwhile you had to copy something else? Just, one of the many things you can easily do with ditto.\nSysinternals Tools\nA real developer will quickly notice that windows build in tools to analyze processes, network connections, autostarts, etc. are quite poor. So, what you really would like is the Sysinternals-Suite. You can make process-explorer your default task manager. Use autoruns to prevent nasty background things to be started automatically. Use tcpview to figure out which process is blocking port 8080, etc.\nCope with file locks\nDid you ever fail to delete a file or directory that was locked by some process and you did not even know which one it was?\nThen you might love IoBit Unlocker.\nSee also this article.\nCreate symbolic links\nAre you are used to symbolic and hard links in Linux? Do you have to work with Windows? Would you also like to have such links in Windows? Why not? Windows supports real links (not shortcuts like in other cases).\nIf you even want to have it integrated in windows explorer you might want to install linkshellextension. However, you might want to disable SmartMove in the configuration if you face strange performance issues when moving folders.\nLinux\nInstall Cygwin and get your bash in windows with ssh-agent, awk, sed, tar, and all the tools you love (or hate). Windows 10 has already a Linux as an installable feature included: WSL and from Version 2004 on WSL2, which is a native Linux Kernel running on Windows (an a light weight VM).\nX11\nDo you want to connect via SSH and need to open an X11 app from the server? Do you want to see the GUI on your windows desktop?\nNo problem: Install VcXsrv.\nKeyboard Freak\nAre you a keyboard shortcut person? Do you want to have shortcuts for things like &#xAB; and &#xBB; ?\nThen you should try AutoHotKey.\nFor the example (&#xAB; and &#xBB;) you can simply use this script to get started:\n^&lt;::Send {U+00AB}\n^+&lt;::Send {U+00BB}\nFirst, just press [ctrl][&lt;] and [ctrl][&gt;] ([ctrl][shift][&lt;]). Next, create shortcuts to launch your IDE, to open your favorite tool, etc.\nIf you like a GUI to easily configure the scrips, that comes with a lot of extensions preinstalled, you should have a look at Ac&#x2019;tive Aid.\nPaint anywhere on your desktop\nDo you collaborate sharing your screen, and want to mark a spot on top of what you see? Use Epic Pen to do just that.\nAnalyze graphs\nDo you need to visualise complex graph structures? Convert them to Trivial Graph Format (.tgf), a run yEd to get an interactive visualization of your graph.\nUp your screen capture game\nCapture any part of your screen with a single click, directly upload to dropbox, or run a svn commit all in one go with Greenshot. Another screen capture tool where you can easily manage and edit your screenshots and also do screen recordings with is Screenpresso.\nFast Search in Windows\nEverything is a desktop search utility for Windows that can rapidly find files and folders by name.\n"},{"id":310,"path":"../website/pages/docs/devonfw-ide-advanced.asciidoc.html#advanced-tooling-mac.asciidoc","type":"docs","title":"MacOS Tooling","body":"6.3. MacOS Tooling\n"},{"id":311,"path":"../website/pages/docs/devonfw-ide-advanced.asciidoc.html#advanced-tooling-mac.asciidoc_finder","type":"docs","title":"Finder","body":"6.3.1. Finder\nIf you want to open a terminal from a folder in Finder and automatically get your environment set properly for devonfw-ide you will find the perfect solution here.\nSo after installing (see below) the integration(s) provided here, you can easily open a terminal ready for your devonfw-ide:\nright click ([control] + click) on file or folder in Finder\nExpand the Quick-Actions sub-menu\nClick on the desired action (e.g. Open devonfw-Terminal here)\nVerify that you environment is properly initialized by invoking:\nmvn -v\nTo get this feature for MacOS Terminal.app open Finder and run the workflow system/mac/terminal/Open_devonfw-Terminal_here.workflow (in ${DEVON_IDE_HOME}). For iTerm2.app (that can be installed from App Store) do the same with system/mac/iterm/Open_devonfw-iTerm_here.workflow.\n"},{"id":312,"path":"../website/pages/docs/devonfw-ide-advanced.asciidoc.html#advanced-tooling-mac.asciidoc_keyboard","type":"docs","title":"Keyboard","body":"6.3.2. Keyboard\nKeyboard support is not an integration however, some users coming from other platforms may struggle with the way MacOS deals with (external non-apple) keyboards.\nSo to make it short: if you are happy with your keyboard and shortcuts, you can skip all the following. Otherwise, if you think that pressing keys like Home, End, etc. should just work as expected or pressing Alt Gr should allow you to type the special characters as printed on your German keyboard then here you will find a solution to your problems!\nTo get all automated you can just run the script system/mac/keyboard/install-mac-keyboard-support.sh (in ${DEVON_IDE_HOME}). If you would like to understand what is going on, you want to customize the keyboard settings to your needs, or you want a keyboard layout other than German ISO, please read on.\nKeyboard Layouts\nKeyboard layouts allow a find-grained mapping of each key on your keyboard to its resulting input character or behaviour. They are MacOS native features and do not need to have software running as a background service to make the keyboard mapping work (see Karabiner section below as an alternative).\nThey are provided as so called bundle (white lego brick icon). Like a MacOS app this is a folder containing a Contents folder with a specific sub-folder structure. In the Resources subfolder *.keylayout files are placed and define the exact mapping for the keyboard. As an example we provide a Keyboard Layouts folder containing a bundle for a German keyboard mapping.\nTo install keyboard layouts simply doubleclick the bundle or copy it to ~/Library/Keyboard Layouts. To actually use them go to System Preferences and select Keyboard. Then, select the tab Input Sources. With the + button you can add a keyboard layout for your daily usage with your mac. Please note that the keyboard layout shipped with devonfw-ide is called German-ISO and can be found in the Others section at the end of the list. It can be used as an example or template, if you want to create your own layout.\nWhen you have multiple mappings in place, on the top menu bar you will find a little icon next to the current time that allows you to switch between the keyboard layouts, which is very handy when you switch from your native MacBook keyboard to an external USB keyboard or vice versa.\nEven for a pure MacOS geek this can be helpful in case a friend coming from Windows/Linux is supposed to type something on the Mac in a pair-programming session.\nIn our German keyboard mapping example you can use the keys like Alt Gr, etc. to type special characters as you would expect and as printed on your keyboard. To make Pos1, End, etc. work properly accross all apps please read on to the next section(s).\nIn case you would like to create your own keyboard layout you can of course edit the *.keylayout files in a text editor. However, to make this much more comfortable, you can use the graphical editor tool Ukelele.\nBesides, the app itself, the Ukelele dmg file, also contains a Documentation and a Resources folder. The latter contains many keyboard layouts that you can use as a starting point.\nKey Bindings\nStill, various keyboard shortcuts might not work as expected for you. Therefore, we provide you with an advanced configuration in the folder system/mac/keyboard/KeyBindings that you can copy to your ~/Library folder:\ncd system/mac/keyboard/\ncp -r KeyBindings ~/Library\nTo make the changes work you need to log out and log in again or you can reboot. After that, your Home (Pos1) and End buttons should work as expected including with selection via Shift and/or Command. Also, you can use Command together with the left or right arrow key to move between words and combined it with Shift for selection. As an example, for further customization you can press Command + &lt; to type the unicode character &#xAB;.\nHowever, still some apps listen to keyboard events on a lower level and come with their own keyboard mappings. In these apps you might still experience unexpected behaviour. Solutions can be found in the following sub-sections.\nSwitch Control and Command\nIf you are used to windows or linux and get easily confused by the apple keyboard behaviour you might want to switch the Control and the Option key.\nOpen System Preferences and select Keyboard. Then, in the first tab, click on the button Modifier Keys&#x2026;&#x200B;. For every keyboard you can customize the behaviour of your modifier keys and therefore switch Control and Option as illustrated in the screenshot:\nProgrammers now should also disable that Control + Space is opening Spotlight Search as otherwise this shortcut can not be redifined in other apps like common IDEs.\nEclipse\nIn Eclipse, move and select by word as described above does not work. Even worse, the most important shortcut does not work: Control + Space for code completion (content assist). You can manually redefine the key bindings in Preferences under General &gt; Keys. However, with multiple IDE installations and workspaces this will quickly get tedious. Therefore, you can Export and Import specific Preferences such as Keys Preferences to/from a *.epf (Eclipse PreFerences) file.\nWe have done all this for you so you can just import the file located in system/mac/keyboard/Eclipse/eclipse-mac-keybindings.epf into your Eclipse. Happy coding.\nKarabiner\nIf you want more dynamics and do not worry about an app that has to run in the background to make your keyboard work as you like (no relevant performance overhead), you can try Karabiner Elements. This is a powerful tool to remap your keyboard shortcuts. In the UI you can only directly create and edit Simple Modifications that are too limited for most use-cases. However, using Complex Modifications you can do a lot of magic to customize the keyboard behaviour to your personal needs. A key with any combination of modifiers can be mapped to any key with arbitrary modifiers. This can also be bound to conditions based on the frontmost application or the keyboard model. These complex modifications are configured as *.json files. We have included a set with useful rules for external keyboards, programmer shortcuts, etc. If you have Karabiner installed, you only need to copy the contents of the karabiner folder located in this directory to your ~/.config folder:\ncd system/mac/keyboard/\ncp karabiner/assets/complex_modifications/*.json ~/.config/karabiner/assets/complex_modifications/\nNow, if you open the Complex Modifications in the Karabiner app, you can click on the + Add rule button and will see these mappings in the pop up. Select the rules you want to add (e.g. add all) and you are done. Unlike other solutions, you can quickly tweak your keyboard without the need to log out and restart apps, which gives faster trial and error turnarounds. Further, if you want to tweak your own configs, Karabiner comes with a secondary app called Karabiner-EventViewer that shows you the names of the keys, modifiers, and apps for the events you are triggering. This is very helpful to get the config right.\n"},{"id":313,"path":"../website/pages/docs/devonfw-ide-advanced.asciidoc.html#advanced-tooling-linux.asciidoc","type":"docs","title":"Linux Tooling","body":"6.4. Linux Tooling\nThere is nothing in this section so far. If you are a Linux user, please share your experience and provide your valuable hints.\n"},{"id":314,"path":"../website/pages/docs/devonfw-ide-advanced.asciidoc.html#lombok.asciidoc","type":"docs","title":"Lombok","body":"6.5. Lombok\nEven though not officially recommended by devon4j some projects want to use lombok in their project.\nAs this requires some tweaks for IDEs we do support you with this guide in case you want to use it.\n"},{"id":315,"path":"../website/pages/docs/devonfw-ide-advanced.asciidoc.html#lombok.asciidoc_lombok-in-eclipse","type":"docs","title":"Lombok in Eclipse","body":"6.5.1. Lombok in Eclipse\nFor eclipse there is a plugin to activate lombok support in eclipse.\nWe have this already preconfigured for you in our default settings. So for manual installation after setup, you can get it via this command:\ndevon eclipse add-plugin lombok\nHowever, to avoid manual extra effort for lombok based projects you only need to activate this plugin in your project specific settings in lombok.properties for eclipse (replace false with true for plugin_active).\n"},{"id":316,"path":"../website/pages/docs/devonfw-ide-advanced.asciidoc.html#lombok.asciidoc_lombok-for-vs-code","type":"docs","title":"Lombok for VS-Code","body":"6.5.2. Lombok for VS-Code\nFor VisualStudio Code there is an extension to activate lombok support in VS-Code.\nWe have this already preconfigured for you in our default settings. So for manual installation after setup, you can get it via this command:\ndevon vscode add-plugin lombok\nHowever, to avoid manual extra effort for lombok based projects you only need to activate this plugin in your project specific settings in lombok.properties for vscode (replace false with true for plugin_active).\n"},{"id":317,"path":"../website/pages/docs/devonfw-ide-advanced.asciidoc.html#lombok.asciidoc_lombok-for-intellij","type":"docs","title":"Lombok for IntelliJ","body":"6.5.3. Lombok for IntelliJ\nFor IntelliJ there is a plugin to activate lombok support in IntelliJ.\nCurrently we have not yet configured or automated this in devonfw-ide.\nPlease contribute to change this. See issues #453 and #491.\n&#x2190;&#xA0;Previous:&#xA0;Usage&#xA0;| &#x2191;&#xA0;Up:&#xA0;devonfw-ide&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Support&#xA0;&#x2192;\n"},{"id":318,"path":"../website/pages/docs/devonfw-ide-introduction.asciidoc.html#devonfw-ide-introduction.asciidoc","type":"docs","title":"Introduction","body":"4. Introduction\ndevonfw provides a solution to building applications which combine best-in-class frameworks and libraries\nas well as industry proven practices and code conventions.\nIt massively speeds up development, reduces risks and helps deliver better results.\nThis document contains the instructions for the tool devonfw-ide to set up and maintain your development tools including your favorite IDE (integrated development environment).\n"},{"id":319,"path":"../website/pages/docs/devonfw-ide-introduction.asciidoc.html#features.asciidoc","type":"docs","title":"Features","body":"4.1. Features\nEvery developer needs great tools to work efficiently. Setting up these tools manually can be tedious and error-prone. Furthermore, some projects may require different versions and configurations of such tools. Especially configurations like code-formatters should be consistent within a project to avoid diff-wars.\nThe devonfw-ide will solve these issues. Here are the features you will find through devonfw-ide:\nEfficient\nSet up your IDE within minutes tailored for the requirements of your project.\nAutomated\nAutomate the setup and update, avoid manual steps and mistakes.\nSimple\nKISS (Keep It Small and Simple), no native installers that globally mess your OS or tool-integrations that break with every release. Instead, use templates and simple shell scripts.\nConfigurable\nYou can change the configuration depending on your needs. Furthermore, the settings contain configuration templates for the different tools (see configurator).\nMaintainable\nFor your project you should copy these settings to an own git repository that can be maintained and updated to manage the tool configurations during the project lifecycle. If you use github or gitlab every developer can easily suggest changes and improvements to these settings via pull/merge requests, which is easier to manage with big teams.\nCustomizable\nDo you need an additional tool you had never heard of before? Put it in the software folder of the structure. The devon CLI will then automatically add it to your PATH variable.\nFurther you can create your own commandlet for your additional tool. For closed-source tools you can create your own archive and distribute it to your team members as long as you care about the terms and licenses of these tools.\nMulti-platform\nIt works on all major platforms: Windows, Mac and Linux.\nMulti-tenancy\nYou can have several instances of the devonfw-ide &quot;installed&quot; on your machine for different projects with different tools, tool versions and configurations. You won&#x2019;t need to set up any physical installation nor changing your operating system. &quot;Installations&quot; of devonfw-ide do not interfere with each other nor with other installed software.\nMultiple Workspaces\nIt supports working with different workspaces on different branches. You can create and update new workspaces with a few clicks. You can see the workspace name in the title-bar of your IDE so you do not get confused and work on the right branch.\nFree\nThe devonfw-ide is free just like everything from devonfw. See LICENSE for details.\n"},{"id":320,"path":"../website/pages/docs/devonfw-ide-introduction.asciidoc.html#features.asciidoc_ides","type":"docs","title":"IDEs","body":"4.1.1. IDEs\nWe support the following IDEs:\nEclipse\nVisual Studio Code\nIntelliJ\n"},{"id":321,"path":"../website/pages/docs/devonfw-ide-introduction.asciidoc.html#features.asciidoc_platforms","type":"docs","title":"Platforms","body":"4.1.2. Platforms\nWe support the following platforms:\njava (see also devon4j)\nC# (see devon4net)\nnode.js, angular and ionic (see devon4ng)\n"},{"id":322,"path":"../website/pages/docs/devonfw-ide-introduction.asciidoc.html#features.asciidoc_build-systems","type":"docs","title":"Build-Systems","body":"4.1.3. Build-Systems\nWe support the following build-systems:\nmvn (maven)\nnpm\ngradle\nHowever, also other IDEs, platforms, or tools can be easily integrated as commandlet.\n"},{"id":323,"path":"../website/pages/docs/devonfw-ide-introduction.asciidoc.html#features.asciidoc_motivation","type":"docs","title":"Motivation","body":"4.1.4. Motivation\nTL;DR? Lets talk to developers a correct language. Here are some examples with devonfw-ide:\n[/]$ devon\nYou are not inside a devonfw-ide installation: /\n[/]$ cd /projects/devonfw\n[devonfw]$ mvn\nzsh: command not found: mvn\n[devonfw]$ devon\ndevonfw-ide environment variables have been set for /projects/devonfw in workspace main\n[devonfw]$ mvn -v\nApache Maven 3.6.0 (97c98ec64a1fdfee7767ce5ffb20918da4f719f3; 2018-10-24T20:41:47+02:00)\nMaven home: /projects/devonfw/software/maven\nJava version: 1.8.0_191, vendor: Oracle Corporation, runtime: /projects/devonfw/software/java\nDefault locale: en_DE, platform encoding: UTF-8\nOS name: &quot;mac os x&quot;, version: &quot;10.14.3&quot;, arch: &quot;x86_64&quot;, family: &quot;mac&quot;\n[devonfw]$ cd /projects/ide-test/workspaces/test/my-project\n[my-project]$ devon\ndevonfw-ide environment variables have been set for /projects/ide-test in workspace main\n[my-project]$ mvn -v\nApache Maven 3.6.0 (97c98ec64a1fdfee7767ce5ffb20918da4f719f3; 2018-10-24T20:41:47+02:00)\nMaven home: /projects/ide-test/software/maven\nJava version: 11.0.2, vendor: Oracle Corporation, runtime: /projects/ide-test/software/jdk/Contents/Home\nDefault locale: en_DE, platform encoding: UTF-8\nOS name: &quot;mac os x&quot;, version: &quot;10.14.3&quot;, arch: &quot;x86_64&quot;, family: &quot;mac&quot;\n[ide-test]$ devon eclipse\nlaunching Eclipse for workspace test...\n[my-project]$ devon build\n[INFO] Scanning for projects...\n...\n[INFO] BUILD SUCCESS\nThis was just a very simple demo of what devonfw-ide can do. For further details have a look at our CLI documentation.\nNow you might ask:\nBut I use Windows/Linux/MacOS//&#x2026; - it works on all platforms!\nBut how about Windows CMD or Power-Shell? - it works!\nBut what if I use cygwin or git-bash on windows? - it works!\nBut I love to use ConEmu or Commander - it works with full integration!\nHow about MacOS Terminal or iTerm2? - it works with full integration!\nBut I use zsh - it works!\n&#x2026;&#x200B;? - it works!\nWow! So let&#x2019;s get started with download &amp; setup.\n"},{"id":324,"path":"../website/pages/docs/devonfw-ide-introduction.asciidoc.html#setup.asciidoc","type":"docs","title":"Setup","body":"4.2. Setup\n"},{"id":325,"path":"../website/pages/docs/devonfw-ide-introduction.asciidoc.html#setup.asciidoc_prerequisites","type":"docs","title":"Prerequisites","body":"4.2.1. Prerequisites\nWe try to make it as simple as possible for you. However, there are some minimal prerequisites:\nYou need to have a tool to extract *.tar.gz files (tar and gzip). On Windows lower Windows 10 (1803) use 7-zip. On all other platforms this comes out of the box.\nYou need to have git and curl installed.\nOn Windows you only need to download and install git for windows. This also ships with bash and curl.\nOn Linux you might need to install the above tools in case they are not present (e.g. sudo apt-get install git curl or sudo yum install git-core curl)\nOn MacOS you only need to download and install git for mac.\n"},{"id":326,"path":"../website/pages/docs/devonfw-ide-introduction.asciidoc.html#setup.asciidoc_download","type":"docs","title":"Download","body":"4.2.2. Download\nThe latest release of devonfw-ide can be downloaded from here (You can find all releases in maven central).\n"},{"id":327,"path":"../website/pages/docs/devonfw-ide-introduction.asciidoc.html#setup.asciidoc_install","type":"docs","title":"Install","body":"4.2.3. Install\nCreate a central folder like C:\\projects or /projects. Inside this folder, create a sub-folder for your new project such as my-project and extract the contents of the downloaded archive (devonfw-ide-scripts-*.tar.gz) to this new folder. Run the command setup in this folder (on windows double clicking on setup.bat).\nThat&#x2019;s all. To get started read the usage.\n"},{"id":328,"path":"../website/pages/docs/devonfw-ide-introduction.asciidoc.html#setup.asciidoc_uninstall","type":"docs","title":"Uninstall","body":"4.2.4. Uninstall\nTo &quot;uninstall&quot; your devonfw-ide you only need to call the following command:\ndevon ide uninstall\nThen you can delete the devonfw-ide top-level folder(s) (${DEVON_IDE_HOME}).\nThe devonfw-ide is designed to be non-invasive to your operating system and computer. Therefore it is not &quot;installed&quot; on your system in a classical way. Instead you just create a folder and extract the downloaded archive to it. You only have to install regularly in advance some specific prerequisites like git. All the other softwares remain locally in your devonfw-ide folder. However, there are the following excuses (what is reverted by devon ide uninstall):\nThe devon command is copied to your home directory (~/.devon/devon)\nThe devon alias is added to your shell config (~/.bashrc and ~/.zshrc, search for alias devon=&quot;source ~/.devon/devon&quot;).\nOn Windows the devon.bat command is copied to your home directory (%USERPROFILE%\\scripts\\devon.bat)\nOn Windows this %USERPROFILE%\\scripts directory is added to the PATH of your user.\nThe devonfw-ide will download a third party software to your ~/Downloads folder to reduce redundant storage.\n&#x2191;&#xA0;Up:&#xA0;devonfw-ide&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Usage&#xA0;&#x2192;\n"},{"id":329,"path":"../website/pages/docs/devonfw-ide-support.asciidoc.html#devonfw-ide-support.asciidoc","type":"docs","title":"Support","body":"7. Support\n"},{"id":330,"path":"../website/pages/docs/devonfw-ide-support.asciidoc.html#migration-from-devonfw-3.0.0-or-lower.asciidoc","type":"docs","title":"Migration from oasp4j-ide","body":"7.1. Migration from oasp4j-ide\nThe devonfw-ide is a completely new and innovative solution for managing the local development environment that has been created from scratch.\nReleases of OASP as well as releases of devonfw until version 3.1.x are based on the old oasp4j-ide that is now considered deprecated. As devonfw-ide is a complete redesign this will have some impact for the users. This section should help and assist so you do not get lost.\n"},{"id":331,"path":"../website/pages/docs/devonfw-ide-support.asciidoc.html#migration-from-devonfw-3.0.0-or-lower.asciidoc_get-familiar-with-devonfw-ide","type":"docs","title":"Get familiar with devonfw-ide","body":"7.1.1. Get familiar with devonfw-ide\nFirst of all you should roughly get familiar with the new devonfw-ide. The key features and changes are:\nplatform-agnostic (supports Windows, Mac, and Linux in a single distribution)\nsmall core (reduced the download package from ~2 gigabyte to ~2 megabyte)\nfast and easy updates (built in update support)\nminimum number of scripts (removed tons of end-user scripts making things much simpler)\nfully automated setup (run setup script and you are ready - even for advanced features that had to be configured manually before)\nsingle command for everything (entire CLI available via new devon command)\nFor all the details you should study the documentation starting from the beginning.\n"},{"id":332,"path":"../website/pages/docs/devonfw-ide-support.asciidoc.html#migration-from-devonfw-3.0.0-or-lower.asciidoc_migration-of-existing-oasp4j-ide-installation","type":"docs","title":"Migration of existing oasp4j-ide installation","body":"7.1.2. Migration of existing oasp4j-ide installation\nextract new devonfw-ide-scripts on top of your existing installation\nrun setup\ndone\nIf you get errors:\nask your technical lead to fix the settings git repo for devonfw-ide or offer him to do it for you.\nyou need to merge the devon folder into your settings\nyou need to merge the devon.properties into your settings\nyou should check your variables[-customized][.bat] and merge required customizations into the proper configuration\n"},{"id":333,"path":"../website/pages/docs/devonfw-ide-support.asciidoc.html#migration-from-devonfw-3.0.0-or-lower.asciidoc_hints-for-users-after-migration","type":"docs","title":"Hints for users after migration","body":"7.1.3. Hints for users after migration\nGetting used to all the new commands might be tedious when starting after a migration.\nTable 25. Comparison of commands\noasp4j-ide command\ndevonfw-ide command\nComment\ncreate-or-update-workspace\ndevon eclipse ws-update\nactually not needed anymore as workspace is updated automatically when IDE is launched. To launch your IDE simply run devon eclipse, devon intellij, or devon vscode. If you like to get launch scripts for your IDE e.g. Eclipse just call devon eclipse --all create-script.\ncreate-or-update-workspace &#xAB;workspace&#xBB;\ncd &#xAB;workspace&#xBB; &amp;&amp; devon eclipse ws-update\nupdate-all-workspaces\ndevon eclipse --all ws-update\ncreate-or-update-workspace-vs\ndevon vscode ws-update\ndevcon workspace create &#xAB;workspace&#xBB;\nSimply create the &#xAB;workspace&#xBB; directory (e.g. cd workspaces &amp;&amp; mkdir examples)\nscripts/update-eclipse-workspace-settings\ndevon eclipse ws-reverse\nTo add new properties (old option --new) use devon eclipse ws-reverse-add\ndevcon project build\ndevcon devon4j build\ndevcon devon4ng build\ndevon build\ndevcon devon4j create\ndevon java create\ndevcon devon4ng create\ndevon ng create\ndevcon system *\ndevcon dist *\nsetup or devon ide setup\nconsole.bat\n-\nSimply open terminal in selected folder. On Windows right-click folder in windows-explorer and select open devonfw CMD here.\ndevcon help\ndevon help\ndevcon doc\nRead the documentation from devonfw.com\n"},{"id":334,"path":"../website/pages/docs/devonfw-ide-support.asciidoc.html#LICENSE.asciidoc","type":"docs","title":"License","body":"7.2. License\nThe product devonfw-ide is licensed under the following terms.\nBinaries of this product have been made available to you by devonfw under the Apache Public License 2.0.\nThe documentation of this product is licensed under the terms of the Creative Commons License (Attribution-NoDerivatives 4.0 International).\nAll of the source code to this product is available under licenses which are both free and open source.\nMore specifically, most of the source code is available under the Apache Public License 2.0. The remainder of the software which is not under the Apache license is available under one of a variety of other free and open source licenses. Those that require reproduction of the license text in the distribution are given below. (Note: your copy of this product may not contain code covered by one or more of the licenses listed here, depending on the exact product and version you choose.)\nThe following table shows the components that may be used. The column inclusion indicates the way the component is included:\ndirectly included means the component is directly contained in the download package of devonfw-ide we provide\ndefault setup means the component is not initially included but will be downloaded during the setup by default\noptional means the component is neither initially included nor downloaded by default, but only gets downloaded and installed if explicitly triggered by you when invoking additional commands or if explicitly configured by your project.\nTable 26. Third party components\nComponent\nInclusion\nLicense\ndevonfw-ide\nDirectly included\nASL 2.0\nJSON-P API\nDirectly included\nEPL 2.0\nJSON-P Implementation\nDirectly included\nEPL 2.0\nOpenJDK / AdoptOpenJDK (Java)\nDefault Setup\nGPLv2\nMaven\nDefault Setup\nASL 2.0\nVS Code\nDefault Setup\nMIT (Terms)\nextension-pack-vscode\nDefault Setup\nASL 2.0\nEclipse\nDefault Setup\nEPL 2.0\nCobiGen\nDefault Setup\nASL 2.0\nTM Terminal\nDefault Setup\nEPL 2.0 (see here)\nAnyEdit\nDefault Setup\nEPL 1.0\nEclipseCS\nDefault Setup\nLGPL 2.1\nSpotBugs Eclipse plugin\nDefault Setup\nLGPL 2.1\nEclEmma\nDefault Setup\nEPL 1.0\nStartExplorer\nDefault Setup\nWTFPL 2\nregex tester\nDefault Setup\nGPL 2.0 (see here)\neclipse-templatevariables\nDefault Setup\nASL 2.0\nNode.js\nDefault Setup\nLicense\nNPM\nDefault Setup\nArtistic License 2.0 (Terms)\nAngular CLI (ng)\nDefault Setup\nMIT\nGroovy\nDefault Setup\nASL 2.0\nApache Ant\nDefault Setup\nASL 2.0\nGradle\nOptional\nASL 2.0\nJenkins\nOptional\nMIT\nSonarQube (CommunityEdition)\nOptional\nLGPL 3.0\nSonarLint\nOptional\nLGPL 3+\ncicdgen\nOptional\nASL 2.0\ndevon4j\nOptional\nASL 2.0\ndevon4ng\nOptional\nASL 2.0\ndevon4node\nOptional\nASL 2.0\n"},{"id":335,"path":"../website/pages/docs/devonfw-ide-support.asciidoc.html#license.asciidoc_apache-software-license---version-2.0","type":"docs","title":"Apache Software License - Version 2.0","body":"7.2.1. Apache Software License - Version 2.0\nApache License\nVersion 2.0, January 2004\nhttp://www.apache.org/licenses/\nTERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n1. Definitions.\n&quot;License&quot; shall mean the terms and conditions for use, reproduction,\nand distribution as defined by Sections 1 through 9 of this document.\n&quot;Licensor&quot; shall mean the copyright owner or entity authorized by\nthe copyright owner that is granting the License.\n&quot;Legal Entity&quot; shall mean the union of the acting entity and all\nother entities that control, are controlled by, or are under common\ncontrol with that entity. For the purposes of this definition,\n&quot;control&quot; means (i) the power, direct or indirect, to cause the\ndirection or management of such entity, whether by contract or\notherwise, or (ii) ownership of fifty percent (50%) or more of the\noutstanding shares, or (iii) beneficial ownership of such entity.\n&quot;You&quot; (or &quot;Your&quot;) shall mean an individual or Legal Entity\nexercising permissions granted by this License.\n&quot;Source&quot; form shall mean the preferred form for making modifications,\nincluding but not limited to software source code, documentation\nsource, and configuration files.\n&quot;Object&quot; form shall mean any form resulting from mechanical\ntransformation or translation of a Source form, including but\nnot limited to compiled object code, generated documentation,\nand conversions to other media types.\n&quot;Work&quot; shall mean the work of authorship, whether in Source or\nObject form, made available under the License, as indicated by a\ncopyright notice that is included in or attached to the work\n(an example is provided in the Appendix below).\n&quot;Derivative Works&quot; shall mean any work, whether in Source or Object\nform, that is based on (or derived from) the Work and for which the\neditorial revisions, annotations, elaborations, or other modifications\nrepresent, as a whole, an original work of authorship. For the purposes\nof this License, Derivative Works shall not include works that remain\nseparable from, or merely link (or bind by name) to the interfaces of,\nthe Work and Derivative Works thereof.\n&quot;Contribution&quot; shall mean any work of authorship, including\nthe original version of the Work and any modifications or additions\nto that Work or Derivative Works thereof, that is intentionally\nsubmitted to Licensor for inclusion in the Work by the copyright owner\nor by an individual or Legal Entity authorized to submit on behalf of\nthe copyright owner. For the purposes of this definition, &quot;submitted&quot;\nmeans any form of electronic, verbal, or written communication sent\nto the Licensor or its representatives, including but not limited to\ncommunication on electronic mailing lists, source code control systems,\nand issue tracking systems that are managed by, or on behalf of, the\nLicensor for the purpose of discussing and improving the Work, but\nexcluding communication that is conspicuously marked or otherwise\ndesignated in writing by the copyright owner as &quot;Not a Contribution.&quot;\n&quot;Contributor&quot; shall mean Licensor and any individual or Legal Entity\non behalf of whom a Contribution has been received by Licensor and\nsubsequently incorporated within the Work.\n2. Grant of Copyright License. Subject to the terms and conditions of\nthis License, each Contributor hereby grants to You a perpetual,\nworldwide, non-exclusive, no-charge, royalty-free, irrevocable\ncopyright license to reproduce, prepare Derivative Works of,\npublicly display, publicly perform, sublicense, and distribute the\nWork and such Derivative Works in Source or Object form.\n3. Grant of Patent License. Subject to the terms and conditions of\nthis License, each Contributor hereby grants to You a perpetual,\nworldwide, non-exclusive, no-charge, royalty-free, irrevocable\n(except as stated in this section) patent license to make, have made,\nuse, offer to sell, sell, import, and otherwise transfer the Work,\nwhere such license applies only to those patent claims licensable\nby such Contributor that are necessarily infringed by their\nContribution(s) alone or by combination of their Contribution(s)\nwith the Work to which such Contribution(s) was submitted. If You\ninstitute patent litigation against any entity (including a\ncross-claim or counterclaim in a lawsuit) alleging that the Work\nor a Contribution incorporated within the Work constitutes direct\nor contributory patent infringement, then any patent licenses\ngranted to You under this License for that Work shall terminate\nas of the date such litigation is filed.\n4. Redistribution. You may reproduce and distribute copies of the\nWork or Derivative Works thereof in any medium, with or without\nmodifications, and in Source or Object form, provided that You\nmeet the following conditions:\n(a) You must give any other recipients of the Work or\nDerivative Works a copy of this License; and\n(b) You must cause any modified files to carry prominent notices\nstating that You changed the files; and\n(c) You must retain, in the Source form of any Derivative Works\nthat You distribute, all copyright, patent, trademark, and\nattribution notices from the Source form of the Work,\nexcluding those notices that do not pertain to any part of\nthe Derivative Works; and\n(d) If the Work includes a &quot;NOTICE&quot; text file as part of its\ndistribution, then any Derivative Works that You distribute must\ninclude a readable copy of the attribution notices contained\nwithin such NOTICE file, excluding those notices that do not\npertain to any part of the Derivative Works, in at least one\nof the following places: within a NOTICE text file distributed\nas part of the Derivative Works; within the Source form or\ndocumentation, if provided along with the Derivative Works; or,\nwithin a display generated by the Derivative Works, if and\nwherever such third-party notices normally appear. The contents\nof the NOTICE file are for informational purposes only and\ndo not modify the License. You may add Your own attribution\nnotices within Derivative Works that You distribute, alongside\nor as an addendum to the NOTICE text from the Work, provided\nthat such additional attribution notices cannot be construed\nas modifying the License.\nYou may add Your own copyright statement to Your modifications and\nmay provide additional or different license terms and conditions\nfor use, reproduction, or distribution of Your modifications, or\nfor any such Derivative Works as a whole, provided Your use,\nreproduction, and distribution of the Work otherwise complies with\nthe conditions stated in this License.\n5. Submission of Contributions. Unless You explicitly state otherwise,\nany Contribution intentionally submitted for inclusion in the Work\nby You to the Licensor shall be under the terms and conditions of\nthis License, without any additional terms or conditions.\nNotwithstanding the above, nothing herein shall supersede or modify\nthe terms of any separate license agreement you may have executed\nwith Licensor regarding such Contributions.\n6. Trademarks. This License does not grant permission to use the trade\nnames, trademarks, service marks, or product names of the Licensor,\nexcept as required for reasonable and customary use in describing the\norigin of the Work and reproducing the content of the NOTICE file.\n7. Disclaimer of Warranty. Unless required by applicable law or\nagreed to in writing, Licensor provides the Work (and each\nContributor provides its Contributions) on an &quot;AS IS&quot; BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\nimplied, including, without limitation, any warranties or conditions\nof TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\nPARTICULAR PURPOSE. You are solely responsible for determining the\nappropriateness of using or redistributing the Work and assume any\nrisks associated with Your exercise of permissions under this License.\n8. Limitation of Liability. In no event and under no legal theory,\nwhether in tort (including negligence), contract, or otherwise,\nunless required by applicable law (such as deliberate and grossly\nnegligent acts) or agreed to in writing, shall any Contributor be\nliable to You for damages, including any direct, indirect, special,\nincidental, or consequential damages of any character arising as a\nresult of this License or out of the use or inability to use the\nWork (including but not limited to damages for loss of goodwill,\nwork stoppage, computer failure or malfunction, or any and all\nother commercial damages or losses), even if such Contributor\nhas been advised of the possibility of such damages.\n9. Accepting Warranty or Additional Liability. While redistributing\nthe Work or Derivative Works thereof, You may choose to offer,\nand charge a fee for, acceptance of support, warranty, indemnity,\nor other liability obligations and/or rights consistent with this\nLicense. However, in accepting such obligations, You may act only\non Your own behalf and on Your sole responsibility, not on behalf\nof any other Contributor, and only if You agree to indemnify,\ndefend, and hold each Contributor harmless for any liability\nincurred by, or claims asserted against, such Contributor by reason\nof your accepting any such warranty or additional liability.\nEND OF TERMS AND CONDITIONS\nAPPENDIX: How to apply the Apache License to your work.\nTo apply the Apache License to your work, attach the following\nboilerplate notice, with the fields enclosed by brackets &quot;[]&quot;\nreplaced with your own identifying information. (Don&apos;t include\nthe brackets!) The text should be enclosed in the appropriate\ncomment syntax for the file format. We also recommend that a\nfile or class name and description of purpose be included on the\nsame &quot;printed page&quot; as the copyright notice for easier\nidentification within third-party archives.\nCopyright [yyyy] [name of copyright owner]\nLicensed under the Apache License, Version 2.0 (the &quot;License&quot;);\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\nhttp://www.apache.org/licenses/LICENSE-2.0\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an &quot;AS IS&quot; BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n"},{"id":336,"path":"../website/pages/docs/devonfw-ide-support.asciidoc.html#license.asciidoc_eclipse-public-license---version-1.0","type":"docs","title":"Eclipse Public License - Version 1.0","body":"7.2.2. Eclipse Public License - Version 1.0\nTHE ACCOMPANYING PROGRAM IS PROVIDED UNDER THE TERMS OF THIS ECLIPSE PUBLIC LICENSE (&quot;AGREEMENT&quot;). ANY USE, REPRODUCTION OR DISTRIBUTION OF THE PROGRAM CONSTITUTES RECIPIENT&apos;S ACCEPTANCE OF THIS AGREEMENT.\n1. DEFINITIONS\n&quot;Contribution&quot; means:\na) in the case of the initial Contributor, the initial code and documentation distributed under this Agreement, and\nb) in the case of each subsequent Contributor:\ni) changes to the Program, and\nii) additions to the Program;\nwhere such changes and/or additions to the Program originate from and are distributed by that particular Contributor. A Contribution &apos;originates&apos; from a Contributor if it was added to the Program by such Contributor itself or anyone acting on such Contributor&apos;s behalf. Contributions do not include additions to the Program which: (i) are separate modules of software distributed in conjunction with the Program under their own license agreement, and (ii) are not derivative works of the Program.\n&quot;Contributor&quot; means any person or entity that distributes the Program.\n&quot;Licensed Patents&quot; mean patent claims licensable by a Contributor which are necessarily infringed by the use or sale of its Contribution alone or when combined with the Program.\n&quot;Program&quot; means the Contributions distributed in accordance with this Agreement.\n&quot;Recipient&quot; means anyone who receives the Program under this Agreement, including all Contributors.\n2. GRANT OF RIGHTS\na) Subject to the terms of this Agreement, each Contributor hereby grants Recipient a non-exclusive, worldwide, royalty-free copyright license to reproduce, prepare derivative works of, publicly display, publicly perform, distribute and sublicense the Contribution of such Contributor, if any, and such derivative works, in source code and object code form.\nb) Subject to the terms of this Agreement, each Contributor hereby grants Recipient a non-exclusive, worldwide, royalty-free patent license under Licensed Patents to make, use, sell, offer to sell, import and otherwise transfer the Contribution of such Contributor, if any, in source code and object code form. This patent license shall apply to the combination of the Contribution and the Program if, at the time the Contribution is added by the Contributor, such addition of the Contribution causes such combination to be covered by the Licensed Patents. The patent license shall not apply to any other combinations which include the Contribution. No hardware per se is licensed hereunder.\nc) Recipient understands that although each Contributor grants the licenses to its Contributions set forth herein, no assurances are provided by any Contributor that the Program does not infringe the patent or other intellectual property rights of any other entity. Each Contributor disclaims any liability to Recipient for claims brought by any other entity based on infringement of intellectual property rights or otherwise. As a condition to exercising the rights and licenses granted hereunder, each Recipient hereby assumes sole responsibility to secure any other intellectual property rights needed, if any. For example, if a third party patent license is required to allow Recipient to distribute the Program, it is Recipient&apos;s responsibility to acquire that license before distributing the Program.\nd) Each Contributor represents that to its knowledge it has sufficient copyright rights in its Contribution, if any, to grant the copyright license set forth in this Agreement.\n3. REQUIREMENTS\nA Contributor may choose to distribute the Program in object code form under its own license agreement, provided that:\na) it complies with the terms and conditions of this Agreement; and\nb) its license agreement:\ni) effectively disclaims on behalf of all Contributors all warranties and conditions, express and implied, including warranties or conditions of title and non-infringement, and implied warranties or conditions of merchantability and fitness for a particular purpose;\nii) effectively excludes on behalf of all Contributors all liability for damages, including direct, indirect, special, incidental and consequential damages, such as lost profits;\niii) states that any provisions which differ from this Agreement are offered by that Contributor alone and not by any other party; and\niv) states that source code for the Program is available from such Contributor, and informs licensees how to obtain it in a reasonable manner on or through a medium customarily used for software exchange.\nWhen the Program is made available in source code form:\na) it must be made available under this Agreement; and\nb) a copy of this Agreement must be included with each copy of the Program.\nContributors may not remove or alter any copyright notices contained within the Program.\nEach Contributor must identify itself as the originator of its Contribution, if any, in a manner that reasonably allows subsequent Recipients to identify the originator of the Contribution.\n4. COMMERCIAL DISTRIBUTION\nCommercial distributors of software may accept certain responsibilities with respect to end users, business partners and the like. While this license is intended to facilitate the commercial use of the Program, the Contributor who includes the Program in a commercial product offering should do so in a manner which does not create potential liability for other Contributors. Therefore, if a Contributor includes the Program in a commercial product offering, such Contributor (&quot;Commercial Contributor&quot;) hereby agrees to defend and indemnify every other Contributor (&quot;Indemnified Contributor&quot;) against any losses, damages and costs (collectively &quot;Losses&quot;) arising from claims, lawsuits and other legal actions brought by a third party against the Indemnified Contributor to the extent caused by the acts or omissions of such Commercial Contributor in connection with its distribution of the Program in a commercial product offering. The obligations in this section do not apply to any claims or Losses relating to any actual or alleged intellectual property infringement. In order to qualify, an Indemnified Contributor must: a) promptly notify the Commercial Contributor in writing of such claim, and b) allow the Commercial Contributor to control, and cooperate with the Commercial Contributor in, the defense and any related settlement negotiations. The Indemnified Contributor may participate in any such claim at its own expense.\nFor example, a Contributor might include the Program in a commercial product offering, Product X. That Contributor is then a Commercial Contributor. If that Commercial Contributor then makes performance claims, or offers warranties related to Product X, those performance claims and warranties are such Commercial Contributor&apos;s responsibility alone. Under this section, the Commercial Contributor would have to defend claims against the other Contributors related to those performance claims and warranties, and if a court requires any other Contributor to pay any damages as a result, the Commercial Contributor must pay those damages.\n5. NO WARRANTY\nEXCEPT AS EXPRESSLY SET FORTH IN THIS AGREEMENT, THE PROGRAM IS PROVIDED ON AN &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, EITHER EXPRESS OR IMPLIED INCLUDING, WITHOUT LIMITATION, ANY WARRANTIES OR CONDITIONS OF TITLE, NON-INFRINGEMENT, MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE. Each Recipient is solely responsible for determining the appropriateness of using and distributing the Program and assumes all risks associated with its exercise of rights under this Agreement , including but not limited to the risks and costs of program errors, compliance with applicable laws, damage to or loss of data, programs or equipment, and unavailability or interruption of operations.\n6. DISCLAIMER OF LIABILITY\nEXCEPT AS EXPRESSLY SET FORTH IN THIS AGREEMENT, NEITHER RECIPIENT NOR ANY CONTRIBUTORS SHALL HAVE ANY LIABILITY FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING WITHOUT LIMITATION LOST PROFITS), HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OR DISTRIBUTION OF THE PROGRAM OR THE EXERCISE OF ANY RIGHTS GRANTED HEREUNDER, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGES.\n7. GENERAL\nIf any provision of this Agreement is invalid or unenforceable under applicable law, it shall not affect the validity or enforceability of the remainder of the terms of this Agreement, and without further action by the parties hereto, such provision shall be reformed to the minimum extent necessary to make such provision valid and enforceable.\nIf Recipient institutes patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Program itself (excluding combinations of the Program with other software or hardware) infringes such Recipient&apos;s patent(s), then such Recipient&apos;s rights granted under Section 2(b) shall terminate as of the date such litigation is filed.\nAll Recipient&apos;s rights under this Agreement shall terminate if it fails to comply with any of the material terms or conditions of this Agreement and does not cure such failure in a reasonable period of time after becoming aware of such noncompliance. If all Recipient&apos;s rights under this Agreement terminate, Recipient agrees to cease use and distribution of the Program as soon as reasonably practicable. However, Recipient&apos;s obligations under this Agreement and any licenses granted by Recipient relating to the Program shall continue and survive.\nEveryone is permitted to copy and distribute copies of this Agreement, but in order to avoid inconsistency the Agreement is copyrighted and may only be modified in the following manner. The Agreement Steward reserves the right to publish new versions (including revisions) of this Agreement from time to time. No one other than the Agreement Steward has the right to modify this Agreement. The Eclipse Foundation is the initial Agreement Steward. The Eclipse Foundation may assign the responsibility to serve as the Agreement Steward to a suitable separate entity. Each new version of the Agreement will be given a distinguishing version number. The Program (including Contributions) may always be distributed subject to the version of the Agreement under which it was received. In addition, after a new version of the Agreement is published, Contributor may elect to distribute the Program (including its Contributions) under the new version. Except as expressly stated in Sections 2(a) and 2(b) above, Recipient receives no rights or licenses to the intellectual property of any Contributor under this Agreement, whether expressly, by implication, estoppel or otherwise. All rights in the Program not expressly granted under this Agreement are reserved.\nThis Agreement is governed by the laws of the State of New York and the intellectual property laws of the United States of America. No party to this Agreement will bring a legal action under this Agreement more than one year after the cause of action arose. Each party waives its rights to a jury trial in any resulting litigation.\n"},{"id":337,"path":"../website/pages/docs/devonfw-ide-support.asciidoc.html#license.asciidoc_eclipse-public-license---version-2.0","type":"docs","title":"Eclipse Public License - Version 2.0","body":"7.2.3. Eclipse Public License - Version 2.0\nTHE ACCOMPANYING PROGRAM IS PROVIDED UNDER THE TERMS OF THIS ECLIPSE PUBLIC LICENSE (&#x201C;AGREEMENT&#x201D;). ANY USE, REPRODUCTION OR DISTRIBUTION OF THE PROGRAM CONSTITUTES RECIPIENT&apos;S ACCEPTANCE OF THIS AGREEMENT.\n1. DEFINITIONS\n&#x201C;Contribution&#x201D; means:\na) in the case of the initial Contributor, the initial content Distributed under this Agreement, and\nb) in the case of each subsequent Contributor:\ni) changes to the Program, and\nii) additions to the Program;\nwhere such changes and/or additions to the Program originate from and are Distributed by that particular Contributor. A Contribution &#x201C;originates&#x201D; from a Contributor if it was added to the Program by such Contributor itself or anyone acting on such Contributor&apos;s behalf. Contributions do not include changes or additions to the Program that are not Modified Works.\n&#x201C;Contributor&#x201D; means any person or entity that Distributes the Program.\n&#x201C;Licensed Patents&#x201D; mean patent claims licensable by a Contributor which are necessarily infringed by the use or sale of its Contribution alone or when combined with the Program.\n&#x201C;Program&#x201D; means the Contributions Distributed in accordance with this Agreement.\n&#x201C;Recipient&#x201D; means anyone who receives the Program under this Agreement or any Secondary License (as applicable), including Contributors.\n&#x201C;Derivative Works&#x201D; shall mean any work, whether in Source Code or other form, that is based on (or derived from) the Program and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship.\n&#x201C;Modified Works&#x201D; shall mean any work in Source Code or other form that results from an addition to, deletion from, or modification of the contents of the Program, including, for purposes of clarity any new file in Source Code form that contains any contents of the Program. Modified Works shall not include works that contain only declarations, interfaces, types, classes, structures, or files of the Program solely in each case in order to link to, bind by name, or subclass the Program or Modified Works thereof.\n&#x201C;Distribute&#x201D; means the acts of a) distributing or b) making available in any manner that enables the transfer of a copy.\n&#x201C;Source Code&#x201D; means the form of a Program preferred for making modifications, including but not limited to software source code, documentation source, and configuration files.\n&#x201C;Secondary License&#x201D; means either the GNU General Public License, Version 2.0, or any later versions of that license, including any exceptions or additional permissions as identified by the initial Contributor.\n2. GRANT OF RIGHTS\na) Subject to the terms of this Agreement, each Contributor hereby grants Recipient a non-exclusive, worldwide, royalty-free copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, Distribute and sublicense the Contribution of such Contributor, if any, and such Derivative Works.\nb) Subject to the terms of this Agreement, each Contributor hereby grants Recipient a non-exclusive, worldwide, royalty-free patent license under Licensed Patents to make, use, sell, offer to sell, import and otherwise transfer the Contribution of such Contributor, if any, in Source Code or other form. This patent license shall apply to the combination of the Contribution and the Program if, at the time the Contribution is added by the Contributor, such addition of the Contribution causes such combination to be covered by the Licensed Patents. The patent license shall not apply to any other combinations which include the Contribution. No hardware per se is licensed hereunder.\nc) Recipient understands that although each Contributor grants the licenses to its Contributions set forth herein, no assurances are provided by any Contributor that the Program does not infringe the patent or other intellectual property rights of any other entity. Each Contributor disclaims any liability to Recipient for claims brought by any other entity based on infringement of intellectual property rights or otherwise. As a condition to exercising the rights and licenses granted hereunder, each Recipient hereby assumes sole responsibility to secure any other intellectual property rights needed, if any. For example, if a third party patent license is required to allow Recipient to Distribute the Program, it is Recipient&apos;s responsibility to acquire that license before distributing the Program.\nd) Each Contributor represents that to its knowledge it has sufficient copyright rights in its Contribution, if any, to grant the copyright license set forth in this Agreement.\ne) Notwithstanding the terms of any Secondary License, no Contributor makes additional grants to any Recipient (other than those set forth in this Agreement) as a result of such Recipient&apos;s receipt of the Program under the terms of a Secondary License (if permitted under the terms of Section 3).\n3. REQUIREMENTS\n3.1 If a Contributor Distributes the Program in any form, then:\na) the Program must also be made available as Source Code, in accordance with section 3.2, and the Contributor must accompany the Program with a statement that the Source Code for the Program is available under this Agreement, and informs Recipients how to obtain it in a reasonable manner on or through a medium customarily used for software exchange; and\nb) the Contributor may Distribute the Program under a license different than this Agreement, provided that such license:\ni) effectively disclaims on behalf of all other Contributors all warranties and conditions, express and implied, including warranties or conditions of title and non-infringement, and implied warranties or conditions of merchantability and fitness for a particular purpose;\nii) effectively excludes on behalf of all other Contributors all liability for damages, including direct, indirect, special, incidental and consequential damages, such as lost profits;\niii) does not attempt to limit or alter the recipients&apos; rights in the Source Code under section 3.2; and\niv) requires any subsequent distribution of the Program by any party to be under a license that satisfies the requirements of this section 3.\n3.2 When the Program is Distributed as Source Code:\na) it must be made available under this Agreement, or if the Program (i) is combined with other material in a separate file or files made available under a Secondary License, and (ii) the initial Contributor attached to the Source Code the notice described in Exhibit A of this Agreement, then the Program may be made available under the terms of such Secondary Licenses, and\nb) a copy of this Agreement must be included with each copy of the Program.\n3.3 Contributors may not remove or alter any copyright, patent, trademark, attribution notices, disclaimers of warranty, or limitations of liability (&#x2018;notices&#x2019;) contained within the Program from any copy of the Program which they Distribute, provided that Contributors may add their own appropriate notices.\n4. COMMERCIAL DISTRIBUTION\nCommercial distributors of software may accept certain responsibilities with respect to end users, business partners and the like. While this license is intended to facilitate the commercial use of the Program, the Contributor who includes the Program in a commercial product offering should do so in a manner which does not create potential liability for other Contributors. Therefore, if a Contributor includes the Program in a commercial product offering, such Contributor (&#x201C;Commercial Contributor&#x201D;) hereby agrees to defend and indemnify every other Contributor (&#x201C;Indemnified Contributor&#x201D;) against any losses, damages and costs (collectively &#x201C;Losses&#x201D;) arising from claims, lawsuits and other legal actions brought by a third party against the Indemnified Contributor to the extent caused by the acts or omissions of such Commercial Contributor in connection with its distribution of the Program in a commercial product offering. The obligations in this section do not apply to any claims or Losses relating to any actual or alleged intellectual property infringement. In order to qualify, an Indemnified Contributor must: a) promptly notify the Commercial Contributor in writing of such claim, and b) allow the Commercial Contributor to control, and cooperate with the Commercial Contributor in, the defense and any related settlement negotiations. The Indemnified Contributor may participate in any such claim at its own expense.\nFor example, a Contributor might include the Program in a commercial product offering, Product X. That Contributor is then a Commercial Contributor. If that Commercial Contributor then makes performance claims, or offers warranties related to Product X, those performance claims and warranties are such Commercial Contributor&apos;s responsibility alone. Under this section, the Commercial Contributor would have to defend claims against the other Contributors related to those performance claims and warranties, and if a court requires any other Contributor to pay any damages as a result, the Commercial Contributor must pay those damages.\n5. NO WARRANTY\nEXCEPT AS EXPRESSLY SET FORTH IN THIS AGREEMENT, AND TO THE EXTENT PERMITTED BY APPLICABLE LAW, THE PROGRAM IS PROVIDED ON AN &#x201C;AS IS&#x201D; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, EITHER EXPRESS OR IMPLIED INCLUDING, WITHOUT LIMITATION, ANY WARRANTIES OR CONDITIONS OF TITLE, NON-INFRINGEMENT, MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE. Each Recipient is solely responsible for determining the appropriateness of using and distributing the Program and assumes all risks associated with its exercise of rights under this Agreement, including but not limited to the risks and costs of program errors, compliance with applicable laws, damage to or loss of data, programs or equipment, and unavailability or interruption of operations.\n6. DISCLAIMER OF LIABILITY\nEXCEPT AS EXPRESSLY SET FORTH IN THIS AGREEMENT, AND TO THE EXTENT PERMITTED BY APPLICABLE LAW, NEITHER RECIPIENT NOR ANY CONTRIBUTORS SHALL HAVE ANY LIABILITY FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING WITHOUT LIMITATION LOST PROFITS), HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OR DISTRIBUTION OF THE PROGRAM OR THE EXERCISE OF ANY RIGHTS GRANTED HEREUNDER, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGES.\n7. GENERAL\nIf any provision of this Agreement is invalid or unenforceable under applicable law, it shall not affect the validity or enforceability of the remainder of the terms of this Agreement, and without further action by the parties hereto, such provision shall be reformed to the minimum extent necessary to make such provision valid and enforceable.\nIf Recipient institutes patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Program itself (excluding combinations of the Program with other software or hardware) infringes such Recipient&apos;s patent(s), then such Recipient&apos;s rights granted under Section 2(b) shall terminate as of the date such litigation is filed.\nAll Recipient&apos;s rights under this Agreement shall terminate if it fails to comply with any of the material terms or conditions of this Agreement and does not cure such failure in a reasonable period of time after becoming aware of such noncompliance. If all Recipient&apos;s rights under this Agreement terminate, Recipient agrees to cease use and distribution of the Program as soon as reasonably practicable. However, Recipient&apos;s obligations under this Agreement and any licenses granted by Recipient relating to the Program shall continue and survive.\nEveryone is permitted to copy and distribute copies of this Agreement, but in order to avoid inconsistency the Agreement is copyrighted and may only be modified in the following manner. The Agreement Steward reserves the right to publish new versions (including revisions) of this Agreement from time to time. No one other than the Agreement Steward has the right to modify this Agreement. The Eclipse Foundation is the initial Agreement Steward. The Eclipse Foundation may assign the responsibility to serve as the Agreement Steward to a suitable separate entity. Each new version of the Agreement will be given a distinguishing version number. The Program (including Contributions) may always be Distributed subject to the version of the Agreement under which it was received. In addition, after a new version of the Agreement is published, Contributor may elect to Distribute the Program (including its Contributions) under the new version.\nExcept as expressly stated in Sections 2(a) and 2(b) above, Recipient receives no rights or licenses to the intellectual property of any Contributor under this Agreement, whether expressly, by implication, estoppel or otherwise. All rights in the Program not expressly granted under this Agreement are reserved. Nothing in this Agreement is intended to be enforceable by any entity that is not a Contributor or Recipient. No third-party beneficiary rights are created under this Agreement.\nExhibit A &#x2013; Form of Secondary Licenses Notice\n&#x201C;This Source Code may also be made available under the following Secondary Licenses when the conditions for such availability set forth in the Eclipse Public License, v. 2.0 are satisfied: {name license(s), version(s), and exceptions or additional permissions here}.&#x201D;\nSimply including a copy of this Agreement, including this Exhibit A is not sufficient to license the Source Code under Secondary Licenses.\nIf it is not possible or desirable to put the notice in a particular file, then You may include the notice in a location (such as a LICENSE file in a relevant directory) where a recipient would be likely to look for such a notice.\nYou may add additional accurate notices of copyright ownership.\n"},{"id":338,"path":"../website/pages/docs/devonfw-ide-support.asciidoc.html#license.asciidoc_mit-license","type":"docs","title":"MIT License","body":"7.2.4. MIT License\nCopyright &lt;YEAR&gt; &lt;COPYRIGHT HOLDER&gt;\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the &quot;Software&quot;), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED &quot;AS IS&quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n"},{"id":339,"path":"../website/pages/docs/devonfw-ide-support.asciidoc.html#license.asciidoc_artistic-license---version-2.0","type":"docs","title":"Artistic License - Version 2.0","body":"7.2.5. Artistic License - Version 2.0\nCopyright (c) 2000-2006, The Perl Foundation.\nEveryone is permitted to copy and distribute verbatim copies of this license document, but changing it is not allowed.\nPreamble\nThis license establishes the terms under which a given free software Package may be copied, modified, distributed, and/or redistributed. The intent is that the Copyright Holder maintains some artistic control over the development of that Package while still keeping the Package available as open source and free software.\nYou are always permitted to make arrangements wholly outside of this license directly with the Copyright Holder of a given Package. If the terms of this license do not permit the full use that you propose to make of the Package, you should contact the Copyright Holder and seek a different licensing arrangement.\nDefinitions\n&quot;Copyright Holder&quot; means the individual(s) or organization(s) named in the copyright notice for the entire Package.\n&quot;Contributor&quot; means any party that has contributed code or other material to the Package, in accordance with the Copyright Holder&apos;s procedures.\n&quot;You&quot; and &quot;your&quot; means any person who would like to copy, distribute, or modify the Package.\n&quot;Package&quot; means the collection of files distributed by the Copyright Holder, and derivatives of that collection and/or of those files. A given Package may consist of either the Standard Version, or a Modified Version.\n&quot;Distribute&quot; means providing a copy of the Package or making it accessible to anyone else, or in the case of a company or organization, to others outside of your company or organization.\n&quot;Distributor Fee&quot; means any fee that you charge for Distributing this Package or providing support for this Package to another party. It does not mean licensing fees.\n&quot;Standard Version&quot; refers to the Package if it has not been modified, or has been modified only in ways explicitly requested by the Copyright Holder.\n&quot;Modified Version&quot; means the Package, if it has been changed, and such changes were not explicitly requested by the Copyright Holder.\n&quot;Original License&quot; means this Artistic License as Distributed with the Standard Version of the Package, in its current version or as it may be modified by The Perl Foundation in the future.\n&quot;Source&quot; form means the source code, documentation source, and configuration files for the Package.\n&quot;Compiled&quot; form means the compiled bytecode, object code, binary, or any other form resulting from mechanical transformation or translation of the Source form.\nPermission for Use and Modification Without Distribution\n(1) You are permitted to use the Standard Version and create and use Modified Versions for any purpose without restriction, provided that you do not Distribute the Modified Version.\nPermissions for Redistribution of the Standard Version\n(2) You may Distribute verbatim copies of the Source form of the Standard Version of this Package in any medium without restriction, either gratis or for a Distributor Fee, provided that you duplicate all of the original copyright notices and associated disclaimers. At your discretion, such verbatim copies may or may not include a Compiled form of the Package.\n(3) You may apply any bug fixes, portability changes, and other modifications made available from the Copyright Holder. The resulting Package will still be considered the Standard Version, and as such will be subject to the Original License.\nDistribution of Modified Versions of the Package as Source\n(4) You may Distribute your Modified Version as Source (either gratis or for a Distributor Fee, and with or without a Compiled form of the Modified Version) provided that you clearly document how it differs from the Standard Version, including, but not limited to, documenting any non-standard features, executables, or modules, and provided that you do at least ONE of the following:\n(a) make the Modified Version available to the Copyright Holder of the Standard Version, under the Original License, so that the Copyright Holder may include your modifications in the Standard Version.\n(b) ensure that installation of your Modified Version does not prevent the user installing or running the Standard Version. In addition, the Modified Version must bear a name that is different from the name of the Standard Version.\n(c) allow anyone who receives a copy of the Modified Version to make the Source form of the Modified Version available to others under\n(i) the Original License or\n(ii) a license that permits the licensee to freely copy, modify and redistribute the Modified Version using the same licensing terms that apply to the copy that the licensee received, and requires that the Source form of the Modified Version, and of any works derived from it, be made freely available in that license fees are prohibited but Distributor Fees are allowed.\nDistribution of Compiled Forms of the Standard Version or Modified Versions without the Source\n(5) You may Distribute Compiled forms of the Standard Version without the Source, provided that you include complete instructions on how to get the Source of the Standard Version. Such instructions must be valid at the time of your distribution. If these instructions, at any time while you are carrying out such distribution, become invalid, you must provide new instructions on demand or cease further distribution. If you provide valid instructions or cease distribution within thirty days after you become aware that the instructions are invalid, then you do not forfeit any of your rights under this license.\n(6) You may Distribute a Modified Version in Compiled form without the Source, provided that you comply with Section 4 with respect to the Source of the Modified Version.\nAggregating or Linking the Package\n(7) You may aggregate the Package (either the Standard Version or Modified Version) with other packages and Distribute the resulting aggregation provided that you do not charge a licensing fee for the Package. Distributor Fees are permitted, and licensing fees for other components in the aggregation are permitted. The terms of this license apply to the use and Distribution of the Standard or Modified Versions as included in the aggregation.\n(8) You are permitted to link Modified and Standard Versions with other works, to embed the Package in a larger work of your own, or to build stand-alone binary or bytecode versions of applications that include the Package, and Distribute the result without restriction, provided the result does not expose a direct interface to the Package.\nItems That are Not Considered Part of a Modified Version\n(9) Works (including, but not limited to, modules and scripts) that merely extend or make use of the Package, do not, by themselves, cause the Package to be a Modified Version. In addition, such works are not considered parts of the Package itself, and are not subject to the terms of this license.\nGeneral Provisions\n(10) Any use, modification, and distribution of the Standard or Modified Versions is governed by this Artistic License. By using, modifying or distributing the Package, you accept this license. Do not use, modify, or distribute the Package, if you do not accept this license.\n(11) If your Modified Version has been derived from a Modified Version made by someone other than you, you are nevertheless required to ensure that your Modified Version complies with the requirements of this license.\n(12) This license does not grant you the right to use any trademark, service mark, tradename, or logo of the Copyright Holder.\n(13) This license includes the non-exclusive, worldwide, free-of-charge patent license to make, have made, use, offer to sell, sell, import and otherwise transfer the Package with respect to any patent claims licensable by the Copyright Holder that are necessarily infringed by the Package. If you institute patent litigation (including a cross-claim or counterclaim) against any party alleging that the Package constitutes direct or contributory patent infringement, then this Artistic License to you shall terminate on the date that such litigation is filed.\n(14) Disclaimer of Warranty: THE PACKAGE IS PROVIDED BY THE COPYRIGHT HOLDER AND CONTRIBUTORS &quot;AS IS&apos; AND WITHOUT ANY EXPRESS OR IMPLIED WARRANTIES. THE IMPLIED WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, OR NON-INFRINGEMENT ARE DISCLAIMED TO THE EXTENT PERMITTED BY YOUR LOCAL LAW. UNLESS REQUIRED BY LAW, NO COPYRIGHT HOLDER OR CONTRIBUTOR WILL BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES ARISING IN ANY WAY OUT OF THE USE OF THE PACKAGE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n"},{"id":340,"path":"../website/pages/docs/devonfw-ide-support.asciidoc.html#license.asciidoc_creative-commons-license---attribution-noderivatives-4.0-international","type":"docs","title":"Creative Commons License - Attribution-NoDerivatives 4.0 International","body":"7.2.6. Creative Commons License - Attribution-NoDerivatives 4.0 International\nBy exercising the Licensed Rights (defined below), You accept and agree to be bound by the terms and conditions of this Creative Commons Attribution-NoDerivatives 4.0 International Public License (&quot;Public License&quot;). To the extent this Public License may be interpreted as a contract, You are granted the Licensed Rights in consideration of Your acceptance of these terms and conditions, and the Licensor grants You such rights in consideration of benefits the Licensor receives from making the Licensed Material available under these terms and conditions.\nSection 1 &#x2013; Definitions.\nAdapted Material means material subject to Copyright and Similar Rights that is derived from or based upon the Licensed Material and in which the Licensed Material is translated, altered, arranged, transformed, or otherwise modified in a manner requiring permission under the Copyright and Similar Rights held by the Licensor. For purposes of this Public License, where the Licensed Material is a musical work, performance, or sound recording, Adapted Material is always produced where the Licensed Material is synched in timed relation with a moving image.\nCopyright and Similar Rights means copyright and/or similar rights closely related to copyright including, without limitation, performance, broadcast, sound recording, and Sui Generis Database Rights, without regard to how the rights are labeled or categorized. For purposes of this Public License, the rights specified in Section 2(b)(1)-(2) are not Copyright and Similar Rights.\nEffective Technological Measures means those measures that, in the absence of proper authority, may not be circumvented under laws fulfilling obligations under Article 11 of the WIPO Copyright Treaty adopted on December 20, 1996, and/or similar international agreements.\nExceptions and Limitations means fair use, fair dealing, and/or any other exception or limitation to Copyright and Similar Rights that applies to Your use of the Licensed Material.\nLicensed Material means the artistic or literary work, database, or other material to which the Licensor applied this Public License.\nLicensed Rights means the rights granted to You subject to the terms and conditions of this Public License, which are limited to all Copyright and Similar Rights that apply to Your use of the Licensed Material and that the Licensor has authority to license.\nLicensor means the individual(s) or entity(ies) granting rights under this Public License.\nShare means to provide material to the public by any means or process that requires permission under the Licensed Rights, such as reproduction, public display, public performance, distribution, dissemination, communication, or importation, and to make material available to the public including in ways that members of the public may access the material from a place and at a time individually chosen by them.\nSui Generis Database Rights means rights other than copyright resulting from Directive 96/9/EC of the European Parliament and of the Council of 11 March 1996 on the legal protection of databases, as amended and/or succeeded, as well as other essentially equivalent rights anywhere in the world.\nYou means the individual or entity exercising the Licensed Rights under this Public License. Your has a corresponding meaning.\nSection 2 &#x2013; Scope.\nLicense grant.\nSubject to the terms and conditions of this Public License, the Licensor hereby grants You a worldwide, royalty-free, non-sublicensable, non-exclusive, irrevocable license to exercise the Licensed Rights in the Licensed Material to:\nreproduce and Share the Licensed Material, in whole or in part; and\nproduce and reproduce, but not Share, Adapted Material.\nExceptions and Limitations. For the avoidance of doubt, where Exceptions and Limitations apply to Your use, this Public License does not apply, and You do not need to comply with its terms and conditions.\nTerm. The term of this Public License is specified in Section 6(a).\nMedia and formats; technical modifications allowed. The Licensor authorizes You to exercise the Licensed Rights in all media and formats whether now known or hereafter created, and to make technical modifications necessary to do so. The Licensor waives and/or agrees not to assert any right or authority to forbid You from making technical modifications necessary to exercise the Licensed Rights, including technical modifications necessary to circumvent Effective Technological Measures. For purposes of this Public License, simply making modifications authorized by this Section 2(a)(4) never produces Adapted Material.\nDownstream recipients.\nOffer from the Licensor &#x2013; Licensed Material. Every recipient of the Licensed Material automatically receives an offer from the Licensor to exercise the Licensed Rights under the terms and conditions of this Public License.\nNo downstream restrictions. You may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, the Licensed Material if doing so restricts exercise of the Licensed Rights by any recipient of the Licensed Material.\nNo endorsement. Nothing in this Public License constitutes or may be construed as permission to assert or imply that You are, or that Your use of the Licensed Material is, connected with, or sponsored, endorsed, or granted official status by, the Licensor or others designated to receive attribution as provided in Section 3(a)(1)(A)(i).\nOther rights.\nMoral rights, such as the right of integrity, are not licensed under this Public License, nor are publicity, privacy, and/or other similar personality rights; however, to the extent possible, the Licensor waives and/or agrees not to assert any such rights held by the Licensor to the limited extent necessary to allow You to exercise the Licensed Rights, but not otherwise.\nPatent and trademark rights are not licensed under this Public License.\nTo the extent possible, the Licensor waives any right to collect royalties from You for the exercise of the Licensed Rights, whether directly or through a collecting society under any voluntary or waivable statutory or compulsory licensing scheme. In all other cases the Licensor expressly reserves any right to collect such royalties.\nSection 3 &#x2013; License Conditions.\nYour exercise of the Licensed Rights is expressly made subject to the following conditions.\nAttribution.\nIf You Share the Licensed Material, You must:\nretain the following if it is supplied by the Licensor with the Licensed Material:\nidentification of the creator(s) of the Licensed Material and any others designated to receive attribution, in any reasonable manner requested by the Licensor (including by pseudonym if designated);\na copyright notice;\na notice that refers to this Public License;\na notice that refers to the disclaimer of warranties;\na URI or hyperlink to the Licensed Material to the extent reasonably practicable;\nindicate if You modified the Licensed Material and retain an indication of any previous modifications; and\nindicate the Licensed Material is licensed under this Public License, and include the text of, or the URI or hyperlink to, this Public License.\nFor the avoidance of doubt, You do not have permission under this Public License to Share Adapted Material.\nYou may satisfy the conditions in Section 3(a)(1) in any reasonable manner based on the medium, means, and context in which You Share the Licensed Material. For example, it may be reasonable to satisfy the conditions by providing a URI or hyperlink to a resource that includes the required information.\nIf requested by the Licensor, You must remove any of the information required by Section 3(a)(1)(A) to the extent reasonably practicable.\nSection 4 &#x2013; Sui Generis Database Rights.\nWhere the Licensed Rights include Sui Generis Database Rights that apply to Your use of the Licensed Material:\nfor the avoidance of doubt, Section 2(a)(1) grants You the right to extract, reuse, reproduce, and Share all or a substantial portion of the contents of the database, provided You do not Share Adapted Material;\nif You include all or a substantial portion of the database contents in a database in which You have Sui Generis Database Rights, then the database in which You have Sui Generis Database Rights (but not its individual contents) is Adapted Material; and\nYou must comply with the conditions in Section 3(a) if You Share all or a substantial portion of the contents of the database.\nFor the avoidance of doubt, this Section 4 supplements and does not replace Your obligations under this Public License where the Licensed Rights include other Copyright and Similar Rights.\nSection 5 &#x2013; Disclaimer of Warranties and Limitation of Liability.\nUnless otherwise separately undertaken by the Licensor, to the extent possible, the Licensor offers the Licensed Material as-is and as-available, and makes no representations or warranties of any kind concerning the Licensed Material, whether express, implied, statutory, or other. This includes, without limitation, warranties of title, merchantability, fitness for a particular purpose, non-infringement, absence of latent or other defects, accuracy, or the presence or absence of errors, whether or not known or discoverable. Where disclaimers of warranties are not allowed in full or in part, this disclaimer may not apply to You.\nTo the extent possible, in no event will the Licensor be liable to You on any legal theory (including, without limitation, negligence) or otherwise for any direct, special, indirect, incidental, consequential, punitive, exemplary, or other losses, costs, expenses, or damages arising out of this Public License or use of the Licensed Material, even if the Licensor has been advised of the possibility of such losses, costs, expenses, or damages. Where a limitation of liability is not allowed in full or in part, this limitation may not apply to You.\nThe disclaimer of warranties and limitation of liability provided above shall be interpreted in a manner that, to the extent possible, most closely approximates an absolute disclaimer and waiver of all liability.\nSection 6 &#x2013; Term and Termination.\nThis Public License applies for the term of the Copyright and Similar Rights licensed here. However, if You fail to comply with this Public License, then Your rights under this Public License terminate automatically.\nWhere Your right to use the Licensed Material has terminated under Section 6(a), it reinstates:\nautomatically as of the date the violation is cured, provided it is cured within 30 days of Your discovery of the violation; or\nupon express reinstatement by the Licensor.\nFor the avoidance of doubt, this Section 6(b) does not affect any right the Licensor may have to seek remedies for Your violations of this Public License.\nFor the avoidance of doubt, the Licensor may also offer the Licensed Material under separate terms or conditions or stop distributing the Licensed Material at any time; however, doing so will not terminate this Public License.\nSections 1, 5, 6, 7, and 8 survive termination of this Public License.\nSection 7 &#x2013; Other Terms and Conditions.\nThe Licensor shall not be bound by any additional or different terms or conditions communicated by You unless expressly agreed.\nAny arrangements, understandings, or agreements regarding the Licensed Material not stated herein are separate from and independent of the terms and conditions of this Public License.\nSection 8 &#x2013; Interpretation.\nFor the avoidance of doubt, this Public License does not, and shall not be interpreted to, reduce, limit, restrict, or impose conditions on any use of the Licensed Material that could lawfully be made without permission under this Public License.\nTo the extent possible, if any provision of this Public License is deemed unenforceable, it shall be automatically reformed to the minimum extent necessary to make it enforceable. If the provision cannot be reformed, it shall be severed from this Public License without affecting the enforceability of the remaining terms and conditions.\nNo term or condition of this Public License will be waived and no failure to comply consented to unless expressly agreed to by the Licensor.\nNothing in this Public License constitutes or may be interpreted as a limitation upon, or waiver of, any privileges and immunities that apply to the Licensor or You, including from the legal processes of any jurisdiction or authority.\n"},{"id":341,"path":"../website/pages/docs/devonfw-ide-support.asciidoc.html#license.asciidoc_gnu-lesser-general-public-license---version-2.1","type":"docs","title":"GNU LESSER GENERAL PUBLIC LICENSE - Version 2.1","body":"7.2.7. GNU LESSER GENERAL PUBLIC LICENSE - Version 2.1\nVersion 2.1, February 1999\nCopyright (C) 1991, 1999 Free Software Foundation, Inc.\n51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\nEveryone is permitted to copy and distribute verbatim copies\nof this license document, but changing it is not allowed.\n[This is the first released version of the Lesser GPL. It also counts\nas the successor of the GNU Library Public License, version 2, hence\nthe version number 2.1.]\nPreamble\nThe licenses for most software are designed to take away your freedom to share and change it. By contrast, the GNU General Public Licenses are intended to guarantee your freedom to share and change free software--to make sure the software is free for all its users.\nThis license, the Lesser General Public License, applies to some specially designated software packages--typically libraries--of the Free Software Foundation and other authors who decide to use it. You can use it too, but we suggest you first think carefully about whether this license or the ordinary General Public License is the better strategy to use in any particular case, based on the explanations below.\nWhen we speak of free software, we are referring to freedom of use, not price. Our General Public Licenses are designed to make sure that you have the freedom to distribute copies of free software (and charge for this service if you wish); that you receive source code or can get it if you want it; that you can change the software and use pieces of it in new free programs; and that you are informed that you can do these things.\nTo protect your rights, we need to make restrictions that forbid distributors to deny you these rights or to ask you to surrender these rights. These restrictions translate to certain responsibilities for you if you distribute copies of the library or if you modify it.\nFor example, if you distribute copies of the library, whether gratis or for a fee, you must give the recipients all the rights that we gave you. You must make sure that they, too, receive or can get the source code. If you link other code with the library, you must provide complete object files to the recipients, so that they can relink them with the library after making changes to the library and recompiling it. And you must show them these terms so they know their rights.\nWe protect your rights with a two-step method: (1) we copyright the library, and (2) we offer you this license, which gives you legal permission to copy, distribute and/or modify the library.\nTo protect each distributor, we want to make it very clear that there is no warranty for the free library. Also, if the library is modified by someone else and passed on, the recipients should know that what they have is not the original version, so that the original author&apos;s reputation will not be affected by problems that might be introduced by others.\nFinally, software patents pose a constant threat to the existence of any free program. We wish to make sure that a company cannot effectively restrict the users of a free program by obtaining a restrictive license from a patent holder. Therefore, we insist that any patent license obtained for a version of the library must be consistent with the full freedom of use specified in this license.\nMost GNU software, including some libraries, is covered by the ordinary GNU General Public License. This license, the GNU Lesser General Public License, applies to certain designated libraries, and is quite different from the ordinary General Public License. We use this license for certain libraries in order to permit linking those libraries into non-free programs.\nWhen a program is linked with a library, whether statically or using a shared library, the combination of the two is legally speaking a combined work, a derivative of the original library. The ordinary General Public License therefore permits such linking only if the entire combination fits its criteria of freedom. The Lesser General Public License permits more lax criteria for linking other code with the library.\nWe call this license the &quot;Lesser&quot; General Public License because it does Less to protect the user&apos;s freedom than the ordinary General Public License. It also provides other free software developers Less of an advantage over competing non-free programs. These disadvantages are the reason we use the ordinary General Public License for many libraries. However, the Lesser license provides advantages in certain special circumstances.\nFor example, on rare occasions, there may be a special need to encourage the widest possible use of a certain library, so that it becomes a de-facto standard. To achieve this, non-free programs must be allowed to use the library. A more frequent case is that a free library does the same job as widely used non-free libraries. In this case, there is little to gain by limiting the free library to free software only, so we use the Lesser General Public License.\nIn other cases, permission to use a particular library in non-free programs enables a greater number of people to use a large body of free software. For example, permission to use the GNU C Library in non-free programs enables many more people to use the whole GNU operating system, as well as its variant, the GNU/Linux operating system.\nAlthough the Lesser General Public License is Less protective of the users&apos; freedom, it does ensure that the user of a program that is linked with the Library has the freedom and the wherewithal to run that program using a modified version of the Library.\nThe precise terms and conditions for copying, distribution and modification follow. Pay close attention to the difference between a &quot;work based on the library&quot; and a &quot;work that uses the library&quot;. The former contains code derived from the library, whereas the latter must be combined with the library in order to run.\nTERMS AND CONDITIONS FOR COPYING, DISTRIBUTION AND MODIFICATION\n0. This License Agreement applies to any software library or other program which contains a notice placed by the copyright holder or other authorized party saying it may be distributed under the terms of this Lesser General Public License (also called &quot;this License&quot;). Each licensee is addressed as &quot;you&quot;.\nA &quot;library&quot; means a collection of software functions and/or data prepared so as to be conveniently linked with application programs (which use some of those functions and data) to form executables.\nThe &quot;Library&quot;, below, refers to any such software library or work which has been distributed under these terms. A &quot;work based on the Library&quot; means either the Library or any derivative work under copyright law: that is to say, a work containing the Library or a portion of it, either verbatim or with modifications and/or translated straightforwardly into another language. (Hereinafter, translation is included without limitation in the term &quot;modification&quot;.)\n&quot;Source code&quot; for a work means the preferred form of the work for making modifications to it. For a library, complete source code means all the source code for all modules it contains, plus any associated interface definition files, plus the scripts used to control compilation and installation of the library.\nActivities other than copying, distribution and modification are not covered by this License; they are outside its scope. The act of running a program using the Library is not restricted, and output from such a program is covered only if its contents constitute a work based on the Library (independent of the use of the Library in a tool for writing it). Whether that is true depends on what the Library does and what the program that uses the Library does.\n1. You may copy and distribute verbatim copies of the Library&apos;s complete source code as you receive it, in any medium, provided that you conspicuously and appropriately publish on each copy an appropriate copyright notice and disclaimer of warranty; keep intact all the notices that refer to this License and to the absence of any warranty; and distribute a copy of this License along with the Library.\nYou may charge a fee for the physical act of transferring a copy, and you may at your option offer warranty protection in exchange for a fee.\n2. You may modify your copy or copies of the Library or any portion of it, thus forming a work based on the Library, and copy and distribute such modifications or work under the terms of Section 1 above, provided that you also meet all of these conditions:\na) The modified work must itself be a software library.\nb) You must cause the files modified to carry prominent notices stating that you changed the files and the date of any change.\nc) You must cause the whole of the work to be licensed at no charge to all third parties under the terms of this License.\nd) If a facility in the modified Library refers to a function or a table of data to be supplied by an application program that uses the facility, other than as an argument passed when the facility is invoked, then you must make a good faith effort to ensure that, in the event an application does not supply such function or table, the facility still operates, and performs whatever part of its purpose remains meaningful.\n(For example, a function in a library to compute square roots has a purpose that is entirely well-defined independent of the application. Therefore, Subsection 2d requires that any application-supplied function or table used by this function must be optional: if the application does not supply it, the square root function must still compute square roots.)\nThese requirements apply to the modified work as a whole. If identifiable sections of that work are not derived from the Library, and can be reasonably considered independent and separate works in themselves, then this License, and its terms, do not apply to those sections when you distribute them as separate works. But when you distribute the same sections as part of a whole which is a work based on the Library, the distribution of the whole must be on the terms of this License, whose permissions for other licensees extend to the entire whole, and thus to each and every part regardless of who wrote it.\nThus, it is not the intent of this section to claim rights or contest your rights to work written entirely by you; rather, the intent is to exercise the right to control the distribution of derivative or collective works based on the Library.\nIn addition, mere aggregation of another work not based on the Library with the Library (or with a work based on the Library) on a volume of a storage or distribution medium does not bring the other work under the scope of this License.\n3. You may opt to apply the terms of the ordinary GNU General Public License instead of this License to a given copy of the Library. To do this, you must alter all the notices that refer to this License, so that they refer to the ordinary GNU General Public License, version 2, instead of to this License. (If a newer version than version 2 of the ordinary GNU General Public License has appeared, then you can specify that version instead if you wish.) Do not make any other change in these notices.\nOnce this change is made in a given copy, it is irreversible for that copy, so the ordinary GNU General Public License applies to all subsequent copies and derivative works made from that copy.\nThis option is useful when you wish to copy part of the code of the Library into a program that is not a library.\n4. You may copy and distribute the Library (or a portion or derivative of it, under Section 2) in object code or executable form under the terms of Sections 1 and 2 above provided that you accompany it with the complete corresponding machine-readable source code, which must be distributed under the terms of Sections 1 and 2 above on a medium customarily used for software interchange.\nIf distribution of object code is made by offering access to copy from a designated place, then offering equivalent access to copy the source code from the same place satisfies the requirement to distribute the source code, even though third parties are not compelled to copy the source along with the object code.\n5. A program that contains no derivative of any portion of the Library, but is designed to work with the Library by being compiled or linked with it, is called a &quot;work that uses the Library&quot;. Such a work, in isolation, is not a derivative work of the Library, and therefore falls outside the scope of this License.\nHowever, linking a &quot;work that uses the Library&quot; with the Library creates an executable that is a derivative of the Library (because it contains portions of the Library), rather than a &quot;work that uses the library&quot;. The executable is therefore covered by this License. Section 6 states terms for distribution of such executables.\nWhen a &quot;work that uses the Library&quot; uses material from a header file that is part of the Library, the object code for the work may be a derivative work of the Library even though the source code is not. Whether this is true is especially significant if the work can be linked without the Library, or if the work is itself a library. The threshold for this to be true is not precisely defined by law.\nIf such an object file uses only numerical parameters, data structure layouts and accessors, and small macros and small inline functions (ten lines or less in length), then the use of the object file is unrestricted, regardless of whether it is legally a derivative work. (Executables containing this object code plus portions of the Library will still fall under Section 6.)\nOtherwise, if the work is a derivative of the Library, you may distribute the object code for the work under the terms of Section 6. Any executables containing that work also fall under Section 6, whether or not they are linked directly with the Library itself.\n6. As an exception to the Sections above, you may also combine or link a &quot;work that uses the Library&quot; with the Library to produce a work containing portions of the Library, and distribute that work under terms of your choice, provided that the terms permit modification of the work for the customer&apos;s own use and reverse engineering for debugging such modifications.\nYou must give prominent notice with each copy of the work that the Library is used in it and that the Library and its use are covered by this License. You must supply a copy of this License. If the work during execution displays copyright notices, you must include the copyright notice for the Library among them, as well as a reference directing the user to the copy of this License. Also, you must do one of these things:\na) Accompany the work with the complete corresponding machine-readable source code for the Library including whatever changes were used in the work (which must be distributed under Sections 1 and 2 above); and, if the work is an executable linked with the Library, with the complete machine-readable &quot;work that uses the Library&quot;, as object code and/or source code, so that the user can modify the Library and then relink to produce a modified executable containing the modified Library. (It is understood that the user who changes the contents of definitions files in the Library will not necessarily be able to recompile the application to use the modified definitions.)\nb) Use a suitable shared library mechanism for linking with the Library. A suitable mechanism is one that (1) uses at run time a copy of the library already present on the user&apos;s computer system, rather than copying library functions into the executable, and (2) will operate properly with a modified version of the library, if the user installs one, as long as the modified version is interface-compatible with the version that the work was made with.\nc) Accompany the work with a written offer, valid for at least three years, to give the same user the materials specified in Subsection 6a, above, for a charge no more than the cost of performing this distribution.\nd) If distribution of the work is made by offering access to copy from a designated place, offer equivalent access to copy the above specified materials from the same place.\ne) Verify that the user has already received a copy of these materials or that you have already sent this user a copy.\nFor an executable, the required form of the &quot;work that uses the Library&quot; must include any data and utility programs needed for reproducing the executable from it. However, as a special exception, the materials to be distributed need not include anything that is normally distributed (in either source or binary form) with the major components (compiler, kernel, and so on) of the operating system on which the executable runs, unless that component itself accompanies the executable.\nIt may happen that this requirement contradicts the license restrictions of other proprietary libraries that do not normally accompany the operating system. Such a contradiction means you cannot use both them and the Library together in an executable that you distribute.\n7. You may place library facilities that are a work based on the Library side-by-side in a single library together with other library facilities not covered by this License, and distribute such a combined library, provided that the separate distribution of the work based on the Library and of the other library facilities is otherwise permitted, and provided that you do these two things:\na) Accompany the combined library with a copy of the same work based on the Library, uncombined with any other library facilities. This must be distributed under the terms of the Sections above.\nb) Give prominent notice with the combined library of the fact that part of it is a work based on the Library, and explaining where to find the accompanying uncombined form of the same work.\n8. You may not copy, modify, sublicense, link with, or distribute the Library except as expressly provided under this License. Any attempt otherwise to copy, modify, sublicense, link with, or distribute the Library is void, and will automatically terminate your rights under this License. However, parties who have received copies, or rights, from you under this License will not have their licenses terminated so long as such parties remain in full compliance.\n9. You are not required to accept this License, since you have not signed it. However, nothing else grants you permission to modify or distribute the Library or its derivative works. These actions are prohibited by law if you do not accept this License. Therefore, by modifying or distributing the Library (or any work based on the Library), you indicate your acceptance of this License to do so, and all its terms and conditions for copying, distributing or modifying the Library or works based on it.\n10. Each time you redistribute the Library (or any work based on the Library), the recipient automatically receives a license from the original licensor to copy, distribute, link with or modify the Library subject to these terms and conditions. You may not impose any further restrictions on the recipients&apos; exercise of the rights granted herein. You are not responsible for enforcing compliance by third parties with this License.\n11. If, as a consequence of a court judgment or allegation of patent infringement or for any other reason (not limited to patent issues), conditions are imposed on you (whether by court order, agreement or otherwise) that contradict the conditions of this License, they do not excuse you from the conditions of this License. If you cannot distribute so as to satisfy simultaneously your obligations under this License and any other pertinent obligations, then as a consequence you may not distribute the Library at all. For example, if a patent license would not permit royalty-free redistribution of the Library by all those who receive copies directly or indirectly through you, then the only way you could satisfy both it and this License would be to refrain entirely from distribution of the Library.\nIf any portion of this section is held invalid or unenforceable under any particular circumstance, the balance of the section is intended to apply, and the section as a whole is intended to apply in other circumstances.\nIt is not the purpose of this section to induce you to infringe any patents or other property right claims or to contest validity of any such claims; this section has the sole purpose of protecting the integrity of the free software distribution system which is implemented by public license practices. Many people have made generous contributions to the wide range of software distributed through that system in reliance on consistent application of that system; it is up to the author/donor to decide if he or she is willing to distribute software through any other system and a licensee cannot impose that choice.\nThis section is intended to make thoroughly clear what is believed to be a consequence of the rest of this License.\n12. If the distribution and/or use of the Library is restricted in certain countries either by patents or by copyrighted interfaces, the original copyright holder who places the Library under this License may add an explicit geographical distribution limitation excluding those countries, so that distribution is permitted only in or among countries not thus excluded. In such case, this License incorporates the limitation as if written in the body of this License.\n13. The Free Software Foundation may publish revised and/or new versions of the Lesser General Public License from time to time. Such new versions will be similar in spirit to the present version, but may differ in detail to address new problems or concerns.\nEach version is given a distinguishing version number. If the Library specifies a version number of this License which applies to it and &quot;any later version&quot;, you have the option of following the terms and conditions either of that version or of any later version published by the Free Software Foundation. If the Library does not specify a license version number, you may choose any version ever published by the Free Software Foundation.\n14. If you wish to incorporate parts of the Library into other free programs whose distribution conditions are incompatible with these, write to the author to ask for permission. For software which is copyrighted by the Free Software Foundation, write to the Free Software Foundation; we sometimes make exceptions for this. Our decision will be guided by the two goals of preserving the free status of all derivatives of our free software and of promoting the sharing and reuse of software generally.\nNO WARRANTY\n15. BECAUSE THE LIBRARY IS LICENSED FREE OF CHARGE, THERE IS NO WARRANTY FOR THE LIBRARY, TO THE EXTENT PERMITTED BY APPLICABLE LAW. EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT HOLDERS AND/OR OTHER PARTIES PROVIDE THE LIBRARY &quot;AS IS&quot; WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE. THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE LIBRARY IS WITH YOU. SHOULD THE LIBRARY PROVE DEFECTIVE, YOU ASSUME THE COST OF ALL NECESSARY SERVICING, REPAIR OR CORRECTION.\n16. IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MAY MODIFY AND/OR REDISTRIBUTE THE LIBRARY AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE USE OR INABILITY TO USE THE LIBRARY (INCLUDING BUT NOT LIMITED TO LOSS OF DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD PARTIES OR A FAILURE OF THE LIBRARY TO OPERATE WITH ANY OTHER SOFTWARE), EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES.\nEND OF TERMS AND CONDITIONS\nHow to Apply These Terms to Your New Libraries\nIf you develop a new library, and you want it to be of the greatest possible use to the public, we recommend making it free software that everyone can redistribute and change. You can do so by permitting redistribution under these terms (or, alternatively, under the terms of the ordinary General Public License).\nTo apply these terms, attach the following notices to the library. It is safest to attach them to the start of each source file to most effectively convey the exclusion of warranty; and each file should have at least the &quot;copyright&quot; line and a pointer to where the full notice is found.\none line to give the library&apos;s name and an idea of what it does.\nCopyright (C) year name of author\nThis library is free software; you can redistribute it and/or\nmodify it under the terms of the GNU Lesser General Public\nLicense as published by the Free Software Foundation; either\nversion 2.1 of the License, or (at your option) any later version.\nThis library is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU\nLesser General Public License for more details.\nYou should have received a copy of the GNU Lesser General Public\nLicense along with this library; if not, write to the Free Software\nFoundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\nAlso add information on how to contact you by electronic and paper mail.\nYou should also get your employer (if you work as a programmer) or your school, if any, to sign a &quot;copyright disclaimer&quot; for the library, if necessary. Here is a sample; alter the names:\nYoyodyne, Inc., hereby disclaims all copyright interest in\nthe library `Frob&apos; (a library for tweaking knobs) written\nby James Random Hacker.\nsignature of Ty Coon, 1 April 1990\nTy Coon, President of Vice\n"},{"id":342,"path":"../website/pages/docs/devonfw-ide-support.asciidoc.html#license.asciidoc_gnu-lesser-general-public-license---version-3","type":"docs","title":"GNU LESSER GENERAL PUBLIC LICENSE - Version 3","body":"7.2.8. GNU LESSER GENERAL PUBLIC LICENSE - Version 3\nVersion 3, 29 June 2007\nCopyright &#xA9; 2007 Free Software Foundation, Inc. &lt;https://fsf.org/&gt;\nEveryone is permitted to copy and distribute verbatim copies of this license document, but changing it is not allowed.\nThis version of the GNU Lesser General Public License incorporates the terms and conditions of version 3 of the GNU General Public License, supplemented by the additional permissions listed below.\n0. Additional Definitions.\nAs used herein, &#x201C;this License&#x201D; refers to version 3 of the GNU Lesser General Public License, and the &#x201C;GNU GPL&#x201D; refers to version 3 of the GNU General Public License.\n&#x201C;The Library&#x201D; refers to a covered work governed by this License, other than an Application or a Combined Work as defined below.\nAn &#x201C;Application&#x201D; is any work that makes use of an interface provided by the Library, but which is not otherwise based on the Library. Defining a subclass of a class defined by the Library is deemed a mode of using an interface provided by the Library.\nA &#x201C;Combined Work&#x201D; is a work produced by combining or linking an Application with the Library. The particular version of the Library with which the Combined Work was made is also called the &#x201C;Linked Version&#x201D;.\nThe &#x201C;Minimal Corresponding Source&#x201D; for a Combined Work means the Corresponding Source for the Combined Work, excluding any source code for portions of the Combined Work that, considered in isolation, are based on the Application, and not on the Linked Version.\nThe &#x201C;Corresponding Application Code&#x201D; for a Combined Work means the object code and/or source code for the Application, including any data and utility programs needed for reproducing the Combined Work from the Application, but excluding the System Libraries of the Combined Work.\n1. Exception to Section 3 of the GNU GPL.\nYou may convey a covered work under sections 3 and 4 of this License without being bound by section 3 of the GNU GPL.\n2. Conveying Modified Versions.\nIf you modify a copy of the Library, and, in your modifications, a facility refers to a function or data to be supplied by an Application that uses the facility (other than as an argument passed when the facility is invoked), then you may convey a copy of the modified version:\na) under this License, provided that you make a good faith effort to ensure that, in the event an Application does not supply the function or data, the facility still operates, and performs whatever part of its purpose remains meaningful, or\nb) under the GNU GPL, with none of the additional permissions of this License applicable to that copy.\n3. Object Code Incorporating Material from Library Header Files.\nThe object code form of an Application may incorporate material from a header file that is part of the Library. You may convey such object code under terms of your choice, provided that, if the incorporated material is not limited to numerical parameters, data structure layouts and accessors, or small macros, inline functions and templates (ten or fewer lines in length), you do both of the following:\na) Give prominent notice with each copy of the object code that the Library is used in it and that the Library and its use are covered by this License.\nb) Accompany the object code with a copy of the GNU GPL and this license document.\n4. Combined Works.\nYou may convey a Combined Work under terms of your choice that, taken together, effectively do not restrict modification of the portions of the Library contained in the Combined Work and reverse engineering for debugging such modifications, if you also do each of the following:\na) Give prominent notice with each copy of the Combined Work that the Library is used in it and that the Library and its use are covered by this License.\nb) Accompany the Combined Work with a copy of the GNU GPL and this license document.\nc) For a Combined Work that displays copyright notices during execution, include the copyright notice for the Library among these notices, as well as a reference directing the user to the copies of the GNU GPL and this license document.\nd) Do one of the following:\n0) Convey the Minimal Corresponding Source under the terms of this License, and the Corresponding Application Code in a form suitable for, and under terms that permit, the user to recombine or relink the Application with a modified version of the Linked Version to produce a modified Combined Work, in the manner specified by section 6 of the GNU GPL for conveying Corresponding Source.\n1) Use a suitable shared library mechanism for linking with the Library. A suitable mechanism is one that (a) uses at run time a copy of the Library already present on the user&apos;s computer system, and (b) will operate properly with a modified version of the Library that is interface-compatible with the Linked Version.\ne) Provide Installation Information, but only if you would otherwise be required to provide such information under section 6 of the GNU GPL, and only to the extent that such information is necessary to install and execute a modified version of the Combined Work produced by recombining or relinking the Application with a modified version of the Linked Version. (If you use option 4d0, the Installation Information must accompany the Minimal Corresponding Source and Corresponding Application Code. If you use option 4d1, you must provide the Installation Information in the manner specified by section 6 of the GNU GPL for conveying Corresponding Source.)\n5. Combined Libraries.\nYou may place library facilities that are a work based on the Library side by side in a single library together with other library facilities that are not Applications and are not covered by this License, and convey such a combined library under terms of your choice, if you do both of the following:\na) Accompany the combined library with a copy of the same work based on the Library, uncombined with any other library facilities, conveyed under the terms of this License.\nb) Give prominent notice with the combined library that part of it is a work based on the Library, and explaining where to find the accompanying uncombined form of the same work.\n6. Revised Versions of the GNU Lesser General Public License.\nThe Free Software Foundation may publish revised and/or new versions of the GNU Lesser General Public License from time to time. Such new versions will be similar in spirit to the present version, but may differ in detail to address new problems or concerns.\nEach version is given a distinguishing version number. If the Library as you received it specifies that a certain numbered version of the GNU Lesser General Public License &#x201C;or any later version&#x201D; applies to it, you have the option of following the terms and conditions either of that published version or of any later version published by the Free Software Foundation. If the Library as you received it does not specify a version number of the GNU Lesser General Public License, you may choose any version of the GNU Lesser General Public License ever published by the Free Software Foundation.\nIf the Library as you received it specifies that a proxy can decide whether future versions of the GNU Lesser General Public License shall apply, that proxy&apos;s public statement of acceptance of any version is permanent authorization for you to choose that version for the Library.\n"},{"id":343,"path":"../website/pages/docs/devonfw-ide-support.asciidoc.html#license.asciidoc_gnu-general-public-license---version-2","type":"docs","title":"GNU GENERAL PUBLIC LICENSE - Version 2","body":"7.2.9. GNU GENERAL PUBLIC LICENSE - Version 2\nVersion 2, June 1991\nCopyright (C) 1989, 1991 Free Software Foundation, Inc.\n51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA\nEveryone is permitted to copy and distribute verbatim copies\nof this license document, but changing it is not allowed.\nPreamble\nThe licenses for most software are designed to take away your freedom to share and change it. By contrast, the GNU General Public License is intended to guarantee your freedom to share and change free software--to make sure the software is free for all its users. This General Public License applies to most of the Free Software Foundation&apos;s software and to any other program whose authors commit to using it. (Some other Free Software Foundation software is covered by the GNU Lesser General Public License instead.) You can apply it to your programs, too.\nWhen we speak of free software, we are referring to freedom, not price. Our General Public Licenses are designed to make sure that you have the freedom to distribute copies of free software (and charge for this service if you wish), that you receive source code or can get it if you want it, that you can change the software or use pieces of it in new free programs; and that you know you can do these things.\nTo protect your rights, we need to make restrictions that forbid anyone to deny you these rights or to ask you to surrender the rights. These restrictions translate to certain responsibilities for you if you distribute copies of the software, or if you modify it.\nFor example, if you distribute copies of such a program, whether gratis or for a fee, you must give the recipients all the rights that you have. You must make sure that they, too, receive or can get the source code. And you must show them these terms so they know their rights.\nWe protect your rights with two steps: (1) copyright the software, and (2) offer you this license which gives you legal permission to copy, distribute and/or modify the software.\nAlso, for each author&apos;s protection and ours, we want to make certain that everyone understands that there is no warranty for this free software. If the software is modified by someone else and passed on, we want its recipients to know that what they have is not the original, so that any problems introduced by others will not reflect on the original authors&apos; reputations.\nFinally, any free program is threatened constantly by software patents. We wish to avoid the danger that redistributors of a free program will individually obtain patent licenses, in effect making the program proprietary. To prevent this, we have made it clear that any patent must be licensed for everyone&apos;s free use or not licensed at all.\nThe precise terms and conditions for copying, distribution and modification follow.\nTERMS AND CONDITIONS FOR COPYING, DISTRIBUTION AND MODIFICATION\n0. This License applies to any program or other work which contains a notice placed by the copyright holder saying it may be distributed under the terms of this General Public License. The &quot;Program&quot;, below, refers to any such program or work, and a &quot;work based on the Program&quot; means either the Program or any derivative work under copyright law: that is to say, a work containing the Program or a portion of it, either verbatim or with modifications and/or translated into another language. (Hereinafter, translation is included without limitation in the term &quot;modification&quot;.) Each licensee is addressed as &quot;you&quot;.\nActivities other than copying, distribution and modification are not covered by this License; they are outside its scope. The act of running the Program is not restricted, and the output from the Program is covered only if its contents constitute a work based on the Program (independent of having been made by running the Program). Whether that is true depends on what the Program does.\n1. You may copy and distribute verbatim copies of the Program&apos;s source code as you receive it, in any medium, provided that you conspicuously and appropriately publish on each copy an appropriate copyright notice and disclaimer of warranty; keep intact all the notices that refer to this License and to the absence of any warranty; and give any other recipients of the Program a copy of this License along with the Program.\nYou may charge a fee for the physical act of transferring a copy, and you may at your option offer warranty protection in exchange for a fee.\n2. You may modify your copy or copies of the Program or any portion of it, thus forming a work based on the Program, and copy and distribute such modifications or work under the terms of Section 1 above, provided that you also meet all of these conditions:\na) You must cause the modified files to carry prominent notices stating that you changed the files and the date of any change.\nb) You must cause any work that you distribute or publish, that in whole or in part contains or is derived from the Program or any part thereof, to be licensed as a whole at no charge to all third parties under the terms of this License.\nc) If the modified program normally reads commands interactively when run, you must cause it, when started running for such interactive use in the most ordinary way, to print or display an announcement including an appropriate copyright notice and a notice that there is no warranty (or else, saying that you provide a warranty) and that users may redistribute the program under these conditions, and telling the user how to view a copy of this License. (Exception: if the Program itself is interactive but does not normally print such an announcement, your work based on the Program is not required to print an announcement.)\nThese requirements apply to the modified work as a whole. If identifiable sections of that work are not derived from the Program, and can be reasonably considered independent and separate works in themselves, then this License, and its terms, do not apply to those sections when you distribute them as separate works. But when you distribute the same sections as part of a whole which is a work based on the Program, the distribution of the whole must be on the terms of this License, whose permissions for other licensees extend to the entire whole, and thus to each and every part regardless of who wrote it.\nThus, it is not the intent of this section to claim rights or contest your rights to work written entirely by you; rather, the intent is to exercise the right to control the distribution of derivative or collective works based on the Program.\nIn addition, mere aggregation of another work not based on the Program with the Program (or with a work based on the Program) on a volume of a storage or distribution medium does not bring the other work under the scope of this License.\n3. You may copy and distribute the Program (or a work based on it, under Section 2) in object code or executable form under the terms of Sections 1 and 2 above provided that you also do one of the following:\na) Accompany it with the complete corresponding machine-readable source code, which must be distributed under the terms of Sections 1 and 2 above on a medium customarily used for software interchange; or,\nb) Accompany it with a written offer, valid for at least three years, to give any third party, for a charge no more than your cost of physically performing source distribution, a complete machine-readable copy of the corresponding source code, to be distributed under the terms of Sections 1 and 2 above on a medium customarily used for software interchange; or,\nc) Accompany it with the information you received as to the offer to distribute corresponding source code. (This alternative is allowed only for noncommercial distribution and only if you received the program in object code or executable form with such an offer, in accord with Subsection b above.)\nThe source code for a work means the preferred form of the work for making modifications to it. For an executable work, complete source code means all the source code for all modules it contains, plus any associated interface definition files, plus the scripts used to control compilation and installation of the executable. However, as a special exception, the source code distributed need not include anything that is normally distributed (in either source or binary form) with the major components (compiler, kernel, and so on) of the operating system on which the executable runs, unless that component itself accompanies the executable.\nIf distribution of executable or object code is made by offering access to copy from a designated place, then offering equivalent access to copy the source code from the same place counts as distribution of the source code, even though third parties are not compelled to copy the source along with the object code.\n4. You may not copy, modify, sublicense, or distribute the Program except as expressly provided under this License. Any attempt otherwise to copy, modify, sublicense or distribute the Program is void, and will automatically terminate your rights under this License. However, parties who have received copies, or rights, from you under this License will not have their licenses terminated so long as such parties remain in full compliance.\n5. You are not required to accept this License, since you have not signed it. However, nothing else grants you permission to modify or distribute the Program or its derivative works. These actions are prohibited by law if you do not accept this License. Therefore, by modifying or distributing the Program (or any work based on the Program), you indicate your acceptance of this License to do so, and all its terms and conditions for copying, distributing or modifying the Program or works based on it.\n6. Each time you redistribute the Program (or any work based on the Program), the recipient automatically receives a license from the original licensor to copy, distribute or modify the Program subject to these terms and conditions. You may not impose any further restrictions on the recipients&apos; exercise of the rights granted herein. You are not responsible for enforcing compliance by third parties to this License.\n7. If, as a consequence of a court judgment or allegation of patent infringement or for any other reason (not limited to patent issues), conditions are imposed on you (whether by court order, agreement or otherwise) that contradict the conditions of this License, they do not excuse you from the conditions of this License. If you cannot distribute so as to satisfy simultaneously your obligations under this License and any other pertinent obligations, then as a consequence you may not distribute the Program at all. For example, if a patent license would not permit royalty-free redistribution of the Program by all those who receive copies directly or indirectly through you, then the only way you could satisfy both it and this License would be to refrain entirely from distribution of the Program.\nIf any portion of this section is held invalid or unenforceable under any particular circumstance, the balance of the section is intended to apply and the section as a whole is intended to apply in other circumstances.\nIt is not the purpose of this section to induce you to infringe any patents or other property right claims or to contest validity of any such claims; this section has the sole purpose of protecting the integrity of the free software distribution system, which is implemented by public license practices. Many people have made generous contributions to the wide range of software distributed through that system in reliance on consistent application of that system; it is up to the author/donor to decide if he or she is willing to distribute software through any other system and a licensee cannot impose that choice.\nThis section is intended to make thoroughly clear what is believed to be a consequence of the rest of this License.\n8. If the distribution and/or use of the Program is restricted in certain countries either by patents or by copyrighted interfaces, the original copyright holder who places the Program under this License may add an explicit geographical distribution limitation excluding those countries, so that distribution is permitted only in or among countries not thus excluded. In such case, this License incorporates the limitation as if written in the body of this License.\n9. The Free Software Foundation may publish revised and/or new versions of the General Public License from time to time. Such new versions will be similar in spirit to the present version, but may differ in detail to address new problems or concerns.\nEach version is given a distinguishing version number. If the Program specifies a version number of this License which applies to it and &quot;any later version&quot;, you have the option of following the terms and conditions either of that version or of any later version published by the Free Software Foundation. If the Program does not specify a version number of this License, you may choose any version ever published by the Free Software Foundation.\n10. If you wish to incorporate parts of the Program into other free programs whose distribution conditions are different, write to the author to ask for permission. For software which is copyrighted by the Free Software Foundation, write to the Free Software Foundation; we sometimes make exceptions for this. Our decision will be guided by the two goals of preserving the free status of all derivatives of our free software and of promoting the sharing and reuse of software generally.\nNO WARRANTY\n11. BECAUSE THE PROGRAM IS LICENSED FREE OF CHARGE, THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY APPLICABLE LAW. EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT HOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM &quot;AS IS&quot; WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE. THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM IS WITH YOU. SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF ALL NECESSARY SERVICING, REPAIR OR CORRECTION.\n12. IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MAY MODIFY AND/OR REDISTRIBUTE THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS), EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES.\nEND OF TERMS AND CONDITIONS\nHow to Apply These Terms to Your New Programs\nIf you develop a new program, and you want it to be of the greatest possible use to the public, the best way to achieve this is to make it free software which everyone can redistribute and change under these terms.\nTo do so, attach the following notices to the program. It is safest to attach them to the start of each source file to most effectively convey the exclusion of warranty; and each file should have at least the &quot;copyright&quot; line and a pointer to where the full notice is found.\none line to give the program&apos;s name and an idea of what it does.\nCopyright (C) yyyy name of author\nThis program is free software; you can redistribute it and/or\nmodify it under the terms of the GNU General Public License\nas published by the Free Software Foundation; either version 2\nof the License, or (at your option) any later version.\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\nGNU General Public License for more details.\nYou should have received a copy of the GNU General Public License\nalong with this program; if not, write to the Free Software\nFoundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.\nAlso add information on how to contact you by electronic and paper mail.\nIf the program is interactive, make it output a short notice like this when it starts in an interactive mode:\nGnomovision version 69, Copyright (C) year name of author\nGnomovision comes with ABSOLUTELY NO WARRANTY; for details\ntype `show w&apos;. This is free software, and you are welcome\nto redistribute it under certain conditions; type `show c&apos;\nfor details.\nThe hypothetical commands `show w&apos; and `show c&apos; should show the appropriate parts of the General Public License. Of course, the commands you use may be called something other than `show w&apos; and `show c&apos;; they could even be mouse-clicks or menu items--whatever suits your program.\nYou should also get your employer (if you work as a programmer) or your school, if any, to sign a &quot;copyright disclaimer&quot; for the program, if necessary. Here is a sample; alter the names:\nYoyodyne, Inc., hereby disclaims all copyright\ninterest in the program `Gnomovision&apos;\n(which makes passes at compilers) written\nby James Hacker.\nsignature of Ty Coon, 1 April 1989\nTy Coon, President of Vice\n"},{"id":344,"path":"../website/pages/docs/devonfw-ide-support.asciidoc.html#license.asciidoc_do-what-the-fuck-you-want-to-public-license---version-2","type":"docs","title":"DO WHAT THE FUCK YOU WANT TO PUBLIC LICENSE - Version 2","body":"7.2.10. DO WHAT THE FUCK YOU WANT TO PUBLIC LICENSE - Version 2\nDO WHAT THE FUCK YOU WANT TO PUBLIC LICENSE\nVersion 2, December 2004\nCopyright (C) 2004 Sam Hocevar\n14 rue de Plaisance, 75014 Paris, France\nEveryone is permitted to copy and distribute verbatim or modified\ncopies of this license document, and changing it is allowed as long\nas the name is changed.\nDO WHAT THE FUCK YOU WANT TO PUBLIC LICENSE\nTERMS AND CONDITIONS FOR COPYING, DISTRIBUTION AND MODIFICATION\n0. You just DO WHAT THE FUCK YOU WANT TO.\n"},{"id":345,"path":"../website/pages/docs/devonfw-ide-support.asciidoc.html#license.asciidoc_license-of-node.js","type":"docs","title":"License of Node.js","body":"7.2.11. License of Node.js\nNode.js is licensed for use as follows:\n&quot;&quot;&quot;\nCopyright Node.js contributors. All rights reserved.\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the &quot;Software&quot;), to\ndeal in the Software without restriction, including without limitation the\nrights to use, copy, modify, merge, publish, distribute, sublicense, and/or\nsell copies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED &quot;AS IS&quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\nFROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\nIN THE SOFTWARE.\n&quot;&quot;&quot;\nThis license applies to parts of Node.js originating from the\nhttps://github.com/joyent/node repository:\n&quot;&quot;&quot;\nCopyright Joyent, Inc. and other Node contributors. All rights reserved.\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the &quot;Software&quot;), to\ndeal in the Software without restriction, including without limitation the\nrights to use, copy, modify, merge, publish, distribute, sublicense, and/or\nsell copies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED &quot;AS IS&quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\nFROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\nIN THE SOFTWARE.\n&quot;&quot;&quot;\nThe Node.js license applies to all parts of Node.js that are not externally\nmaintained libraries.\nThe externally maintained libraries used by Node.js are:\n- Acorn, located at deps/acorn, is licensed as follows:\n&quot;&quot;&quot;\nCopyright (C) 2012-2018 by various contributors (see AUTHORS)\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the &quot;Software&quot;), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED &quot;AS IS&quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n&quot;&quot;&quot;\n- Acorn plugins, located at deps/acorn-plugins, is licensed as follows:\n&quot;&quot;&quot;\nCopyright (C) 2017-2018 by Adrian Heine\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the &quot;Software&quot;), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED &quot;AS IS&quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n&quot;&quot;&quot;\n- c-ares, located at deps/cares, is licensed as follows:\n&quot;&quot;&quot;\nCopyright (c) 2007 - 2018, Daniel Stenberg with many contributors, see AUTHORS\nfile.\nCopyright 1998 by the Massachusetts Institute of Technology.\nPermission to use, copy, modify, and distribute this software and its\ndocumentation for any purpose and without fee is hereby granted, provided that\nthe above copyright notice appear in all copies and that both that copyright\nnotice and this permission notice appear in supporting documentation, and that\nthe name of M.I.T. not be used in advertising or publicity pertaining to\ndistribution of the software without specific, written prior permission.\nM.I.T. makes no representations about the suitability of this software for any\npurpose. It is provided &quot;as is&quot; without express or implied warranty.\n&quot;&quot;&quot;\n- ICU, located at deps/icu-small, is licensed as follows:\n&quot;&quot;&quot;\nCOPYRIGHT AND PERMISSION NOTICE (ICU 58 and later)\nCopyright &#xA9; 1991-2019 Unicode, Inc. All rights reserved.\nDistributed under the Terms of Use in https://www.unicode.org/copyright.html.\nPermission is hereby granted, free of charge, to any person obtaining\na copy of the Unicode data files and any associated documentation\n(the &quot;Data Files&quot;) or Unicode software and any associated documentation\n(the &quot;Software&quot;) to deal in the Data Files or Software\nwithout restriction, including without limitation the rights to use,\ncopy, modify, merge, publish, distribute, and/or sell copies of\nthe Data Files or Software, and to permit persons to whom the Data Files\nor Software are furnished to do so, provided that either\n(a) this copyright and permission notice appear with all copies\nof the Data Files or Software, or\n(b) this copyright and permission notice appear in associated\nDocumentation.\nTHE DATA FILES AND SOFTWARE ARE PROVIDED &quot;AS IS&quot;, WITHOUT WARRANTY OF\nANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE\nWARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\nNONINFRINGEMENT OF THIRD PARTY RIGHTS.\nIN NO EVENT SHALL THE COPYRIGHT HOLDER OR HOLDERS INCLUDED IN THIS\nNOTICE BE LIABLE FOR ANY CLAIM, OR ANY SPECIAL INDIRECT OR CONSEQUENTIAL\nDAMAGES, OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE,\nDATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER\nTORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR\nPERFORMANCE OF THE DATA FILES OR SOFTWARE.\nExcept as contained in this notice, the name of a copyright holder\nshall not be used in advertising or otherwise to promote the sale,\nuse or other dealings in these Data Files or Software without prior\nwritten authorization of the copyright holder.\n---------------------\nThird-Party Software Licenses\nThis section contains third-party software notices and/or additional\nterms for licensed third-party software components included within ICU\nlibraries.\n1. ICU License - ICU 1.8.1 to ICU 57.1\nCOPYRIGHT AND PERMISSION NOTICE\nCopyright (c) 1995-2016 International Business Machines Corporation and others\nAll rights reserved.\nPermission is hereby granted, free of charge, to any person obtaining\na copy of this software and associated documentation files (the\n&quot;Software&quot;), to deal in the Software without restriction, including\nwithout limitation the rights to use, copy, modify, merge, publish,\ndistribute, and/or sell copies of the Software, and to permit persons\nto whom the Software is furnished to do so, provided that the above\ncopyright notice(s) and this permission notice appear in all copies of\nthe Software and that both the above copyright notice(s) and this\npermission notice appear in supporting documentation.\nTHE SOFTWARE IS PROVIDED &quot;AS IS&quot;, WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT\nOF THIRD PARTY RIGHTS. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR\nHOLDERS INCLUDED IN THIS NOTICE BE LIABLE FOR ANY CLAIM, OR ANY\nSPECIAL INDIRECT OR CONSEQUENTIAL DAMAGES, OR ANY DAMAGES WHATSOEVER\nRESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF\nCONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN\nCONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.\nExcept as contained in this notice, the name of a copyright holder\nshall not be used in advertising or otherwise to promote the sale, use\nor other dealings in this Software without prior written authorization\nof the copyright holder.\nAll trademarks and registered trademarks mentioned herein are the\nproperty of their respective owners.\n2. Chinese/Japanese Word Break Dictionary Data (cjdict.txt)\n# The Google Chrome software developed by Google is licensed under\n# the BSD license. Other software included in this distribution is\n# provided under other licenses, as set forth below.\n#\n# The BSD License\n# http://opensource.org/licenses/bsd-license.php\n# Copyright (C) 2006-2008, Google Inc.\n#\n# All rights reserved.\n#\n# Redistribution and use in source and binary forms, with or without\n# modification, are permitted provided that the following conditions are met:\n#\n# Redistributions of source code must retain the above copyright notice,\n# this list of conditions and the following disclaimer.\n# Redistributions in binary form must reproduce the above\n# copyright notice, this list of conditions and the following\n# disclaimer in the documentation and/or other materials provided with\n# the distribution.\n# Neither the name of Google Inc. nor the names of its\n# contributors may be used to endorse or promote products derived from\n# this software without specific prior written permission.\n#\n#\n# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND\n# CONTRIBUTORS &quot;AS IS&quot; AND ANY EXPRESS OR IMPLIED WARRANTIES,\n# INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF\n# MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n# DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE\n# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR\n# BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF\n# LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING\n# NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\n# SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n#\n#\n# The word list in cjdict.txt are generated by combining three word lists\n# listed below with further processing for compound word breaking. The\n# frequency is generated with an iterative training against Google web\n# corpora.\n#\n# * Libtabe (Chinese)\n# - https://sourceforge.net/project/?group_id=1519\n# - Its license terms and conditions are shown below.\n#\n# * IPADIC (Japanese)\n# - http://chasen.aist-nara.ac.jp/chasen/distribution.html\n# - Its license terms and conditions are shown below.\n#\n# ---------COPYING.libtabe ---- BEGIN--------------------\n#\n# /*\n# * Copyright (c) 1999 TaBE Project.\n# * Copyright (c) 1999 Pai-Hsiang Hsiao.\n# * All rights reserved.\n# *\n# * Redistribution and use in source and binary forms, with or without\n# * modification, are permitted provided that the following conditions\n# * are met:\n# *\n# * . Redistributions of source code must retain the above copyright\n# * notice, this list of conditions and the following disclaimer.\n# * . Redistributions in binary form must reproduce the above copyright\n# * notice, this list of conditions and the following disclaimer in\n# * the documentation and/or other materials provided with the\n# * distribution.\n# * . Neither the name of the TaBE Project nor the names of its\n# * contributors may be used to endorse or promote products derived\n# * from this software without specific prior written permission.\n# *\n# * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n# * &quot;AS IS&quot; AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n# * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS\n# * FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE\n# * REGENTS OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,\n# * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n# * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n# * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)\n# * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,\n# * STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n# * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED\n# * OF THE POSSIBILITY OF SUCH DAMAGE.\n# */\n#\n# /*\n# * Copyright (c) 1999 Computer Systems and Communication Lab,\n# * Institute of Information Science, Academia\n# * Sinica. All rights reserved.\n# *\n# * Redistribution and use in source and binary forms, with or without\n# * modification, are permitted provided that the following conditions\n# * are met:\n# *\n# * . Redistributions of source code must retain the above copyright\n# * notice, this list of conditions and the following disclaimer.\n# * . Redistributions in binary form must reproduce the above copyright\n# * notice, this list of conditions and the following disclaimer in\n# * the documentation and/or other materials provided with the\n# * distribution.\n# * . Neither the name of the Computer Systems and Communication Lab\n# * nor the names of its contributors may be used to endorse or\n# * promote products derived from this software without specific\n# * prior written permission.\n# *\n# * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n# * &quot;AS IS&quot; AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n# * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS\n# * FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE\n# * REGENTS OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,\n# * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n# * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n# * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)\n# * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,\n# * STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n# * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED\n# * OF THE POSSIBILITY OF SUCH DAMAGE.\n# */\n#\n# Copyright 1996 Chih-Hao Tsai @ Beckman Institute,\n# University of Illinois\n# c-tsai4@uiuc.edu http://casper.beckman.uiuc.edu/~c-tsai4\n#\n# ---------------COPYING.libtabe-----END--------------------------------\n#\n#\n# ---------------COPYING.ipadic-----BEGIN-------------------------------\n#\n# Copyright 2000, 2001, 2002, 2003 Nara Institute of Science\n# and Technology. All Rights Reserved.\n#\n# Use, reproduction, and distribution of this software is permitted.\n# Any copy of this software, whether in its original form or modified,\n# must include both the above copyright notice and the following\n# paragraphs.\n#\n# Nara Institute of Science and Technology (NAIST),\n# the copyright holders, disclaims all warranties with regard to this\n# software, including all implied warranties of merchantability and\n# fitness, in no event shall NAIST be liable for\n# any special, indirect or consequential damages or any damages\n# whatsoever resulting from loss of use, data or profits, whether in an\n# action of contract, negligence or other tortuous action, arising out\n# of or in connection with the use or performance of this software.\n#\n# A large portion of the dictionary entries\n# originate from ICOT Free Software. The following conditions for ICOT\n# Free Software applies to the current dictionary as well.\n#\n# Each User may also freely distribute the Program, whether in its\n# original form or modified, to any third party or parties, PROVIDED\n# that the provisions of Section 3 (&quot;NO WARRANTY&quot;) will ALWAYS appear\n# on, or be attached to, the Program, which is distributed substantially\n# in the same form as set out herein and that such intended\n# distribution, if actually made, will neither violate or otherwise\n# contravene any of the laws and regulations of the countries having\n# jurisdiction over the User or the intended distribution itself.\n#\n# NO WARRANTY\n#\n# The program was produced on an experimental basis in the course of the\n# research and development conducted during the project and is provided\n# to users as so produced on an experimental basis. Accordingly, the\n# program is provided without any warranty whatsoever, whether express,\n# implied, statutory or otherwise. The term &quot;warranty&quot; used herein\n# includes, but is not limited to, any warranty of the quality,\n# performance, merchantability and fitness for a particular purpose of\n# the program and the nonexistence of any infringement or violation of\n# any right of any third party.\n#\n# Each user of the program will agree and understand, and be deemed to\n# have agreed and understood, that there is no warranty whatsoever for\n# the program and, accordingly, the entire risk arising from or\n# otherwise connected with the program is assumed by the user.\n#\n# Therefore, neither ICOT, the copyright holder, or any other\n# organization that participated in or was otherwise related to the\n# development of the program and their respective officials, directors,\n# officers and other employees shall be held liable for any and all\n# damages, including, without limitation, general, special, incidental\n# and consequential damages, arising out of or otherwise in connection\n# with the use or inability to use the program or any product, material\n# or result produced or otherwise obtained by using the program,\n# regardless of whether they have been advised of, or otherwise had\n# knowledge of, the possibility of such damages at any time during the\n# project or thereafter. Each user will be deemed to have agreed to the\n# foregoing by his or her commencement of use of the program. The term\n# &quot;use&quot; as used herein includes, but is not limited to, the use,\n# modification, copying and distribution of the program and the\n# production of secondary products from the program.\n#\n# In the case where the program, whether in its original form or\n# modified, was distributed or delivered to or received by a user from\n# any person, organization or entity other than ICOT, unless it makes or\n# grants independently of ICOT any specific warranty to the user in\n# writing, such person, organization or entity, will also be exempted\n# from and not be held liable to the user for any such damages as noted\n# above as far as the program is concerned.\n#\n# ---------------COPYING.ipadic-----END----------------------------------\n3. Lao Word Break Dictionary Data (laodict.txt)\n# Copyright (c) 2013 International Business Machines Corporation\n# and others. All Rights Reserved.\n#\n# Project: http://code.google.com/p/lao-dictionary/\n# Dictionary: http://lao-dictionary.googlecode.com/git/Lao-Dictionary.txt\n# License: http://lao-dictionary.googlecode.com/git/Lao-Dictionary-LICENSE.txt\n# (copied below)\n#\n# This file is derived from the above dictionary, with slight\n# modifications.\n# ----------------------------------------------------------------------\n# Copyright (C) 2013 Brian Eugene Wilson, Robert Martin Campbell.\n# All rights reserved.\n#\n# Redistribution and use in source and binary forms, with or without\n# modification,\n# are permitted provided that the following conditions are met:\n#\n#\n# Redistributions of source code must retain the above copyright notice, this\n# list of conditions and the following disclaimer. Redistributions in\n# binary form must reproduce the above copyright notice, this list of\n# conditions and the following disclaimer in the documentation and/or\n# other materials provided with the distribution.\n#\n#\n# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n# &quot;AS IS&quot; AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n# LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS\n# FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE\n# COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT,\n# INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n# (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n# SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)\n# HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,\n# STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED\n# OF THE POSSIBILITY OF SUCH DAMAGE.\n# --------------------------------------------------------------------------\n4. Burmese Word Break Dictionary Data (burmesedict.txt)\n# Copyright (c) 2014 International Business Machines Corporation\n# and others. All Rights Reserved.\n#\n# This list is part of a project hosted at:\n# github.com/kanyawtech/myanmar-karen-word-lists\n#\n# --------------------------------------------------------------------------\n# Copyright (c) 2013, LeRoy Benjamin Sharon\n# All rights reserved.\n#\n# Redistribution and use in source and binary forms, with or without\n# modification, are permitted provided that the following conditions\n# are met: Redistributions of source code must retain the above\n# copyright notice, this list of conditions and the following\n# disclaimer. Redistributions in binary form must reproduce the\n# above copyright notice, this list of conditions and the following\n# disclaimer in the documentation and/or other materials provided\n# with the distribution.\n#\n# Neither the name Myanmar Karen Word Lists, nor the names of its\n# contributors may be used to endorse or promote products derived\n# from this software without specific prior written permission.\n#\n# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND\n# CONTRIBUTORS &quot;AS IS&quot; AND ANY EXPRESS OR IMPLIED WARRANTIES,\n# INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF\n# MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n# DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS\n# BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,\n# EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED\n# TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n# DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON\n# ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR\n# TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF\n# THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF\n# SUCH DAMAGE.\n# --------------------------------------------------------------------------\n5. Time Zone Database\nICU uses the public domain data and code derived from Time Zone\nDatabase for its time zone support. The ownership of the TZ database\nis explained in BCP 175: Procedure for Maintaining the Time Zone\nDatabase section 7.\n# 7. Database Ownership\n#\n# The TZ database itself is not an IETF Contribution or an IETF\n# document. Rather it is a pre-existing and regularly updated work\n# that is in the public domain, and is intended to remain in the\n# public domain. Therefore, BCPs 78 [RFC5378] and 79 [RFC3979] do\n# not apply to the TZ Database or contributions that individuals make\n# to it. Should any claims be made and substantiated against the TZ\n# Database, the organization that is providing the IANA\n# Considerations defined in this RFC, under the memorandum of\n# understanding with the IETF, currently ICANN, may act in accordance\n# with all competent court orders. No ownership claims will be made\n# by ICANN or the IETF Trust on the database or the code. Any person\n# making a contribution to the database or code waives all rights to\n# future claims in that contribution or in the TZ Database.\n6. Google double-conversion\nCopyright 2006-2011, the V8 project authors. All rights reserved.\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are\nmet:\n* Redistributions of source code must retain the above copyright\nnotice, this list of conditions and the following disclaimer.\n* Redistributions in binary form must reproduce the above\ncopyright notice, this list of conditions and the following\ndisclaimer in the documentation and/or other materials provided\nwith the distribution.\n* Neither the name of Google Inc. nor the names of its\ncontributors may be used to endorse or promote products derived\nfrom this software without specific prior written permission.\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n&quot;AS IS&quot; AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\nLIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\nA PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\nOWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\nSPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\nLIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\nDATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\nTHEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n&quot;&quot;&quot;\n- libuv, located at deps/uv, is licensed as follows:\n&quot;&quot;&quot;\nlibuv is licensed for use as follows:\n====\nCopyright (c) 2015-present libuv project contributors.\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the &quot;Software&quot;), to\ndeal in the Software without restriction, including without limitation the\nrights to use, copy, modify, merge, publish, distribute, sublicense, and/or\nsell copies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED &quot;AS IS&quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\nFROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\nIN THE SOFTWARE.\n====\nThis license applies to parts of libuv originating from the\nhttps://github.com/joyent/libuv repository:\n====\nCopyright Joyent, Inc. and other Node contributors. All rights reserved.\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the &quot;Software&quot;), to\ndeal in the Software without restriction, including without limitation the\nrights to use, copy, modify, merge, publish, distribute, sublicense, and/or\nsell copies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED &quot;AS IS&quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\nFROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\nIN THE SOFTWARE.\n====\nThis license applies to all parts of libuv that are not externally\nmaintained libraries.\nThe externally maintained libraries used by libuv are:\n- tree.h (from FreeBSD), copyright Niels Provos. Two clause BSD license.\n- inet_pton and inet_ntop implementations, contained in src/inet.c, are\ncopyright the Internet Systems Consortium, Inc., and licensed under the ISC\nlicense.\n- stdint-msvc2008.h (from msinttypes), copyright Alexander Chemeris. Three\nclause BSD license.\n- pthread-fixes.c, copyright Google Inc. and Sony Mobile Communications AB.\nThree clause BSD license.\n- android-ifaddrs.h, android-ifaddrs.c, copyright Berkeley Software Design\nInc, Kenneth MacKay and Emergya (Cloud4all, FP7/2007-2013, grant agreement\nn&#xB0; 289016). Three clause BSD license.\n&quot;&quot;&quot;\n- llhttp, located at deps/llhttp, is licensed as follows:\n&quot;&quot;&quot;\nThis software is licensed under the MIT License.\nCopyright Fedor Indutny, 2018.\nPermission is hereby granted, free of charge, to any person obtaining a\ncopy of this software and associated documentation files (the\n&quot;Software&quot;), to deal in the Software without restriction, including\nwithout limitation the rights to use, copy, modify, merge, publish,\ndistribute, sublicense, and/or sell copies of the Software, and to permit\npersons to whom the Software is furnished to do so, subject to the\nfollowing conditions:\nThe above copyright notice and this permission notice shall be included\nin all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED &quot;AS IS&quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS\nOR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\nNO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\nDAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\nOTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\nUSE OR OTHER DEALINGS IN THE SOFTWARE.\n&quot;&quot;&quot;\n- OpenSSL, located at deps/openssl, is licensed as follows:\n&quot;&quot;&quot;\nCopyright (c) 1998-2019 The OpenSSL Project. All rights reserved.\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions\nare met:\n1. Redistributions of source code must retain the above copyright\nnotice, this list of conditions and the following disclaimer.\n2. Redistributions in binary form must reproduce the above copyright\nnotice, this list of conditions and the following disclaimer in\nthe documentation and/or other materials provided with the\ndistribution.\n3. All advertising materials mentioning features or use of this\nsoftware must display the following acknowledgment:\n&quot;This product includes software developed by the OpenSSL Project\nfor use in the OpenSSL Toolkit. (http://www.openssl.org/)&quot;\n4. The names &quot;OpenSSL Toolkit&quot; and &quot;OpenSSL Project&quot; must not be used to\nendorse or promote products derived from this software without\nprior written permission. For written permission, please contact\nopenssl-core@openssl.org.\n5. Products derived from this software may not be called &quot;OpenSSL&quot;\nnor may &quot;OpenSSL&quot; appear in their names without prior written\npermission of the OpenSSL Project.\n6. Redistributions of any form whatsoever must retain the following\nacknowledgment:\n&quot;This product includes software developed by the OpenSSL Project\nfor use in the OpenSSL Toolkit (http://www.openssl.org/)&quot;\nTHIS SOFTWARE IS PROVIDED BY THE OpenSSL PROJECT ``AS IS&apos;&apos; AND ANY\nEXPRESSED OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR\nPURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE OpenSSL PROJECT OR\nITS CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\nSPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\nNOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\nLOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)\nHOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,\nSTRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\nARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED\nOF THE POSSIBILITY OF SUCH DAMAGE.\n====================================================================\nThis product includes cryptographic software written by Eric Young\n(eay@cryptsoft.com). This product includes software written by Tim\nHudson (tjh@cryptsoft.com).\n&quot;&quot;&quot;\n- Punycode.js, located at lib/punycode.js, is licensed as follows:\n&quot;&quot;&quot;\nCopyright Mathias Bynens &lt;https://mathiasbynens.be/&gt;\nPermission is hereby granted, free of charge, to any person obtaining\na copy of this software and associated documentation files (the\n&quot;Software&quot;), to deal in the Software without restriction, including\nwithout limitation the rights to use, copy, modify, merge, publish,\ndistribute, sublicense, and/or sell copies of the Software, and to\npermit persons to whom the Software is furnished to do so, subject to\nthe following conditions:\nThe above copyright notice and this permission notice shall be\nincluded in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED &quot;AS IS&quot;, WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\nNONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\nLIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\nOF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\nWITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n&quot;&quot;&quot;\n- V8, located at deps/v8, is licensed as follows:\n&quot;&quot;&quot;\nThis license applies to all parts of V8 that are not externally\nmaintained libraries. The externally maintained libraries used by V8\nare:\n- PCRE test suite, located in\ntest/mjsunit/third_party/regexp-pcre/regexp-pcre.js. This is based on the\ntest suite from PCRE-7.3, which is copyrighted by the University\nof Cambridge and Google, Inc. The copyright notice and license\nare embedded in regexp-pcre.js.\n- Layout tests, located in test/mjsunit/third_party/object-keys. These are\nbased on layout tests from webkit.org which are copyrighted by\nApple Computer, Inc. and released under a 3-clause BSD license.\n- Strongtalk assembler, the basis of the files assembler-arm-inl.h,\nassembler-arm.cc, assembler-arm.h, assembler-ia32-inl.h,\nassembler-ia32.cc, assembler-ia32.h, assembler-x64-inl.h,\nassembler-x64.cc, assembler-x64.h, assembler-mips-inl.h,\nassembler-mips.cc, assembler-mips.h, assembler.cc and assembler.h.\nThis code is copyrighted by Sun Microsystems Inc. and released\nunder a 3-clause BSD license.\n- Valgrind client API header, located at src/third_party/valgrind/valgrind.h\nThis is released under the BSD license.\n- The Wasm C/C++ API headers, located at third_party/wasm-api/wasm.{h,hh}\nThis is released under the Apache license. The API&apos;s upstream prototype\nimplementation also formed the basis of V8&apos;s implementation in\nsrc/wasm/c-api.cc.\nThese libraries have their own licenses; we recommend you read them,\nas their terms may differ from the terms below.\nFurther license information can be found in LICENSE files located in\nsub-directories.\nCopyright 2014, the V8 project authors. All rights reserved.\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are\nmet:\n* Redistributions of source code must retain the above copyright\nnotice, this list of conditions and the following disclaimer.\n* Redistributions in binary form must reproduce the above\ncopyright notice, this list of conditions and the following\ndisclaimer in the documentation and/or other materials provided\nwith the distribution.\n* Neither the name of Google Inc. nor the names of its\ncontributors may be used to endorse or promote products derived\nfrom this software without specific prior written permission.\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n&quot;AS IS&quot; AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\nLIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\nA PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\nOWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\nSPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\nLIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\nDATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\nTHEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n&quot;&quot;&quot;\n- SipHash, located at deps/v8/src/third_party/siphash, is licensed as follows:\n&quot;&quot;&quot;\nSipHash reference C implementation\nCopyright (c) 2016 Jean-Philippe Aumasson &lt;jeanphilippe.aumasson@gmail.com&gt;\nTo the extent possible under law, the author(s) have dedicated all\ncopyright and related and neighboring rights to this software to the public\ndomain worldwide. This software is distributed without any warranty.\n&quot;&quot;&quot;\n- zlib, located at deps/zlib, is licensed as follows:\n&quot;&quot;&quot;\nzlib.h -- interface of the &apos;zlib&apos; general purpose compression library\nversion 1.2.11, January 15th, 2017\nCopyright (C) 1995-2017 Jean-loup Gailly and Mark Adler\nThis software is provided &apos;as-is&apos;, without any express or implied\nwarranty. In no event will the authors be held liable for any damages\narising from the use of this software.\nPermission is granted to anyone to use this software for any purpose,\nincluding commercial applications, and to alter it and redistribute it\nfreely, subject to the following restrictions:\n1. The origin of this software must not be misrepresented; you must not\nclaim that you wrote the original software. If you use this software\nin a product, an acknowledgment in the product documentation would be\nappreciated but is not required.\n2. Altered source versions must be plainly marked as such, and must not be\nmisrepresented as being the original software.\n3. This notice may not be removed or altered from any source distribution.\nJean-loup Gailly Mark Adler\njloup@gzip.org madler@alumni.caltech.edu\n&quot;&quot;&quot;\n- npm, located at deps/npm, is licensed as follows:\n&quot;&quot;&quot;\nThe npm application\nCopyright (c) npm, Inc. and Contributors\nLicensed on the terms of The Artistic License 2.0\nNode package dependencies of the npm application\nCopyright (c) their respective copyright owners\nLicensed on their respective license terms\nThe npm public registry at https://registry.npmjs.org\nand the npm website at https://www.npmjs.com\nOperated by npm, Inc.\nUse governed by terms published on https://www.npmjs.com\n&quot;Node.js&quot;\nTrademark Joyent, Inc., https://joyent.com\nNeither npm nor npm, Inc. are affiliated with Joyent, Inc.\nThe Node.js application\nProject of Node Foundation, https://nodejs.org\nThe npm Logo\nCopyright (c) Mathias Pettersson and Brian Hammond\n&quot;Gubblebum Blocky&quot; typeface\nCopyright (c) Tjarda Koster, https://jelloween.deviantart.com\nUsed with permission\n--------\nThe Artistic License 2.0\nCopyright (c) 2000-2006, The Perl Foundation.\nEveryone is permitted to copy and distribute verbatim copies\nof this license document, but changing it is not allowed.\nPreamble\nThis license establishes the terms under which a given free software\nPackage may be copied, modified, distributed, and/or redistributed.\nThe intent is that the Copyright Holder maintains some artistic\ncontrol over the development of that Package while still keeping the\nPackage available as open source and free software.\nYou are always permitted to make arrangements wholly outside of this\nlicense directly with the Copyright Holder of a given Package. If the\nterms of this license do not permit the full use that you propose to\nmake of the Package, you should contact the Copyright Holder and seek\na different licensing arrangement.\nDefinitions\n&quot;Copyright Holder&quot; means the individual(s) or organization(s)\nnamed in the copyright notice for the entire Package.\n&quot;Contributor&quot; means any party that has contributed code or other\nmaterial to the Package, in accordance with the Copyright Holder&apos;s\nprocedures.\n&quot;You&quot; and &quot;your&quot; means any person who would like to copy,\ndistribute, or modify the Package.\n&quot;Package&quot; means the collection of files distributed by the\nCopyright Holder, and derivatives of that collection and/or of\nthose files. A given Package may consist of either the Standard\nVersion, or a Modified Version.\n&quot;Distribute&quot; means providing a copy of the Package or making it\naccessible to anyone else, or in the case of a company or\norganization, to others outside of your company or organization.\n&quot;Distributor Fee&quot; means any fee that you charge for Distributing\nthis Package or providing support for this Package to another\nparty. It does not mean licensing fees.\n&quot;Standard Version&quot; refers to the Package if it has not been\nmodified, or has been modified only in ways explicitly requested\nby the Copyright Holder.\n&quot;Modified Version&quot; means the Package, if it has been changed, and\nsuch changes were not explicitly requested by the Copyright\nHolder.\n&quot;Original License&quot; means this Artistic License as Distributed with\nthe Standard Version of the Package, in its current version or as\nit may be modified by The Perl Foundation in the future.\n&quot;Source&quot; form means the source code, documentation source, and\nconfiguration files for the Package.\n&quot;Compiled&quot; form means the compiled bytecode, object code, binary,\nor any other form resulting from mechanical transformation or\ntranslation of the Source form.\nPermission for Use and Modification Without Distribution\n(1) You are permitted to use the Standard Version and create and use\nModified Versions for any purpose without restriction, provided that\nyou do not Distribute the Modified Version.\nPermissions for Redistribution of the Standard Version\n(2) You may Distribute verbatim copies of the Source form of the\nStandard Version of this Package in any medium without restriction,\neither gratis or for a Distributor Fee, provided that you duplicate\nall of the original copyright notices and associated disclaimers. At\nyour discretion, such verbatim copies may or may not include a\nCompiled form of the Package.\n(3) You may apply any bug fixes, portability changes, and other\nmodifications made available from the Copyright Holder. The resulting\nPackage will still be considered the Standard Version, and as such\nwill be subject to the Original License.\nDistribution of Modified Versions of the Package as Source\n(4) You may Distribute your Modified Version as Source (either gratis\nor for a Distributor Fee, and with or without a Compiled form of the\nModified Version) provided that you clearly document how it differs\nfrom the Standard Version, including, but not limited to, documenting\nany non-standard features, executables, or modules, and provided that\nyou do at least ONE of the following:\n(a) make the Modified Version available to the Copyright Holder\nof the Standard Version, under the Original License, so that the\nCopyright Holder may include your modifications in the Standard\nVersion.\n(b) ensure that installation of your Modified Version does not\nprevent the user installing or running the Standard Version. In\naddition, the Modified Version must bear a name that is different\nfrom the name of the Standard Version.\n(c) allow anyone who receives a copy of the Modified Version to\nmake the Source form of the Modified Version available to others\nunder\n(i) the Original License or\n(ii) a license that permits the licensee to freely copy,\nmodify and redistribute the Modified Version using the same\nlicensing terms that apply to the copy that the licensee\nreceived, and requires that the Source form of the Modified\nVersion, and of any works derived from it, be made freely\navailable in that license fees are prohibited but Distributor\nFees are allowed.\nDistribution of Compiled Forms of the Standard Version\nor Modified Versions without the Source\n(5) You may Distribute Compiled forms of the Standard Version without\nthe Source, provided that you include complete instructions on how to\nget the Source of the Standard Version. Such instructions must be\nvalid at the time of your distribution. If these instructions, at any\ntime while you are carrying out such distribution, become invalid, you\nmust provide new instructions on demand or cease further distribution.\nIf you provide valid instructions or cease distribution within thirty\ndays after you become aware that the instructions are invalid, then\nyou do not forfeit any of your rights under this license.\n(6) You may Distribute a Modified Version in Compiled form without\nthe Source, provided that you comply with Section 4 with respect to\nthe Source of the Modified Version.\nAggregating or Linking the Package\n(7) You may aggregate the Package (either the Standard Version or\nModified Version) with other packages and Distribute the resulting\naggregation provided that you do not charge a licensing fee for the\nPackage. Distributor Fees are permitted, and licensing fees for other\ncomponents in the aggregation are permitted. The terms of this license\napply to the use and Distribution of the Standard or Modified Versions\nas included in the aggregation.\n(8) You are permitted to link Modified and Standard Versions with\nother works, to embed the Package in a larger work of your own, or to\nbuild stand-alone binary or bytecode versions of applications that\ninclude the Package, and Distribute the result without restriction,\nprovided the result does not expose a direct interface to the Package.\nItems That are Not Considered Part of a Modified Version\n(9) Works (including, but not limited to, modules and scripts) that\nmerely extend or make use of the Package, do not, by themselves, cause\nthe Package to be a Modified Version. In addition, such works are not\nconsidered parts of the Package itself, and are not subject to the\nterms of this license.\nGeneral Provisions\n(10) Any use, modification, and distribution of the Standard or\nModified Versions is governed by this Artistic License. By using,\nmodifying or distributing the Package, you accept this license. Do not\nuse, modify, or distribute the Package, if you do not accept this\nlicense.\n(11) If your Modified Version has been derived from a Modified\nVersion made by someone other than you, you are nevertheless required\nto ensure that your Modified Version complies with the requirements of\nthis license.\n(12) This license does not grant you the right to use any trademark,\nservice mark, tradename, or logo of the Copyright Holder.\n(13) This license includes the non-exclusive, worldwide,\nfree-of-charge patent license to make, have made, use, offer to sell,\nsell, import and otherwise transfer the Package with respect to any\npatent claims licensable by the Copyright Holder that are necessarily\ninfringed by the Package. If you institute patent litigation\n(including a cross-claim or counterclaim) against any party alleging\nthat the Package constitutes direct or contributory patent\ninfringement, then this Artistic License to you shall terminate on the\ndate that such litigation is filed.\n(14) Disclaimer of Warranty:\nTHE PACKAGE IS PROVIDED BY THE COPYRIGHT HOLDER AND CONTRIBUTORS &quot;AS\nIS&apos; AND WITHOUT ANY EXPRESS OR IMPLIED WARRANTIES. THE IMPLIED\nWARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, OR\nNON-INFRINGEMENT ARE DISCLAIMED TO THE EXTENT PERMITTED BY YOUR LOCAL\nLAW. UNLESS REQUIRED BY LAW, NO COPYRIGHT HOLDER OR CONTRIBUTOR WILL\nBE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL\nDAMAGES ARISING IN ANY WAY OUT OF THE USE OF THE PACKAGE, EVEN IF\nADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n--------\n&quot;&quot;&quot;\n- GYP, located at tools/gyp, is licensed as follows:\n&quot;&quot;&quot;\nCopyright (c) 2009 Google Inc. All rights reserved.\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are\nmet:\n* Redistributions of source code must retain the above copyright\nnotice, this list of conditions and the following disclaimer.\n* Redistributions in binary form must reproduce the above\ncopyright notice, this list of conditions and the following disclaimer\nin the documentation and/or other materials provided with the\ndistribution.\n* Neither the name of Google Inc. nor the names of its\ncontributors may be used to endorse or promote products derived from\nthis software without specific prior written permission.\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n&quot;AS IS&quot; AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\nLIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\nA PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\nOWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\nSPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\nLIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\nDATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\nTHEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n&quot;&quot;&quot;\n- inspector_protocol, located at tools/inspector_protocol, is licensed as follows:\n&quot;&quot;&quot;\n// Copyright 2016 The Chromium Authors. All rights reserved.\n//\n// Redistribution and use in source and binary forms, with or without\n// modification, are permitted provided that the following conditions are\n// met:\n//\n// * Redistributions of source code must retain the above copyright\n// notice, this list of conditions and the following disclaimer.\n// * Redistributions in binary form must reproduce the above\n// copyright notice, this list of conditions and the following disclaimer\n// in the documentation and/or other materials provided with the\n// distribution.\n// * Neither the name of Google Inc. nor the names of its\n// contributors may be used to endorse or promote products derived from\n// this software without specific prior written permission.\n//\n// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n// &quot;AS IS&quot; AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n&quot;&quot;&quot;\n- jinja2, located at tools/inspector_protocol/jinja2, is licensed as follows:\n&quot;&quot;&quot;\nCopyright (c) 2009 by the Jinja Team, see AUTHORS for more details.\nSome rights reserved.\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are\nmet:\n* Redistributions of source code must retain the above copyright\nnotice, this list of conditions and the following disclaimer.\n* Redistributions in binary form must reproduce the above\ncopyright notice, this list of conditions and the following\ndisclaimer in the documentation and/or other materials provided\nwith the distribution.\n* The names of the contributors may not be used to endorse or\npromote products derived from this software without specific\nprior written permission.\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n&quot;AS IS&quot; AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\nLIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\nA PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\nOWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\nSPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\nLIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\nDATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\nTHEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n&quot;&quot;&quot;\n- markupsafe, located at tools/inspector_protocol/markupsafe, is licensed as follows:\n&quot;&quot;&quot;\nCopyright (c) 2010 by Armin Ronacher and contributors. See AUTHORS\nfor more details.\nSome rights reserved.\nRedistribution and use in source and binary forms of the software as well\nas documentation, with or without modification, are permitted provided\nthat the following conditions are met:\n* Redistributions of source code must retain the above copyright\nnotice, this list of conditions and the following disclaimer.\n* Redistributions in binary form must reproduce the above\ncopyright notice, this list of conditions and the following\ndisclaimer in the documentation and/or other materials provided\nwith the distribution.\n* The names of the contributors may not be used to endorse or\npromote products derived from this software without specific\nprior written permission.\nTHIS SOFTWARE AND DOCUMENTATION IS PROVIDED BY THE COPYRIGHT HOLDERS AND\nCONTRIBUTORS &quot;AS IS&quot; AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT\nNOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\nA PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER\nOR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,\nEXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,\nPROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR\nPROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF\nLIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING\nNEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\nSOFTWARE AND DOCUMENTATION, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH\nDAMAGE.\n&quot;&quot;&quot;\n- cpplint.py, located at tools/cpplint.py, is licensed as follows:\n&quot;&quot;&quot;\nCopyright (c) 2009 Google Inc. All rights reserved.\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are\nmet:\n* Redistributions of source code must retain the above copyright\nnotice, this list of conditions and the following disclaimer.\n* Redistributions in binary form must reproduce the above\ncopyright notice, this list of conditions and the following disclaimer\nin the documentation and/or other materials provided with the\ndistribution.\n* Neither the name of Google Inc. nor the names of its\ncontributors may be used to endorse or promote products derived from\nthis software without specific prior written permission.\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n&quot;AS IS&quot; AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\nLIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\nA PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\nOWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\nSPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\nLIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\nDATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\nTHEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n&quot;&quot;&quot;\n- ESLint, located at tools/node_modules/eslint, is licensed as follows:\n&quot;&quot;&quot;\nCopyright JS Foundation and other contributors, https://js.foundation\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the &quot;Software&quot;), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED &quot;AS IS&quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n&quot;&quot;&quot;\n- babel-eslint, located at tools/node_modules/babel-eslint, is licensed as follows:\n&quot;&quot;&quot;\nCopyright (c) 2014-2016 Sebastian McKenzie &lt;sebmck@gmail.com&gt;\nMIT License\nPermission is hereby granted, free of charge, to any person obtaining\na copy of this software and associated documentation files (the\n&quot;Software&quot;), to deal in the Software without restriction, including\nwithout limitation the rights to use, copy, modify, merge, publish,\ndistribute, sublicense, and/or sell copies of the Software, and to\npermit persons to whom the Software is furnished to do so, subject to\nthe following conditions:\nThe above copyright notice and this permission notice shall be\nincluded in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED &quot;AS IS&quot;, WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\nNONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\nLIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\nOF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\nWITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n&quot;&quot;&quot;\n- gtest, located at test/cctest/gtest, is licensed as follows:\n&quot;&quot;&quot;\nCopyright 2008, Google Inc.\nAll rights reserved.\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are\nmet:\n* Redistributions of source code must retain the above copyright\nnotice, this list of conditions and the following disclaimer.\n* Redistributions in binary form must reproduce the above\ncopyright notice, this list of conditions and the following disclaimer\nin the documentation and/or other materials provided with the\ndistribution.\n* Neither the name of Google Inc. nor the names of its\ncontributors may be used to endorse or promote products derived from\nthis software without specific prior written permission.\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n&quot;AS IS&quot; AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\nLIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\nA PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\nOWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\nSPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\nLIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\nDATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\nTHEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n&quot;&quot;&quot;\n- nghttp2, located at deps/nghttp2, is licensed as follows:\n&quot;&quot;&quot;\nThe MIT License\nCopyright (c) 2012, 2014, 2015, 2016 Tatsuhiro Tsujikawa\nCopyright (c) 2012, 2014, 2015, 2016 nghttp2 contributors\nPermission is hereby granted, free of charge, to any person obtaining\na copy of this software and associated documentation files (the\n&quot;Software&quot;), to deal in the Software without restriction, including\nwithout limitation the rights to use, copy, modify, merge, publish,\ndistribute, sublicense, and/or sell copies of the Software, and to\npermit persons to whom the Software is furnished to do so, subject to\nthe following conditions:\nThe above copyright notice and this permission notice shall be\nincluded in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED &quot;AS IS&quot;, WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\nNONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\nLIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\nOF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\nWITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n&quot;&quot;&quot;\n- node-inspect, located at deps/node-inspect, is licensed as follows:\n&quot;&quot;&quot;\nCopyright Node.js contributors. All rights reserved.\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the &quot;Software&quot;), to\ndeal in the Software without restriction, including without limitation the\nrights to use, copy, modify, merge, publish, distribute, sublicense, and/or\nsell copies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED &quot;AS IS&quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\nFROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\nIN THE SOFTWARE.\n&quot;&quot;&quot;\n- large_pages, located at src/large_pages, is licensed as follows:\n&quot;&quot;&quot;\nCopyright (C) 2018 Intel Corporation\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the &quot;Software&quot;),\nto deal in the Software without restriction, including without limitation\nthe rights to use, copy, modify, merge, publish, distribute, sublicense,\nand/or sell copies of the Software, and to permit persons to whom\nthe Software is furnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included\nin all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED &quot;AS IS&quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS\nOR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\nTHE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES\nOR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,\nARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE\nOR OTHER DEALINGS IN THE SOFTWARE.\n&quot;&quot;&quot;\n- caja, located at lib/internal/freeze_intrinsics.js, is licensed as follows:\n&quot;&quot;&quot;\nAdapted from SES/Caja - Copyright (C) 2011 Google Inc.\nCopyright (C) 2018 Agoric\nLicensed under the Apache License, Version 2.0 (the &quot;License&quot;);\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\nhttp://www.apache.org/licenses/LICENSE-2.0\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an &quot;AS IS&quot; BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n&quot;&quot;&quot;\n- brotli, located at deps/brotli, is licensed as follows:\n&quot;&quot;&quot;\nCopyright (c) 2009, 2010, 2013-2016 by the Brotli Authors.\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the &quot;Software&quot;), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED &quot;AS IS&quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n&quot;&quot;&quot;\n- HdrHistogram, located at deps/histogram, is licensed as follows:\n&quot;&quot;&quot;\nThe code in this repository code was Written by Gil Tene, Michael Barker,\nand Matt Warren, and released to the public domain, as explained at\nhttp://creativecommons.org/publicdomain/zero/1.0/\nFor users of this code who wish to consume it under the &quot;BSD&quot; license\nrather than under the public domain or CC0 contribution text mentioned\nabove, the code found under this directory is *also* provided under the\nfollowing license (commonly referred to as the BSD 2-Clause License). This\nlicense does not detract from the above stated release of the code into\nthe public domain, and simply represents an additional license granted by\nthe Author.\n-----------------------------------------------------------------------------\n** Beginning of &quot;BSD 2-Clause License&quot; text. **\nCopyright (c) 2012, 2013, 2014 Gil Tene\nCopyright (c) 2014 Michael Barker\nCopyright (c) 2014 Matt Warren\nAll rights reserved.\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n1. Redistributions of source code must retain the above copyright notice,\nthis list of conditions and the following disclaimer.\n2. Redistributions in binary form must reproduce the above copyright notice,\nthis list of conditions and the following disclaimer in the documentation\nand/or other materials provided with the distribution.\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\nARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE\nLIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\nCONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\nSUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\nINTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\nCONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\nARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF\nTHE POSSIBILITY OF SUCH DAMAGE.\n&quot;&quot;&quot;\n- node-heapdump, located at src/heap_utils.cc, is licensed as follows:\n&quot;&quot;&quot;\nISC License\nCopyright (c) 2012, Ben Noordhuis &lt;info@bnoordhuis.nl&gt;\nPermission to use, copy, modify, and/or distribute this software for any\npurpose with or without fee is hereby granted, provided that the above\ncopyright notice and this permission notice appear in all copies.\nTHE SOFTWARE IS PROVIDED &quot;AS IS&quot; AND THE AUTHOR DISCLAIMS ALL WARRANTIES\nWITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF\nMERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR\nANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES\nWHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN\nACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF\nOR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.\n=== src/compat.h src/compat-inl.h ===\nISC License\nCopyright (c) 2014, StrongLoop Inc.\nPermission to use, copy, modify, and/or distribute this software for any\npurpose with or without fee is hereby granted, provided that the above\ncopyright notice and this permission notice appear in all copies.\nTHE SOFTWARE IS PROVIDED &quot;AS IS&quot; AND THE AUTHOR DISCLAIMS ALL WARRANTIES\nWITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF\nMERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR\nANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES\nWHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN\nACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF\nOR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.\n&quot;&quot;&quot;\n- rimraf, located at lib/internal/fs/rimraf.js, is licensed as follows:\n&quot;&quot;&quot;\nThe ISC License\nCopyright (c) Isaac Z. Schlueter and Contributors\nPermission to use, copy, modify, and/or distribute this software for any\npurpose with or without fee is hereby granted, provided that the above\ncopyright notice and this permission notice appear in all copies.\nTHE SOFTWARE IS PROVIDED &quot;AS IS&quot; AND THE AUTHOR DISCLAIMS ALL WARRANTIES\nWITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF\nMERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR\nANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES\nWHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN\nACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR\nIN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.\n&quot;&quot;&quot;\n- uvwasi, located at deps/uvwasi, is licensed as follows:\n&quot;&quot;&quot;\nMIT License\nCopyright (c) 2019 Colin Ihrig and Contributors\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the &quot;Software&quot;), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED &quot;AS IS&quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n&quot;&quot;&quot;\n"},{"id":346,"path":"../website/pages/docs/devonfw-ide-support.asciidoc.html#license.asciidoc_microsoft-software-license-terms","type":"docs","title":"MICROSOFT SOFTWARE LICENSE TERMS","body":"7.2.12. MICROSOFT SOFTWARE LICENSE TERMS\nMICROSOFT VISUAL STUDIO CODE\nThese license terms are an agreement between you and Microsoft Corporation (or based on where you live, one of its affiliates). They apply to the software named above. The terms also apply to any Microsoft services or updates for the software, except to the extent those have different terms.\nIF YOU COMPLY WITH THESE LICENSE TERMS, YOU HAVE THE RIGHTS BELOW.\n1. INSTALLATION AND USE RIGHTS.\na. General. You may use any number of copies of the software to develop and test your applications, including deployment within your internal corporate network.\nb. Demo use. The uses permitted above include use of the software in demonstrating your applications.\nc. Third Party Components. The software may include third party components with separate legal notices or governed by other agreements, as may be described in the ThirdPartyNotices file accompanying the software.\nd. Extensions. The software gives you the option to download other Microsoft and third party software packages from our extension marketplace or package managers. Those packages are under their own licenses, and not this agreement. Microsoft does not distribute, license or provide any warranties for any of the third party packages. By accessing or using our extension marketplace, you agree to the extension marketplace terms located at https://aka.ms/vsmarketplace-ToU.\n2. DATA.\na. Data Collection. The software may collect information about you and your use of the software, and send that to Microsoft. Microsoft may use this information to provide services and improve our products and services. You may opt-out of many of these scenarios, but not all, as described in the product documentation located at https://code.visualstudio.com/docs/supporting/faq#_how-to-disable-telemetry-reporting. There may also be some features in the software that may enable you and Microsoft to collect data from users of your applications. If you use these features, you must comply with applicable law, including providing appropriate notices to users of your applications together with Microsoft&#x2019;s privacy statement. Our privacy statement is located at https://go.microsoft.com/fwlink/?LinkID=824704. You can learn more about data collection and use in the help documentation and our privacy statement. Your use of the software operates as your consent to these practices.\nc. Processing of Personal Data. To the extent Microsoft is a processor or subprocessor of personal data in connection with the software, Microsoft makes the commitments in the European Union General Data Protection Regulation Terms of the Online Services Terms to all customers effective May 25, 2018, at https://go.microsoft.com/?linkid=9840733.\n3. UPDATES. The software may periodically check for updates and download and install them for you. You may obtain updates only from Microsoft or authorized sources. Microsoft may need to update your system to provide you with updates. You agree to receive these automatic updates without any additional notice. Updates may not include or support all existing software features, services, or peripheral devices. If you do not want automatic updates, you may turn them off by following the instructions in the documentation at https://go.microsoft.com/fwlink/?LinkID=616397.\n4. FEEDBACK. If you give feedback about the software to Microsoft, you give to Microsoft, without charge, the right to use, share and commercialize your feedback in any way and for any purpose. You will not give feedback that is subject to a license that requires Microsoft to license its software or documentation to third parties because we include your feedback in them. These rights survive this agreement.\n5. SCOPE OF LICENSE. This license applies to the Visual Studio Code product. Source code for Visual Studio Code is available at https://github.com/Microsoft/vscode under the MIT license agreement. The software is licensed, not sold. This agreement only gives you some rights to use the software. Microsoft reserves all other rights. Unless applicable law gives you more rights despite this limitation, you may use the software only as expressly permitted in this agreement. In doing so, you must comply with any technical limitations in the software that only allow you to use it in certain ways. You may not\nreverse engineer, decompile or disassemble the software, or otherwise attempt to derive the source code for the software except and solely to the extent required by third party licensing terms governing use of certain open source components that may be included in the software;\nremove, minimize, block or modify any notices of Microsoft or its suppliers in the software;\nuse the software in any way that is against the law;\nshare, publish, rent or lease the software, or provide the software as a stand-alone offering for others to use.\n6. SUPPORT SERVICES. Because this software is &#x201C;as is,&#x201D; we may not provide support services for it.\n7. ENTIRE AGREEMENT. This agreement, and the terms for supplements, updates, Internet-based services and support services that you use, are the entire agreement for the software and support services.\n8. EXPORT RESTRICTIONS. You must comply with all domestic and international export laws and regulations that apply to the software, which include restrictions on destinations, end-users, and end use. For further information on export restrictions, see https://www.microsoft.com/exporting.\n9. APPLICABLE LAW. If you acquired the software in the United States, Washington law applies to interpretation of and claims for breach of this agreement, and the laws of the state where you live apply to all other claims. If you acquired the software in any other country, its laws apply.\n10. CONSUMER RIGHTS; REGIONAL VARIATIONS. This agreement describes certain legal rights. You may have other rights, including consumer rights, under the laws of your state or country. Separate and apart from your relationship with Microsoft, you may also have rights with respect to the party from which you acquired the software. This agreement does not change those other rights if the laws of your state or country do not permit it to do so. For example, if you acquired the software in one of the below regions, or mandatory country law applies, then the following provisions apply to you:\na. Australia. You have statutory guarantees under the Australian Consumer Law and nothing in this agreement is intended to affect those rights.\nb. Canada. If you acquired this software in Canada, you may stop receiving updates by turning off the automatic update feature, disconnecting your device from the Internet (if and when you re-connect to the Internet, however, the software will resume checking for and installing updates), or uninstalling the software. The product documentation, if any, may also specify how to turn off updates for your specific device or software.\nc. Germany and Austria.\nWarranty. The properly licensed software will perform substantially as described in any Microsoft materials that accompany the software. However, Microsoft gives no contractual guarantee in relation to the licensed software.\nLimitation of Liability. In case of intentional conduct, gross negligence, claims based on the Product Liability Act, as well as, in case of death or personal or physical injury, Microsoft is liable according to the statutory law.\nSubject to the foregoing clause (ii), Microsoft will only be liable for slight negligence if Microsoft is in breach of such material contractual obligations, the fulfillment of which facilitate the due performance of this agreement, the breach of which would endanger the purpose of this agreement and the compliance with which a party may constantly trust in (so-called &quot;cardinal obligations&quot;). In other cases of slight negligence, Microsoft will not be liable for slight negligence.\n11. DISCLAIMER OF WARRANTY. The software is licensed &#x201C;as-is.&#x201D; You bear the risk of using it. Microsoft gives no express warranties, guarantees or conditions. To the extent permitted under your local laws, Microsoft excludes the implied warranties of merchantability, fitness for a particular purpose and non-infringement.\n12. LIMITATION ON AND EXCLUSION OF DAMAGES. You can recover from Microsoft and its suppliers only direct damages up to U.S. $5.00. You cannot recover any other damages, including consequential, lost profits, special, indirect or incidental damages.\nThis limitation applies to (a) anything related to the software, services, content (including code) on third party Internet sites, or third party applications; and (b) claims for breach of contract, breach of warranty, guarantee or condition, strict liability, negligence, or other tort to the extent permitted by applicable law.\nIt also applies even if Microsoft knew or should have known about the possibility of the damages. The above limitation or exclusion may not apply to you because your state or country may not allow the exclusion or limitation of incidental, consequential or other damages.\n&#x2190;&#xA0;Previous:&#xA0;Advanced Features&#xA0;| &#x2191;&#xA0;Up:&#xA0;devonfw-ide&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;devonfw for Java (devon4j)&#xA0;&#x2192;\n"},{"id":347,"path":"../website/pages/docs/devonfw-ide-usage.asciidoc.html#devonfw-ide-usage.asciidoc","type":"docs","title":"Usage","body":"5. Usage\n"},{"id":348,"path":"../website/pages/docs/devonfw-ide-usage.asciidoc.html#usage.asciidoc","type":"docs","title":"Roles","body":"5.1. Roles\nThis section is designed to explain devonfw-ide depending on each role\nEverybody should read and follow the usage for developer.\nIn case you want to administrate devonfw-ide settings for your project, you should also read the usage for the ide-admin.\n"},{"id":349,"path":"../website/pages/docs/devonfw-ide-usage.asciidoc.html#usage.asciidoc_developer","type":"docs","title":"Developer","body":"5.1.1. Developer\nAs a developer you are supported to setup your IDE automated and fast while you can have a nice cup of coffee (after you provided settings-URL and accepted the license).\nYou only need the settings URL from your ide-admin.\nExperienced developers can directly call setup &#xAB;settings-URL&#xBB;.\nOtherwise if you just call setup (e.g. by double-clicking it), you can enter it when you are prompted for Settings URL (using copy&amp;paste to avoid typos).\nNote: devonfw-ide supports autocompletion (since 2021.04.001). Currently this only works in bash (on windows use git bash). Simply type devon and hit [Tab] to get completion.\nUpdate\nTo update your IDE (if instructed by your ide-admin), you only need to run the following command:\ndevon ide update\nPlease note that windows is using file-locking what can have ugly side-effects.\nTo be safe, you should have your IDE tools shut down before invoking the above update command.\nE.g. if a tool needs to be updated, the old installation folder will be moved to a backup and the new version is installed on top.\nIf there are windows file locks in place this can fail and mess up things.\nYou can still delete the according installation from your software folder and rerun devon ide update if you ran into this error.\nWorking with multiple workspaces\nIf you are working on different branches in parallel you typically want to use multiple workspaces.\nGo to the workspaces folder in your ${DEVON_IDE_HOME} and create a new folder with the name of your choice (e.g. release2.1).\nCheck out (git clone &#x2026;&#x200B;) the according projects and branch into that workspace folder.\nOpen a shell in that new workspace folder (cd to it) and according to your IDE run e.g. eclipse, vscode, or intellij to create your workspace and launch the IDE. You can also add the parameter create-script to the IDE commandlet in order to create a launch-script for your IDE.\nYou can have multiple instances of eclipse running for each workspace in parallel. To distinguish these instances you will find the workspace name in the title of eclipse.\n"},{"id":350,"path":"../website/pages/docs/devonfw-ide-usage.asciidoc.html#usage.asciidoc_admin","type":"docs","title":"Admin","body":"5.1.2. Admin\nYou can easily customize and configure devonfw-ide for the requirements of your project.\nIn order to do so, you need to create your own project-specific settings git repository and provide the URL to all developers for the setup.\nWith tools such as gitlab, bitbucket or github every developer can easily propose changes and improvements.\nHowever, we suggest that one team member is responsible to ensure that everything stays consistent and works.\nWe will call this person the ide-admin of your project.\nThe following are the suggested step-by-step instructions how an ide-admin should prepare devonfw-ide for his new project:\nFork ide-settings to a git repository specific for your project (e.g. a new project in the gitlab of your production-line instance). In case you are using github, all you need to do is use the Fork button. In other cases simply create a new and empty git repository and clone this to your machine. Then add the default ide-settings as origin, fetch and pull from it:\ngit remote add upstream https://github.com/devonfw/ide-settings.git\ngit fetch upstream\ngit pull upstream master\ngit push\nNow you should have a full fork as a copy of the settings git repo with all its history that is ready for upstream merges.\nStudy the structure of this git repository to understand where to find which configuration.\nStudy the configuration and understand that general settings can be tweaked in the toplevel devon.properties file of your settings git repository.\nConfigure the tools and their versions for your project. Here is an example:\nDEVON_IDE_TOOLS=(java mvn eclipse)\nECLIPSE_VERSION=2020-06\n# use e.g. 8u242b08 for Java 8\n#JAVA_VERSION=8u242b08\nJAVA_VERSION=11.0.5_10\nMAVEN_VERSION=3.6.2\nThis way you will take over control of the tools and their versions for every developer in your project team and ensure that things get reproducible.\nIn case you need a proprietary or unsupported tool, you can study how to include custom tools.\nIn case you have very restrictive policies about downloading tools from the internet, you can create and configure a software repository for your project or company.\nSome of the tools (espcially the actual IDEs) allow extensions via plugins. You can customize them to your needs for eclipse, VS code, or intelliJ.\nIn your settings git repository you will find a projects folder. Here you will find configurations files for every git project relevant for your actual project. Feel free to create new projects for your needs and delete the devonfw specific default projects. The projects documentation will explain you how to do this.\nFor every IDE you will also find an according folder in your settings git repository. Here are the individual configuration settings for that IDE. You can change them by directly editing the according configuration files directly with a text-editor in your settings git repository. However, this is a really complex way and will take you a lot of time to find the right file and property to tweak for your actual need. Instead we suggest to study\nhow to customize IDE specific settings.\nYou may also create new sub-folders in your settings git repository and put individual things according to your needs. E.g. you could add scripts for greasemonkey or tampermonkey, as well as scripts for your database or whatever may be useful and worth to share in your team. However, to share and maintain knowledge we recommend to use a wiki instead.\nYou may want to customize the Eclipse spellchecker dictionary for your project and your language.\nAll described in the above steps (except the first one) can be used to manage and update the configuration during the project lifecycle.\nHowever, when you have done changes especially in a larger project, please consider the following best-practices to avoid that a large teams gets blocked by a non-functional IDE:\nCommit your changes to a feature-branch.\nFirst test the changes yourself.\nIf all works as expected, pick a pilot user of the team to test the changes from the feature branch (go to settings folder, git fetch, git checkout -t origin/feature/&#xAB;name&#xBB;, devon ide update).\nOnly after that works well for a couple of days, inform the entire team to update.\nAnnounce changes to your team\nIn order to roll out the perfectly configured devonfw-ide to your project initially or when new members join, you only have to provide the Settings URL to the developers of your team.\nYou can also provide a specific branch with Settings URL#branch to use variations of common settings or to test new settings before making them public to the team.\nAfter you changed and tested your settings git repository (main branch), you only need to announce this to your developers (e.g. via email or some communication tool) so that they will can devon ide update and automatically get up-to-date with the latest changes (see update).\nIn case you want to go to a new version of devonfw-ide itself, developers have to call devon ide update scripts.\n"},{"id":351,"path":"../website/pages/docs/devonfw-ide-usage.asciidoc.html#configuration.asciidoc","type":"docs","title":"Configuration","body":"5.2. Configuration\nThe devonfw-ide aims to be highly configurable and flexible. The configuration of the devon command and environment variables takes place via devon.properties files. The following list shows these configuration files in the order they are loaded so files can override variables from files above in the list:\nbuild in defaults (for JAVA_VERSION, ECLIPSE_PLUGINS, etc.)\n~/devon.properties - user specific global defaults (on windows in %USERPROFILE%/devon.properties)\nscripts/devon.properties - defaults provided by devonfw-ide. Never directly modify this file!\ndevon.properties - vendor variables for custom distributions of devonfw-ide-scripts, may e.g. tweak SETTINGS_PATH or predefine SETTINGS_URL.\nsettings/devon.properties (${SETTINGS_PATH}/devon.properties) - project specific configurations from settings.\nworkspaces/${WORKSPACE}/devon.properties - optional workspace specific configurations (especially helpful in projects using docker).\nconf/devon.properties - user specific configurations (e.g. M2_REPO=~/.m2/repository). During setup this file is created by copying a template from ${SETTINGS_PATH}/devon/conf/devon.properties.\nsettings/projects/*.properties- properties to configure project checkout and import\n"},{"id":352,"path":"../website/pages/docs/devonfw-ide-usage.asciidoc.html#configuration.asciidoc_devon.properties","type":"docs","title":"devon.properties","body":"5.2.1. devon.properties\nThe devon.properties files allow to define environment variables in a simple and OS independent way:\n# comments begin with a hash sign (#) and are ignored\nvariable_name=variable_value with space etc.\nvariable_name=${predefined_variable}/folder_name\nvariable values can refer to other variables that are already defined, which will be resolved to their value. You have to used ${&#x2026;&#x200B;} syntax to make it work on all platforms (never use %&#x2026;&#x200B;%, $&#x2026;&#x200B;, or $(&#x2026;&#x200B;) syntax in devon.properties files).\nexport exported_variable=this value will be exported in bash, in windows CMD the export prefix is ignored\nvariable_name=\nthis will unset the specified variable\nvariable_name=~/some/path/and.file\ntilde is resolved to your personal home directory on any OS including windows.\narray_variable=(value1 value2 value3)\nThis will only work properly in bash worlds but as no arrays are used in CMD world of devonfw-ide it does not hurt on windows.\nPlease never surround values with quotes (var=&quot;value&quot;)\nThis format is similar to Java *.properties but does not support advanced features as unicode literals, multi-lined values, etc.\nIn order to know what to configure, have a look at the available variables.\nPlease only tweak configurations that you need to change and take according responsibility. There is a price to pay for flexibility, which means you have to be careful what you do.\nFurther, you can configure maven via conf/settings.xml. To configure your IDE such as eclipse or vscode you can tweak the settings.\n"},{"id":353,"path":"../website/pages/docs/devonfw-ide-usage.asciidoc.html#variables.asciidoc","type":"docs","title":"Variables","body":"5.3. Variables\nThe devonfw-ide defines a set of standard variables to your environment for configuration via variables[.bat] files.\nThese environment variables are described by the following table.\nThose variables printed bold are also exported in your shell (except for windows CMD that does not have such concept). Variables with the value - are not set by default but may be set via configuration to override defaults.\nPlease note that we are trying to minimize any potential side-effect from devonfw-ide to the outside world by reducing the number of variables and only exporting those that are required.\nTable 1. Variables of devonfw-ide\nVariable\nValue\nMeaning\nDEVON_IDE_HOME\ne.g. /projects/my-project\nThe top level directory of your devonfw-ide structure.\nPATH\n$PATH:$DEVON_IDE_HOME/software/java:&#x2026;&#x200B;\nYou system path is adjusted by devon command.\nDEVON_HOME_DIR\n~\nThe platform independent home directory of the current user. In some edge-cases (e.g. in cygwin) this differs from ~ to ensure a central home directory for the user on a single machine in any context or environment.\nDEVON_IDE_TOOLS\n(java mvn node npm)\nList of tools that should be installed and upgraded by default for your current IDE.\nDEVON_IDE_CUSTOM_TOOLS\n-\nList of custom tools that should be installed additionally. See software for further details.\nDEVON_CREATE_START_SCRIPTS\n(eclipse vscode)\nList of IDEs that shall be used by developers in the project and therefore start-scripts are created on setup.\nDEVON_OLD_PATH\n&#x2026;&#x200B;\nA &quot;backup&quot; of PATH before it was extended by devon to allow recovering it. Internal variable that should never be set or tweaked.\nWORKSPACE\nmain\nThe workspace you are currently in. Defaults to main if you are not inside a workspace. Never touch this variable in any varibales file.\nWORKSPACE_PATH\n$DEVON_IDE_HOME/workspaces/$WORKSPACE\nAbsolute path to current workspace. Never touch this variable in any varibales file.\nJAVA_HOME\n$DEVON_IDE_HOME/software/java\nPath to JDK\nSETTINGS_PATH\n$DEVON_IDE_HOME/settings\nPath to your settings. To keep oasp4j-ide legacy behaviour set this to $DEVON_IDE_HOME/workspaces/main/development/settings.\nM2_REPO\n$DEVON_IDE_HOME/conf/.m2/repository\nPath to your local maven repository. For projects without high security demands, you may change this to the maven default ~/.m2/repository and share your repository amongst multiple projects.\nMAVEN_HOME\n$DEVON_IDE_HOME/software/maven\nPath to Maven\nMAVEN_OPTS\n-Xmx512m -Duser.home=$DEVON_IDE_HOME/conf\nMaven options\nDEVON_SOFTWARE_REPOSITORY\n-\nProject specific or custom software-repository.\nDEVON_SOFTWARE_PATH\n-\nGlobally shared user-specific local software installation location.\nECLIPSE_VMARGS\n-Xms128M -Xmx768M -XX:MaxPermSize=256M\nJVM options for Eclipse\ndeprecated: ECLIPSE_PLUGINS\n-\nArray with &quot;feature groups&quot; and &quot;update site URLs&quot; to customize required eclipse plugins. Deprecated - see Eclipse plugins.\n&#xAB;TOOL&#xBB;_VERSION\n-\nThe version of the tool &#xAB;TOOL&#xBB; to install and use (e.g. ECLIPSE_VERSION or MAVEN_VERSION).\n&#xAB;TOOL&#xBB;_BUILD_OPTS\ne.g.clean install\nThe arguments provided to the build-tool &#xAB;TOOL&#xBB; in order to run a build.\n&#xAB;TOOL&#xBB;_RELEASE_OPTS\ne.g.clean deploy -Dchangelist= -Pdeploy\nThe arguments provided to the build-tool &#xAB;TOOL&#xBB; in order to perform a release build.\nDEVON_IDE_TRACE\nIf value is not an empty string, the devonfw-ide scripts will trace each script line executed. For bash two lines output: before and again after expansion. ATTENTION: This is not a regular variable working via devon.properties. Instead manually do export DEVON_IDE_TRACE=true in bash or DEVON_IDE_TRACE=true in windows CMD before running a devon command to get a trace log that you can provide to experts in order to trace down a bug and see what went wrong.\n"},{"id":354,"path":"../website/pages/docs/devonfw-ide-usage.asciidoc.html#cli.asciidoc","type":"docs","title":"Devon CLI","body":"5.4. Devon CLI\nThe devonfw-ide is shipped with a central command devon. The setup will automatically register this command so it is available in any shell on your system. This page describes the Command Line Interface (CLI) of this command.\n"},{"id":355,"path":"../website/pages/docs/devonfw-ide-usage.asciidoc.html#cli.asciidoc_devon","type":"docs","title":"Devon","body":"5.4.1. Devon\nWithout any argument the devon command will determine your DEVON_IDE_HOME and setup your environment variables automatically. In case you are not inside of a devonfw-ide folder the command will echo a message and do nothing.\n[/]$ devon\nYou are not inside a devon IDE installation: /\n[/]$ cd /projects/my-project/workspaces/test/my-git-repo\n[my-git-repo]$ devon\ndevonfw-ide has environment variables have been set for /projects/my-project in workspace main\n[my-git-repo]$ echo $DEVON_IDE_HOME\n/projects/devon\n[my-git-repo]$ echo $JAVA_HOME\n/projects/my-project/software/java\n"},{"id":356,"path":"../website/pages/docs/devonfw-ide-usage.asciidoc.html#cli.asciidoc_commandlets","type":"docs","title":"Commandlets","body":"5.4.2. Commandlets\nThe devon command supports a pluggable set of commandlets. Such commandlet is provided as first argument to the devon command and may take additional arguments:\ndevon &#xAB;commandlet&#xBB; [&#xAB;arg&#xBB;]*\nTechnically, a commandlet is a bash script located in $DEVON_IDE_HOME/scripts/command. So if you want to integrate another tool with devonfw-ide we are awaiting your pull-request.\nEvery commandlet takes the following generic arguments:\nTable 2. Generic arguments of every commandlet\nArgument(s)\nMeaning\n-b or --batch\nrun in non-interactive mode (do not ask any questions).\n-q or --quiet\nbe quiet and avoid output.\nThe following commandlets are currently available:\nbuild\ncobigen\ndocker\neclipse\ngradle\nhelp\nide\nintellij\nionic\njasypt\njava\njenkins\nkubernetes\nmvn\nng\nnode\nnpm\nrelease\nsonar\nvscode\nyarn\n"},{"id":357,"path":"../website/pages/docs/devonfw-ide-usage.asciidoc.html#build.asciidoc","type":"docs","title":"build","body":"5.4.3. build\nThe build commandlet is an abstraction of build systems like maven, gradle, yarn, npm, etc.\nIt will auto-detect your build-system (via existence of files like pom.xml, package.json, etc.). According to this detection it will simply delegate to the according commandlet of the specific build system. If that build-system is not yet available it will be downloaded and installed automatically.\nSo devon build allows users to build any project without bothering about the build-system. Further specific build options can be configured per project. This makes devon build a universal part of every definition of done. Before pushing your changes, please always run the following command to verify the build:\ndevon build\nYou may also supply additional arguments as devon build &#xAB;args&#xBB;. This will simply delegate these arguments to the detected build command (e.g. call mvn &#xAB;args&#xBB;).\n"},{"id":358,"path":"../website/pages/docs/devonfw-ide-usage.asciidoc.html#docker.asciidoc","type":"docs","title":"docker","body":"5.4.4. docker\nThe docker commandlet allows to install and use docker.\nOn Windows WSL 2(Windows Subsystem for Linux) has to be installed properly as a prerequisite.\nThe arguments (devon docker &#xAB;args&#xBB;) are explained by the following table:\nTable 3. Usage of devon docker\nArgument(s)\nMeaning\nsetup\nsetup Docker (install and verify) as per above flow.\n&#xAB;args&#xBB;\ncall docker with the specified arguments. Call docker help for details or use docker directly as preferred.&quot; (&#xAB;args&#xBB;)\n"},{"id":359,"path":"../website/pages/docs/devonfw-ide-usage.asciidoc.html#eclipse.asciidoc","type":"docs","title":"eclipse","body":"5.4.5. eclipse\nThe eclipse commandlet allows to install, configure, and launch the Eclipse IDE.\nTo launch Eclipse for your current workspace and devonfw-ide installation simply run:\ndevon eclipse\nYou may also supply additional arguments as devon eclipse &#xAB;args&#xBB;. These are explained by the following table:\nTable 4. Usage of devon eclipse\nArgument(s)\nMeaning\n--all\nif provided as first arg then to command will be invoked for each workspace\nsetup\nsetup Eclipse (install or update)\nadd-plugin &#xAB;id&#xBB; [&#xAB;url&#xBB;]\ninstall an additional plugin\nrun\nlaunch Eclipse (default if no argument is given)\nstart\nsame as run\nws-up[date]\nupdate workspace\nws-re[verse]\nreverse merge changes from workspace into settings\nws-reverse-add\nreverse merge adding new properties\ncreate-script\ncreate launch script for this IDE, your current workspace and your OS\nThere are variables that can be used for Eclipse. These are explained by the following table:\nTable 5. Variables of devonfw-ide for Eclipse\nVariable\nDefault-Value\nMeaning\nECLIPSE_VERSION\n2020-12\nThe version of the tool Eclipse to install and use.\nECLIPSE_EDITION_TYPE\njava\nThe edition of the tool Eclipse to install and use. You can choose betwenn &apos;java&apos; for standard edition or &apos;jee&apos; for enterprise edition.\nplugins\nTo be productive with Eclipse you need plugins. Of course devonfw-ide can automate this for your:\nIn your settings git repository create a folder eclipse/plugins (click on this link to see more examples and see which plugins come by default).\nHere you can create a properties file for each plugin. This is an example tmterminal.properties:\nplugin_url=http://download.eclipse.org/tm/terminal/marketplace\nplugin_id=org.eclipse.tm.terminal.feature.feature.group,org.eclipse.tm.terminal.view.feature.feature.group,org.eclipse.tm.terminal.control.feature.feature.group,org.eclipse.tm.terminal.connector.ssh.feature.feature.group,org.eclipse.tm.terminal.connector.telnet.feature.feature.group\nplugin_active=true\nThe variables are defined as follows:\nplugin_url defines the URL of the Eclipse update site of the plugin\nplugin_id defines the feature group ID(s) to install. To install multiple features/plugins provide a coma-separated list of IDs. If you want to customize devonfw-ide with new plugins you can first install them manually and then go to About Eclipse &gt; Installation Details then you can filter for your newly installed plugin and find the values in the Id column. Copy &amp; paste them from here to make up your own custom config.\nplugin_active is an optional parameter. If it is true (default) the plugin will be installed automatically during the project setup for all developers in your team. Otherwise, developers can still install the plugin manually via devon eclipse add-plugin &#xAB;plugin-name&#xBB; from the config file settings/eclipse/plugins/&#xAB;plugin-name&#xBB;.properties. See the settings/eclipse/plugins folder for possible values of &#xAB;plugin-name&#xBB;.\nIn general you should try to stick with the configuration pre-defined by your project. But some plugins may be considered as personal flavor and are typically not predefined by the project config. This e.g. applies for devstyle that allows a real dark mode for eclipse and tunes the theming and layout of Eclipse in general. Such plugins should be shipped with your settings as described above with plugin_active=false allowing you to easily install it manually.\nAs the maintainer of the settings for your project you should avoid to ship too many plugins that may waste resources but are not used by every developer. By configuring additional plugins with plugin_active=false you can give your developers the freedom to install some additional plugins easily.\nlegacy plugin config\nFor downward compatibility we still support the deprecated legacy configuration if the folder settings/eclipse/plugins does not exist:\nThe project configuration typically defines the plugins that will be installed via ECLIPSE_PLUGINS variable. Otherwise defaults from this eclipse commandlet will apply.\nBe aware that this comes at your own risk and sometimes plugins can conflict and break your IDE.\nHere is an example how a project can configure the plugins in its devon.properties inside the settings:\nECLIPSE_PLUGINS=(&quot;AnyEditTools.feature.group&quot; &quot;https://raw.githubusercontent.com/iloveeclipse/plugins/latest/&quot; &quot;com.ess.regexutil.feature.group&quot; &quot;http://regex-util.sourceforge.net/update/&quot;)\nFor the above listed plugins you can also use the short form:\nECLIPSE_PLUGINS=(&quot;anyedit&quot; &quot;&quot; &quot;regexutil&quot; &quot;&quot;)\nOf course you may also mix plugin IDs with fully qualified plugins.\ndictionary\nEclipse already comes with a buid-in spellchecker. This is very helpful when writing comments. The default settings of devonfw-ide ship with a project specific dictionary file and according configurations to enable spellchecking and configuring this dictionary.\nWhen typing JavaDoc, inline comments or other texts the spellchecker will underline unknown words in red.\nIf your cursor is located at such a word you can hit [Ctrl][1] to get a context menu with additional options.\nThere you can either choose similar correct words to correct a typo or you may even add the word (maybe a new buisness term) to your local dictionary.\nIn the latter case, you should commit the changes to your settings so that it will be available to your entire team.\nFor further details about comitting changes to the settings please consult the admin usage.\nnon-english dictionary\nIn case your project has to write documentation or text in languages other than English, you might want to prefill your project dictionary for that language.\nHere we collect a list of such dictionaries that you can download and merge into your project dictionary:\nGerman: https://sourceforge.net/projects/germandict/ (has to be converted to UTF-8 e.g. with Notepad++ via Encoding &gt; Convert to UTF-8)\n"},{"id":360,"path":"../website/pages/docs/devonfw-ide-usage.asciidoc.html#gradle.asciidoc","type":"docs","title":"gradle","body":"5.4.6. gradle\nThe gradle commandlet allows to install, configure, and launch gradle. It is similar to gradle-wrapper. So calling devon gradle &#xAB;args&#xBB; is more or less the same as calling gradle &#xAB;args&#xBB; but with the benefit that the version of gradle preferred by your project is used (and will be installed if not yet available).\nThe arguments (devon gradle &#xAB;args&#xBB;) are explained by the following table:\nTable 6. Usage of devon gradle\nArgument(s)\nMeaning\nsetup\nsetup gradle (install and verify), configurable via GRADLE_VERSION\n&#xAB;args&#xBB;\nrun gradle with the given arguments (&#xAB;args&#xBB;)\n"},{"id":361,"path":"../website/pages/docs/devonfw-ide-usage.asciidoc.html#help.asciidoc","type":"docs","title":"help","body":"5.4.7. help\nThe help commandlet provides help for the CLI.\nTable 7. Usage of devon help\nArgument(s)\nMeaning\nPrint general help\n&#xAB;command&#xBB;\nPrint help for the commandlet &#xAB;command&#xBB;.\nPlease note that devon help &#xAB;command&#xBB; will do the same as devon &#xAB;command&#xBB; help.\n"},{"id":362,"path":"../website/pages/docs/devonfw-ide-usage.asciidoc.html#ide.asciidoc","type":"docs","title":"ide","body":"5.4.8. ide\nThe ide commandlet manages your devonfw-ide.\nYou need to supply additional arguments as devon ide &#xAB;args&#xBB;. These are explained by the following table:\nTable 8. Usage of devon ide\nArgument(s)\nMeaning\nsetup [&#xAB;SETTINGS_URL&#xBB;]\nsetup devonfw-ide (cloning the settings from the given URL, optionally from specific branch URL#branch)\nupdate [&#xAB;package&#xBB;]\nupdate devonfw-ide\nupdate scripts [to &#xAB;version&#xBB;]\nupdate devonfw-ide\nuninstall\nuninstall devonfw-ide (if you want remote it entirely from your system)\nsetup\nRun devon ide setup to initially setup your devonfw-ide. It is recommended to run the setup script in the top-level directory ($DEVON_IDE_HOME). However, in case you want to skip some system specific integrations, you may also run this command directly instead. The setup only needs to be called once after a new devonfw-ide instance has been created. It will follow this process:\ninstall the devon command on your system (if not already installed).\nclone the settings (you may provide a git URL directly as argument or you will be prompted for it).\ninstall all required software from DEVON_IDE_TOOLS variable (if not already installed).\nconfigure all these tools\ncreate IDE launch scripts\nperform OS specific system integration such as WindowsExplorer integration (only done from setup script and not from devon ide setup)\nupdate\nRun devon ide update to update your devonfw-ide. This will check for updates and install them automatically.\nThe optinal extra argument (&#xAB;package&#xBB;) behaves as follows:\nscripts: check if a new version of devonfw-ide-scripts is available. If so it will be downloaded and installed. As Windows is using file-locks, it is tricky to update a script while it is executed. Therefore, we update the scripts folder as an async background task and have to abort further processing at this point on windows as a workaround.\nsettings: update the settings (git pull).\nsoftware: update the software (e.g. if versions have changed via scripts or settings update).\nprojects: update the projects (checkout and import repositories into workspace/IDEs).\nall: do all the above sequentially.\nnone: settings and software are updated by default if no extra argument is given. This is the regular usage for project developers. Only perform an update of scripts when you are requested to do so by your technical lead. Bigger projects especially need to test updates before rolling them out to the entire team. If developers always updated the latest release of the scripts which is released globally, some project functionality would break causing problems and extra efforts in the teams.\nIn order to update to a specific version of scripts an explicit version can be specified after the additional to argument:\ndevon ide update scripts to 3.1.99\nThe above example will update to the exact version 3.1.99 no matter if this is an upgrade or a downgrade of your current installed version.\nIf you just use devon ide update scripts then the latest available version will be installed. In larger teams it is recommended to communicate exact version updates to avoid that a new release can interfere and break anything. Therefore, some pilot user will test a new version for the entire team and, only after a successful test, they will communicate to the team to update to that exact version by providing the complete command as in the above example.\nuninstall\nWe hope you love devonfw-ide. However, if you don&#x2019;t and want to get rid of it entirely and completely remove all integrations, you can use this command:\ndevon ide uninstall\nThis will remove devonfw-ide from all central places of your OS (user home directory such as scripts, .devon, .bashrc, as well as windows registry, etc.).\nHowever, it will not remove your current installations (or shared software folder). So after running this uninstall, simply remove your DEVON_IDE_HOME directory of all devonfw-ide installations and potential shared software folder. You may also want to clean up your ~/Downloads directory from files downloaded by devonfw-ide. We do not automate this as deleting a directory is a very simple manual step and we do not want to take responsibility for severe data loss if your workspaces contained valuable work.\n"},{"id":363,"path":"../website/pages/docs/devonfw-ide-usage.asciidoc.html#intellij.asciidoc","type":"docs","title":"intellij","body":"5.4.9. intellij\nThe intellij commandlet allows to install, configure, and launch IntelliJ.\nTo launch IntelliJ for your current workspace and devonfw-ide installation, simply run:\ndevon intellij\nYou may also supply additional arguments as devon intellij &#xAB;args&#xBB;. These are explained by the following table:\nTable 9. Usage of devon intellij\nArgument(s)\nMeaning\n--all\nif provided as first arg then to command will be invoked for each workspace\nsetup\nsetup IntelliJ (install or update)\nrun\nlaunch IntelliJ (default if no argument is given)\nstart\nsame as run\nws-up[date]\nupdate workspace\nws-re[verse]\nreverse merge changes from workspace into settings\nws-reverse-add\nreverse merge adding new properties\ncreate-script\ncreate launch script for this IDE, your current workspace and your OS\nThere are variables that can be used for IntelliJ. These are explained by the following table:\nTable 10. Variables of devonfw-ide for intelliJ\nVariable\nDefault-Value\nMeaning\nINTELLIJ_VERSION\nlatest_tested_version\nThe version of the tool IntelliJ to install and use.\nINTELLIJ_EDITION_TYPE\nC\nThe edition of the tool IntelliJ to install and use. The value C mean Community edition and the value U mean Ultimate edition. The Ultimate edition requires a license. The user has to buy the license separately and it is not part of devonfw-ide. The devonfw-ide only supports download and installation.\n"},{"id":364,"path":"../website/pages/docs/devonfw-ide-usage.asciidoc.html#ionic.asciidoc","type":"docs","title":"ionic","body":"5.4.10. ionic\nThe ionic commandlet allows to install, configure, and launch ionic (ionic-cli). Calling devon ionic &#xAB;args&#xBB; is more or less the same as calling ionic &#xAB;args&#xBB; but with some advanced features and ensuring that ionic is properly set up for your project.\nThe arguments (devon ionic &#xAB;args&#xBB;) are explained by the following table:\nTable 11. Usage of devon ionic\nArgument(s)\nMeaning\nsetup\nsetup yarn (install and verify), configurable via YARN_VERSION\ncreate\nCreate a new devon4ng ionic project.\ncicd &#xAB;args&#xBB;\ngenerate cicd files for the currect devon4ng project\n&#xAB;args&#xBB;\nrun ionic with the given arguments (&#xAB;args&#xBB;)\n"},{"id":365,"path":"../website/pages/docs/devonfw-ide-usage.asciidoc.html#jasypt.asciidoc","type":"docs","title":"jasypt","body":"5.4.11. jasypt\nThe jasypt commandlet allows to install jasypt and encrypt or decrept secrets using strong encryption given a secure masterpassword. See also devon4j password encryption guide for further details.\nThe arguments (devon jasypt &#xAB;args&#xBB;) are explained by the following table:\nTable 12. Usage of devon mvn\nArgument(s)\nMeaning\nsetup\nsetup jasypt (install and verify), configurable via JASYPT_VERSION\nencrypt\nEncrypt a secret with a masterpassword\ndecrypt\nDecrypt an encrypted secret with a masterpassword\nexample\ndevon jasypt encrypt\nEnter masterpassword: master\nEnter secret to encrypt/decrypt: secret\n----ENVIRONMENT-----------------\nRuntime: AdoptOpenJDK OpenJDK 64-Bit Server VM 11.0.9.1+1\n----ARGUMENTS-------------------\ninput: secret\npassword: master\nivGeneratorClassName: org.jasypt.iv.RandomIvGenerator\nalgorithm: PBEWITHHMACSHA512ANDAES_256\n----OUTPUT----------------------\nfQPbaDd8wq0h0qOZw/AEKp2TD4Y07Y//M5PzaLgF3qL7YnBQjiGLtW8s5XkP3Ly9\ndevon jasypt decrypt\nEnter masterpassword: master\nEnter secret to encrypt/decrypt: fQPbaDd8wq0h0qOZw/AEKp2TD4Y07Y//M5PzaLgF3qL7YnBQjiGLtW8s5XkP3Ly9\n----ENVIRONMENT-----------------\nRuntime: AdoptOpenJDK OpenJDK 64-Bit Server VM 11.0.9.1+1\n----ARGUMENTS-------------------\ninput: fQPbaDd8wq0h0qOZw/AEKp2TD4Y07Y//M5PzaLgF3qL7YnBQjiGLtW8s5XkP3Ly9\npassword: master\nivGeneratorClassName: org.jasypt.iv.RandomIvGenerator\nalgorithm: PBEWITHHMACSHA512ANDAES_256\n----OUTPUT----------------------\nsecret\n"},{"id":366,"path":"../website/pages/docs/devonfw-ide-usage.asciidoc.html#java.asciidoc","type":"docs","title":"java","body":"5.4.12. java\nThe java commandlet allows to install and setup Java. Also it supports devon4j.\nThe arguments (devon java &#xAB;args&#xBB;) are explained by the following table:\nTable 13. Usage of devon java\nArgument(s)\nMeaning\nsetup\nsetup OpenJDK (install or update and verify), configurable via JAVA_VERSION (e.g. 8u242b08 or 11.0.6_10)\ncreate &#xAB;args&#xBB;\ncreate a new Java project based on devon4j application template. If a single argument is provided, this is the package name and is automatically split into groupId and artifactId. Use -DdbType=&#xAB;db&#xBB; to choose the database (hana, oracle, mssql, postgresql, mariadb, mysql, h2, hsqldb). Any option starting with dash is passed as is.&quot;\nmigrate [from &#xAB;version&#xBB;] [single]\nmigrate a devon4j project to the latest version. If for some reasons the current devonfw version (e.g. oasp4j:2.6.0) can not be auto-detected you may provide it manually after the &apos;from&apos; argument. Also the &apos;single&apos; option allows to migrate only to the next available version.&quot;\ncicd &#xAB;args&#xBB;\ngenerate cicd files for the currect devon4java project\ncreate\nExamples for create a new devon4j application:\ndevon java create com.example.domain.myapp\nWill create an app with package com.example.domain.myapp, groupId com.example.domain, artifactId myapp, version 1.0.0-SNAPSHOT, and h2 database.\ndevon java create -Dversion=0.0.1-alpha1 com.example.domain.myapp\nWill create an app with package com.example.domain.myapp, groupId com.example.domain, artifactId myapp, version 0.0.1-alpha1, and h2 database.\ndevon java create com.example.domain.myapp com.example.group\nWill create an app with package com.example.domain.myapp, groupId com.example.group, artifactId myapp, version 1.0.0-SNAPSHOT, and h2 database.\ndevon java create com.example.domain.myapp com.example.group demo-app\nWill create an app with package com.example.domain.myapp, groupId com.example.group, artifactId demo-app, version 1.0.0-SNAPSHOT, and h2 database.\ndevon java create com.example.domain.myapp -DartifactId=demo-app -DdbType=hana\nWill create an app with package com.example.domain.myapp, groupId com.example.group, artifactId demo-app, version 1.0.0-SNAPSHOT, and SAP hana database.\ndevon java create com.example.domain.myapp -DdbType=oracle -Dversion=0.0.1 com.example.group -Dbatch=batch\nWill create an app with package com.example.domain.myapp, groupId com.example.group, artifactId myapp, version 0.0.1, oracle database, and with a batch module.\nmigrate\nExample for migrating a devon4j application:\ndevon java migrate\nWill migrate current devon4j application to the latest version available.\n"},{"id":367,"path":"../website/pages/docs/devonfw-ide-usage.asciidoc.html#jenkins.asciidoc","type":"docs","title":"jenkins","body":"5.4.13. jenkins\nThe jenkins commandlet allows to install, configure, and launch Jenkins.\nTable 14. Usage of devon jenkins\nArgument(s)\nMeaning\nsetup\nSetup Jenkins (install and verify)\nstart\nStart your local Jenkins server\nstop\nStop your local Jenkins server\nadd\nAdd current project as CI job to your local Jenkins\n"},{"id":368,"path":"../website/pages/docs/devonfw-ide-usage.asciidoc.html#kubectl.asciidoc","type":"docs","title":"kubernetes","body":"5.4.14. kubernetes\nThe kubectl commandlet allows to install and use kubernetes.\nOn Windows WSL 2(Windows Subsystem for Linux) has to be installed properly as a prerequisite.\nThe setup on windows will then install kubernetes with K3D. K3D will create a cluster with a single node with a default name as &quot;devonfw-cluster&quot;\nThe arguments (devon kubectl &#xAB;args&#xBB;) are explained by the following table:\nTable 15. Usage of devon kubectl\nArgument(s)\nMeaning\nsetup\nsetup Kubernetes (install and verify) as per above flow.\n&#xAB;args&#xBB;\ncall kubectl with the specified arguments. Call kubectl help for details or use kubectl directly as preferred.\n"},{"id":369,"path":"../website/pages/docs/devonfw-ide-usage.asciidoc.html#mvn.asciidoc","type":"docs","title":"mvn","body":"5.4.15. mvn\nThe mvn commandlet allows to install, configure, and launch maven. It is similar to maven-wrapper and mdub. So calling devon mvn &#xAB;args&#xBB; is more or less the same as calling mvn &#xAB;args&#xBB; but with the benefit that the version of maven preferred by your project is used (and will be installed if not yet available).\nThe arguments (devon mvn &#xAB;args&#xBB;) are explained by the following table:\nTable 16. Usage of devon mvn\nArgument(s)\nMeaning\nrun default build, configurable via MVN_BUILD_OPTS\nsetup\nsetup Maven (install and verify), configurable via MAVEN_VERSION\nget-version\nPrint the version of your current project. Will consolidate the version for multi-module projects ignoring dev[-SNAPSHOT] versions and fail on mixed versions.\nset-version &#xAB;nv&#xBB; [&#xAB;cv&#xBB;]\nSet the version of your current project to &#xAB;nv&#xBB; (assuming your current version is &#xAB;cv&#xBB;).\ncheck-no-snapshots\nCheck if no &#xAB;version&#xBB;-SNAPSHOT dependencies are used.\ncheck-top-level-project\nCheck if you are running on a top-level project or fail if in a module or no maven project at all.\nrelease\nStart a clean deploy release build, configurable via MVN_RELEASE_OPTS\n&#xAB;args&#xBB;\nrun maven with the given arguments (&#xAB;args&#xBB;)\n"},{"id":370,"path":"../website/pages/docs/devonfw-ide-usage.asciidoc.html#ng.asciidoc","type":"docs","title":"ng","body":"5.4.16. ng\nThe ng commandlet allows to install, configure, and launch ng (angular-cli). Calling devon ng &#xAB;args&#xBB; is more or less the same as calling ng &#xAB;args&#xBB; but with some advanced features and ensuring that ng is properly set up for your project.\nThe arguments (devon ng &#xAB;args&#xBB;) are explained by the following table:\nTable 17. Usage of devon ng\nArgument(s)\nMeaning\nsetup\nsetup yarn (install and verify), configurable via NG_VERSION\ncreate\nCreate a new devon4ng project.\ncicd &#xAB;args&#xBB;\ngenerate cicd files for the currect devon4ng project\n&#xAB;args&#xBB;\nrun ng with the given arguments (&#xAB;args&#xBB;)\n"},{"id":371,"path":"../website/pages/docs/devonfw-ide-usage.asciidoc.html#node.asciidoc","type":"docs","title":"node","body":"5.4.17. node\nThe node commandlet allows to install and setup node.js.\nThe arguments (devon node &#xAB;args&#xBB;) are explained by the following table:\nTable 18. Usage of devon node\nArgument(s)\nMeaning\nsetup\nsetup node.js (install and verify), configurable via NODE_VERSION\ncreate &#xAB;name&#xBB; [&#xAB;args&#xBB;]\ncreate a new devon4node application (same as devon4node new)\ngenerate &#xAB;s&#xBB; [&#xAB;args&#xBB;]\ngenerate devon4node components using the schematic &#xAB;s&#xBB; (same as devon4node generate)\ndb &#xAB;c&#xBB; [&#xAB;args&#xBB;]\nexecute a TypeORM command &#xAB;c&#xBB; (same as devon4node db)\ncicd &#xAB;args&#xBB;\ngenerate cicd files for the currect devon4node project\n&#xAB;args&#xBB;\ncall NodeJS with the specified arguments\n"},{"id":372,"path":"../website/pages/docs/devonfw-ide-usage.asciidoc.html#npm.asciidoc","type":"docs","title":"npm","body":"5.4.18. npm\nThe npm commandlet allows to install, configure, and launch npm. Calling devon npm &#xAB;args&#xBB; is more or less the same as calling npm &#xAB;args&#xBB; but with the benefit that the version of npm preferred by your project is used (and will be installed if not yet available).\nThe arguments (devon npm &#xAB;args&#xBB;) are explained by the following table:\nTable 19. Usage of devon npm\nArgument(s)\nMeaning\nrun default build, configurable via NPM_BUILD_OPTS\nsetup\nsetup NPM (install and verify), configurable via NPM_VERSION\nget-version\nprint the version of your current project\nset-version &#xAB;nv&#xBB; [&#xAB;cv&#xBB;]\nset the version of your current project to &#xAB;nv&#xBB; (assuming your current version is &#xAB;cv&#xBB;)\ncheck-top-level-project\ncheck if you are running on a top-level project or fail if in a module or no NPM project at all\nrelease\nStart a clean deploy release build, configurable via NPM_RELEASE_OPTS\n&#xAB;args&#xBB;\nrun NPM with the given arguments (&#xAB;args&#xBB;)\n"},{"id":373,"path":"../website/pages/docs/devonfw-ide-usage.asciidoc.html#release.asciidoc","type":"docs","title":"release","body":"5.4.19. release\nCreate a release in a standardized way including the following steps:\nverify the current project (no local changes, etc.)\nwarn if &#xAB;version&#xBB;-SNAPSHOT dependencies are used\ndetermine &#xAB;version&#xBB; (if currently &#xAB;version&#xBB;-SNAPSHOT) and print out release information.\nask user for confirmation\nbump release to &#xAB;version&#xBB; in build configuration (e.g. pom.xml files)\ncommit the change\ncreate annotated tag for your release as release/&#xAB;version&#xBB;\ninvoke deployment on build-system\nset next version as (&#xAB;version&#xBB;+1)-SNAPSHOT in build configuration (e.g. pom.xml files)\ncommit the change\npush your changes\nTable 20. Usage of devon java\nArgument(s)\nMeaning\n&#x2026;&#x200B;\nany optional argument will directly be passed to the actual command to build the deployment\nBuild-Tools\nThis release commandlet utilizes the build commandlet to support mutliple build-tools such as maven, gradle, or npm. Each of those commandlets should respect the variable &#xAB;TOOL&#xBB;_RELEASE_OPTS to customize the parameters for the release build.\nSo e.g. if a pom.xml is detected, maven will be used. In this example the variable MVN_RELEASE_OPTS is used that defaults to clean deploy -Dchangelist= -Pdeploy.\nIf you provide a specific argument this will be passed additionally.\nSo if you invoke the command devon release -P myProfile, the above step invoke deployment on build-system would technically call this:\nmvn clean deploy -Dchangelist= -Pdeploy -P myProfile\nPlease also note that it is very tricky to determine and modify the version of a project in a fully generic way.\nEven though we try our best to support different scenarios, we can not ensure this is working for edge-cases.\nTherefore, we strongly encourage to follow best practices such as ci-friendly maven.\nFurther, sticking to the defaults and follow the devonfw standard to name the profile for custom goals in deployment simply deploy is recommended.\n"},{"id":374,"path":"../website/pages/docs/devonfw-ide-usage.asciidoc.html#sonar.asciidoc","type":"docs","title":"sonar","body":"5.4.20. sonar\nThe sonar commandlet allows to install, configure, and launch SonarQube.\nTable 21. Usage of devon sonar\nArgument(s)\nMeaning\nsetup\nSetup SonarQube (install and verify)\nstart\nStart your local SonarQube server\nstop\nStop your local SonarQube server\nanalyze\nAnalyze current project with SonarQube\n"},{"id":375,"path":"../website/pages/docs/devonfw-ide-usage.asciidoc.html#vscode.asciidoc","type":"docs","title":"vscode","body":"5.4.21. vscode\nThe vscode commandlet allows to install, configure, and launch Visual Studio Code.\nTo launch VSCode for your current workspace and devonfw-ide installation, simply run:\ndevon vscode\nYou may also supply additional arguments as devon vscode &#xAB;args&#xBB;. These are explained by the following table:\nTable 22. Usage of devon vscode\nArgument(s)\nMeaning\n--all\nif provided as first arg then to command will be invoked for each workspace\nsetup\nsetup VSCode (install or update)\nrun\nlaunch VSCode (default if no argument is given)\nstart\nsame as run\nws-up[date]\nupdate workspace\nws-re[verse]\nreverse merge changes from workspace into settings\nws-reverse-add\nreverse merge adding new properties\ncreate-script\ncreate launch script for this IDE, your current workspace and your OS\nplugins\nTo be productive with VS Code you need plugins (called extensions in VS Code). Of course devonfw-ide can automate this for your:\nIn your settings git repository create a folder vscode/plugins (click this link to see more examples and see which plugins come by default).\nHere you can create a properties file for each plugin. This is an example devonfw-extension-pack.properties:\nplugin_id=devonfw.devonfw-extension-pack\nplugin_active=true\nThe variables are defined as following:\nplugin_id defines the unique ID of the plugin to install. If you want to customize devonfw-ide with new plugins click on Extensions at the bottom of the left navigation icon bar in VS code. Then use the search to find the plugin of your choice. If you click on it the plugin ID is displayed in grey beside the official title at the top of the plugin details page. Copy &amp; paste the ID from here to make up your own custom config.\nplugin_active is an optional parameter. If it is true (default) the plugin will be installed automatically during the project setup for all developers in your team. Otherwise developers can still install the plugin manually via devon vscode add-plugin &#xAB;plugin-name&#xBB; from the config file settings/vscode/plugins/&#xAB;plugin-name&#xBB;.properties. See the settings/vscode/plugins folder for possible values of &#xAB;plugin-name&#xBB;.\nIn general you should try to stick with the configuration pre-defined by your project. But some plugins may be considered as personal flavor and are typically not predefined by the project config. Such plugins should be shipped with your settings as described above with plugin_active=false allowing you to easily install it manually. Surely, you can easily add plugins via the UI of VS code. However, be aware that some plugins may collect sensitive data or could introduce other vulnerabilities. So consider the governance of your project and talk to your technical lead before installing additional plugins that are not pre-defined in your settings.\nAs maintainer of the settings for your project you should avoid to ship too many plugins that may waste resources but are not used by every developer. By configuring additional plugins with plugin_active=false you can give your developers the freedom to install some additional plugins easily.\ncleaning plugins on update\nIf you want to striclty manage the plugins for VS code in your project, you can create or edit the file settings/vscode/plugins in your settings and add this variable:\nclean_plugins_on_update=true\nThis will wipe all plugins when an update of VS code is performed (e.g. via devon ide update) and reinstall all configured plugins. While this gives you more control over the governance of the plugins and allows to remove a plugin later during project lifecycle. However, this will delete all manually installed plugins automatically without asking.\n"},{"id":376,"path":"../website/pages/docs/devonfw-ide-usage.asciidoc.html#yarn.asciidoc","type":"docs","title":"yarn","body":"5.4.22. yarn\nThe yarn commandlet allows to install, configure, and launch npm. Calling devon yarn &#xAB;args&#xBB; is more or less the same as calling yarn &#xAB;args&#xBB; but with the benefit that the version of npm preferred by your project is used (and will be installed if not yet available).\nThe arguments (devon yarn &#xAB;args&#xBB;) are explained by the following table:\nTable 23. Usage of devon yarn\nArgument(s)\nMeaning\nrun default build, configurable via YARN_BUILD_OPTS\nsetup\nsetup yarn (install and verify), configurable via YARN_VERSION\nget-version\nprint the version of your current project\nset-version &#xAB;nv&#xBB; [&#xAB;cv&#xBB;]\nset the version of your current project to &#xAB;nv&#xBB; (assuming your current version is &#xAB;cv&#xBB;)\ncheck-top-level-project\ncheck if you are running on a top-level project or fail if in a module or no NPM project at all\nrelease\nstart a clean deploy release build, configurable via YARN_RELEASE_OPTS\n&#xAB;args&#xBB;\nrun yarn with the given arguments (&#xAB;args&#xBB;)\n"},{"id":377,"path":"../website/pages/docs/devonfw-ide-usage.asciidoc.html#structure.asciidoc","type":"docs","title":"Structure","body":"5.5. Structure\nThe directory layout of your devonfw-ide will look like this:\nListing 1. File structure of your devonfw-ide\n/ projects (or C:\\Projects, etc.)\n&#x2514;&#x2500;&#x2500;/ my-project ($DEVON_IDE_HOME)\n&#x251C;&#x2500;&#x2500;/ conf\n&#x251C;&#x2500;&#x2500;/ log\n&#x251C;&#x2500;&#x2500;/ scripts\n&#x251C;&#x2500;&#x2500;/ settings\n&#x251C;&#x2500;&#x2500;/ software\n&#x251C;&#x2500;&#x2500;/ system\n&#x251C;&#x2500;&#x2500;/ updates\n&#x251C;&#x2500;&#x2500;/ workspaces\n&#x251C;&#x2500;&#x2500; setup\n&#x251C;&#x2500;&#x2500; setup.bat\n&#x2514;&#x2500;&#x2500; devon-ide-doc.pdf\nThe elements of the above structure are described in the individual sections. As they are hyperlinks you can simply click on them to get more details.\n"},{"id":378,"path":"../website/pages/docs/devonfw-ide-usage.asciidoc.html#conf.asciidoc","type":"docs","title":"conf","body":"5.5.1. conf\nThis folder contains configurations for your IDE:\nListing 2. File structure of the conf folder\n/ conf\n&#x251C;&#x2500;&#x2500;/ .m2\n&#x2502; &#x251C;&#x2500;&#x2500;/ repository\n&#x2502; &#x2502; &#x251C;&#x2500;&#x2500;/ ant\n&#x2502; &#x2502; &#x251C;&#x2500;&#x2500;/ ...\n&#x2502; &#x2502; &#x2514;&#x2500;&#x2500;/ zw\n&#x2502; &#x251C;&#x2500;&#x2500; settings-security.xml\n&#x2502; &#x2514;&#x2500;&#x2500; settings.xml\n&#x251C;&#x2500;&#x2500;/ .sonar\n&#x251C;&#x2500;&#x2500;/ ...\n&#x2514;&#x2500;&#x2500; variables\nThe .m2 folder is used for configurations of maven. It contains the local repository folder used as cache for artifacts downloaded and installed by maven (see also maven repositories).\nFurther, there are two configuration files for maven:\nsettings.xml initialized from a template from your devonfw-ide settings. You may customize this to your needs (configuring HTTP proxies, credentials, or other user-specific settings). Secrets can be specified as $[&#xAB;variable.name&#xBB;] and will be prompted, encrypted and replaced automatically during the setup (unless in batch mode). In case your credentials have changed or you made a typo, you can simply redo this step by first moving your ${DEVON_IDE_HOME}/conf/.m2/settings.xml file to a temporary folder and then calling devon mvn setup.\nsettings-security.xml is auto-generated for you by devonfw-ide with a random password. This should make it easier for devonfw-ide users to use password encryption and never add passwords in plain text for better security.\nFinally,there is a file variables for the user-specific configuration of devonfw-ide.\n"},{"id":379,"path":"../website/pages/docs/devonfw-ide-usage.asciidoc.html#log.asciidoc","type":"docs","title":"log","body":"5.5.2. log\nThe log directory is used to store log files e.g. for the IDE configurator. You may look here for debug information if something goes wrong.\n"},{"id":380,"path":"../website/pages/docs/devonfw-ide-usage.asciidoc.html#scripts.asciidoc","type":"docs","title":"scripts","body":"5.5.3. scripts\nThis directory is the heart of the devonfw-ide and contains the required scripts.\nListing 3. File structure of the conf folder\n/scripts\n&#x251C;&#x2500;&#x2500;/ command\n&#x2502; &#x251C;&#x2500;&#x2500; build\n&#x2502; &#x251C;&#x2500;&#x2500; docker\n&#x2502; &#x251C;&#x2500;&#x2500; eclipse\n&#x2502; &#x251C;&#x2500;&#x2500; gradle\n&#x2502; &#x251C;&#x2500;&#x2500; help\n&#x2502; &#x251C;&#x2500;&#x2500; ide\n&#x2502; &#x251C;&#x2500;&#x2500; intellij\n&#x2502; &#x251C;&#x2500;&#x2500; ionic\n&#x2502; &#x251C;&#x2500;&#x2500; jasypt\n&#x2502; &#x251C;&#x2500;&#x2500; java\n&#x2502; &#x251C;&#x2500;&#x2500; jenkins\n&#x2502; &#x251C;&#x2500;&#x2500; kubectl\n&#x2502; &#x251C;&#x2500;&#x2500; mvn\n&#x2502; &#x251C;&#x2500;&#x2500; ng\n&#x2502; &#x251C;&#x2500;&#x2500; node\n&#x2502; &#x251C;&#x2500;&#x2500; npm\n&#x2502; &#x251C;&#x2500;&#x2500; project\n&#x2502; &#x251C;&#x2500;&#x2500; release\n&#x2502; &#x251C;&#x2500;&#x2500; sonar\n&#x2502; &#x251C;&#x2500;&#x2500; vscode\n&#x2502; &#x2514;&#x2500;&#x2500; yarn\n&#x251C;&#x2500;&#x2500; devon\n&#x251C;&#x2500;&#x2500; devon.bat\n&#x251C;&#x2500;&#x2500; environment-project\n&#x251C;&#x2500;&#x2500; environment-project.bat\n&#x251C;&#x2500;&#x2500; functions\n&#x2514;&#x2500;&#x2500; devon.properties\nThe command folder contains the commandlets.\nThe devon script is the key command line interface for devonfw-ide.\nThere is also devon.bat that can be used in CMD or PowerShell.\nAs the devon CLI can be used as a global command on your computer from any directory and gets installed centrally, it aims to be stable, minimal, and lightweight.\nThe key logic to set up the environment variables is therefore in a separate script environment-project and its Windows variant environment-project.bat inside this scripts folder.\nThe file functions contains a collection of reusable bash functions.\nThese are sourced and used by the commandlets.\nFinally the devon.properties file contains defaults for the general configuration of devonfw-ide.\n"},{"id":381,"path":"../website/pages/docs/devonfw-ide-usage.asciidoc.html#settings.asciidoc","type":"docs","title":"settings","body":"5.5.4. settings\nThe devonfw-ide requires settings with configuration templates for the arbitrary tools.\nTo get an initial set of these settings we provide the default ide-settings as an initial package. These are also released so you can download the latest stable or any history version at maven central.\nTo test devonfw-ide or for very small projects you can also use these the latest default settings (just hit return when setup is asking for the Settings URL).\nHowever, for collaborative projects we strongly encourage you to distribute and maintain the settings via a dedicated and project specific git repository.\nThis gives you the freedom to control and manage the tools with their versions and configurations during the project lifecycle.\nTherefore simply follow the admin usage guide.\nStructure\nThe settings folder (see SETTINGS_PATH) has to follow this file structure:\nListing 4. File structure of settings\n/settings\n&#x251C;&#x2500;&#x2500;/ devon\n&#x2502; &#x251C;&#x2500;&#x2500;/ conf\n&#x2502; &#x2502; &#x251C;&#x2500;&#x2500;/ .m2\n&#x2502; &#x2502; &#x2502; &#x2514;&#x2500;&#x2500; settings.xml\n&#x2502; &#x2502; &#x251C;&#x2500;&#x2500;/ npm\n&#x2502; &#x2502; &#x2502; &#x2514;&#x2500;&#x2500; .npmrc\n&#x2502; &#x2502; &#x2514;&#x2500;&#x2500; devon.properties\n&#x251C;&#x2500;&#x2500;/ eclipse\n&#x2502; &#x251C;&#x2500;&#x2500;/ workspace\n&#x2502; &#x2502; &#x251C;&#x2500;&#x2500;/ setup\n&#x2502; &#x2502; &#x2514;&#x2500;&#x2500;/ update\n&#x2502; &#x251C;&#x2500;&#x2500; lifecycle-mapping-metadata.xml\n&#x2502; &#x2514;&#x2500;&#x2500; project.dictionary\n&#x251C;&#x2500;&#x2500;/ ...\n&#x251C;&#x2500;&#x2500;/ sonarqube\n&#x2502; &#x2514;&#x2500;&#x2500;/ profiles\n&#x2502; &#x251C;&#x2500;&#x2500; Devon-C#.xml\n&#x2502; &#x251C;&#x2500;&#x2500; ...\n&#x2502; &#x2514;&#x2500;&#x2500; Devon-XML.xml\n&#x251C;&#x2500;&#x2500;/ vscode\n&#x2502; &#x2514;&#x2500;&#x2500;/ workspace\n&#x2502; &#x251C;&#x2500;&#x2500;/ setup\n&#x2502; &#x2514;&#x2500;&#x2500;/ update\n&#x2514;&#x2500;&#x2500; devon.properties\nAs you can see, the settings folder contains sub-folders for tools of the IDE.\nSo the devon folder contains devon.properties files for the configuration of your environment.\nFurther, for the IDEs such as eclipse or vscode, the according folders contain the templates to manage the workspace via our configurator.\nConfiguration Philosophy\nDifferent tools and configuration files require a different handling:\nWhere suitable, we directly use these configurations from your settings (e.g. for eclipse/lifecycle-mapping-metadata.xml, or eclipse/project.dictionary).\nThe devon folder in settings contains templates for configuration files. There are copied to the devonfw-ide installation during setup (if no such file already exists). In this way the settings repository can provide reasonable defaults but allows the user to take over control and customize to his personal needs (e.g. .m2/settings.xml).\nOther configurations need to be imported manually. To avoid manual steps and simplify use we try to automate as much as possible. This currently applies to sonarqube profiles but will be automated with sonar-devon4j-plugin in the future.\nFor tools with complex configuration structures like eclipse, intellij, or vscode we provide a smart mechanism via our configurator.\nCustomize Settings\nYou can easily customize these settings for the requirements of your project. We suggest that one team member is responsible to ensure that everything stays consistent and works.\nYou may also create new sub-folders in settings and put individual items according to your needs. E.g. you could add scripts for greasemonkey or tampermonkey, as well as scripts for your database or whatever may be useful and worth to share in your team. However, to share and maintain knowledge we recommend to use a wiki.\n"},{"id":382,"path":"../website/pages/docs/devonfw-ide-usage.asciidoc.html#software.asciidoc","type":"docs","title":"software","body":"5.5.5. software\nThe software folder contains the third party tools for your IDE such as maven, npm, java, etc.\nWith respect to the licensing terms you may create a custom archive containing a devonfw-ide together with the required software.\nHowever, to be platform independent and allow lightweight updates, the devonfw-ide is capable to download and install the software automatically for you.\nRepository\nBy default, software is downloaded via the internet from public download URLs of the according tools. However, some projects may need specific tools or tool versions that are not publicly available.\nIn such case, they can create their own software repository (e.g. in a VPN) and configure the base URL of it via DEVON_SOFTWARE_REPOSITORY variable.\nThen, devonfw-ide will download all software from this repository only instead of the default public download URLs.\nThis repository (URL) should be accessible within your network via HTTPS (or HTTP) and without any authentication.\nThe repository needs to have the following structure:\n${DEVON_SOFTWARE_REPOSITORY}/&#xAB;tool&#xBB;/&#xAB;version&#xBB;/&#xAB;tool&#xBB;-&#xAB;version&#xBB;[-&#xAB;os&#xBB;].tgz\nSo for every tool &#xAB;tool&#xBB; (java, maven, vscode, eclipse, etc.) you need to provide a folder in your repository.\nWithin this folder for every supported version &#xAB;version&#xBB; you need a subfolder.\nThis subfolder needs to contain the tool in that version for every operating system &#xAB;os&#xBB; (windows, linux, or mac - omitted if platform independent, e.g. for maven).\nShared\nBy default, each installation of devonfw-ide has its own physical installations of the required tools in the desired versions stored in its local software folder.\nWhile this is great for isolation of devonfw-ide installations and to prevent side-effects, it can cause a huge waste of disc resources in case you are having many installations of devonfw-ide.\nIf you are a power-user of devonfw-ide with more then ten or even up to hundreds of installations on your machine, you might love to share installations of a software tool in a particular version between multiple devonfw-ide installations.\nCaution\nIf you use this power-feature you are taking responsibility for side-effects and should not expect support. Also if you are using Windows please read Symlinks in Windows and make your mind if you really want to do so. You might also use this hint and maintain it manually without enabling the following feature.\nIn order to do so, you only need to configure the variable DEVON_SOFTWARE_PATH in your ~/devon.properties pointing to an existing directory on your disc (e.g. /projects/software or C:\\projects\\software).\nThen devonfw-ide will install required software into ${DEVON_SOFTWARE_PATH}/${software_name}/${software_version} as needed and create a symbolic link to it in ${DEVON_IDE_HOME}/software/${software_name}.\nAs a benefit, another devonfw-ide installation will using the same software with the same version can re-use the existing installation and only needs to create the symbolic link. No more waste of having many identical JDK installations on your disc.\nAs a drawback, you need to be aware that specific tools may be &quot;manipulated&quot; after installation.\nThe most common case is that a tool allows to install plugins or extensions such as all IDEs do. Such &quot;manipulations&quot; will cause side-effects between the different devonfw-ide installations sharing the same version of that tool.\nWhile this can also be a benefit it may also cause trouble.\nIf you have a sensitive project that should not be affected by such side-effects, you may again override the DEVON_SOFTWARE_PATH variable to the empty value in your ${DEVON_IDE_HOME}/conf/devon.properties of that sensitive installation:\nDEVON_SOFTWARE_PATH=\nThis will disable this feature particularly for that specific sensitive devonfw-ide installation but let you use it for all other ones.\nCustom\nIn some cases, a project might need a (proprietary) tool(s) that (are) not supported by devonfw-ide. A very simple solution is to get a release of devonfw-ide and add the tool(s) to the software folder and then distribute this modified release to your team. However, this has several drawbacks as you then have a fork of devonfw-ide all will loose your tool(s) when updating to a new release.\nAs a solution for this need, devonfw-ide let&#x2019;s you configure custom tools via the DEVON_IDE_CUSTOM_TOOLS variable. It can be defined in devon.properties of your settings git repository as an array of the custom tools you need to add.\nEach entry applies:\nIt needs to have the form &#xAB;tool&#xBB;:&#xAB;version&#xBB;[:all][:&#xAB;repository-url&#xBB;]\nThe first entry must have the &#xAB;repository-url&#xBB; included which is used as default\nFurther entries will inherit this default if omitted\nThis URL is used in the same way as described above for a software repository.\nThe DEVON_SOFTWARE_REPOSITORY variable is ignored by this feature.\nThe optional infix :all is used to indicate that the tool is platform independent. Otherwise, an OS specific infix is appended to the URL file to download for your platform (windows, linux, or mac).\nAs an example, we define it in ${DEVON_IDE_HOME}/settings/devon.properties:\nDEVON_IDE_CUSTOM_TOOLS=(jboss-eap:7.1.4.GA:all:https://host.tld/projects/my-project firefox:70.0.1)\nThis will download and extract the following content to your software folder:\nhttps://host.tld/projects/my-project/jboss-eap/7.1.4.GA/jboss-eap-7.1.4.GA.tgz\nhttps://host.tld/projects/my-project/firefox/70.0.1/firefox-70.0.1-windows.tgz\nPlease note that if you are not using windows, the -windows suffix will be -mac or -linux.\n"},{"id":383,"path":"../website/pages/docs/devonfw-ide-usage.asciidoc.html#system.asciidoc","type":"docs","title":"system","body":"5.5.6. system\nThe system folder contains documentation and solutions for operation system specific integration. Please have a look to get the maximum out of devonfw-ide and become a very efficient power user.\n"},{"id":384,"path":"../website/pages/docs/devonfw-ide-usage.asciidoc.html#updates.asciidoc","type":"docs","title":"updates","body":"5.5.7. updates\nThe updates folder is used for temporary data. This includes:\nextracted archives for installation and updates\nbackups of old content on updates to prevent data loss\nIf all works fine you may clean this folder to save some kilo- or mega-bytes. Otherwise, you can ignore it unless you are looking for a backup after a failed or unplanned upgrade.\n"},{"id":385,"path":"../website/pages/docs/devonfw-ide-usage.asciidoc.html#workspaces.asciidoc","type":"docs","title":"workspaces","body":"5.5.8. workspaces\nThe workspaces folder contains folders for your active work. There is a workspace folder main dedicated for your primary work. You may do all your work inside the main workspace. Also, you are free to create any number of additional workspace folders named as you like (e.g. test, release, testing, my-sub-project, etc.). Using multiple workspaces is especially relevant for Eclipse as each workspace has its own Eclipse runtime instance and configuration.\nWithin the workspace folder (e.g. workspaces/main) you are again free to create sub-folders for (sub-)projects according to your needs. We assume that in most cases you clone git repositories here. The following structure shows an example layout for devonfw:\nListing 5. File structure of workspaces\n/ workspaces\n&#x251C;&#x2500;&#x2500;/ main\n&#x2502; &#x251C;&#x2500;&#x2500;/ .metadata\n&#x2502; &#x251C;&#x2500;&#x2500;/ ide\n&#x2502; &#x251C;&#x2500;&#x2500;/ devon4j\n&#x2502; &#x2514;&#x2500;&#x2500;/ my-thai-star\n&#x2514;&#x2500;&#x2500;/ stable\n&#x251C;&#x2500;&#x2500;/ .metadata\n&#x251C;&#x2500;&#x2500;/ ide\n&#x2514;&#x2500;&#x2500;/ devon4j\nIn the main workspace you may find the cloned forks for regular work (in the example e.g. devon4j) as a base to create pull-requests while in the stable workspace there is a clone of devon4j from the official devon4j.\nHowever, this is just an example. Some people like to create separate workspaces for development and maintenance branches with git. Other people just switch between those via git checkout.\n"},{"id":386,"path":"../website/pages/docs/devonfw-ide-usage.asciidoc.html#projects.asciidoc","type":"docs","title":"Project import","body":"5.5.9. Project import\nThe devonfw-ide supports to automatically check out and import required projects into your IDE during setup. To configure this you put a .properties file for each desired project into the projects sub-folder in your settings. Each .properties file describes one &quot;project&quot; which you would like to check out and (potentially) import:\npath=myproject\nworkingsets=Set1,Set2\nworkspace=example\ngit.url=http://github.com/someorg/someproject\ngit.branch=develop\nbuild.path=.\nbuild.cmd=mvn -DskipTests=true -Darchetype.test.skip=true clean install\neclipse=import\nactive=true\nTable 24. Variables of project import\nVariable\nValue\nMeaning\npath\ne.g. myproject, will clone into ${WORKSPACE_PATH}/myproject\n(required) Path into which the projects is cloned. This path is relative to the workspace.\nworking sets\ne.g. ws1,ws2\n(optional) This will create working sets (in eclipse). Each module (eclipse project) of this project will be part of all these working sets. Working sets will be automatically created if necessary.\nworkspace\nmain\nWorkspace to use for checkout and import. Default is main.\ngit.url\ne.g. http://github.com/someorg/someproject\n(required) Git URL to use for cloning the project.\ngit.branch\ne.g. develop\n(optional) Git branch to checkout. Git default branch is default.\nbuild.path\ne.g. . (default)\n(optional) The directory inside path where to trigger an initial build after clone or pull (if build.cmd is set). For a regular project use . to build top-level project.\nbuild.cmd\ne.g. build or mvn -DskipTests=true -Darchetype.test.skip=true clean install\n(optional) The devonfw command to invoke to build the project after clone or pull. If omitted no build is triggered.\neclipse\ne.g. import\n(optional) Desired action for eclipse IDE. If you put import here all modules (eclipse projects) in the current project will be imported into eclipse. If you leave this out or put any other value for this parameter, no change in eclipse is done.\nactive\ntrue\n(optional) If set to false the project is skipped during the setup.\nPlease note that the .properties file is parsed via shell and not via java. So be careful with &quot;advanced&quot; features .properties files normally support.\n&#x2190;&#xA0;Previous:&#xA0;Introduction&#xA0;| &#x2191;&#xA0;Up:&#xA0;devonfw-ide&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Advanced Features&#xA0;&#x2192;\n"},{"id":387,"path":"../website/pages/docs/devonfw-ide.asciidoc.html#devonfw-ide.asciidoc","type":"docs","title":"II. devonfw-ide","body":"II. devonfw-ide\nIntroduction\nUsage\nAdvanced Features\nSupport\n&#x2190;&#xA0;Previous:&#xA0;Further Information&#xA0;| &#x2191;&#xA0;Up:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Introduction&#xA0;&#x2192;\n"},{"id":388,"path":"../website/pages/docs/dsf-how-to-use.asciidoc.html#dsf-how-to-use.asciidoc","type":"tutorial","title":"How to use it","body":"54. How to use it\nThis is the documentation about shop floor and its different tools. Here you are going to learn how to create new projects, so that they can include continuous integration and continuous delivery processes, and be deployed automatically in different environments.\n"},{"id":389,"path":"../website/pages/docs/dsf-how-to-use.asciidoc.html#dsf-how-to-use.asciidoc_prerequisites---provisioning-environment","type":"tutorial","title":"Prerequisites - Provisioning environment","body":"54.1. Prerequisites - Provisioning environment\nTo start working you need to have some services running in your provisioning environment, such as Jenkins (automation server), GitLab (git repository), SonarQube (program analysis), Nexus (software repository) or similar.\nTo host those services we recommend to have a Production Line instance but you can use other platforms. Here is the list for the different options:\nProduction Line.\ndsf4docker.\n"},{"id":390,"path":"../website/pages/docs/dsf-how-to-use.asciidoc.html#dsf-how-to-use.asciidoc_step-1---configuration-and-services-integration","type":"tutorial","title":"Step 1 - Configuration and services integration","body":"54.2. Step 1 - Configuration and services integration\nThe first step is configuring your services and integrate them with jenkins. Here you have an example about how to manually configure the next services:\nNexus.\nSonarQube.\n"},{"id":391,"path":"../website/pages/docs/dsf-how-to-use.asciidoc.html#dsf-how-to-use.asciidoc_step-2---create-the-project","type":"tutorial","title":"Step 2 - Create the project","body":"54.3. Step 2 - Create the project\n"},{"id":392,"path":"../website/pages/docs/dsf-how-to-use.asciidoc.html#dsf-how-to-use.asciidoc_create-and-integrate-git-repository","type":"tutorial","title":"Create and integrate git repository","body":"54.3.1. Create and integrate git repository\nThe second is create or git repository and integrate it with Jenkins.\nHere you can find a manual guide about how it:\nGitLab new project.\n"},{"id":393,"path":"../website/pages/docs/dsf-how-to-use.asciidoc.html#dsf-how-to-use.asciidoc_start-new-devonfw-project","type":"tutorial","title":"Start new devonfw project","body":"54.3.2. Start new devonfw project\nIt is time to create your devonfw project:\nYou can find all that you need about how to create a new devonfw project\n"},{"id":394,"path":"../website/pages/docs/dsf-how-to-use.asciidoc.html#dsf-how-to-use.asciidoc_cicd-configuration","type":"tutorial","title":"cicd configuration","body":"54.3.3. cicd configuration\nNow you need to add cicd files in your project.\nManual configuration\nJenkinsfile\nHere you can find all that you need to know to do your Jenkinsfile.\nDockerfile\nHere you can find all that you need to know to do your Dockerfile.\nAutomatic configuration\ncicdgen\nIf you are using production line for provisioning you could use cicdgen to configure automatically almost everything explained in the manual configuration. To do it see the cicdgen documentation.\n"},{"id":395,"path":"../website/pages/docs/dsf-how-to-use.asciidoc.html#dsf-how-to-use.asciidoc_step-3---deployment","type":"tutorial","title":"Step 3 - Deployment","body":"54.4. Step 3 - Deployment\nThe third is configure our deployment environment. Here is the list for the different options:\ndsf4openshift.\n"},{"id":396,"path":"../website/pages/docs/dsf-how-to-use.asciidoc.html#dsf-how-to-use.asciidoc_step-4---monitoring","type":"tutorial","title":"Step 4 - Monitoring","body":"54.5. Step 4 - Monitoring\nHere you can find information about tools for monitoring:\nbuild monitor view for Jenkins. With this tool you will be able to see in real time what is the state of your Jenkins pipelines.\n&#x2190;&#xA0;Previous:&#xA0;What is devonfw shop floor?&#xA0;| &#x2191;&#xA0;Up:&#xA0;devonfw shop floor&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Provisioning environments&#xA0;&#x2192;\n"},{"id":397,"path":"../website/pages/docs/getting-started.asciidoc.html#getting-started.asciidoc","type":"docs","title":"I. Getting Started","body":"I. Getting Started\nIntroduction\nGuides\nFurther Information\n&#x2191;&#xA0;Up:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Introduction&#xA0;&#x2192;\n"},{"id":398,"path":"../website/pages/docs/getting-started.asciidoc_further-information.html#getting-started.asciidoc_further-information","type":"docs","title":"Further Information","body":"3. Further Information\n"},{"id":399,"path":"../website/pages/docs/getting-started.asciidoc_further-information.html#further-info-repo-overview.asciidoc","type":"docs","title":"Repository Overview","body":"3.1. Repository Overview\nThe GitHub repositories within the devonfw organization contain the source code and documentation for official devonfw projects.\nAn overview of the devonfw organization repositories.\nThe most relevant repositories here are the individual devonfw technology stacks:\ndevon4j (for Java)\ndevon4ng (for Angular)\ndevon4net (for .NET)\ndevon4node (for Node.js)\ndevon4x (for Xamarin)\nOur framework also delivers a number of tools and plug-ins that aim to accelerate and streamline the development process, for example:\ndevonfw-ide (for environment/workspace setup)\nCobiGen (for automated code generation)\ndevon4j-sonar-plugin (for architecture validation)\nMrChecker (for E2E test automation)\nWe also provide educational material and reference implementations to aid new users and drive the adoption of our framework, for example:\nJumpTheQueue (simple, step-by-step app creation tutorial)\nMyThaiStar (well documented, complex reference application)\ndevonfw-shop-floor (tools and tutorials for CI/CD efforts)\naccelerated-solution-design (work-methodology for faster app design)\nand many more &#x2026;&#x200B;\nProjects in early development and prototypes are located in the devonfw forge repository. They usually remain there until they are ready for broader release or use in production.\n"},{"id":400,"path":"../website/pages/docs/getting-started.asciidoc_further-information.html#further-info-community-links.asciidoc","type":"docs","title":"Links to our Community","body":"3.2. Links to our Community\nWe strive to foster an active, diverse and dynamic community around devonfw and are relying on modern collaboration tools to do so. Please note that some resources listed here might only be accessible to members or partners of Capgemini.\n"},{"id":401,"path":"../website/pages/docs/getting-started.asciidoc_further-information.html#further-info-community-links.asciidoc_microsoft-teams","type":"docs","title":"Microsoft Teams","body":"3.2.1. Microsoft Teams\nThe devonfw public channel is accessible to everyone who has a Microsoft Teams account. You can find the latest discussions on ongoing development topics here, as well as new commits and pull requests to our repos.\nJoin us to stay in the loop, and feel free to post your questions regarding devonfw here.\ndevonfw Public Channel\n"},{"id":402,"path":"../website/pages/docs/getting-started.asciidoc_further-information.html#further-info-community-links.asciidoc_yammer","type":"docs","title":"Yammer","body":"3.2.2. Yammer\nOur corporate Yammer channel is accessible to Capgemini employees and members. If you are looking for information or feedback on current and planned projects regarding devonfw, we reccomend you ask around here first.\ndevonfw Corporate Yammer\n"},{"id":403,"path":"../website/pages/docs/getting-started.asciidoc_further-information.html#further-info-community-links.asciidoc_e-mail","type":"docs","title":"E-Mail","body":"3.2.3. E-Mail\nYou can reach our dedicated iCSD Support Team via e-mail at:\nicsddevonfwsupport.apps2@capgemini.com\n"},{"id":404,"path":"../website/pages/docs/getting-started.asciidoc_further-information.html#getting-started.asciidoc_contributing","type":"docs","title":"Contributing","body":"3.3. Contributing\nPlease refer to our Contributing section.\n"},{"id":405,"path":"../website/pages/docs/getting-started.asciidoc_further-information.html#getting-started.asciidoc_code-of-conduct","type":"docs","title":"Code of Conduct","body":"3.4. Code of Conduct\nPlease refer to our Code of Conduct section.\n&#x2190;&#xA0;Previous:&#xA0;Guides&#xA0;| &#x2191;&#xA0;Up:&#xA0;Getting Started&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;devonfw-ide&#xA0;&#x2192;\n"},{"id":406,"path":"../website/pages/docs/getting-started.asciidoc_guides.html#getting-started.asciidoc_guides","type":"docs","title":"Guides","body":"2. Guides\nOur goal is to provide a smooth starting experience to all users of devonfw, no matter how experienced they are or what their stakeholder role is. To achieve this, we provide a list of recommended guides here:\nFor Students and Junior Engineers:\nExplore the devonfw sample application.\nBuild your first application with devon4j/devon4ng.\nCreate an application with devon4node.\nCreate an application with devon4net.\nFor Senior Engineers and Architects:\nExplore the devonfw sample application.\nFor Team Leaders and Product Ambassadors:\nLicense management for OSS projects.\n"},{"id":407,"path":"../website/pages/docs/getting-started.asciidoc_guides.html#guide-first-application.asciidoc","type":"docs","title":"Build Your First devonfw Application","body":"2.1. Build Your First devonfw Application\nJumpTheQueue is a small application based on the devonfw framework, which you can create yourself by following our simple step-by-step tutorial. By doing so, you will learn about the app development workflow and gain insight into the design of a professional business information system. Please visit the JumpTheQueue wiki and start working trough the tutorial HERE.\nTip\nThe tutorial assumes you have successfully set up the devonfw-ide previously.\nYou can also clone the project and explore the finished source code via:\ngit clone https://github.com/devonfw/jump-the-queue.git\nAnother way to check out the JumpTheQueue-Application is to try our interactive katacoda scenario where you set up the application step by step.\nJumpTheQueue Katacoda Scenario\n"},{"id":408,"path":"../website/pages/docs/getting-started.asciidoc_guides.html#guide-sample-application.asciidoc","type":"docs","title":"Explore Our devonfw Sample Application","body":"2.2. Explore Our devonfw Sample Application\nMyThaiStar is a complex sample app, that demonstrates the full capabilities of our framework. On this page we will describe how to download and launch the app on your system, so you can test the various functionalities it offers and explore its code.\nYou can also check out the interactive katacoda scenario for setting up and trying out the MyThaiStar-Application.\nMyThaiStar Katacoda Scenario\nTip\nWe assume you have successfully set up the devonfw-ide previously.\nIn the root directory of a devonfw-ide directory, right click and select &quot;Open Devon CMD shell here&quot; from the Windows Explorer context menu. Then navigate to the main workspace and checkout the MyThaiStar Git repository like this:\ncd workspaces/main\ngit clone https://github.com/devonfw/my-thai-star.git\nPerform: cd my-thai-star\nExecute: devon eclipse ws-up\nExecute: devon eclipse create-script\nGo to the root folder of the distribution and run eclipse-main.bat\nIn Eclipse navigate to File &gt; Import &gt; Maven &gt; Existing Maven Projects, then import the cloned project from your workspace by clicking the &quot;Browse&quot; button and selecting /workspaces/my-thai-star/java/mtsj/.\nRun the backend by right-clicking SpringBootApp.java and selecting Run as &gt; Java Application in the context menu. The backend will start up and create log entries in the Eclipse Console tab.\nReturn to your command shell and perform: cd angular\nExecute: npm install\nExecute: ng serve\nOnce started, the frontend will be available at localhost:4200/restaurant. Login with the username and password waiter and take a look at the various functionalities provided by MyThaiStar.\nYou should now take a look at both the front- and backend code and familiarize yourself with its structure and concepts, since most devonfw projects follow this exemplary implementation. Please visit the architecture overview pages of devon4ng and devon4j to learn more about the internal workings of front- and backend.\n&#x2190;&#xA0;Previous:&#xA0;Introduction&#xA0;| &#x2191;&#xA0;Up:&#xA0;Getting Started&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Further Information&#xA0;&#x2192;\n"},{"id":409,"path":"../website/pages/docs/getting-started.asciidoc_introduction.html#getting-started.asciidoc_introduction","type":"docs","title":"Introduction","body":"1. Introduction\n"},{"id":410,"path":"../website/pages/docs/getting-started.asciidoc_introduction.html#introduction-what-is-devonfw.asciidoc","type":"docs","title":"What is devonfw?","body":"1.1. What is devonfw?\nWelcome to the devonfw platform. This is a product of the CSD (Custom Solution Development) industrialization effort to establish a standardized platform for custom software development within Capgemini APPS2. This platform is aimed at engagements, in which clients don&#x2019;t specify the use of a predefined technology stack. In these cases we can offer a proven alternative as a result of our experience as a group.\ndevonfw is a development platform aiming for the standardization of processes and the boosting of productivity. It provides an architecture blueprint for server and client applications, alongside a set of tools to deliver a fully functional, out-of-the-box development environment.\nTip\nThe devonfw name is a registered trademark of , but the software and documentation included in devonfw are fully open source. Please refer to our OSS Compliance section for more information.\n"},{"id":411,"path":"../website/pages/docs/getting-started.asciidoc_introduction.html#introduction-what-is-devonfw.asciidoc_building-blocks-of-the-platform","type":"docs","title":"Building Blocks of the Platform","body":"1.1.1. Building Blocks of the Platform\ndevonfw uses a state-of-the-art, open source, core reference architecture for the server (these days considered a commodity in the IT-industry) and on top of that an ever increasing number of high-value assets, which are developed by Capgemini.\n"},{"id":412,"path":"../website/pages/docs/getting-started.asciidoc_introduction.html#introduction-what-is-devonfw.asciidoc_the-devonfw-technology-stack","type":"docs","title":"The devonfw Technology Stack","body":"1.1.2. The devonfw Technology Stack\ndevonfw is fully open source and consists of the following technology stacks:\nBack-End Solutions\nFor server applications, devonfw includes the following solutions:\ndevon4j: Server implementation based on Java, Spring and Spring Boot.\ndevon4net: Server implementation based on .NET.\ndevon4node: Server implementation based on NestJS.\nFront-End solutions\nFor client applications, devonfw includes two solutions based on TypeScript, JavaScript, C# and .NET:\ndevon4ng: Frontend implementation based on Angular and a hybrid mobile implementation based on Ionic.\ndevon4X: Mobile implementation based on Xamarin.\n"},{"id":413,"path":"../website/pages/docs/getting-started.asciidoc_introduction.html#introduction-what-is-devonfw.asciidoc_custom-tools","type":"docs","title":"Custom Tools","body":"1.1.3. Custom Tools\ndevonfw-ide\nThe devonfw-ide is not one monolithic program that is installed with a traditional executable; rather it&#x2019;s a collection of scripts which are invoked via command line to automate several, repetetive development tasks. These scripts then interact with other tools, frameworks, and third-party IDEs to streamline the development workflow.\nThe advantage of this approach is, that you can have as many instances of the devonfw-ide on your machine as you need&#x2009;&#x2014;&#x2009;for different projects with different tools, tool versions and configurations. No need for a physical installation and no tweaking of your operating system required!\nInstances of the devonfw-ide do not interfere with each other, nor with other installed software. The package size of the devonfw-ide is initally very small, the setup is simple, and the included software is portable.\nIDEs\nIt supports the following IDEs:\nEclipse\nVisual Studio Code\nIntelliJ IDEA\nPlatforms\nIt supports the following platforms:\nJava (see also devon4j)\nNode.js (see also devon4node)\nAngular (see also devon4ng)\nC# (see also devon4net)\nBuild-Systems\nIt supports the following build-systems:\nMaven\nNPM\nGradle\nTip\nOther IDEs, platforms, or tools can easily be integrated as commandlets.\nCobiGen\nCobiGen is a code generator included in the devonfw-ide, that allows users to generate the project structure and large parts of the application component code. This saves a lot of time, which is usually wasted on repetitive engineering tasks and/or writing boilerplate code.\nFollowing the same philosophy as the devonfw-ide, CobiGen bundles a new command line interface (CLI), that enables the generation of code using only a few commands. This approach also allows us to decouple CobiGen from Eclipse and use it alongside VS Code or IntelliJ IDEA.\n"},{"id":414,"path":"../website/pages/docs/getting-started.asciidoc_introduction.html#introduction-why-should-i-use-devonfw.asciidoc","type":"docs","title":"Why should I use devonfw?","body":"1.2. Why should I use devonfw?\ndevonfw aims to provide a framework for the development of web applications based on the Java EE programming model. It uses the Spring framework as its Java EE default implementation.\n"},{"id":415,"path":"../website/pages/docs/getting-started.asciidoc_introduction.html#introduction-why-should-i-use-devonfw.asciidoc_objectives","type":"docs","title":"Objectives","body":"1.2.1. Objectives\nStandardization\nWe don&#x2019;t want to keep reinventing the wheel for thousands of projects, for hundreds of customers, across dozens of countries. For this reason, we aim to rationalize, harmonize and standardize the development assets for software projects and industrialize the software development process.\nIndustrialization of Innovative Technologies &amp; &#x201C;Digital&#x201D;\ndevonfw&#x2019;s goal is to standardize &amp; industrialize. But this applies not only to large volume, &#x201C;traditional&#x201D; custom software development projects. devonfw also aims to offer a standardized platform which contains a range of state-of-the-art methodologies and technology stacks. devonfw supports agile development by small teams utilizing the latest technologies for projects related to Mobile, IoT and the Cloud.\nDeliver &amp; Improve Business Value\nEfficiency\nUp to 20% reduction in time to market, with faster delivery due to automation and reuse.\nUp to 25% less implementation efforts due to code generation and reuse.\nFlat pyramid and rightshore, ready for junior developers.\nQuality\nState-of-the-art architecture and design.\nLower cost on maintenance and warranty.\nTechnical debt reduction by reuse.\nRisk reduction due to continuous improvement of individual assets.\nStandardized, automated quality checks.\nAgility\nFocus on business functionality, not on technicalities.\nShorter release cycles.\nDevOps by design&#x2009;&#x2014;&#x2009;Infrastructure as Code.\nContinuous Delivery pipeline.\nOn- and off-premise flexibility.\nPoCs and prototypes in days not months.\n"},{"id":416,"path":"../website/pages/docs/getting-started.asciidoc_introduction.html#introduction-why-should-i-use-devonfw.asciidoc_features","type":"docs","title":"Features","body":"1.2.2. Features\nEverything in a Single ZIP\nThe devonfw distributions is packaged in a ZIP file that includes all the custom tools, software and configurations.\nHaving all the dependencies self-contained in the distribution&#x2019;s ZIP file, users don&#x2019;t need to install or configure anything. Just extracting the ZIP content is enough to have a fully functional devonfw.\ndevonfw&#x2009;&#x2014;&#x2009;The Package\nThe devonfw platform provides:\nImplementation blueprints for a modern cloud-ready server and a choice on JS-Client technologies (either open source Angular or a very rich and impressive solution based on commercial Sencha UI).\nQuality documentation and step-by-step quick start guides.\nHighly integrated and packaged development environment based around Eclipse and Jenkins. You will be ready to start implementing your first customer-specific use case in 2h time.\nIterative eclipse-based code-generator that understands &quot;Java&quot; and works on higher architectural concepts than Java-classes.\nAn example application as a reference implementation.\nSupport through a large community + industrialization services (Standard Platform as a Service) available in the iProd service catalog.\n"},{"id":417,"path":"../website/pages/docs/getting-started.asciidoc_introduction.html#getting-started.asciidoc_devonfw-ide-download-and-setup","type":"docs","title":"devonfw-ide Download and Setup","body":"1.3. devonfw-ide Download and Setup\nPlease refer to our devonfw-ide Setup section.\n&#x2191;&#xA0;Up:&#xA0;Getting Started&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Guides&#xA0;&#x2192;\n"},{"id":418,"path":"../website/pages/docs/guide-blazegraph.asciidoc.html#guide-blazegraph.asciidoc","type":"docs","title":"Blazegraph","body":"49. Blazegraph\nThis section is the place to share experience for those who use Blazegraph as NoSQL database.\n"},{"id":419,"path":"../website/pages/docs/guide-blazegraph.asciidoc.html#guide-blazegraph.asciidoc_attention","type":"docs","title":"Attention","body":"49.1. Attention\nNote\ndevonfw did not focus on the integration of this database so far. No reports have been given from our users about successfully integrating this database with any devonfw tech stack. If you want to share your knowledge or report usage, please contribute by clicking on the pen next to the section headline.If you need help on devonfw tech stack knowledge to get the integration working for you, stay in contact at GitHub.\n"},{"id":420,"path":"../website/pages/docs/guide-blazegraph.asciidoc.html#guide-blazegraph.asciidoc_driver","type":"docs","title":"Driver","body":"49.2. Driver\nPlease be aware that there is not a regular JDBC driver in case you are using Java (devon4j).\nFor driver options see here.\n&#x2190;&#xA0;Previous:&#xA0;OrientDB&#xA0;| &#x2191;&#xA0;Up:&#xA0;Choosing your Database&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;HBase&#xA0;&#x2192;\n"},{"id":421,"path":"../website/pages/docs/guide-cassandra.asciidoc.html#guide-cassandra.asciidoc","type":"docs","title":"Cassandra","body":"43. Cassandra\nThis section is the place to share experience for those who use Cassandra as NoSQL database.\n"},{"id":422,"path":"../website/pages/docs/guide-cassandra.asciidoc.html#guide-cassandra.asciidoc_attention","type":"docs","title":"Attention","body":"43.1. Attention\nNote\ndevonfw did not focus on the integration of this database so far. No reports have been given from our users about successfully integrating this database with any devonfw tech stack. If you want to share your knowledge or report usage, please contribute by clicking on the pen next to the section headline.If you need help on devonfw tech stack knowledge to get the integration working for you, stay in contact at GitHub.\n"},{"id":423,"path":"../website/pages/docs/guide-cassandra.asciidoc.html#guide-cassandra.asciidoc_driver","type":"docs","title":"Driver","body":"43.2. Driver\nPlease be aware that there is not a regular JDBC driver in case you are using Java (devon4j).\nFor driver options see here.\n"},{"id":424,"path":"../website/pages/docs/guide-cassandra.asciidoc.html#guide-cassandra.asciidoc_spring-data","type":"docs","title":"Spring-Data","body":"43.3. Spring-Data\nThere is spring-data support available for cassandra via spring-data-cassandra.\nNote\nPlease note that some time ago we had feedback from projects that had issues with spring-data-cassandra and switched back to using the driver natively. We assume the issues are meanwhile resolved. TODO: collect more feedback and update this guide.\n&#x2190;&#xA0;Previous:&#xA0;Database&#xA0;| &#x2191;&#xA0;Up:&#xA0;Choosing your Database&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;neo4j&#xA0;&#x2192;\n"},{"id":425,"path":"../website/pages/docs/guide-couchdb.asciidoc.html#guide-couchdb.asciidoc","type":"docs","title":"CouchDB","body":"46. CouchDB\nThis section is the place to share experience for those who use CouchDB as NoSQL database.\n"},{"id":426,"path":"../website/pages/docs/guide-couchdb.asciidoc.html#guide-couchdb.asciidoc_attention","type":"docs","title":"Attention","body":"46.1. Attention\nNote\ndevonfw did not focus on the integration of this database so far. No reports have been given from our users about successfully integrating this database with any devonfw tech stack. If you want to share your knowledge or report usage, please contribute by clicking on the pen next to the section headline.If you need help on devonfw tech stack knowledge to get the integration working for you, stay in contact at GitHub.\n"},{"id":427,"path":"../website/pages/docs/guide-couchdb.asciidoc.html#guide-couchdb.asciidoc_driver","type":"docs","title":"Driver","body":"46.2. Driver\nPlease be aware that there is not a regular JDBC driver in case you are using Java (devon4j).\nFor driver options see here.\n&#x2190;&#xA0;Previous:&#xA0;MongoDB&#xA0;| &#x2191;&#xA0;Up:&#xA0;Choosing your Database&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Redis&#xA0;&#x2192;\n"},{"id":428,"path":"../website/pages/docs/guide-database.asciidoc.html#guide-database.asciidoc","type":"docs","title":"Database","body":"42. Database\nFor your business application with devonfw you need to choose the right database.\nIn devonfw we are not biased for a particular product so you have the freedom of choice.\n"},{"id":429,"path":"../website/pages/docs/guide-database.asciidoc.html#guide-database.asciidoc_rdbms","type":"docs","title":"RDBMS","body":"42.1. RDBMS\nThe classical and well-established form of a database is a relational database management system (RDBMS).\nIn devonfw we recommend to use an RDBMS unless you have specific need.\nHowever, in case you have the need for big data, graph-data, BLOB focus, or schema-less dynamic data you can have a look at NoSQL options but be aware that these may be experimental and are not fully supported by devonfw.\n"},{"id":430,"path":"../website/pages/docs/guide-database.asciidoc.html#guide-database.asciidoc_options","type":"docs","title":"Options","body":"42.1.1. Options\nIn devonfw we are not biased for a particular RDBMS so you have the freedom of choice.\nHere are the most common options:\nSAP Hana (high performance in-memory, many advanced features)\nOracle (most established, well featured for enterprise)\nPostgreSQL (great open-source RDBMS)\nMariaDB (true OSS successor of MySQL)\nMS SQL Server (best choice for Microsoft and Windows dominated IT landscapes)\nPlease click on any of the above choices and go to the according guide to find specific detials such as client/driver.\n"},{"id":431,"path":"../website/pages/docs/guide-database.asciidoc.html#guide-database.asciidoc_nosql","type":"docs","title":"NoSQL","body":"42.2. NoSQL\nWhile not (yet) officially supported and recommendet there are also interesting NoSQL (Not Only SQL) databases that could be an interesting alternative. Please be aware that you will typically not be able to use JPA (and hibernate). Further before choosing a NoSQL database you should check the following aspects:\nIs the database of choice reliable and mature enough for your project?\nCan the operators of your product support the database of choice properly (provisioning, administration, backup, scaling &amp; clustering, monitoring, etc.)?\nDoes the database of choice meet the requirements of your project (ACID vs. eventual consistencey, CAP theorem)?\nThere are good reasons to choose a particular NoSQL database in specific cases (e.g. extreme demand for big-data, throughput or scaling).\nBut as indicated by the questions above you need to be fully aware of what you are doing.\nNoSQL databases can be schemaless (untyped, dynamic &amp; flexible) and/or schemaful (typed, structured &amp; strict).\nFurhter, there are different types of NoSQL databases that are discussed in the following sub-sections:\n"},{"id":432,"path":"../website/pages/docs/guide-database.asciidoc.html#guide-database.asciidoc_column-db","type":"docs","title":"Column DB","body":"42.2.1. Column DB\nColumn NoSQL databases are more related to a regular RDBMS with their tables and columns.\nHowever, they typically do not offer relational support with joins to the same level as you expect from an RDBMS.\nTherefore, you have to carefully design your data-model upfront with the all the knowledge how you later want to query your data.\nThe most prominent options are:\nCassandra (high-performance, schema-based DB)\nHBase (distributed, big-data Hadoop database)\n"},{"id":433,"path":"../website/pages/docs/guide-database.asciidoc.html#guide-database.asciidoc_key-value-db","type":"docs","title":"Key-Value DB","body":"42.2.2. Key-Value DB\nAs indicated by the name, a key-value database stores objects as key/value pairs similar to Properties or Map in Java.\nThe most prominent options are:\nRedis (in-memory key/value store, especially used as cache or message broker)\naerospike\n"},{"id":434,"path":"../website/pages/docs/guide-database.asciidoc.html#guide-database.asciidoc_document-db","type":"docs","title":"Document DB","body":"42.2.3. Document DB\nA document database is similar to a key-value database, but it stores objects in standard structured formats such as XML, JSON, or BSON.\nTherefore not only flat key/value pairs but even trees of hierarchical data can be stored, retrieved and queried.\nThe most prominent options are:\nMongoDB\nCouchDB\nRavenDB\n"},{"id":435,"path":"../website/pages/docs/guide-database.asciidoc.html#guide-database.asciidoc_graph-db","type":"docs","title":"Graph DB","body":"42.2.4. Graph DB\nIf the connections (links/relations) between your data is key and an RDBMS is just not flexible or fast enough for your plans, then a graph database can help you.\nThey are very strong on storing and querying complex connections between entities.\nFor queries there are even specific standards and languages like Gremlin.\nThe most prominent options are:\nneo4j\nblazegraph\n"},{"id":436,"path":"../website/pages/docs/guide-database.asciidoc.html#guide-database.asciidoc_hybrid-db","type":"docs","title":"Hybrid DB","body":"42.2.5. Hybrid DB\nIn addition to the above types there are some NoSQL databases that are hybrid and combine the features and aspects of these types.\nWhile as an architect and developer you might love the idea to get all in one, you have to be careful with your choice.\nIf you do not exactly know your problem, you are not ready to make the right choice for your database.\nFurther, you might still be best-off with an good old RDBMS if you need to address multiple aspects together.\nAnyhow, for experiments, PoCs, or small microservices with little risk it might be a great idea to choose a hybrid NoSQL database.\nIf you have collected very positive, profound and productive experience with such product you can grow on it.\nThe most prominent options are:\nOrientDB (object-oriented, hyper-flexible, column- and graph-based)\n&#x2190;&#xA0;Previous:&#xA0;MariaDB&#xA0;| &#x2191;&#xA0;Up:&#xA0;Choosing your Database&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Cassandra&#xA0;&#x2192;\n"},{"id":437,"path":"../website/pages/docs/guide-gigaspaces.asciidoc.html#guide-gigaspaces.asciidoc","type":"docs","title":"GigaSpaces XAP (Smart Cache)","body":"52. GigaSpaces XAP (Smart Cache)\nThis section is the place to share experience for those who use GigaSpaces XAP as NoSQL database.\n"},{"id":438,"path":"../website/pages/docs/guide-gigaspaces.asciidoc.html#guide-gigaspaces.asciidoc_attention","type":"docs","title":"Attention","body":"52.1. Attention\nNote\nA sample for GigaSpaces integration has been contributed from a graduate work, which will be described here. No reports have been given from our users about successfully integrating this database with any devonfw tech stack. If you want to share your knowledge or report usage, please contribute by clicking on the pen next to the section headline.If you need help on devonfw tech stack knowledge to get the integration working for you, stay in contact at GitHub.\n"},{"id":439,"path":"../website/pages/docs/guide-gigaspaces.asciidoc.html#guide-gigaspaces.asciidoc_possible-approach","type":"docs","title":"Possible Approach","body":"52.2. Possible Approach\nGigaSpaces is currently not in the central maven repository, therefore an additional repository needs to be added along with the dependency:\n&lt;repositories&gt;\n&lt;repository&gt;\n&lt;id&gt;org.openspaces&lt;/id&gt;\n&lt;url&gt;http://maven-repository.openspaces.org&lt;/url&gt;\n&lt;/repository&gt;\n&lt;/repositories&gt;\n&lt;dependency&gt;\n&lt;groupId&gt;org.gigaspaces&lt;/groupId&gt;\n&lt;artifactId&gt;xap-openspaces&lt;/artifactId&gt;\n&lt;version&gt;${gsVersion}&lt;/version&gt;\n&lt;/dependency&gt;\nOf course the version (${gsVersion}) needs to be adopted to your needs.\n@Configuration\npublic class ContextConfiguration {\n@Bean\npublic GigaSpace space() {\nUrlSpaceConfigurer urlSpaceConfigurer = new UrlSpaceConfigurer(&quot;jini://*/*/my-space&quot;);\nreturn new GigaSpaceConfigurer(urlSpaceConfigurer).gigaSpace();\n}\n}\nTo establish a connection with a running instance of GigaSpaces, a Configuration Class is required. Here a Bean will be created that retrieves via URL the name of a Space e.g. my-space (a Space is equivalent to a Database Schema). Of course a Space needs to be firstly created in order to use it (see also the Example). This bean can be used for all database typical operations e.g. create, read, update and delete data (a complete list can be found here). Another possibility to execute those operations is via spring-data (see section below). The spring-data-gigaspaces automatically detects if a GigaSpaces Bean exists.\n"},{"id":440,"path":"../website/pages/docs/guide-gigaspaces.asciidoc.html#guide-gigaspaces.asciidoc_spring-data","type":"docs","title":"Spring-Data","body":"52.3. Spring-Data\nThere is spring-data support available for GigaSpaces XAP (Smart Cache) via spring-data-gigaspaces.\n"},{"id":441,"path":"../website/pages/docs/guide-gigaspaces.asciidoc.html#guide-gigaspaces.asciidoc_example","type":"docs","title":"Example","body":"52.4. Example\nThere is an implementation of the sample application, My Thai Star, using GigaSpaces XAP (Smart Cache) as data storage. More details can be found on mts-gigaspaces.\n&#x2190;&#xA0;Previous:&#xA0;RavenDB&#xA0;| &#x2191;&#xA0;Up:&#xA0;Choosing your Database&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;devonfw shop floor&#xA0;&#x2192;\n"},{"id":442,"path":"../website/pages/docs/guide-hana.asciidoc.html#guide-hana.asciidoc","type":"docs","title":"SAP HANA","body":"37. SAP HANA\nThis section contains hints for those who use SAP HANA, a very powerful and fast RDBMS. Besides general hints about the driver there are tips for more tight integration with other SAP features or products.\n"},{"id":443,"path":"../website/pages/docs/guide-hana.asciidoc.html#guide-hana.asciidoc_driver","type":"docs","title":"Driver","body":"37.1. Driver\nSAP Hana is a commercial and professional product.\nHowever, the hana JDBC driver is available in Maven Central what makes it easy to integrate.\nAll you need is the following maven dependency:\n&lt;dependency&gt;\n&lt;groupId&gt;com.sap.cloud.db.jdbc&lt;/groupId&gt;\n&lt;artifactId&gt;ngdbc&lt;/artifactId&gt;\n&lt;version&gt;${hana.driver.version}&lt;/version&gt;\n&lt;/dependency&gt;\nOf course the version (${hana.driver.version}) needs to be adopted to your needs (Hana installtion in production, e.g. 2.4.64).\nFor an overview of available driver versions see here.\n"},{"id":444,"path":"../website/pages/docs/guide-hana.asciidoc.html#guide-hana.asciidoc_developer-usage","type":"docs","title":"Developer Usage","body":"37.2. Developer Usage\nFor your local development environment you will love the free SAP HANA, Express Edition.\nYou can run HANA in several ways:\nOn-premise\nVia a Docker image (Linux only)\nVia a pre-configured virtual machine (Windows, Linux, OS X)\nInstalled natively on your local machine (Linux only)\nIn the cloud\nVia a pre-configured machine on the Google Cloud Platform\nVia a pre-configured machine in the Microsoft Azure Cloud\nVia a pre-configured machine on Amazon Web Services\nTo get started with SAP HANA, Express Edition you can check out the tutorials at the SAP Developer Center.\n"},{"id":445,"path":"../website/pages/docs/guide-hana.asciidoc.html#guide-hana.asciidoc_pooling","type":"docs","title":"Pooling","body":"37.3. Pooling\nSee Overriding the JDBC Connection Pool Settings.\n"},{"id":446,"path":"../website/pages/docs/guide-hana.asciidoc.html#guide-hana.asciidoc_fuzzy-search","type":"docs","title":"Fuzzy Search","body":"37.4. Fuzzy Search\nSee https://blogs.sap.com/2015/08/28/dynamism-of-fuzzy-search-in-sap-hana/ or the SAP HANA Search Developer Guide\n&#x2190;&#xA0;Previous:&#xA0;Database&#xA0;| &#x2191;&#xA0;Up:&#xA0;Choosing your Database&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Oracle RDBMS&#xA0;&#x2192;\n"},{"id":447,"path":"../website/pages/docs/guide-hbase.asciidoc.html#guide-hbase.asciidoc","type":"docs","title":"HBase","body":"50. HBase\nThis section is the place to share experience for those who use HBase as NoSQL database.\n"},{"id":448,"path":"../website/pages/docs/guide-hbase.asciidoc.html#guide-hbase.asciidoc_attention","type":"docs","title":"Attention","body":"50.1. Attention\nNote\ndevonfw did not focus on the integration of this database so far. No reports have been given from our users about successfully integrating this database with any devonfw tech stack. If you want to share your knowledge or report usage, please contribute by clicking on the pen next to the section headline.If you need help on devonfw tech stack knowledge to get the integration working for you, stay in contact at GitHub.\n"},{"id":449,"path":"../website/pages/docs/guide-hbase.asciidoc.html#guide-hbase.asciidoc_driver","type":"docs","title":"Driver","body":"50.2. Driver\nPlease be aware that there is not a regular JDBC driver in case you are using Java (devon4j).\nFor driver options see here and\nhbase-java-api tutorial.\n&#x2190;&#xA0;Previous:&#xA0;Blazegraph&#xA0;| &#x2191;&#xA0;Up:&#xA0;Choosing your Database&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;RavenDB&#xA0;&#x2192;\n"},{"id":450,"path":"../website/pages/docs/guide-mariadb.asciidoc.html#guide-mariadb.asciidoc","type":"docs","title":"MariaDB","body":"41. MariaDB\nThis section gives guidance and hints for those who use MariaDB as RDBMS.\n"},{"id":451,"path":"../website/pages/docs/guide-mariadb.asciidoc.html#guide-mariadb.asciidoc_driver","type":"docs","title":"Driver","body":"41.1. Driver\nMariaDB is fully open-source. The driver is therefore available in maven central.\nYour dependency for the driver should look as following:\n&lt;dependency&gt;\n&lt;groupId&gt;org.mariadb.jdbc&lt;/groupId&gt;\n&lt;artifactId&gt;mariadb-java-client&lt;/artifactId&gt;\n&lt;version&gt;${mariadb.driver.version}&lt;/version&gt;\n&lt;/dependency&gt;\nOf course the version (${mariadb.driver.version}) needs to be adopted to your needs (MariaDB installtion in production and JDK version, e.g. 2.5.1).\nFor an overview of available driver versions see here.\n&#x2190;&#xA0;Previous:&#xA0;PostgreSQL&#xA0;| &#x2191;&#xA0;Up:&#xA0;Choosing your Database&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Database&#xA0;&#x2192;\n"},{"id":452,"path":"../website/pages/docs/guide-mongodb.asciidoc.html#guide-mongodb.asciidoc","type":"docs","title":"MongoDB","body":"45. MongoDB\nThis section is the place to share experience for those who use MongoDB as NoSQL database.\n"},{"id":453,"path":"../website/pages/docs/guide-mongodb.asciidoc.html#guide-mongodb.asciidoc_attention","type":"docs","title":"Attention","body":"45.1. Attention\nNote\ndevonfw did not focus on the integration of this database so far. No reports have been given from our users about successfully integrating this database with any devonfw tech stack. If you want to share your knowledge or report usage, please contribute by clicking on the pen next to the section headline.If you need help on devonfw tech stack knowledge to get the integration working for you, stay in contact at GitHub.\n"},{"id":454,"path":"../website/pages/docs/guide-mongodb.asciidoc.html#guide-mongodb.asciidoc_driver","type":"docs","title":"Driver","body":"45.2. Driver\nPlease be aware that there is not a regular JDBC driver in case you are using Java (devon4j).\nFor driver options see here.\n&#x2190;&#xA0;Previous:&#xA0;neo4j&#xA0;| &#x2191;&#xA0;Up:&#xA0;Choosing your Database&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;CouchDB&#xA0;&#x2192;\n"},{"id":455,"path":"../website/pages/docs/guide-mssqlserver.asciidoc.html#guide-mssqlserver.asciidoc","type":"docs","title":"MS-SQL-Server","body":"39. MS-SQL-Server\nThis section gives guidance and hints for those who use Microsoft SQL Server as RDBMS.\n"},{"id":456,"path":"../website/pages/docs/guide-mssqlserver.asciidoc.html#guide-mssqlserver.asciidoc_driver","type":"docs","title":"Driver","body":"39.1. Driver\nMicrosoft SQL Server is a commercial and professional product.\nHowever, the JDBC driver is MIT licensed and available in Maven Central what makes it easy to integrate.\nYour dependency for the driver should look as following:\n&lt;dependency&gt;\n&lt;groupId&gt;com.microsoft.sqlserver&lt;/groupId&gt;\n&lt;artifactId&gt;mssql-jdbc&lt;/artifactId&gt;\n&lt;version&gt;${mssqlserver.driver.version}&lt;/version&gt;\n&lt;/dependency&gt;\nOf course the version (${mssqlserver.driver.version}) needs to be adopted to your needs (SQL Server installtion in production and JDK version, e.g. 7.4.1.jre8).\nFor an overview of available driver versions see here.\n&#x2190;&#xA0;Previous:&#xA0;Oracle RDBMS&#xA0;| &#x2191;&#xA0;Up:&#xA0;Choosing your Database&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;PostgreSQL&#xA0;&#x2192;\n"},{"id":457,"path":"../website/pages/docs/guide-neo4j.asciidoc.html#guide-neo4j.asciidoc","type":"docs","title":"neo4j","body":"44. neo4j\nThis section is the place to share experience for those who use neo4j as NoSQL database.\n"},{"id":458,"path":"../website/pages/docs/guide-neo4j.asciidoc.html#guide-neo4j.asciidoc_attention","type":"docs","title":"Attention","body":"44.1. Attention\nNote\ndevonfw did not focus on the integration of this database so far. No reports have been given from our users about successfully integrating this database with any devonfw tech stack. If you want to share your knowledge or report usage, please contribute by clicking on the pen next to the section headline.If you need help on devonfw tech stack knowledge to get the integration working for you, stay in contact at GitHub.\n"},{"id":459,"path":"../website/pages/docs/guide-neo4j.asciidoc.html#guide-neo4j.asciidoc_driver","type":"docs","title":"Driver","body":"44.2. Driver\nPlease be aware that there is not a regular JDBC driver in case you are using Java (devon4j).\nFor driver options see here.\n"},{"id":460,"path":"../website/pages/docs/guide-neo4j.asciidoc.html#guide-neo4j.asciidoc_spring-data","type":"docs","title":"Spring-Data","body":"44.3. Spring-Data\nThere is spring-data integration available via spring-data-neo4j.\n&#x2190;&#xA0;Previous:&#xA0;Cassandra&#xA0;| &#x2191;&#xA0;Up:&#xA0;Choosing your Database&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;MongoDB&#xA0;&#x2192;\n"},{"id":461,"path":"../website/pages/docs/guide-oracle.asciidoc.html#guide-oracle.asciidoc","type":"docs","title":"Oracle RDBMS","body":"38. Oracle RDBMS\nThis section contains hints for those who use Oracle RDBMS. Besides general hints about the driver there are tips for more tight integration with other Oracle features or products. However, if you work for a project where Oracle RDBMS is settled and not going to be replaced (you are in a vendor lock-in anyway), you might want to use even more from Oracle technology to take advantage from a closer integration.\n"},{"id":462,"path":"../website/pages/docs/guide-oracle.asciidoc.html#guide-oracle.asciidoc_xe","type":"docs","title":"XE","body":"38.1. XE\nFor local development you should setup Oracle XE (eXpress Edition).\nYou need an oracle account, then you can download it from here.\nThe most comfortable way to run it as needed is using docker. You can build your own docker image from the downloaded RPM using the instructions and dockerfile from oracle. The following commands will build and start Oracle XE 18.4.0 on your machine:\ngit clone https://github.com/oracle/docker-images.git\ncd docker-images/OracleDatabase/SingleInstance/dockerfiles\n./buildDockerImage.sh -x -v 18.4.0\ndocker run -d -p 1521:1521 --name=oracle-xe --restart=always -e ORACLE_PWD=&#xAB;my-sys-pwd&#xBB; oracle/database:18.4.0-xe\nPlease note that the buildDockerImage.sh will take a long time. Further after docker run has passed you need to give time for your new container to startup and setup the Oracle XE DB. So be patient and give it some time.\n(In case the build of the docker-image fails reproducibly and you want to give up with the Dockerfiles from Oracle you can also try this inofficial docker-oracle-xe solution. However, this is not recommended and may lead to other problems.).\nStarting with XE 18c you need to be aware that oracle introduced a multi-tenant architecture. Hence xe refers to the root CDB while you typically want to connect to the PDB (pluggable database) and XE ships with exactly one of this called xepdb1.\nTo connect to your local XE database you need to use xepdb1 as the Service Name (typically in SQL Developer). The hostname should be localhost and the port is by default 1521 if you did not remap it with docker to something else.\nIn order to create schema users, use sys as Username and change Role to SYSDBA.\nHint: If you happen to end up connected to xe instead of xepdb1 in some case (e.g. in sqlplus), you may switch using this statement:\nALTER SESSION SET CONTAINER = XEPDB1;\nThe JDBC URL for your Oracle XE Database is:\njdbc:oracle:thin:@//localhost:1521/xepdb1\nTo locally connect as sysdba without password use the following command (connect / as sysdba is not working anymore):\nsqlplus sys/Oracle18@localhost/XE as sysdba\n"},{"id":463,"path":"../website/pages/docs/guide-oracle.asciidoc.html#guide-oracle.asciidoc_driver","type":"docs","title":"Driver","body":"38.2. Driver\nThe oracle JDBC driver is available in maven central.\nOracle JDBC drivers usually are backward and forward compatible so you should be able to use an older driver with a newer Oracle DB, etc.\nYour dependency for the oracle driver should look as follows:\n&lt;dependency&gt;\n&lt;groupId&gt;com.oracle.database.jdbc&lt;/groupId&gt;\n&lt;artifactId&gt;ojdbc10&lt;/artifactId&gt;\n&lt;version&gt;${oracle.driver.version}&lt;/version&gt;\n&lt;/dependency&gt;\nFor the most recent Oracle DB 19 the property oracle.driver.version should be 19.8.0.0. The number in the artifactId correlates to the minimum Java Version so for Java8 artifactId should be ojdbc8 instead. It is fine to use ojdbc10 with Java11 or higher.\n"},{"id":464,"path":"../website/pages/docs/guide-oracle.asciidoc.html#guide-oracle.asciidoc_pooling","type":"docs","title":"Pooling","body":"38.3. Pooling\nIn order to boost performance JDBC connections should be pooled and reused. If you are using Oracle RDBMS and do not plan to change that you can use the Oracle specific connection pool &quot;Universal Connection Pool (UCP)&quot; that is perfectly integrated with the Oracle driver. According to the documentation, UCP can even be used to manage third party data sources.\nLike the JDBC driver also the UCP is available in maven central. The dependency should look like this:\n&lt;dependency&gt;\n&lt;groupId&gt;com.oracle.database.jdbc&lt;/groupId&gt;\n&lt;artifactId&gt;ucp&lt;/artifactId&gt;\n&lt;version&gt;${oracle.ucp.version}&lt;/version&gt;\n&lt;/dependency&gt;\nwith property oracle.ucp.version analogue to oracle.driver.version.\nConfiguration is done via application.properties like this (example):\n#Oracle UCP\n# Datasource for accessing the database\nspring.datasource.url=jdbc:oracle:thin:@192.168.58.2:1521:xe\nspring.jpa.database-platform=org.hibernate.dialect.Oracle12cDialect\nspring.datasource.user=MyUser\nspring.datasource.password=ThisIsMyPassword\nspring.datasource.driver-class-name=oracle.jdbc.OracleDriver\nspring.datasource.schema=MySchema\nspring.datasource.type=oracle.ucp.jdbc.PoolDataSourceImpl\nspring.datasource.factory=oracle.ucp.jdbc.PoolDataSourceFactory\nspring.datasource.factory-method=getPoolDataSource\nspring.datasource.connectionFactoryClassName=oracle.jdbc.pool.OracleDataSource\nspring.datasource.validateConnectionOnBorrow=true\nspring.datasource.connectionPoolName=MyPool\nspring.datasource.jmx-enabled=true\n# Optional: Set the log level to INTERNAL_ERROR, SEVERE, WARNING, INFO, CONFIG, FINE, TRACE_10, FINER, TRACE_20, TRACE_30, or FINEST\n# logging.level.oracle.ucp=INTERNAL_ERROR\n# Optional: activate tracing\n# logging.level.oracle.ucp.jdbc.oracle.OracleUniversalPooledConnection=TRACE\n#Optional: Configures pool size manually\n#spring.datasource.minPoolSize=10\n#spring.datasource.maxPoolSize=40\n#spring.datasource.initialPoolSize=20\nResources: FAQ, developer&#x2019;s guide, Java API Reference. For an in-depth discussion on how to use JDBC and UCP, see the Oracle documentation Connection Management Strategies for Java Applications using JDBC and UCP.\nNote: there is a bug in UCP 12.1.0.2 that results in the creation of thousands of java.lang.Timer threads over hours or days of system uptime (see article on stackoverflow). Also, Oracle has a strange bug fixing / patching policy: instead of producing a fixed version 12.1.0.3 or 12.1.0.2.x, Oracle publishes collections of *.class files that must be manually patched into the ucp.jar! Therefore, use the newest versions only.\n"},{"id":465,"path":"../website/pages/docs/guide-oracle.asciidoc.html#guide-oracle.asciidoc_messaging","type":"docs","title":"Messaging","body":"38.4. Messaging\nIn case you want to do messaging based on JMS you might consider the Oracle JMS also called Oracle Streams Advanced Queuing, or Oracle Advanced Queuing, or OAQ or AQ for short. OAQ is a JMS provider based on the Oracle RDBMS and included in the DB product for no extra fee. OAQ has some features that exceed the JMS standard like a retention time (i.e. a built-in backup mechanism that allows to make messages &quot;unread&quot; within a configurable period of time so that these messages do not have to be resent by the sending application). Also, OAQ messages are stored in relational tables so they can easily be observed by a test driver in a system test scenario.\nCapgemini has used the Spring Data JDBC Extension in order to process OAQ messages within the same technical transaction as the resulting Oracle RDBMS data changes without using 2PC and an XA-compliant transaction manager - which is not available out of the box in Tomcat. This is possible only due to the fact that OAQ queues and RDBMS tables actually reside in the same database. However, this is higher magic and should only be tried if high transaction rates must be achieved by avoiding 2PC.\n"},{"id":466,"path":"../website/pages/docs/guide-oracle.asciidoc.html#guide-oracle.asciidoc_general-notes-on-the-use-of-oracle-products","type":"docs","title":"General Notes on the use of Oracle products","body":"38.5. General Notes on the use of Oracle products\nOracle sells commercial products and receives licence fees for them. This includes access to a support organization. Therefore, at an early stage of your project, prepare for contacting oracle support in case of technical problems. You will need the Oracle support ID of your customer [i.e. the legal entity who pays the licence fee and runs the RDBMS] and your customer must grant you permission to use it in a service request - it is not legal to use a your own support ID in a customer-related project. Your customer pays for that service anyway, so use it in case of a problem!\nSoftware components like the JDBC driver or the UCP may be available without a registration or fee but they are protected by the Oracle Technology Network (OTN) License Agreement. The most important aspect of this licence agreement is the fact that an IT service provider is not allowed to simply download the Oracle software component, bundle it in a software artefact and deliver it to the customer. Instead, the Oracle software component must be (from a legal point of view) provided by the owner of the Oracle DB licence (i.e. your customer). This can be achieved in two ways: Advise your customer to install the Oracle software component in the application server as a library that can be used by your custom built system. Or, in cases where this is not feasible, e.g. in a OpenShift environment where the IT service provider delivers complete Docker images, you must advise your customer to (legally, i.e. documented in a written form) provide the Oracle software component to you, i.e. you don&#x2019;t download the software component from the Oracle site but receive it from your customer.\n"},{"id":467,"path":"../website/pages/docs/guide-oracle.asciidoc.html#guide-oracle.asciidoc_fix-for-tns-listener-issues","type":"docs","title":"Fix for TNS-Listener issues","body":"38.6. Fix for TNS-Listener issues\nWhen switching networks (e.g. due to VPN) you might end up that your local Oracle XE stopps working with this error:\nListener refused the connection with the following error:\nORA-12505, TNS:listener does not currently know of SID given in connect descriptor\nWhile a reboot resolves this problem, it is a huge pain to reboot every time this error occurs as this wastes a lot of time.\nTherefore we suggest the following fix:\nGo to your oracle installation and open the folder product/&#xAB;version&#xBB;/dbhomeXE/network/admin.\nEdit the file listener.ora and change the value of the property HOST from your qualified hostname to localhost (HOST = localhost).\nEdit the file tnsnames.ora and change the value of the HOST properties (two occurences) from your qualified hostname to localhost (HOST = localhost).\nReboot your machine or (on windows) restart the service OracleServiceXE via services.msc.\nNow this problem should be gone forever and you can continue your work.\nOn older XE versions until 11g you could run the following SQL (sqlplus / as sysdba @reset_tns_listener.sql):\nWHENEVER SQLERROR EXIT;\nALTER SYSTEM SET local_listener = &apos;(ADDRESS = (PROTOCOL = TCP)(HOST = 127.0.0.1)(PORT = 1521))&apos;;\nALTER SYSTEM REGISTER;\nEXIT;\n&#x2190;&#xA0;Previous:&#xA0;SAP HANA&#xA0;| &#x2191;&#xA0;Up:&#xA0;Choosing your Database&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;MS-SQL-Server&#xA0;&#x2192;\n"},{"id":468,"path":"../website/pages/docs/guide-orientdb.asciidoc.html#guide-orientdb.asciidoc","type":"docs","title":"OrientDB","body":"48. OrientDB\nThis section is the place to share experience for those who use OrientDB (see also Open-Source community edition) as NoSQL database.\n"},{"id":469,"path":"../website/pages/docs/guide-orientdb.asciidoc.html#guide-orientdb.asciidoc_attention","type":"docs","title":"Attention","body":"48.1. Attention\nNote\ndevonfw did not focus on the integration of this database so far. No reports have been given from our users about successfully integrating this database with any devonfw tech stack. If you want to share your knowledge or report usage, please contribute by clicking on the pen next to the section headline.If you need help on devonfw tech stack knowledge to get the integration working for you, stay in contact at GitHub.\n"},{"id":470,"path":"../website/pages/docs/guide-orientdb.asciidoc.html#guide-orientdb.asciidoc_driver","type":"docs","title":"Driver","body":"48.2. Driver\nFor driver options see here.\n"},{"id":471,"path":"../website/pages/docs/guide-orientdb.asciidoc.html#guide-orientdb.asciidoc_administration","type":"docs","title":"Administration","body":"48.3. Administration\nOrientDB comes with a powerful, impressive admin interface for your web-browser called Studio.\n&#x2190;&#xA0;Previous:&#xA0;Redis&#xA0;| &#x2191;&#xA0;Up:&#xA0;Choosing your Database&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Blazegraph&#xA0;&#x2192;\n"},{"id":472,"path":"../website/pages/docs/guide-postgresql.asciidoc.html#guide-postgresql.asciidoc","type":"docs","title":"PostgreSQL","body":"40. PostgreSQL\nThis section gives guidance and hints for those who use PostgreSQL as RDBMS.\n"},{"id":473,"path":"../website/pages/docs/guide-postgresql.asciidoc.html#guide-postgresql.asciidoc_driver","type":"docs","title":"Driver","body":"40.1. Driver\nPostgreSQL is fully open-source. The driver is therefore available in maven central.\nYour dependency for the driver should look as following:\n&lt;dependency&gt;\n&lt;groupId&gt;postgresql&lt;/groupId&gt;\n&lt;artifactId&gt;postgresql&lt;/artifactId&gt;\n&lt;version&gt;${postgresql.driver.version}&lt;/version&gt;\n&lt;/dependency&gt;\nOf course the version (${postgresql.driver.version}) needs to be adopted to your needs (PostgreSQL installtion in production and JDBC level suitable for your JDK, e.g. 9.1-901-1.jdbc4).\nFor an overview of available driver versions see here.\n&#x2190;&#xA0;Previous:&#xA0;MS-SQL-Server&#xA0;| &#x2191;&#xA0;Up:&#xA0;Choosing your Database&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;MariaDB&#xA0;&#x2192;\n"},{"id":474,"path":"../website/pages/docs/guide-ravendb.asciidoc.html#guide-ravendb.asciidoc","type":"docs","title":"RavenDB","body":"51. RavenDB\nThis section is the place to share experience for those who use RavenDB as NoSQL database.\n"},{"id":475,"path":"../website/pages/docs/guide-ravendb.asciidoc.html#guide-ravendb.asciidoc_attention","type":"docs","title":"Attention","body":"51.1. Attention\nNote\ndevonfw did not focus on the integration of this database so far. No reports have been given from our users about successfully integrating this database with any devonfw tech stack. If you want to share your knowledge or report usage, please contribute by clicking on the pen next to the section headline.If you need help on devonfw tech stack knowledge to get the integration working for you, stay in contact at GitHub.\n"},{"id":476,"path":"../website/pages/docs/guide-ravendb.asciidoc.html#guide-ravendb.asciidoc_driver","type":"docs","title":"Driver","body":"51.2. Driver\nPlease be aware that there is not a regular JDBC driver in case you are using Java (devon4j).\nFor driver options see ravendb-jvm-client and Java Client Features.\n&#x2190;&#xA0;Previous:&#xA0;HBase&#xA0;| &#x2191;&#xA0;Up:&#xA0;Choosing your Database&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;GigaSpaces XAP (Smart Cache)&#xA0;&#x2192;\n"},{"id":477,"path":"../website/pages/docs/guide-redis.asciidoc.html#guide-redis.asciidoc","type":"docs","title":"Redis","body":"47. Redis\nThis section is the place to share experience for those who use Redis as NoSQL database.\n"},{"id":478,"path":"../website/pages/docs/guide-redis.asciidoc.html#guide-redis.asciidoc_attention","type":"docs","title":"Attention","body":"47.1. Attention\nNote\ndevonfw did not focus on the integration of this database so far. No reports have been given from our users about successfully integrating this database with any devonfw tech stack. If you want to share your knowledge or report usage, please contribute by clicking on the pen next to the section headline.If you need help on devonfw tech stack knowledge to get the integration working for you, stay in contact at GitHub.\n"},{"id":479,"path":"../website/pages/docs/guide-redis.asciidoc.html#guide-redis.asciidoc_driver","type":"docs","title":"Driver","body":"47.2. Driver\nPlease be aware that there is not a regular JDBC driver in case you are using Java (devon4j).\nFor driver options see here.\n&#x2190;&#xA0;Previous:&#xA0;CouchDB&#xA0;| &#x2191;&#xA0;Up:&#xA0;Choosing your Database&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;OrientDB&#xA0;&#x2192;\n"},{"id":480,"path":"../website/pages/docs/guide-structure.asciidoc.html#guide-structure.asciidoc","type":"docs","title":"Project structure","body":"10. Project structure\nThe structure of a devon4j application is divided into the following modules:\napi: module containing the API of your application. The API contains the required artifacts to interact with your application via remote services. This can be REST service interfaces, transfer-objects with their interfaces and datatypes but also OpenAPI or gRPC contracts.\ncore: maven module containing the core of the application with service implementation, as well as entire logic layer and dataaccess layer.\nbatch: optional module for batch layer\nserver: module that bundles the entire app (core with optional batch) typically as a bootified WAR file.\n"},{"id":481,"path":"../website/pages/docs/guide-structure.asciidoc.html#guide-structure.asciidoc_make-jar-not-war","type":"docs","title":"Make jar not war","body":"10.1. Make jar not war\nFirst of all it is important to understand that the above defined structure aims to make modules like api, core, and batch reusable maven artifacts, that can be used as a regular maven dependency.\nOn the other hand to build and deploy your application you want a final artifact that is containing all required 3rd party libraries. This artifact is not reusable as a maven dependency. That is exactly the purpose of the server module to build and package this final deployment artifact. By default we first build a regular WAR file with maven in your server/target directory (*-server-&#xAB;version&#xBB;.war) and in a second step create a bootified WAR out of this (*-server-bootified.war). The bootified WAR file can then be started standalone (java -jar &#xAB;filename&#xBB;.war). However, it is also possible to deploy the same WAR file to a servlet container like tomcat or jetty. As application servers and externally provided servlet containers are not recommendet anymore for various reasons (see JEE), you may also want to create a bootified JAR file instead. All you need to do in that case is to change the packaging in your server/pom.xml from war to jar.\n"},{"id":482,"path":"../website/pages/docs/guide-structure.asciidoc.html#guide-structure.asciidoc_package-structure","type":"docs","title":"Package Structure","body":"10.2. Package Structure\nThe package structure of your code inside src/main/java (and src/test/java) of your modules is described in our coding conventions in the sections packages and architecture-mapping.\n&#x2190;&#xA0;Previous:&#xA0;Coding Conventions&#xA0;| &#x2191;&#xA0;Up:&#xA0;devonfw for Java (devon4j)&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Layers&#xA0;&#x2192;\n"},{"id":483,"path":"../website/pages/docs/h0ec2830b289a5d728774589aca18d6e7.asciidoc.html#h0ec2830b289a5d728774589aca18d6e7.asciidoc","type":"docs","title":"What is devonfw shop floor?","body":"53. What is devonfw shop floor?\ndevonfw shop floor is a platform to industrialize continuous delivery and continuous integration processes.\ndevonfw shop floor is a set of documentation, tools and methodologies used to configure the provisioning, development and uat environments used in your projects. devonfw shop floor allows the administrators of those environments to apply CI/CD operations and enables automated application deployment.\ndevonfw shop floor is mainly oriented to configure the provisioning environment provided by Production Line and deploy applications on an OpenShift cluster. In the cases where Production Line or OpenShift cluster are not available, there will be alternatives to achieve similar goals.\nThe devonfw shop floor 4 OpenShift is a solution based on the experience of priming devonfw for OpenShift by RedHat.\nLet&#x2019;s start.\n&#x2191;&#xA0;Up:&#xA0;devonfw shop floor&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;How to use it&#xA0;&#x2192;\n"},{"id":484,"path":"../website/pages/docs/h593708e8db8bc7e0b53adee5b191ee9b.asciidoc.html#h593708e8db8bc7e0b53adee5b191ee9b.asciidoc","type":"docs","title":"CICDGEN","body":"61. CICDGEN\ncicdgen is a devonfw tool for generate all code/files related to CICD. It will include/modify into your project all files that the project needs run a Jenkins cicd pipeline, to create a docker image based on your project, etc. It&#x2019;s based on angular schematics, so you can add it as a dependency into your project and generate the code using ng generate. In addition, it has its own CLI for those projects that are not angular based.\n"},{"id":485,"path":"../website/pages/docs/h593708e8db8bc7e0b53adee5b191ee9b.asciidoc.html#h593708e8db8bc7e0b53adee5b191ee9b.asciidoc_what-is-angular-schematics","type":"docs","title":"What is angular schematics?","body":"61.1. What is angular schematics?\nSchematics are generators that transform an existing filesystem. They can create files, refactor existing files, or move files from one place to another.\nWhat distinguishes Schematics from other generators, such as Yeoman or Yarn Create, is that schematics are purely descriptive; no changes are applied to the actual filesystem until everything is ready to be committed. There is no side effect, by design, in Schematics.\n"},{"id":486,"path":"../website/pages/docs/h593708e8db8bc7e0b53adee5b191ee9b.asciidoc.html#h593708e8db8bc7e0b53adee5b191ee9b.asciidoc_cicdgen-cli","type":"docs","title":"cicdgen CLI","body":"61.2. cicdgen CLI\nIn order to know more about how to use the cicdgen CLI, you can check the CLI page\n"},{"id":487,"path":"../website/pages/docs/h593708e8db8bc7e0b53adee5b191ee9b.asciidoc.html#h593708e8db8bc7e0b53adee5b191ee9b.asciidoc_cicdgen-schematics","type":"docs","title":"cicdgen Schematics","body":"61.3. cicdgen Schematics\nIn order to know more about how to use the cicdgen schematics, you can check the schematics page\n"},{"id":488,"path":"../website/pages/docs/h593708e8db8bc7e0b53adee5b191ee9b.asciidoc.html#h593708e8db8bc7e0b53adee5b191ee9b.asciidoc_usage-example","type":"docs","title":"Usage example","body":"61.4. Usage example\nA specific page about how to use cicdgen is also available.\n&#x2191;&#xA0;Up:&#xA0;cicdgen&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;cicdgen CLI&#xA0;&#x2192;\n"},{"id":489,"path":"../website/pages/docs/master-cicdgen.asciidoc.html#master-cicdgen.asciidoc","type":"docs","title":"IX. cicdgen","body":"IX. cicdgen\nCICDGEN\ncicdgen CLI\ncicdgen Schematics\n&#x2190;&#xA0;Previous:&#xA0;Annexes&#xA0;| &#x2191;&#xA0;Up:&#xA0;devonfw guide&#xA0;| Next:&#xA0;CICDGEN&#xA0;&#x2192;\n"},{"id":490,"path":"../website/pages/docs/master-cicdgen.asciidoc_cicdgen-cli.html#master-cicdgen.asciidoc_cicdgen-cli","type":"docs","title":"cicdgen CLI","body":"62. cicdgen CLI\n"},{"id":491,"path":"../website/pages/docs/master-cicdgen.asciidoc_cicdgen-cli.html#cicdgen-cli.asciidoc_cicdgen-cli","type":"docs","title":"CICDGEN CLI","body":"62.1. CICDGEN CLI\ncicdgen is a command line interface that helps you with some CICD in a devonfw project. At this moment we can only generate files related to CICD in a project but we plan to add more functionlity in a future.\nInstallation\n$ npm i -g @devonfw/cicdgen\nUsage\nGlobal arguments\n--version\nPrints the cicdgen version number\n--help\nShows the usage of the command\nCommands\nGenerate.\nThis command wraps the usage of angular schematics CLI. With this we generate files in a easy way and also print a better help about usage.\nAvailable schematics that generate the code:\ndevon4j\ndevon4ng\ndevon4net\ndevon4node\nExamples\nGenerate all CICD files related to a devon4j project\n$ cicdgen generate devon4j\nGenerate all CICD files related to a devon4ng project with docker deployment.\n$ cicdgen generate devon4ng --groupid com.devonfw --docker --registryurl docker-registry-devon.s2-eu.capgemini.com\nGenerate all CICD files related to a devon4node project with OpenShift deployment.\n$ cicdgen generate devon4ng --groupid com.devonfw --openshift --registryurl docker-registry-devon.s2-eu.capgemini.com --ocname default --ocn devonfw\n"},{"id":492,"path":"../website/pages/docs/master-cicdgen.asciidoc_cicdgen-cli.html#usage-example.asciidoc_cicdgen-usage-example","type":"docs","title":"cicdgen usage example","body":"62.2. cicdgen usage example\nIn this example we are going to show how to use cicdgen step by step in a devon4ng project.\nInstall cicdgen\ncicdgen is already included in the devonfw distribution, but if you want to use it outside the devonfw console you can execute the following command:\n$ npm i -g cicdgen\nGenerate a new devon4ng project using devonfw ide.\nInside a devonfw ide distrubution execute the command (devon ng create &lt;app-name&gt;):\n$ devon ng create devon4ng\nExecute cicdgen generate command\nAs we want to send notifications to MS Teams, we need to create de connector first:\nGo to a channel in teams and click at the connectors button. Then click at the jenkins configure button.\nPut a name for the connector\nCopy the name and the Webhook URL, we will use it later.\nWith the values that we get in the previous steps, we will execute the cicdgen command inside the project folder. If you have any doubt you can use the help.\n$ cicdgen generate devon4ng --groupid com.devonfw --docker --dockerurl tpc://127.0.0.1:2376 --registryurl docker-registry-devon.s2-eu.capgemini.com --teams --teamsname devon4ng --teamsurl https://outlook.office.com/webhook/...\nCreate a git repository and upload the code\n$ git remote add origin https://devon.s2-eu.capgemini.com/gitlab/darrodri/devon4ng.git\n$ git push -u origin master\nAs you can see, no git init or git commit is required, cicdgen do it for you.\nCreate a multibranch-pipeline in Jenkins\nWhen you push the save button, it will download the repository and execute the pipeline defined in the Jenkinsfile. If you get any problem, check the environment variables defined in the Jenkinsfile. Here we show all variables related with Jenkins:\nchrome\nsonarTool\nsonarEnv\nrepositoryId\nglobalSettingsId\nmavenInstallation\ndockerTool\nAdd a webhook in GitLab\nIn order to run the pipeline every time that you push code to GitLab, you need to configure a webhook in your repository.\nNow your project is ready to work following a CICD strategy.\nThe last thing to take into account is the branch naming. We prepare the pipeline in order to work following the git-flow strategy. So all stages of the pipeline will be executed for the branchs: develop, release/*, master. For the branchs: feature/*, hotfix/*, bugfix/* only the steps related to unit testing will be executed.\n&#x2190;&#xA0;Previous:&#xA0;CICDGEN&#xA0;| &#x2191;&#xA0;Up:&#xA0;cicdgen&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;cicdgen Schematics&#xA0;&#x2192;\n"},{"id":493,"path":"../website/pages/docs/master-cicdgen.asciidoc_cicdgen-schematics.html#master-cicdgen.asciidoc_cicdgen-schematics","type":"docs","title":"cicdgen Schematics","body":"63. cicdgen Schematics\n"},{"id":494,"path":"../website/pages/docs/master-cicdgen.asciidoc_cicdgen-schematics.html#cicdgen-schematics.asciidoc_cicdgen-schematics","type":"docs","title":"CICDGEN SCHEMATICS","body":"63.1. CICDGEN SCHEMATICS\nWe use angular schematics to create and update an existing devonfw project in order to adapt it to a CICD environment. All schematics are prepared to work with Production Line, a Capgemini CICD platform, but it can also work in other environment which have the following tools:\nJenkins\nGitLab\nNexus 3\nSonarQube\nThe list of available schematics are:\ndevon4j\ndevon4ng\ndevon4net\ndevon4node\nHow to run the schematics\nYou can run the schematics using the schematics CLI provided by the angular team, but the easiest way to run it is using the cicdgen CLI which is a wrapper for the schematics CLI in order to use it in a easy way.\nTo generate files you only need to run the command\n$ cicdgen generate &lt;schematic-name&gt; [arguments]\n&lt;schematic-name&gt; is the name of the schematic that you want to execute.\nYou can find all information about arguments in the schematic section.\nMerge Strategies\nWhen you execute cicdgen in a project, is possible that you already have some files that cicdgen will generate. Until version 1.5 the behaviour in these cases was to throw an error and not create/modify any file. Since version 1.6 you can choose what to do in case of conflict. In this page we will explain who to choose one merge strategy and how it works.\nChoose a merge strategy\nTo choose a merge strategy, you must pass to cicdgen the merge parameter followed by the name of the strategy. The strategies available are: error, keep, override, combine.\nExample:\n$ cicdgen generate devon4j --merge keep\nMerge strategies\nerror: The error strategy is the same as until version 1.5, throwing an error and do not create/modify any file. This is the default value, if you do not pass the merge parameter this value will be taken.\nkeep: The keep strategy will keep the actual content of your files in case of conflict. If there is no conflict, the file will be created with the new content.\noverride: The override strategy will override your current files, without throwing any error, and create a new ones with the new content. If there is no conflict, the file will be created with the new content.\ncombine: The combine strategy will create a new file combining the current content with the new content. In order to combine both files, it will apply a diff algorithm and it will show the conflicts in the same way that git does. If there is no conflict, the file will be created with the new content.\nBy resolving the conflicts in the same way as git, you can use the same tools in order to solve them. For example, you can use VSCode:\nExamples:\nkeep\nCurrent file:\nLine 1\nLine 2\nLine 3\nLine 4\nNew file:\nLine 5\nLine 2\nLine 3\nLine 4\nThe result will be:\nLine 1\nLine 2\nLine 3\nLine 4\noverride\nCurrent file:\nLine 1\nLine 2\nLine 3\nLine 4\nNew file:\nLine 5\nLine 2\nLine 3\nLine 4\nThe result will be:\nLine 5\nLine 2\nLine 3\nLine 4\ncombine\nCurrent file:\nLine 1\nLine 2\nLine 3\nLine 4\nNew file:\nLine 5\nLine 2\nLine 3\nLine 4\nThe result will be:\n&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD\nLine 1\n=======\nLine 5\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; new_content\nLine 2\nLine 3\nLine 4\n"},{"id":495,"path":"../website/pages/docs/master-cicdgen.asciidoc_cicdgen-schematics.html#devon4j-schematic.asciidoc_devon4j-schematic","type":"docs","title":"devon4j schematic","body":"63.2. devon4j schematic\nWith the cicdgen generate devon4j command you can generate some files required for CICD. In this section we will explain the arguments of this command and also the files that will be generated.\ndevon4j schematic arguments\nWhen you execute the cicdgen generate devon4j command you can also add some arguments in order to modify the behaviour of the command. Those arguments are:\n--docker\nThe type of this paramter if boolean. If it is present, docker related files and pipeline stage will be also generated. For more details see docker section of Jenkinsfile and files generated for docker\n--dockerurl\nThe URL of your external docker daemon. Example: tcp://127.0.0.1:2376\n--dockercertid\nThe Jenkins credential id for your docker daemon certificate. It is only required when your docker daemon is secure.\n--registryurl\nYour docker registry URL. It is required when --docker is true, and it will be used to know where the docker image will be uploaded.\n--openshift\nThe type of this paramter if boolean. If it is present, OpenShift related files and pipeline stage will be also generated. For more details see OpenShift section of Jenkinsfile and files generated for docker (same as --docker)\n--ocname\nThe name used for register your Openshift cluster in Jenkins.\n--ocn\nOpenshift cluster namespace\n--teams\nWith this argument we can add the teams notification option in the Jenkinsfile.\n--teamsname\nThe name of the Microsft Teams webhook. It is defined at Microsoft Teams connectors.\n--teamsurl\nThe url of the Microsft Teams webhook. It is returned by Microsoft Teams when you create a connector.\n--merge\nIf you have used cicdgen previously, you can choose what you want to do in case of file conflict. The default behavior is to throw an error and not modify any file. You can see the other strategies on their specific page.\n--commit\nIf true, all changes will be commited at the end of the process (if possible). In order to send a false value, you need to write --commit=false\nDevon4ng generated files\nWhen you execute the generate devon4ng command, some files will be added/updated in your project.\nFiles\n.gitignore\nDefines all files that git will ignore. e.g: compiled files, IDE configurations. It will download the content from: https://gitignore.io/api/java,maven,eclipse,intellij,intellij+all,intellij+iml,visualstudiocode\npom.xml\nThe pom.xml is modified in order to add, if needed, the distributionManagement.\nJenkinsfile\nThe Jenkinsfile is the file which define the Jenkins pipeline of our project. With this we can execute the test, build the application and deploy it automatically following a CICD methodology. This file is prepared to work with the Production Line default values, but it is also fully configurable to your needs.\nPrerequisites\nA Production Line instance. It can works also if you have a Jenkins, SonarQube and Nexus3, but in this case maybe you need to configure them properly.\nJava 11 installed in Jenkins as a global tool.\nSonarQube installed in Jenkins as a global tool.\nMaven3 installed in Jenkins as a global tool.\nA maven global settings properly configured in Jenkins.\nIf you will use docker to deploy:\nDocker installed in Jenkins as a global custom tool.\nThe Nexus3 with a docker repository.\nA machine with docker installed where the build and deploy will happen.\nA docker network called application.\nIf you will use OpenShift to deploy:\nAn OpenShift instance\nThe OpenShift projects created\nThe Jenkins syntax\nIn this section we will explain a little bit the syntax of the Jenkins, so if you need to change something you will be able to do it properly.\nagent: Here you can specify the Jenkins agente where the pipeline will be executed. The default value is any.\noptions: Here you can set global options to the pipeline. By default, we add a build discarded to delete old artifacts/buils of the pipeline and also we disable the concurrent builds.\nIf the teams option is passed to cicdgen, we add a new option in order to send notifications to Microsoft Teams with the status of the pipeline executions.\nenvironment: Here all environment variables are defined. All values defined here matches with the Production Line defaults. If you Jenkins has other values, you need to update it manually.\nstages: Here are defined all stages that our pipeline will execute. Those stages are:\nLoading Custom Tools: Load some custom tools that can not be loaded in the tools section. Also set some variables depending on the git branch which you are executing. Also, we set properly the version number in all pom files. It means that if your branch is develop, your version should end with the word -SNAPSHOT, in order case, if -SNAPSHOT is present it will be removed.\nFresh Dependency Installation: install all packages need to build/run your java project.\nUnit Tests: execute the mvn test command.\nSonarQube code analysis: send the project to SonarQube in order to get the static code analysis of your project.\nDeliver application into Nexus: build the project and send all bundle files to Nexsu3.\nIf --docker is present:\nCreate the Docker image: build a new docker image that contains the new version of the project.\nDeploy the new image: deploy a new version of the application using the image created in the previous stage. The previous version is removed.\nIf --openshift is present:\nCreate the Docker image: build a new docker image that contains the new version of the project using a OpenShift build config.\nDeploy the new image: deploy a new version of the application in OpenShift.\nCheck pod status: checks that the application deployed in the previous stage is running properly. If the application does not run the pipeline will fail.\npost: actions that will be executed after the stages. We use it to clean up all files.\ndevon4j Docker generated files\nWhen you generate the files for a devon4ng you can also pass the option --docker. It will generate also some extra files related to docker.\nNote\nIf you pass the --docker option the option --registryurl is also required. It will be used to upload the images to a docker registry. Example: if your registry url is docker-registry-test.s2-eu.capgemini.com you should execute the command in this way: cicdgen generate devon4node --groupid com.devonfw --docker --registryurl docker-registry-test.s2-eu.capgemini.com.\nFiles\nDockerfile\nThis file contains the instructions to build a docker image for you project. This Dockerfile is for local development purposes, you can use it in your machine executing:\n$ cd &lt;path-to-your-project&gt;\n$ docker build -t &lt;project-name&gt;/&lt;tag&gt; .\nThis build is using a multi-stage build. First, it use a maven image in order to compile the source code, then it will use a java image to run the application. With the multi-stage build we keep the final image as clean as possible.\nDockerfile.ci\nThis file contains the instructions to create a docker image for you project. The main difference with the Dockerfile is that this file will be only used in the Jenkins pipeline. Instead of compiling again the code, it takes the compiled war from Jenkins to the image.\n"},{"id":496,"path":"../website/pages/docs/master-cicdgen.asciidoc_cicdgen-schematics.html#devon4ng-schematic.asciidoc_devon4ng-schematic","type":"docs","title":"devon4ng schematic","body":"63.3. devon4ng schematic\nWith the cicdgen generate devon4ng command you can generate some files required for CICD. In this section we will explain the arguments of this command and also the files that will be generated.\ndevon4ng schematic arguments\nWhen you execute the cicdgen generate devon4ng command you can also add some arguments in order to modify the behaviour of the command. Those arguments are:\n--docker\nThe type of this paramter if boolean. If it is present, docker related files and pipeline stage will be also generated. For more details see docker section of Jenkinsfile and files generated for docker\n--dockerurl\nThe URL of your external docker daemon. Example: tcp://127.0.0.1:2376\n--dockercertid\nThe Jenkins credential id for your docker daemon certificate. It is only required when your docker daemon is secure.\n--registryurl\nYour docker registry URL. It is required when --docker is true, and it will be used to know where the docker image will be uploaded.\n--openshift\nThe type of this paramter if boolean. If it is present, OpenShift related files and pipeline stage will be also generated. For more details see OpenShift section of Jenkinsfile and files generated for OpenShift (same as --docker)\n--ocname\nThe name used for register your Openshift cluster in Jenkins.\n--ocn\nOpenshift cluster namespace\n--groupid\nThe project groupId. This argument is required. It will be used for store the project in a maven repository at Nexus 3. Why maven? Because is the kind of repository where we can upload/download a zip file easily. Npm repository needs a package.json file but, as we compile the angular application to static javascript and html files, the package.json is no needed anymore.\n--teams\nWith this argument we can add the teams notification option in the Jenkinsfile.\n--teamsname\nThe name of the Microsft Teams webhook. It is defined at Microsoft Teams connectors.\n--teamsurl\nThe url of the Microsft Teams webhook. It is returned by Microsoft Teams when you create a connector.\n--merge\nIf you have used cicdgen previously, you can choose what you want to do in case of file conflict. The default behavior is to throw an error and not modify any file. You can see the other strategies on their specific page.\n--commit\nIf true, all changes will be commited at the end of the process (if possible). In order to send a false value, you need to write --commit=false\ndevon4ng generated files\nWhen you execute the generate devon4ng command, some files will be added/updated in your project.\nFiles\nangular.json\nThe angular.json is modified in order to change the compiled files destination folder. Now, when you make a build of your project, the compiled files will be generated into dist folder instead of dist/&lt;project-name&gt; folder.\npackage.json\nThe package.json is modified in order to add a script for test the application using Chrome Headless instead of a regular chrome. This script is called test:ci.\nkarma.conf.js\nThe karma.conf.js is also modified in order to add the Chrome Headless as a browser to execute test. The coverage output folder is change to ./coverage instead of ./coverage/&lt;project-name&gt;\nJenkinsfile\nThe Jenkinsfile is the file which define the Jenkins pipeline of our project. With this we can execute the test, build the application and deploy it automatically following a CICD methodology. This file is prepared to work with the Production Line default values, but it is also fully configurable to your needs.\nPrerequisites\nA Production Line instance. It can works also if you have a Jenkins, SonarQube and Nexus3, but in this case maybe you need to configure them properly.\nNodeJS installed in Jenkins as a global tool.\nGoogle Chrome installed in Jenkins as a global custom tool.\nSonarQube installed in Jenkins as a global tool.\nMaven3 installed in Jenkins as a global tool.\nA maven global settings properly configured in Jenkins.\nIf you will use docker :\nDocker installed in Jenkins as a global custom tool.\nThe Nexus3 with a docker repository.\nA machine with docker installed where the build and deploy will happen.\nA docker network called application.\nIf you will use OpenShift :\nAn OpenShift instance\nThe OpenShift projects created\nThe Jenkins syntax\nIn this section we will explain a little bit the syntax of the Jenkins, so if you need to change something you will be able to do it properly.\nagent: Here you can specify the Jenkins agente where the pipeline will be executed. The default value is any.\noptions: Here you can set global options for the pipeline. By default, we add a build discarded to delete old artifacts/buils of the pipeline and also we disable the concurrent builds.\nIf the teams option is passed to cicdgen, we add a new option in order to send notifications to Microsoft Teams with the status of the pipeline executions.\ntools: Here we define the global tools configurations. By default a version of nodejs is added here.\nenvironment: Here all environment variables are defined. All values defined here matches with the Production Line defaults. If you Jenkins has other values, you need to update it manually.\nstages: Here are defined all stages that our pipeline will execute. Those stages are:\nLoading Custom Tools: in this stage some custom tools are loaded. Also we set some variables depending on the git branch which you are executing.\nFresh Dependency Installation: install all packages need to build/run your angular project.\nCode Linting: execute the linter analysis.\nExecute Angular tests: execute the angular test in a Chrome Headless.\nSonarQube code analysis: send the project to SonarQube in order to get the static code analysis of your project.\nBuild Application: compile the application to be ready to deploy in a web server.\nDeliver application into Nexus: store all compiled files in Nexus3 as a zip file.\nIf --docker is present:\nCreate the Docker image: build a new docker image that contains the new version of the project.\nDeploy the new image: deploy a new version of the application using the image created in the previous stage. The previous version is removed.\nIf --openshift is present:\nCreate the Docker image: build a new docker image that contains the new version of the project using a OpenShift build config.\nDeploy the new image: deploy a new version of the application in OpenShift.\nCheck pod status: checks that the application deployed in the previous stage is running properly. If the application does not run the pipeline will fail.\npost: actions that will be executed after the stages. We use it to clean up all files.\ndevon4ng Docker generated files\nWhen you generate the files for a devon4ng you can also pass the option --docker. It will generate also some extra files related to docker.\nNote\nIf you pass the --docker option the option --registryurl is also required. It will be used to upload the images to a docker registry. Example: if your registry url is docker-registry-test.s2-eu.capgemini.com you should execute the command in this way: cicdgen generate devon4node --groupid com.devonfw --docker --registryurl docker-registry-test.s2-eu.capgemini.com.\nFiles\n.dockerignore\nIn this files are defined the folders that will not be copied to the docker image. Fore more information read the official documentation.\nDockerfile\nThis file contains the instructions to build a docker image for you project. This Dockerfile is for local development purposes, you can use it in your machine executing:\n$ cd &lt;path-to-your-project&gt;\n$ docker build -t &lt;project-name&gt;/&lt;tag&gt; .\nThis build is using a multi-stage build. First, it use a node image in order to compile the source code, then it will use a nginx image as a web server for our devon4ng application. With the multi-stage build we avoid everything related to node.js in our final image, where we only have a nginx with our application compiled.\nDockerfile.ci\nThis file contains the instructions to create a docker image for you project. The main difference with the Dockerfile is that this file will be only used in the Jenkins pipeline. Instead of compiling again the code, it takes all compiled files and the nginx.conf from Jenkins to the image.\n"},{"id":497,"path":"../website/pages/docs/master-cicdgen.asciidoc_cicdgen-schematics.html#devon4net-schematic.asciidoc_devon4net-schematic","type":"docs","title":"devon4net schematic","body":"63.4. devon4net schematic\nWith the cicdgen generate devon4net command you can generate some files required for CICD. In this section we will explain the arguments of this command and also the files that will be generated.\ndevon4net schematic arguments\nWhen you execute the cicdgen generate devon4net command you can also add some arguments in order to modify the behaviour of the command. Those arguments are:\n--appname\nThe name of your devon4net application.\n--appversion\nThe initial version of your devon4net application\n--docker\nThe type of this paramter if boolean. If it is present, docker related files and pipeline stage will be also generated. For more details see docker section of Jenkinsfile and files generated for docker\n--dockerurl\nThe URL of your external docker daemon. Example: tcp://127.0.0.1:2376\n--dockercertid\nThe Jenkins credential id for your docker daemon certificate. It is only required when your docker daemon is secure.\n--registryurl\nYour docker registry URL. It is required when --docker is true, and it will be used to know where the docker image will be uploaded.\n--openshift\nThe type of this paramter if boolean. If it is present, OpenShift related files and pipeline stage will be also generated. For more details see OpenShift section of Jenkinsfile and files generated for OpenShift (same as --docker)\n--ocname\nThe name used for register your Openshift cluster in Jenkins.\n--ocn\nOpenshift cluster namespace\n--groupid\nThe project groupId. This argument is required. It will be used for store the project in a maven repository at Nexus 3. Why maven? Because is the kind of repository where we can upload/download a zip file easily. Npm repository needs a package.json file but, as we compile the angular application to static javascript and html files, the package.json is no needed anymore.\n--teams\nWith this argument we can add the teams notification option in the Jenkinsfile.\n--teamsname\nThe name of the Microsft Teams webhook. It is defined at Microsoft Teams connectors.\n--teamsurl\nThe url of the Microsft Teams webhook. It is returned by Microsoft Teams when you create a connector.\n--merge\nIf you have used cicdgen previously, you can choose what you want to do in case of file conflict. The default behavior is to throw an error and not modify any file. You can see the other strategies on their specific page.\n--commit\nIf true, all changes will be commited at the end of the process (if possible). In order to send a false value, you need to write --commit=false\ndevon4net generated files\nWhen you execute the generate devon4net command, some files will be added/updated in your project.\nFiles\nJenkinsfile\nThe Jenkinsfile is the file which define the Jenkins pipeline of our project. With this we can execute the test, build the application and deploy it automatically following a CICD methodology. This file is prepared to work with the Production Line default values, but it is also fully configurable to your needs.\nPrerequisites\nA Production Line instance. It can works also if you have a Jenkins, SonarQube and Nexus3, but in this case maybe you need to configure them properly.\ndotnet core installed in Jenkins as a global tool.\nSonarQube installed in Jenkins as a global tool.\nMaven3 installed in Jenkins as a global tool.\nA maven global settings properly configured in Jenkins.\nIf you will use docker :\nDocker installed in Jenkins as a global custom tool.\nThe Nexus3 with a docker repository.\nA machine with docker installed where the build and deploy will happen.\nIf you will use OpenShift :\nAn OpenShift instance\nThe OpenShift projects created\nThe Jenkins syntax\nIn this section we will explain a little bit the syntax of the Jenkins, so if you need to change something you will be able to do it properly.\nagent: Here you can specify the Jenkins agente where the pipeline will be executed. The default value is any.\noptions: Here you can set global options for the pipeline. By default, we add a build discarded to delete old artifacts/buils of the pipeline and also we disable the concurrent builds.\nIf the teams option is passed to cicdgen, we add a new option in order to send notifications to Microsoft Teams with the status of the pipeline executions.\ntools: Here we define the global tools configurations. By default a version of nodejs is added here.\nenvironment: Here all environment variables are defined. All values defined here matches with the Production Line defaults. If you Jenkins has other values, you need to update it manually.\nstages: Here are defined all stages that our pipeline will execute. Those stages are:\nLoading Custom Tools: in this stage some custom tools are loaded. Also we set some variables depending on the git branch which you are executing.\nFresh Dependency Installation: install all dependencies need to build/run your dotnet project.\nExecute dotnet tests: execute the tests.\nSonarQube code analysis: send the project to SonarQube in order to get the static code analysis of your project.\nBuild Application: compile the application to be ready to deploy in a web server.\nDeliver application into Nexus: store all compiled files in Nexus3 as a zip file.\nIf --docker is present:\nCreate the Docker image: build a new docker image that contains the new version of the project.\nDeploy the new image: deploy a new version of the application using the image created in the previous stage. The previous version is removed.\nIf --openshift is present:\nCreate the Docker image: build a new docker image that contains the new version of the project using a OpenShift build config.\nDeploy the new image: deploy a new version of the application in OpenShift.\nCheck pod status: checks that the application deployed in the previous stage is running properly. If the application does not run the pipeline will fail.\npost: actions that will be executed after the stages. We use it to clean up all files.\ndevon4net Docker generated files\nWhen you generate the files for devon4net you can also pass the option --docker. It will generate also some extra files related to docker.\nNote\nIf you pass the --docker option the option --registryurl is also required. It will be used to upload the images to a docker registry. Example: if your registry url is docker-registry-test.s2-eu.capgemini.com you should execute the command in this way: cicdgen generate devon4net --groupid com.devonfw --docker --registryurl docker-registry-test.s2-eu.capgemini.com.\nFiles\n.dockerignore\nIn this files are defined the folders that will not be copied to the docker image. Fore more information read the official documentation.\nDockerfile\nThis file contains the instructions to build a docker image for your project. This Dockerfile is for local development purposes, you can use it in your machine executing:\n$ cd &lt;path-to-your-project&gt;\n$ docker build -t &lt;project-name&gt;/&lt;tag&gt; .\nDockerfile.ci\nThis file contains the instructions to create a docker image for you project. The main difference with the Dockerfile is that this file will be only used in the Jenkins pipeline. Instead of compiling again the code, it takes all compiled files from Jenkins to the image.\n"},{"id":498,"path":"../website/pages/docs/master-cicdgen.asciidoc_cicdgen-schematics.html#devon4node-schematic.asciidoc_devon4node-schematic","type":"docs","title":"devon4node schematic","body":"63.5. devon4node schematic\nWith the cicdgen generate devon4node command you can generate some files required for CICD. In this section we will explain the arguments of this command and also the files that will be generated.\ndevon4node schematic arguments\nWhen you execute the cicdgen generate devon4node command you can also add some arguments in order to modify the behaviour of the command. Those arguments are:\n--docker\nThe type of this paramter if boolean. If it is present, docker related files and pipeline stage will be also generated. For more details see docker section of Jenkinsfile and files generated for docker\n--dockerurl\nThe URL of your external docker daemon. Example: tcp://127.0.0.1:2376\n--dockercertid\nThe Jenkins credential id for your docker daemon certificate. It is only required when your docker daemon is secure.\n--registryurl\nYour docker registry URL. It is required when --docker is true, and it will be used to know where the docker image will be uploaded.\n--openshift\nThe type of this paramter if boolean. If it is present, OpenShift related files and pipeline stage will be also generated. For more details see OpenShift section of Jenkinsfile and files generated for OpenShift (same as --docker)\n--ocname\nThe name used for register your Openshift cluster in Jenkins.\n--ocn\nOpenshift cluster namespace\n--groupid\nThe project groupId. This argument is required. It will be used for store the project in a maven repository at Nexus 3. Why maven? Because is the kind of repository where we can upload/download a zip file easily. Npm repository needs a package.json file but, as we compile the angular application to static javascript and html files, the package.json is no needed anymore.\n--teams\nWith this argument we can add the teams notification option in the Jenkinsfile.\n--teamsname\nThe name of the Microsft Teams webhook. It is defined at Microsoft Teams connectors.\n--teamsurl\nThe url of the Microsft Teams webhook. It is returned by Microsoft Teams when you create a connector.\n--merge\nIf you have used cicdgen previously, you can choose what you want to do in case of file conflict. The default behavior is to throw an error and not modify any file. You can see the other strategies on their specific page.\n--commit\nIf true, all changes will be commited at the end of the process (if possible). In order to send a false value, you need to write --commit=false\ndevon4node generated files\nWhen you execute the generate devon4node command, some files will be added/updated in your project.\nFiles\npackage.json\nThe package.json is modified in order to add a script for run the linter and generate the json report. This script is called lint:ci.\nJenkinsfile\nThe Jenkinsfile is the file which define the Jenkins pipeline of our project. With this we can execute the test, build the application and deploy it automatically following a CICD methodology. This file is prepared to work with the Production Line default values, but it is also fully configurable to your needs.\nPrerequisites\nA Production Line instance. It can works also if you have a Jenkins, SonarQube and Nexus3, but in this case maybe you need to configure them properly.\nNodeJS installed in Jenkins as a global tool.\nSonarQube installed in Jenkins as a global tool.\nMaven3 installed in Jenkins as a global tool.\nA maven global settings properly configured in Jenkins.\nIf you will use docker :\nDocker installed in Jenkins as a global custom tool.\nThe Nexus3 with a docker repository.\nA machine with docker installed where the build and deploy will happen.\nIf you will use OpenShift :\nAn OpenShift instance\nThe OpenShift projects created\nThe Jenkins syntax\nIn this section we will explain a little bit the syntax of the Jenkins, so if you need to change something you will be able to do it properly.\nagent: Here you can specify the Jenkins agente where the pipeline will be executed. The default value is any.\noptions: Here you can set global options for the pipeline. By default, we add a build discarded to delete old artifacts/buils of the pipeline and also we disable the concurrent builds.\nIf the teams option is passed to cicdgen, we add a new option in order to send notifications to Microsoft Teams with the status of the pipeline executions.\ntools: Here we define the global tools configurations. By default a version of nodejs is added here.\nenvironment: Here all environment variables are defined. All values defined here matches with the Production Line defaults. If you Jenkins has other values, you need to update it manually.\nstages: Here are defined all stages that our pipeline will execute. Those stages are:\nLoading Custom Tools: in this stage some custom tools are loaded. Also we set some variables depending on the git branch which you are executing.\nFresh Dependency Installation: install all packages need to build/run your node project.\nCode Linting: execute the linter analysis.\nExecute tests: execute the tests.\nSonarQube code analysis: send the project to SonarQube in order to get the static code analysis of your project.\nBuild Application: compile the application to be ready to deploy in a web server.\nDeliver application into Nexus: store all compiled files in Nexus3 as a zip file.\nIf --docker is present:\nCreate the Docker image: build a new docker image that contains the new version of the project.\nDeploy the new image: deploy a new version of the application using the image created in the previous stage. The previous version is removed.\nIf --openshift is present:\nCreate the Docker image: build a new docker image that contains the new version of the project using a OpenShift build config.\nDeploy the new image: deploy a new version of the application in OpenShift.\nCheck pod status: checks that the application deployed in the previous stage is running properly. If the application does not run the pipeline will fail.\npost: actions that will be executed after the stages. We use it to clean up all files.\ndevon4node Docker generated files\nWhen you generate the files for a devon4node you can also pass the option --docker. It will generate also some extra files related to docker.\nNote\nIf you pass the --docker option the option --registryurl is also required. It will be used to upload the images to a docker registry. Example: if your registry url is docker-registry-test.s2-eu.capgemini.com you should execute the command in this way: cicdgen generate devon4node --groupid com.devonfw --docker --registryurl docker-registry-test.s2-eu.capgemini.com.\nFiles\n.dockerignore\nIn this files are defined the folders that will not be copied to the docker image. Fore more information read the official documentation.\nDockerfile\nThis file contains the instructions to build a docker image for you project. This Dockerfile is for local development purposes, you can use it in your machine executing:\n$ cd &lt;path-to-your-project&gt;\n$ docker build -t &lt;project-name&gt;/&lt;tag&gt; .\nThis build is installs all dependencies in ordre to build the project and then remove all devDependencies in order to keep only the production dependencies.\n.dockerignore.ci\nAnother .dockerignore. The purpose of this one is to define de file exclusions in your CI pipeline.\nDockerfile.ci\nThis file contains the instructions to create a docker image for you project. The main difference with the Dockerfile is that this file will be only used in the Jenkins pipeline. Instead of compiling again the code, it takes all compiled files from Jenkins to the image.\n&#x2190;&#xA0;Previous:&#xA0;cicdgen CLI&#xA0;| &#x2191;&#xA0;Up:&#xA0;cicdgen&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Production Line Templates&#xA0;&#x2192;\n"},{"id":499,"path":"../website/pages/docs/master-cobigen.asciidoc.html#master-cobigen.asciidoc","type":"docs","title":"XI. CobiGen&#x2009;&#x2014;&#x2009;Code-based incremental Generator","body":"XI. CobiGen&#x2009;&#x2014;&#x2009;Code-based incremental Generator\nDocument Description\nCobiGen\nCobiGen CLI\nMaven Build Integration\nEclipse Integration\nHow to\nTemplate Development\n&#x2190;&#xA0;Previous:&#xA0;Troubleshooting&#xA0;| &#x2191;&#xA0;Up:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Document Description&#xA0;&#x2192;\n"},{"id":500,"path":"../website/pages/docs/master-cobigen.asciidoc_cobigen-cli.html#master-cobigen.asciidoc_cobigen-cli","type":"docs","title":"CobiGen CLI","body":"72. CobiGen CLI\n"},{"id":501,"path":"../website/pages/docs/master-cobigen.asciidoc_cobigen-cli.html#howto_Cobigen-CLI-generation.asciidoc","type":"docs","title":"Cobigen Command line Interface generation","body":"72.1. Cobigen Command line Interface generation\nOur new command line interface (CLI) for CobiGen enables the generation of code using few commands. This feature allows us to decouple CobiGen from Eclipse.\nYou can check out our interactive katacoda tutorial where you can setup and use the cobigen cli step by step.\nCobiGen CLI Katacoda Scenario\n"},{"id":502,"path":"../website/pages/docs/master-cobigen.asciidoc_cobigen-cli.html#howto_cobigen-cli-generation.asciidoc_install-cobigen-cli","type":"docs","title":"Install CobiGen CLI","body":"72.1.1. Install CobiGen CLI\nIn order to install the CobiGen CLI you will need to use the devonfw/ide. In a console run devon cobigen.\n"},{"id":503,"path":"../website/pages/docs/master-cobigen.asciidoc_cobigen-cli.html#howto_cobigen-cli-generation.asciidoc_commands-and-options","type":"docs","title":"Commands and options","body":"72.1.2. Commands and options\nUsing the following command and option you will be able to customize your generation as follows:\ncobigen, cg: Main entry point of the CLI. If no arguments are passed, man page will be printed.\n[generate, g]: Command used for code generation.\nInputGlob: Glob pattern of the input file or the whole path of the input file from which the code will be generated.\n&lt; --increment, -i &gt; : Specifies an increment ID to be generated. You can also search increments by name and CobiGen will output the resultant list. If an exact match found, code generation will happen.\n&lt; --template, -t &gt; : specifies a template ID to be generated. You can also search templates by name and CobiGen will output the resultant list.\n&lt; --outputRootPath, -out &gt;: The project file path in which you want to generate your code. If no output path is given, CobiGen will use the project of your input file.\n[adapt-templates, a]: Generates a new templates folder next to the cobigen cli and stores its location inside a configuration file. After executing this command, the CLI will attempt to use the specified Templates folder.\n&lt; --verbose, -v &gt; : Prints debug information, verbose log.\n&lt; --help, -h &gt; : Prints man page.\n&lt; update, u&gt; : This command compare the artificial pom plug-ins version with central latest version available and user can update any outdated plug-ins version .\n"},{"id":504,"path":"../website/pages/docs/master-cobigen.asciidoc_cobigen-cli.html#howto_cobigen-cli-generation.asciidoc_cli-execution-steps","type":"docs","title":"CLI Execution steps:","body":"72.1.3. CLI Execution steps:\nCobiGen CLI is installed inside your devonfw distribution. In order to execute it follow the next steps:\nRun console.bat, this will open a console.\nExecute cobigen or cg and the man page should be printed.\nUse a valid CobiGen input file and run cobigen generate &lt;pathToInputFile&gt;. Note: On the first execution of the CLI, CobiGen will download all the needed dependencies, please be patient.\nA list of increments will be printed so that you can start the generation.\nPreview of the man page for generate command:\n"},{"id":505,"path":"../website/pages/docs/master-cobigen.asciidoc_cobigen-cli.html#howto_cobigen-cli-generation.asciidoc_examples","type":"docs","title":"Examples","body":"72.1.4. Examples\nA selection of commands that you can use with the CLI:\ncobigen generate foo\\bar\\EmployeeEntity.java: As no output path has been defined, CobiGen will try to find the pom.xml of the current project in order to set the generation root path.\ncobigen generate foo\\bar\\*.java --out other\\project: Will retrieve all the Java files on that input folder and generate the code on the path specified by --out.\ncg g foo\\bar\\webServices.yml --increment TO: Performs a string search using TO and will print the closest increments like in the following image:\ncg g foo\\bar\\webServices.yml -i 1,4,6: Directly generates increments with IDs 1, 4 and 6. CobiGen will not request you any other input.\ncg a: Downloads the latest CobiGen_Templates and unpacks them next to the CLI. CobiGen will from now on use these unpacked Templates for generation.\ncg a -cl C:\\my\\custom\\location: Downloads the latest CobiGen_Templates and unpacks them in C:\\my\\custom\\location. CobiGen will from now on use these unpacked Templates for generation.\n"},{"id":506,"path":"../website/pages/docs/master-cobigen.asciidoc_cobigen-cli.html#howto_cobigen-cli-generation.asciidoc_cli-update-command","type":"docs","title":"CLI update command","body":"72.1.5. CLI update command\nExample of Update Command :\nSelect the plug-ins which you want to update like below :\n"},{"id":507,"path":"../website/pages/docs/master-cobigen.asciidoc_cobigen-cli.html#howto_cobigen-cli-generation.asciidoc_cli-custom-templates","type":"docs","title":"CLI custom templates","body":"72.1.6. CLI custom templates\nTo use custom templates, it&#x2019;s neccessary to set up a configuration file .cobigen. This file should be put in either cobigen home (user-dir/.cobigen/) or the environment parameter COBIGEN_CONFIG_DIR should be pointed to the directory where the file is located\nExample\n.cobigen\ncobigen.templates.templates_location=path\\\\to\\\\custom\\\\CobiGen_Templates\n"},{"id":508,"path":"../website/pages/docs/master-cobigen.asciidoc_cobigen-cli.html#howto_cobigen-cli-generation.asciidoc_troubleshooting","type":"docs","title":"Troubleshooting","body":"72.1.7. Troubleshooting\nWhen generating code from a Java file, CobiGen makes use of Java reflection for generating templates. In order to do that, the CLI needs to find the compiled source code of your project.\nIf you find an error like Compiled class foo\\bar\\EmployeeEntity.java has not been found, it means you need to run mvn clean install on the input project so that a new target folder gets created with the needed compiled sources.\n&#x2190;&#xA0;Previous:&#xA0;CobiGen&#xA0;| &#x2191;&#xA0;Up:&#xA0;CobiGen&#x2009;&#x2014;&#x2009;Code-based incremental Generator&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Maven Build Integration&#xA0;&#x2192;\n"},{"id":509,"path":"../website/pages/docs/master-cobigen.asciidoc_cobigen.html#master-cobigen.asciidoc_cobigen","type":"docs","title":"CobiGen","body":"71. CobiGen\n"},{"id":510,"path":"../website/pages/docs/master-cobigen.asciidoc_cobigen.html#cobigen-core_configuration.asciidoc","type":"docs","title":"Configuration","body":"71.1. Configuration\nCobiGen will be configured using a configuration folder containing a context configuration, multiple template folders with a templates configuration per template folder, and a number of templates in each template folder. Find some examples here. Thus, a simple folder structure might look like this:\nCobiGen_Templates\n|- templateFolder1\n|- templates.xml\n|- templateFolder2\n|- templates.xml\n|- context.xml\n"},{"id":511,"path":"../website/pages/docs/master-cobigen.asciidoc_cobigen.html#cobigen-core_configuration.asciidoc_context-configuration","type":"docs","title":"Context Configuration","body":"71.1.1. Context Configuration\nThe context configuration (context.xml) always has the following root structure:\nListing 97. Context Configuration\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;\n&lt;contextConfiguration xmlns=&quot;http://capgemini.com&quot;\nxmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;\nversion=&quot;1.0&quot;&gt;\n&lt;triggers&gt;\n...\n&lt;/triggers&gt;\n&lt;/contextConfiguration&gt;\nThe context configuration has a version attribute, which should match the XSD version the context configuration is an instance of. It should not state the version of the currently released version of CobiGen. This attribute should be maintained by the context configuration developers. If configured correctly, it will provide a better feedback for the user and thus higher user experience. Currently there is only the version v1.0. For further version there will be a changelog later on.\nTrigger Node\nAs children of the &lt;triggers&gt; node you can define different triggers. By defining a &lt;trigger&gt; you declare a mapping between special inputs and a templateFolder, which contains all templates, which are worth to be generated with the given input.\nListing 98. trigger configuration\n&lt;trigger id=&quot;...&quot; type=&quot;...&quot; templateFolder=&quot;...&quot; inputCharset=&quot;UTF-8&quot; &gt;\n...\n&lt;/trigger&gt;\nThe attribute id should be unique within an context configuration. It is necessary for efficient internal processing.\nThe attribute type declares a specific trigger interpreter, which might be provided by additional plug-ins. A trigger interpreter has to provide an input reader, which reads specific inputs and creates a template object model out of it to be processed by the FreeMarker template engine later on. Have a look at the plug-in&#x2019;s documentation of your interest and see, which trigger types and thus inputs are currently supported.\nThe attribute templateFolder declares the relative path to the template folder, which will be used if the trigger gets activated.\nThe attribute inputCharset (optional) determines the charset to be used for reading any input file.\nMatcher Node\nA trigger will be activated if its matchers hold the following formula:\n!(NOT || &#x2026;&#x200B; || NOT) &amp;&amp; AND &amp;&amp; &#x2026;&#x200B; &amp;&amp; AND &amp;&amp; (OR || &#x2026;&#x200B; || OR)\nWhereas NOT/AND/OR describes the accumulationType of a matcher (see below) and e.g. NOT means &apos;a matcher with accumulationType NOT matches a given input&apos;. Thus additionally to an input reader, a trigger interpreter has to define at least one set of matchers, which are satisfiable, to be fully functional. A &lt;matcher&gt; node declares a specific characteristics a valid input should have.\nListing 99. Matcher Configuration\n&lt;matcher type=&quot;...&quot; value=&quot;...&quot; accumulationType=&quot;...&quot;&gt;\n...\n&lt;/matcher&gt;\nThe attribute type declares a specific type of matcher, which has to be provided by the surrounding trigger interpreter. Have a look at the plug-in&#x2019;s documentation, which also provides the used trigger type for more information about valid matcher and their functionalities.\nThe attribute value might contain any information necessary for processing the matcher&#x2019;s functionality. Have a look at the relevant plug-in&#x2019;s documentation for more detail.\nThe attribute accumulationType (optional) specifies how the matcher will influence the trigger activation. Valid values are:\nOR (default): if any matcher of accumulation type OR matches, the trigger will be activated as long as there are no further matchers with different accumulation types\nAND: if any matcher with AND accumulation type does not match, the trigger will not be activated\nNOT: if any matcher with NOT accumulation type matches, the trigger will not be activated\nVariableAssignment Node\nFinally, a &lt;matcher&gt; node can have multiple &lt;variableAssignment&gt; nodes as children. Variable assignments allow to parametrize the generation by additional values, which will be added to the object model for template processing. The variables declared using variable assignments, will be made accessible in the templates.xml as well in the object model for template processing via the namespace variables.*.\nListing 100. Complete Configuration Pattern\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;\n&lt;contextConfiguration xmlns=&quot;http://capgemini.com&quot;\nxmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;\nversion=&quot;1.0&quot;&gt;\n&lt;triggers&gt;\n&lt;trigger id=&quot;...&quot; type=&quot;...&quot; templateFolder=&quot;...&quot;&gt;\n&lt;matcher type=&quot;...&quot; value=&quot;...&quot;&gt;\n&lt;variableAssignment type=&quot;...&quot; key=&quot;...&quot; value=&quot;...&quot; /&gt;\n&lt;/matcher&gt;\n&lt;/trigger&gt;\n&lt;/triggers&gt;\n&lt;/contextConfiguration&gt;\nThe attribute type declares the type of variable assignment to be processed by the trigger interpreter providing plug-in. This attribute enables variable assignments with different dynamic value resolutions.\nThe attribute key declares the namespace under which the resolved value will be accessible later on.\nThe attribute value might declare a constant value to be assigned or any hint for value resolution done by the trigger interpreter providing plug-in. For instance, if type is regex, then on value you will assign the matched group number by the regex (1, 2, 3&#x2026;&#x200B;)\nContainerMatcher Node\nThe &lt;containerMatcher&gt; node is an additional matcher for matching containers of multiple input objects.\nSuch a container might be a package, which encloses multiple types or---more generic---a model, which encloses multiple elements. A container matcher can be declared side by side with other matchers:\nListing 101. ContainerMatcher Declaration\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;\n&lt;contextConfiguration xmlns=&quot;http://capgemini.com&quot;\nxmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;\nversion=&quot;1.0&quot;&gt;\n&lt;triggers&gt;\n&lt;trigger id=&quot;...&quot; type=&quot;...&quot; templateFolder=&quot;...&quot; &gt;\n&lt;containerMatcher type=&quot;...&quot; value=&quot;...&quot; retrieveObjectsRecursively=&quot;...&quot; /&gt;\n&lt;matcher type=&quot;...&quot; value=&quot;...&quot;&gt;\n&lt;variableAssignment type=&quot;...&quot; variable=&quot;...&quot; value=&quot;...&quot; /&gt;\n&lt;/matcher&gt;\n&lt;/trigger&gt;\n&lt;/triggers&gt;\n&lt;/contextConfiguration&gt;\nThe attribute type declares a specific type of matcher, which has to be provided by the surrounding trigger interpreter. Have a look at the plug-in&#x2019;s documentation, which also provides the used trigger type for more information about valid matcher and their functionalities.\nThe attribute value might contain any information necessary for processing the matcher&#x2019;s functionality. Have a look at the relevant plug-in&#x2019;s documentation for more detail.\nThe attribute retrieveObjectsRecursively (optional boolean) states, whether the children of the input should be retrieved recursively to find matching inputs for generation.\nThe semantics of a container matchers are the following:\nA &lt;containerMatcher&gt; does not declare any &lt;variableAssignment&gt; nodes\nA &lt;containerMatcher&gt; matches an input if and only if one of its enclosed elements satisfies a set of &lt;matcher&gt; nodes of the same &lt;trigger&gt;\nInputs, which match a &lt;containerMatcher&gt; will cause a generation for each enclosed element\n"},{"id":512,"path":"../website/pages/docs/master-cobigen.asciidoc_cobigen.html#cobigen-core_configuration.asciidoc_templates-configuration","type":"docs","title":"Templates Configuration","body":"71.1.2. Templates Configuration\nThe template configuration (templates.xml) specifies, which templates exist and under which circumstances it will be generated. There are two possible configuration styles:\nConfigure the template meta-data for each template file by template nodes\n(since cobigen-core-v1.2.0): Configure templateScan nodes to automatically retrieve a default configuration for all files within a configured folder and possibly modify the automatically configured templates using templateExtension nodes\nTo get an intuition of the idea, the following will initially describe the first (more extensive) configuration style. Such an configuration root structure looks as follows:\nListing 102. Extensive Templates Configuration\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;\n&lt;templatesConfiguration xmlns=&quot;http://capgemini.com&quot;\nxmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;\nversion=&quot;1.0&quot; templateEngine=&quot;FreeMarker&quot;&gt;\n&lt;templates&gt;\n...\n&lt;/templates&gt;\n&lt;increments&gt;\n...\n&lt;/increments&gt;\n&lt;/templatesConfiguration&gt;\nThe root node &lt;templatesConfiguration&gt; specifies two attributes. The attribute version provides further usability support and will be handled analogous to the version attribute of the context configuration. The optional attribute templateEngine specifies the template engine to be used for processing the templates (since cobigen-core-4.0.0). By default it is set to FreeMarker.\nThe node &lt;templatesConfiguration&gt; allows two different grouping nodes as children. First, there is the &lt;templates&gt; node, which groups all declarations of templates. Second, there is the &lt;increments&gt; node, which groups all declarations about increments.\nTemplate Node\nThe &lt;templates&gt; node groups multiple &lt;template&gt; declarations, which enables further generation. Each template file should be registered at least once as a template to be considered.\nListing 103. Example Template Configuration\n&lt;templates&gt;\n&lt;template name=&quot;...&quot; destinationPath=&quot;...&quot; templateFile=&quot;...&quot; mergeStrategy=&quot;...&quot; targetCharset=&quot;...&quot; /&gt;\n...\n&lt;/templates&gt;\nA template declaration consist of multiple information:\nThe attribute name specifies an unique ID within the templates configuration, which will later be reused in the increment definitions.\nThe attribute destinationPath specifies the destination path the template will be generated to. It is possible to use all variables defined by variable assignments within the path declaration using the FreeMarker syntax ${variables.*}. While resolving the variable expressions, each dot within the value will be automatically replaced by a slash. This behavior is accounted for by the transformations of Java packages to paths as CobiGen has first been developed in the context of the Java world. Furthermore, the destination path variable resolution provides the following additional built-in operators analogue to the FreeMarker syntax:\n?cap_first analogue to FreeMarker\n?uncap_first analogue to FreeMarker\n?lower_case analogue to FreeMarker\n?upper_case analogue to FreeMarker\n?replace(regex, replacement) - Replaces all occurrences of the regular expression regex in the variable&#x2019;s value with the given replacement string. (since cobigen-core v1.1.0)\n?removeSuffix(suffix) - Removes the given suffix in the variable&#x2019;s value iff the variable&#x2019;s value ends with the given suffix. Otherwise nothing will happen. (since cobigen-core v1.1.0)\n?removePrefix(prefix) - Analogue to ?removeSuffix but removes the prefix of the variable&#x2019;s value. (since cobigen-core v1.1.0)\nThe attribute templateFile describes the relative path dependent on the template folder specified in the trigger to the template file to be generated.\nThe attribute mergeStrategy (optional) can be optionally specified and declares the type of merge mechanism to be used, when the destinationPath points to an already existing file. CobiGen by itself just comes with a mergeStrategy override, which enforces file regeneration in total. Additional available merge strategies have to be obtained from the different plug-in&#x2019;s documentations (see here for java, XML, properties, and text). Default: not set (means not mergeable)\nThe attribute targetCharset (optional) can be optionally specified and declares the encoding with which the contents will be written into the destination file. This also includes reading an existing file at the destination path for merging its contents with the newly generated ones. Default: UTF-8\n(Since version 4.1.0) It is possible to reference external template (templates defined on another trigger), thanks to using &lt;incrementRef &#x2026;&#x200B;&gt; that are explained here.\nTemplateScan Node\n(since cobigen-core-v1.2.0)\nThe second configuration style for template meta-data is driven by initially scanning all available templates and automatically configure them with a default set of meta-data. A scanning configuration might look like this:\nListing 104. Example of Template-scan configuration\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;\n&lt;templatesConfiguration xmlns=&quot;http://capgemini.com&quot;\nxmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;\nversion=&quot;1.2&quot;&gt;\n&lt;templateScans&gt;\n&lt;templateScan templatePath=&quot;templates&quot; templateNamePrefix=&quot;prefix_&quot; destinationPath=&quot;src/main/java&quot;/&gt;\n&lt;/templateScans&gt;\n&lt;/templatesConfiguration&gt;\nYou can specify multiple &lt;templateScan &#x2026;&#x200B;&gt; nodes for different templatePaths and different templateNamePrefixes.\nThe name can be specified to later on reference the templates found by a template-scan within an increment. (since cobigen-core-v2.1.)\nThe templatePath specifies the relative path from the templates.xml to the root folder from which the template scan should be performed.\nThe templateNamePrefix (optional) defines a common id prefix, which will be added to all found and automatically configured templates.\nThe destinationPath defines the root folder all found templates should be generated to, whereas the root folder will be a prefix for all found and automatically configured templates.\nA templateScan will result in the following default configuration of templates. For each file found, new template will be created virtually with the following default values:\nid: file name without .ftl extension prefixed by templateNamePrefix from template-scan\ndestinationPath: relative file path of the file found with the prefix defined by destinationPath from template-scan. Furthermore,\nit is possible to use the syntax for accessing and modifying variables as described for the attribute destinationPath of the template node, besides the only difference, that due to file system restrictions you have to replace all ?-signs (for built-ins) with #-signs.\nthe files to be scanned, should provide their final file extension by the following file naming convention: &lt;filename&gt;.&lt;extension&gt;.ftl Thus the file extension .ftl will be removed after generation.\ntemplateFile: relative path to the file found\nmergeStrategy: (optional) not set means not mergeable\ntargetCharset: (optional) defaults to UTF-8\n(Since version 4.1.0) It is possible to reference external templateScan (templateScans defined on another trigger), thanks to using &lt;incrementRef &#x2026;&#x200B;&gt; that are explained here.\nTemplateExtension Node\n(since cobigen-core-v1.2.0)\nAdditionally to the templateScan declaration it is easily possible to rewrite specific attributes for any scanned and automatically configured template.\nListing 105. Example Configuration of a TemplateExtension\n&lt;templates&gt;\n&lt;templateExtension ref=&quot;prefix_FooClass.java&quot; mergeStrategy=&quot;javamerge&quot; /&gt;\n&lt;/templates&gt;\n&lt;templateScans&gt;\n&lt;templateScan templatePath=&quot;foo&quot; templateNamePrefix=&quot;prefix_&quot; destinationPath=&quot;src/main/java/foo&quot;/&gt;\n&lt;/templateScans&gt;\nLets assume, that the above example declares a template-scan for the folder foo, which contains a file FooClass.java.ftl in any folder depth. Thus the template scan will automatically create a virtual template declaration with id=prefix_FooClass.java and further default configuration.\nUsing the templateExtension declaration above will reference the scanned template by the attribute ref and overrides the mergeStrategy of the automatically configured template by the value javamerge. Thus we are able to minimize the needed templates configuration.\n(Since version 4.1.0) It is possible to reference external templateExtension (templateExtensions defined on another trigger), thanks to using &lt;incrementRef &#x2026;&#x200B;&gt; that are explained here.\nIncrement Node\nThe &lt;increments&gt; node groups multiple &lt;increment&gt; nodes, which can be seen as a collection of templates to be generated. An increment will be defined by a unique id and a human readable description.\n&lt;increments&gt;\n&lt;increment id=&quot;...&quot; description=&quot;...&quot;&gt;\n&lt;incrementRef ref=&quot;...&quot; /&gt;\n&lt;templateRef ref=&quot;...&quot; /&gt;\n&lt;templateScanRef ref=&quot;...&quot; /&gt;\n&lt;/increment&gt;\n&lt;/increments&gt;\nAn increment might contain multiple increments and/or templates, which will be referenced using &lt;incrementRef &#x2026;&#x200B;&gt;, &lt;templateRef &#x2026;&#x200B;&gt;, resp. &lt;templateScanRef &#x2026;&#x200B;&gt; nodes. These nodes only declare the attribute ref, which will reference an increment, a template, or a template-scan by its id or name.\n(Since version 4.1.0) An special case of &lt;incrementRef &#x2026;&#x200B;&gt; is the external incrementsRef. By default, &lt;incrementRef &#x2026;&#x200B;&gt; are used to reference increments defined in the same templates.xml file. So for example, we could have:\n&lt;increments&gt;\n&lt;increment id=&quot;incA&quot; description=&quot;...&quot;&gt;\n&lt;incrementRef ref=&quot;incB&quot; /&gt;\n&lt;/increment&gt;\n&lt;increment id=&quot;incB&quot; description=&quot;...&quot;&gt;\n&lt;templateRef .... /&gt;\n&lt;templateScan .... /&gt;\n&lt;/increment&gt;\n&lt;/increments&gt;\nHowever, if we want to reference an increment that it is not defined inside our templates.xml (an increment defined for another trigger), then we can use external incrementRef as shown below:\n&lt;increment name=&quot;...&quot; description=&quot;...&quot;&gt;\n&lt;incrementRef ref=&quot;trigger_id::increment_id&quot;/&gt;\n&lt;/increment&gt;\nThe ref string is split using as delimiter ::. The first part of the string, is the trigger_id to reference. That trigger contains an increment_id. Currently, this functionality only works when both templates use the same kind of input file.\n"},{"id":513,"path":"../website/pages/docs/master-cobigen.asciidoc_cobigen.html#cobigen-core_configuration.asciidoc_java-template-logic","type":"docs","title":"Java Template Logic","body":"71.1.3. Java Template Logic\nsince cobigen-core-3.0.0 which is included in the Eclipse and Maven Plugin since version 2.0.0\nIn addition, it is possible to implement more complex template logic by custom Java code. To enable this feature, you can simply import the the CobiGen_Templates by clicking on Adapt Templates, turn it into a simple maven project (if it is not already) and implement any Java logic in the common maven layout (e.g. in the source folder src/main/java). Each Java class will be instantiated by CobiGen for each generation process. Thus, you can even store any state within a Java class instance during generation. However, there is currently no guarantee according to the template processing order.\nAs a consequence, you have to implement your Java classes with a public default (non-parameter) constructor to be used by any template. Methods of the implemented Java classes can be called within templates by the simple standard FreeMarker expression for calling Bean methods: SimpleType.methodName(param1). Until now, CobiGen will shadow multiple types with the same simple name non-deterministically. So please prevent yourself from that situation.\nFinally, if you would like to do some reflection within your Java code accessing any type of the template project or any type referenced by the input, you should load classes by making use of the classloader of the util classes. CobiGen will take care of the correct classloader building including the classpath of the input source as well as of the classpath of the template project. If you use any other classloader or build it by your own, there will be no guarantee, that generation succeeds.\n"},{"id":514,"path":"../website/pages/docs/master-cobigen.asciidoc_cobigen.html#cobigen-core_configuration.asciidoc_template-properties","type":"docs","title":"Template Properties","body":"71.1.4. Template Properties\nsince cobigen-core-4.0.0\nUsing a configuration with template scan, you can make use of properties in templates specified in property files named cobigen.properties next to the templates. The property files are specified as Java property files. Property files can be nested in subfolders. Properties will be resolved including property shading. Properties defined nearest to the template to be generated will take precedence.\nIn addition, a cobigen.properties file can be specified in the target folder root (in eclipse plugin, this is equal to the source project root). These properties take precedence over template properties specified in the template folder.\nNote\nIt is not allowed to override context variables in cobigen.properties specifications as we have not found any interesting use case. This is most probably an error of the template designer, CobiGen will raise an error in this case.\nMulti module support or template target path redirects\nsince cobigen-core-4.0.0\nOne special property you can specify in the template properties is the property relocate. It will cause the current folder and its subfolders to be relocated at destination path resolution time. Take the following example:\nfolder\n- sub1\nTemplate.java.ftl\ncobigen.properties\nLet the cobigen.properties file contain the line relocate=../sub2/${cwd}. Given that, the relative destination path of Template.java.ftl will be resolved to folder/sub2/Template.java. Compare template scan configuration for more information about basic path resolution. The relocate property specifies a relative path from the location of the cobigen.properties. The ${cwd} placeholder will contain the remaining relative path from the cobigen.properties location to the template file. In this basic example it just contains Template.java.ftl, but it may even be any relative path including subfolders of sub1 and its templates.\nGiven the relocate feature, you can even step out of the root path, which in general is the project/maven module the input is located in. This enables template designers to even address, e.g., maven modules located next to the module the input is coming from.\n"},{"id":515,"path":"../website/pages/docs/master-cobigen.asciidoc_cobigen.html#cobigen-core_configuration.asciidoc_basic-template-model","type":"docs","title":"Basic Template Model","body":"71.1.5. Basic Template Model\nIn addition to what is served by the different model builders of the different plug-ins, CobiGen provides a minimal model based on context variables as well as CobiGen properties. The following model is independent of the input format and will be served as a template model all the time:\nvariables\nall triggered context variables mapped to its assigned/mapped value\nall template properties\nall simple names of Java template logic implementation classes\nall full qualified names of Java template logic implementation classes\nfurther input related model, e.g. model from Java inputs\n"},{"id":516,"path":"../website/pages/docs/master-cobigen.asciidoc_cobigen.html#cobigen-core_configuration.asciidoc_plugin-mechanism","type":"docs","title":"Plugin Mechanism","body":"71.1.6. Plugin Mechanism\nSince cobigen-core 4.1.0, we changed the plug-in discovery mechanism. So far it was necessary to register new plugins programmatically, which introduces the need to let every tool integration, i.e. for eclipse or maven, be dependent on every plug-in, which should be released. This made release cycles take long time as all plug-ins have to be integrated into a final release of maven or eclipse integration.\nNow, plug-ins are automatically discovered by the Java Service Loader mechanism from the classpath. This also effects the setup of eclipse and maven integrations to allow modular releases of CobiGen in future. We are now able to provide faster rollouts of bug-fixes in any of the plug-ins as they can be released completely independently.\n"},{"id":517,"path":"../website/pages/docs/master-cobigen.asciidoc_cobigen.html#master-cobigen.asciidoc_plug-ins","type":"docs","title":"Plug-ins","body":"71.2. Plug-ins\n"},{"id":518,"path":"../website/pages/docs/master-cobigen.asciidoc_cobigen.html#cobigen-javaplugin.asciidoc","type":"docs","title":"Java Plug-in","body":"71.2.1. Java Plug-in\nThe CobiGen Java Plug-in comes with a new input reader for java artifacts, new java related trigger and matchers, as well as a merging mechanism for Java sources.\nTrigger extension\nThe Java Plug-in provides a new trigger for Java related inputs. It accepts different representations as inputs (see Java input reader) and provides additional matching and variable assignment mechanisms. The configuration in the context.xml for this trigger looks like this:\ntype &apos;java&apos;\nListing 106. Example of a java trigger definition\n&lt;trigger id=&quot;...&quot; type=&quot;java&quot; templateFolder=&quot;...&quot;&gt;\n...\n&lt;/trigger&gt;\nThis trigger type enables Java elements as inputs.\nMatcher types\nWith the trigger you might define matchers, which restrict the input upon specific aspects:\ntype &apos;fqn&apos; &#x2192; full qualified name matching\nListing 107. Example of a java trigger definition with a full qualified name matcher\n&lt;trigger id=&quot;...&quot; type=&quot;java&quot; templateFolder=&quot;...&quot;&gt;\n&lt;matcher type=&quot;fqn&quot; value=&quot;(.+)\\.persistence\\.([^\\.]+)\\.entity\\.([^\\.]+)&quot;&gt;\n...\n&lt;/matcher&gt;\n&lt;/trigger&gt;\nThis trigger will be enabled if the full qualified name (fqn) of the declaring input class matches the given regular expression (value).\ntype &apos;package&apos; &#x2192; package name of the input\nListing 108. Example of a java trigger definition with a package name matcher\n&lt;trigger id=&quot;...&quot; type=&quot;java&quot; templateFolder=&quot;...&quot;&gt;\n&lt;matcher type=&quot;package&quot; value=&quot;(.+)\\.persistence\\.([^\\.]+)\\.entity&quot;&gt;\n...\n&lt;/matcher&gt;\n&lt;/trigger&gt;\nThis trigger will be enabled if the package name (package) of the declaring input class matches the given regular expression (value).\ntype &apos;expression&apos;\nListing 109. Example of a java trigger definition with a package name matcher\n&lt;trigger id=&quot;...&quot; type=&quot;java&quot; templateFolder=&quot;...&quot;&gt;\n&lt;matcher type=&quot;expression&quot; value=&quot;instanceof java.lang.String&quot;&gt;\n...\n&lt;/matcher&gt;\n&lt;/trigger&gt;\nThis trigger will be enabled if the expression evaluates to true. Valid expressions are\ninstanceof fqn: checks an &apos;is a&apos; relation of the input type\nisAbstract: checks, whether the input type is declared abstract\nContainerMatcher types\nAdditionally, the java plugin provides the ability to match packages (containers) as follows:\ntype &apos;package&apos;\nListing 110. Example of a java trigger definition with a container matcher for packages\n&lt;trigger id=&quot;...&quot; type=&quot;java&quot; templateFolder=&quot;...&quot;&gt;\n&lt;containerMatcher type=&quot;package&quot; value=&quot;com\\.example\\.app\\.component1\\.persistence.entity&quot; /&gt;\n&lt;/trigger&gt;\nThe container matcher matches packages provided by the type com.capgemini.cobigen.javaplugin.inputreader.to.PackageFolder with a regular expression stated in the value attribute. (See containerMatcher semantics to get more information about containerMatchers itself.)\nVariableAssignment types\nFurthermore, it provides the ability to extract information from each input for further processing in the templates. The values assigned by variable assignments will be made available in template and the destinationPath of context.xml through the namespace variables.&lt;key&gt;. The Java Plug-in currently provides two different mechanisms:\ntype &apos;regex&apos; &#x2192; regular expression group\n&lt;trigger id=&quot;...&quot; type=&quot;java&quot; templateFolder=&quot;...&quot;&gt;\n&lt;matcher type=&quot;fqn&quot; value=&quot;(.+)\\.persistence\\.([^\\.]+)\\.entity\\.([^\\.]+)&quot;&gt;\n&lt;variableAssignment type=&quot;regex&quot; key=&quot;rootPackage&quot; value=&quot;1&quot; /&gt;\n&lt;variableAssignment type=&quot;regex&quot; key=&quot;component&quot; value=&quot;2&quot; /&gt;\n&lt;variableAssignment type=&quot;regex&quot; key=&quot;pojoName&quot; value=&quot;3&quot; /&gt;\n&lt;/matcher&gt;\n&lt;/trigger&gt;\nThis variable assignment assigns the value of the given regular expression group number to the given key.\ntype &apos;constant&apos; &#x2192; constant parameter\n&lt;trigger id=&quot;...&quot; type=&quot;java&quot; templateFolder=&quot;...&quot;&gt;\n&lt;matcher type=&quot;fqn&quot; value=&quot;(.+)\\.persistence\\.([^\\.]+)\\.entity\\.([^\\.]+)&quot;&gt;\n&lt;variableAssignment type=&quot;constant&quot; key=&quot;domain&quot; value=&quot;restaurant&quot; /&gt;\n&lt;/matcher&gt;\n&lt;/trigger&gt;\nThis variable assignment assigns the value to the key as a constant.\nJava input reader\nThe Cobigen Java Plug-in implements an input reader for parsed java sources as well as for java Class&lt;?&gt; objects (loaded by reflection). So API user can pass Class&lt;?&gt; objects as well as JavaClass objects for generation. The latter depends on QDox, which will be used for parsing and merging java sources. For getting the right parsed java inputs you can easily use the JavaParserUtil, which provides static functionality to parse java files and get the appropriate JavaClass object.\nFurthermore, due to restrictions on both inputs according to model building (see below), it is also possible to provide an array of length two as an input, which contains the Class&lt;?&gt; as well as the JavaClass object of the same class.\nTemplate object model\nNo matter whether you use reflection objects or parsed java classes as input, you will get the following object model for template creation:\nclassObject (&apos;Class&apos; :: Class object of the Java input)\npojo\nname (&apos;String&apos; :: Simple name of the input class)\npackage (&apos;String&apos; :: Package name of the input class)\ncanonicalName (&apos;String&apos; :: Full qualified name of the input class)\nannotations (&apos;Map&lt;String, Object&gt;&apos; :: Annotations, which will be represented by a mapping of the full qualified type of an annotation to its value. To gain template compatibility, the key will be stored with &apos;_&apos; instead of &apos;.&apos; in the full qualified annotation type. Furthermore, the annotation might be recursively defined and thus be accessed using the same type of mapping. Example ${pojo.annotations.javax_persistence_Id})\njavaDoc (&apos;Map&lt;String, Object&gt;&apos;) :: A generic way of addressing all available javaDoc doclets and comments. The only fixed variable is comment (see below). All other provided variables depend on the doclets found while parsing. The value of a doclet can be accessed by the doclets name (e.g. ${&#x2026;&#x200B;javaDoc.author}). In case of doclet tags that can be declared multiple times (currently @param and @throws), you will get a map, which you access in a specific way (see below).\ncomment (&apos;String&apos; :: javaDoc comment, which does not include any doclets)\nparams (&apos;Map&lt;String,String&gt; :: javaDoc parameter info. If the comment follows proper conventions, the key will be the name of the parameter and the value being its description. You can also access the parameters by their number, as in arg0, arg1 etc, following the order of declaration in the signature, not in order of javadoc)\nthrows (&apos;Map&lt;String,String&gt; :: javaDoc exception info. If the comment follows proper conventions, the key will be the name of the thrown exception and the value being its description)\nextendedType (&apos;Map&lt;String, Object&gt;&apos; :: The supertype, represented by a set of mappings (since cobigen-javaplugin v1.1.0)\nname (&apos;String&apos; :: Simple name of the supertype)\ncanonicalName (&apos;String&apos; :: Full qualified name of the supertype)\npackage (&apos;String&apos; :: Package name of the supertype)\nimplementedTypes (&apos;List&lt;Map&lt;String, Object&gt;&gt;&apos; :: A list of all implementedTypes (interfaces) represented by a set of mappings (since cobigen-javaplugin v1.1.0)\ninterface (&apos;Map&lt;String, Object&gt;&apos; :: List element)\nname (&apos;String&apos; :: Simple name of the interface)\ncanonicalName (&apos;String&apos; :: Full qualified name of the interface)\npackage (&apos;String&apos; :: Package name of the interface)\nfields (&apos;List&lt;Map&lt;String, Object&gt;&gt;&apos; :: List of fields of the input class) (renamed since cobigen-javaplugin v1.2.0; previously attributes)\nfield (&apos;Map&lt;String, Object&gt;&apos; :: List element)\nname (&apos;String&apos; :: Name of the Java field)\ntype (&apos;String&apos; :: Type of the Java field)\ncanonicalType (&apos;String&apos; :: Full qualified type declaration of the Java field&#x2019;s type)\n&apos;isId&apos; (&apos;Deprecated&apos; :: &apos;boolean&apos; :: true if the Java field or its setter or its getter is annotated with the javax.persistence.Id annotation, false otherwise. Equivalent to ${pojo.attributes[i].annotations.javax_persistence_Id?has_content})\njavaDoc (see pojo.javaDoc)\nannotations (see pojo.annotations with the remark, that for fields all annotations of its setter and getter will also be collected)\nmethodAccessibleFields (&apos;List&lt;Map&lt;String, Object&gt;&gt;&apos; :: List of fields of the input class or its inherited classes, which are accessible using setter and getter methods)\nsame as for field (but without javaDoc!)\nmethods (&apos;List&lt;Map&lt;String, Object&gt;&gt;&apos; :: The list of all methods, whereas one method will be represented by a set of property mappings)\nmethod (&apos;Map&lt;String, Object&gt;&apos; :: List element)\nname (&apos;String&apos; :: Name of the method)\njavaDoc (see pojo.javaDoc)\nannotations (see pojo.annotations)\nFurthermore, when providing a Class&lt;?&gt; object as input, the Java Plug-in will provide additional functionalities as template methods (deprecated):\nisAbstract(String fqn) (Checks whether the type with the given full qualified name is an abstract class. Returns a boolean value.) (since cobigen-javaplugin v1.1.1) (deprecated)\nisSubtypeOf(String subType, String superType) (Checks whether the subType declared by its full qualified name is a sub type of the superType declared by its full qualified name. Equals the Java expression subType instanceof superType and so also returns a boolean value.) (since cobigen-javaplugin v1.1.1) (deprecated)\nModel Restrictions\nAs stated before both inputs (Class&lt;?&gt; objects and JavaClass objects ) have their restrictions according to model building. In the following these restrictions are listed for both models, the ParsedJava Model which results from an JavaClass input and the ReflectedJava Model, which results from a Class&lt;?&gt;` input.\nIt is important to understand, that these restrictions are only present if you work with either Parsed Model OR the Reflected Model. If you use the Maven Build Plug-in or Eclipse Plug-in these two models are merged together so that they can mutually compensate their weaknesses.\nParsed Model\nannotations of the input&#x2019;s supertype are not accessible due to restrictions in the QDox library. So pojo.methodAccessibleFields[i].annotations will always be empty for super type fields.\nannotations&apos; parameter values are available as Strings only (e.g. the Boolean value true is transformed into &quot;true&quot;). This also holds for the Reflected Model.\nfields of &quot;supersupertypes&quot; of the input JavaClass are not available at all. So pojo.methodAccessibleFields will only contain the input type&#x2019;s and the direct superclass&#x2019;s fields.\n[resolved, since cobigen-javaplugin 1.3.1] field types of supertypes are always canonical. So pojo.methodAccessibleFields[i].type will always provide the same value as pojo.methodAccessibleFields[i].canonicalType (e.g. java.lang.String instead of the expected String) for super type fields.\nReflected Model\nannotations&apos; parameter values are available as Strings only (e.g. the Boolean value true is transformed into &quot;true&quot;). This also holds for the Parsed Model.\nannotations are only available if the respective annotation has @Retention(value=RUNTIME), otherwise the annotations are to be discarded by the compiler or by the VM at run time. For more information see RetentionPolicy.\ninformation about generic types is lost. E.g. a field&#x2019;s/ methodAccessibleField&#x2019;s type for List&lt;String&gt; can only be provided as List&lt;?&gt;.\nMerger extensions\nThe Java Plug-in provides two additional merging strategies for Java sources, which can be configured in the templates.xml:\nMerge strategy javamerge (merges two Java resources and keeps the existing Java elements on conflicts)\nMerge strategy javamerge_override (merges two Java resources and overrides the existing Java elements on conflicts)\nIn general merging of two Java sources will be processed as follows:\nPrecondition of processing a merge of generated contents and existing ones is a common Java root class resp. surrounding class. If this is the case this class and all further inner classes will be merged recursively. Therefore, the following Java elements will be merged and conflicts will be resolved according to the configured merge strategy:\nextends and implements relations of a class: Conflicts can only occur for the extends relation.\nAnnotations of a class: Conflicted if an annotation declaration already exists.\nFields of a class: Conflicted if there is already a field with the same name in the existing sources. (Will be replaced / ignored in total, also including annotations)\nMethods of a class: Conflicted if there is already a method with the same signature in the existing sources. (Will be replaced / ignored in total, also including annotations)\n"},{"id":519,"path":"../website/pages/docs/master-cobigen.asciidoc_cobigen.html#cobigen-propertyplugin.asciidoc","type":"docs","title":"Property Plug-in","body":"71.2.2. Property Plug-in\nThe CobiGen Property Plug-in currently only provides different merge mechanisms for documents written in Java property syntax.\nMerger extensions\nThere are two merge strategies for Java properties, which can be configured in the templates.xml:\nMerge strategy propertymerge (merges two properties documents and keeps the existing properties on conflicts)\nMerge strategy propertymerge_override (merges two properties documents and overrides the existing properties on conflicts)\nBoth documents (base and patch) will be parsed using the Java 7 API and will be compared according their keys. Conflicts will occur if a key in the patch already exists in the base document.\n"},{"id":520,"path":"../website/pages/docs/master-cobigen.asciidoc_cobigen.html#cobigen-xmlplugin.asciidoc","type":"docs","title":"XML Plug-in","body":"71.2.3. XML Plug-in\nThe CobiGen XML Plug-in comes with an input reader for xml artifacts, xml related trigger and matchers and provides different merge mechanisms for XML result documents.\nTrigger extension\n(since cobigen-xmlplugin v2.0.0)\nThe XML Plug-in provides a trigger for xml related inputs. It accepts xml documents as input (see XML input reader) and provides additional matching and variable assignment mechanisms. The configuration in the context.xml for this trigger looks like this:\ntype &apos;xml&apos;\nListing 111. Example of a xml trigger definition.\n&lt;trigger id=&quot;...&quot; type=&quot;xml&quot; templateFolder=&quot;...&quot;&gt;\n...\n&lt;/trigger&gt;\nThis trigger type enables xml documents as inputs.\ntype &apos;xpath&apos;\nListing 112. Example of a xpath trigger definition.\n&lt;trigger id=&quot;...&quot; type=&quot;xpath&quot; templateFolder=&quot;...&quot;&gt;\n...\n&lt;/trigger&gt;\nThis trigger type enables xml documents as container inputs, which consists of several subdocuments.\nContainerMatcher type\nA ContainerMatcher check if the input is a valid container.\nxpath: type: &apos;xpath&apos;\nListing 113. Example of a xml trigger definition with a nodename matcher.\n&lt;trigger id=&quot;...&quot; type=&quot;xml&quot; templateFolder=&quot;...&quot;&gt;\n&lt;containerMatcher type=&quot;xpath&quot; value=&quot;./uml:Model//packagedElement[@xmi:type=&apos;uml:Class&apos;]&quot;&gt;\n...\n&lt;/matcher&gt;\n&lt;/trigger&gt;\nBefore applying any Matcher, this containerMatcher checks if the XML file contains a node &quot;uml:Model&quot; with a childnode &quot;packagedElement&quot; which contains an attribute &quot;xmi:type&quot; with the value &quot;uml:Class&quot;.\nMatcher types\nWith the trigger you might define matchers, which restrict the input upon specific aspects:\nxml: type &apos;nodename&apos; &#x2192; document&#x2019;s root name matching\nListing 114. Example of a xml trigger definition with a nodename matcher\n&lt;trigger id=&quot;...&quot; type=&quot;xml&quot; templateFolder=&quot;...&quot;&gt;\n&lt;matcher type=&quot;nodename&quot; value=&quot;\\D\\w*&quot;&gt;\n...\n&lt;/matcher&gt;\n&lt;/trigger&gt;\nThis trigger will be enabled if the root name of the declaring input document matches the given regular expression (value).\nxpath: type: &apos;xpath&apos; &#x2192; matching a node with a xpath value\nListing 115. Example of a xpath trigger definition with a xpath matcher.\n&lt;trigger id=&quot;...&quot; type=&quot;xml&quot; templateFolder=&quot;...&quot;&gt;\n&lt;matcher type=&quot;xpath&quot; value=&quot;/packagedElement[@xmi:type=&apos;uml:Class&apos;]&quot;&gt;\n...\n&lt;/matcher&gt;\n&lt;/trigger&gt;\nThis trigger will be enabled if the XML file contains a node &quot;/packagedElement&quot; where the &quot;xmi:type&quot; property equals &quot;uml:Class&quot;.\nVariableAssignment types\nFurthermore, it provides the ability to extract information from each input for further processing in the templates. The values assigned by variable assignments will be made available in template and the destinationPath of context.xml through the namespace variables.&lt;key&gt;. The XML Plug-in currently provides only one mechanism:\ntype &apos;constant&apos; &#x2192; constant parameter\n&lt;trigger id=&quot;...&quot; type=&quot;xml&quot; templateFolder=&quot;...&quot;&gt;\n&lt;matcher type=&quot;nodename&quot; value=&quot;\\D\\w*&quot;&gt;\n&lt;variableAssignment type=&quot;constant&quot; key=&quot;domain&quot; value=&quot;restaurant&quot; /&gt;\n&lt;/matcher&gt;\n&lt;/trigger&gt;\nThis variable assignment assigns the value to the key as a constant.\nXML input reader\nThe Cobigen XML Plug-in implements an input reader for parsed xml documents. So API user can pass org.w3c.dom.Document objects for generation. For getting the right parsed xml inputs you can easily use the xmlplugin.util.XmlUtil, which provides static functionality to parse xml files or input streams and get the appropriate Document object.\nTemplate object\nDue to the heterogeneous structure an xml document can have, the xml input reader does not always create exactly the same model structure (in contrast to the java input reader). For example the model&#x2019;s depth differs strongly, according to it&#x2019;s input document. To allow navigational access to the nodes, the model also depends on the document&#x2019;s element&#x2019;s node names. All child elements with unique names, are directly accessible via their names. In addition it is possible to iterate over all child elements with held of the child list Children. So it is also possible to access child elements with non unique names.\nThe XML input reader will create the following object model for template creation (EXAMPLEROOT, EXAMPLENODE1, EXAMPLENODE2, EXAMPLEATTR1,&#x2026;&#x200B; are just used here as examples. Of course they will be replaced later by the actual node or attribute names):\n~EXAMPLEROOT~ (&apos;Map&lt;String, Object&gt;&apos; :: common element structure)\n_nodeName_ (&apos;String&apos; :: Simple name of the root node)\n_text_ (&apos;String&apos; :: Concatenated text content (PCDATA) of the root node)\nTextNodes (&apos;List&lt;String&gt;&apos; :: List of all the root&#x2019;s text node contents)\n_at_~EXAMPLEATTR1~ (&apos;String&apos; :: String representation of the attribute&#x2019;s value)\n_at_~EXAMPLEATTR2~ (&apos;String&apos; :: String representation of the attribute&#x2019;s value)\n_at_&#x2026;&#x200B;\nAttributes (&apos;List&lt;Map&lt;String, Object&gt;&gt;&apos; :: List of the root&#x2019;s attributes\nat (&apos;Map&lt;String, Object&gt;&apos; :: List element)\n_attName_ (&apos;String&apos; :: Name of the attribute)\n_attValue_ (&apos;String&apos; :: String representation of the attribute&#x2019;s value)\nChildren (&apos;List&lt;Map&lt;String, Object&gt;&gt;&apos; :: List of the root&#x2019;s child elements\nchild (&apos;Map&lt;String, Object&gt;&apos; :: List element)\n&#x2026;&#x200B;common element sub structure&#x2026;&#x200B;\n~EXAMPLENODE1~ (&apos;Map&lt;String, Object&gt;&apos; :: One of the root&#x2019;s child nodes)\n&#x2026;&#x200B;common element structure&#x2026;&#x200B;\n~EXAMPLENODE2~ (&apos;Map&lt;String, Object&gt;&apos; :: One of the root&#x2019;s child nodes)\n&#x2026;&#x200B;common element sub structure&#x2026;&#x200B;\n~EXAMPLENODE21~ (&apos;Map&lt;String, Object&gt;&apos; :: One of the nodes&apos; child nodes)\n&#x2026;&#x200B;common element structure&#x2026;&#x200B;\n~EXAMPLENODE&#x2026;&#x200B;~\n~EXAMPLENODE&#x2026;&#x200B;~\nIn contrast to the java input reader, this xml input reader does currently not provide any additional template methods.\nMerger extensions\nThe XML plugin uses the LeXeMe merger library to produce semantically correct merge products. The merge strategies can be found in the MergeType enum and can be configured in the templates.xml as a mergeStrategy attribute:\nmergeStrategy &apos;xmlmerge&apos;\nListing 116. Example of a template using the mergeStrategy xmlmerge\n&lt;templates&gt;\n&lt;template name=&quot;...&quot; destinationPath=&quot;...&quot; templateFile=&quot;...&quot; mergeStrategy=&quot;xmlmerge&quot;/&gt;\n&lt;/templates&gt;\nCurrently only the document types included in LeXeMe are supported.\nOn how the merger works consult the LeXeMe Wiki.\n"},{"id":521,"path":"../website/pages/docs/master-cobigen.asciidoc_cobigen.html#cobigen-textmerger.asciidoc","type":"docs","title":"Text Merger Plug-in","body":"71.2.4. Text Merger Plug-in\nThe Text Merger Plug-in enables merging result free text documents to existing free text documents. Therefore, the algorithms are also very rudimentary.\nMerger extensions\nThere are currently three main merge strategies that apply for the whole document:\nmerge strategy textmerge_append (appends the text directly to the end of the existing document)\n_Remark_: If no anchors are defined, this will simply append the patch.\nmerge strategy textmerge_appendWithNewLine (appends the text after adding a new line break to the existing document)\n_Remark_: empty patches will not result in appending a new line any more since v1.0.1\nRemark: Only suitable if no anchors are defined, otherwise it will simply act as textmerge_append\nmerge strategy textmerge_override (replaces the contents of the existing file with the patch)\n_Remark_: If anchors are defined, override is set as the default mergestrategy for every text block if not redefined in an anchor specification.\nAnchor functionality\nIf a template contains text that fits the definition of anchor:${documentpart}:${mergestrategy}:anchorend or more specifically the regular expression (.*)anchor:([:]+):(newline_)?([:]+)(_newline)?:anchorend\\\\s*(\\\\r\\\\n|\\\\r|\\\\n), some additional functionality becomes available about specific parts of the incoming text and the way it will be merged with the existing text. These anchors always change things about the text to come up until the next anchor, text before it is ignored.\nIf no anchors are defined, the complete patch will be appended depending on your choice for the template in the file templates.xml.\nAnchor Definition\nAnchors should always be defined as a comment of the language the template results in, as you do not want them to appear in your readable version, but cannot define them as freemarker comments in the template, or the merger will not know about them.\nAnchors will also be read when they are not comments due to the merger being able to merge multiple types of text-based languages, thus making it practically impossible to filter for the correct comment declaration. That is why anchors have to always be followed by line breaks. That way there is a universal way to filter anchors that should have anchor functionality and ones that should appear in the text.\nRemark: If the resulting language has closing tags for comments, they have to appear in the next line.\nRemark: If you do not put the anchor into a new line, all the text that appears before it will be added to the anchor.\nDocumentparts\nIn general, ${documentpart} is an id to mark a part of the document, that way the merger knows what parts of the text to merge with which parts of the patch (e.g. if the existing text contains anchor:table:${}:anchorend that part will be merged with the part tagged anchor:table:${}:anchorend of the patch).\nIf the same documentpart is defined multiple times, it can lead to errors, so instead of defining table multiple times, use table1, table2, table3 etc.\nIf a ${documentpart} is defined in the document but not in the patch and they are in the same position, it is processed in the following way: If only the documentparts header, test and footer are defined in the document in that order, and the patch contains header, order and footer, the resulting order will be header, test, order then footer.\nThe following documentparts have default functionality:\nanchor:header:${mergestrategy}:anchorend marks the beginning of a header, that will be added once when the document is created, but not again.\nRemark: This is only done once, if you have header in another anchor, it will be ignored\nanchor:footer:${mergestrategy}:anchorend marks the beginning of a footer, that will be added once when the document is created, but not again. Once this is invoked, all following text will be included in the footer, including other anchors.\nMergestrategies\nMergestrategies are only relevant in the patch, as the merger is only interested in how text in the patch should be managed, not how it was managed in the past.\nanchor:${documentpart}::anchorend will use the merge strategy from templates.xml, see Merger-Extensions.\nanchor:${}:${mergestrategy}_newline:anchorend or anchor:${}:newline_${mergestrategy}:anchorend states that a new line should be appended before or after this anchors text, depending on where the newline is (before or after the mergestrategy). anchor:${documentpart}:newline:anchorend puts a new line after the anchors text.\nRemark: Only works with appending strategies, not merging/replacing ones. These strategies currently include: appendbefore, append/appendafter\nanchor:${documentpart}:override:anchorend means that the new text of this documentpart will replace the existing one completely\nanchor:${documentpart}:appendbefore:anchorend or anchor:${documentpart}:appendafter:anchorend/anchor:${documentpart}:append:anchorend specifies whether the text of the patch should come before the existing text or after.\nUsage Examples\nGeneral\nBelow you can see how a file with anchors might look like (using Asciidoc comment tags), with examples of what you might want to use the different functions for.\n// anchor:header:append:anchorend\nTable of contents\nIntroduction/Header\n// anchor:part1:appendafter:anchorend\nLists\nTable entries\n// anchor:part2:nomerge:anchorend\nDocument Separators\nAsciidoc table definitions\n// anchor:part3:override:anchorend\nAnything that you only want once but changes from time to time\n// anchor:footer:append:anchorend\nCopyright Info\nImprint\nMerging\nIn this section you will see a comparison on what files look like before and after merging\noverride\nListing 117. Before\n// anchor:part:override:anchorend\nLorem Ipsum\nListing 118. Patch\n// anchor:part:override:anchorend\nDolor Sit\nListing 119. After\n// anchor:part:override:anchorend\nDolor Sit\nAppending\nListing 120. Before\n// anchor:part:append:anchorend\nLorem Ipsum\n// anchor:part2:appendafter:anchorend\nLorem Ipsum\n// anchor:part3:appendbefore:anchorend\nLorem Ipsum\nListing 121. Patch\n// anchor:part:append:anchorend\nDolor Sit\n// anchor:part2:appendafter:anchorend\nDolor Sit\n// anchor:part3:appendbefore:anchorend\nDolor Sit\nListing 122. After\n// anchor:part:append:anchorend\nLorem Ipsum\nDolor Sit\n// anchor:part2:appendafter:anchorend\nLorem Ipsum\nDolor Sit\n// anchor:part3:appendbefore:anchorend\nDolor Sit\nLorem Ipsum\nNewline\nListing 123. Before\n// anchor:part:newline_append:anchorend\nLorem Ipsum\n// anchor:part:append_newline:anchorend\nLorem Ipsum\n(end of file)\nListing 124. Patch\n// anchor:part:newline_append:anchorend\nDolor Sit\n// anchor:part:append_newline:anchorend\nDolor Sit\n(end of file)\nListing 125. After\n// anchor:part:newline_append:anchorend\nLorem Ipsum\nDolor Sit\n// anchor:part:append_newline:anchorend\nLorem Ipsum\nDolor Sit\n(end of file)\nError List\nIf there are anchors in the text, but either base or patch do not start with one, the merging process wil be aborted, as text might go missing this way.\nUsing _newline or newline_ with mergestrategies that don&#x2019;t support it , like override, will abort the merging process. See Merge Strategies &#x2192;2 for details.\nUsing undefined mergestrategies will abort the merging process.\nWrong anchor definitions, for example anchor:${}:anchorend will abort the merging process, see Anchor Definition for details.\n"},{"id":522,"path":"../website/pages/docs/master-cobigen.asciidoc_cobigen.html#cobigen-jsonplugin.asciidoc","type":"docs","title":"JSON Plug-in","body":"71.2.5. JSON Plug-in\nAt the moment the plug-in can be used for merge generic JSOn files depending on the merge strategy defined at the templates.\nMerger extensions\nThere are currently these merge strategies:\nGeneric JSON Merge\nmerge strategy jsonmerge(add the new code respecting the existent is case of conflict)\nmerge strategy jsonmerge_override (add the new code overwriting the existent in case of conflict)\nJsonArray&#x2019;s will be ignored / replaced in total\nJsonObjects in conflict will be processed recursively ignoring adding non existent elements.\nMerge Process\nGeneric JSON Merging\nThe merge process will be:\nAdd non existent JSON Objects from patch file to base file.\nFor existent object in both files, will add non existent keys from patch to base object. This process will be done recursively for all existent objects.\nFor Json Arrays existent in both files, the arrays will be just concatenated.\n"},{"id":523,"path":"../website/pages/docs/master-cobigen.asciidoc_cobigen.html#cobigen-tsplugin.asciidoc","type":"docs","title":"TypeScript Plug-in","body":"71.2.6. TypeScript Plug-in\nThe TypeScript Plug-in enables merging result TS files to existing ones. This plug-in is used at the moment for generate an Angular2 client with all CRUD functionalities enabled. The plug-in also generates de i18n functionality just appending at the end of the word the ES or EN suffixes, to put into the developer knowledge that this words must been translated to the correspondent language. Currently, the generation of Angular2 client requires an ETO java object as input so, there is no need to implement an input reader for ts artifacts for the moment.\nTrigger Extensions\nAs for the Angular2 generation the input is a java object, the trigger expressions (including matchers and variable assignments) are implemented as Java.\nMerger extensions\nThis plugin uses the OASP TypeScript Merger to merge files. There are currently two merge strategies:\nmerge strategy tsmerge (add the new code respecting the existing is case of conflict)\nmerge strategy tsmerge_override (add the new code overwriting the existent in case of conflict)\nThe merge algorithm mainly handles the following AST nodes:\nImportDeclaration\nWill add non existent imports whatever the merge strategy is.\nFor different imports from same module, the import clauses will be merged.\nimport { a } from &apos;b&apos;;\nimport { c } from &apos;b&apos;;\n//Result\nimport { a, c } from &apos;b&apos;;\nClassDeclaration\nAdds non existent base properties from patch based on the name property.\nAdds non existent base methods from patch based on the name signature.\nAdds non existent annotations to class, properties and methods.\nPropertyDeclaration\nAdds non existent decorators.\nMerge existent decorators.\nWith override strategy, the value of the property will be replaced by the patch value.\nMethodDeclaration\nWith override strategy, the body will be replaced.\nThe parameters will be merged.\nParameterDeclaration\nReplace type and modifiers with override merge strategy, adding non existent from patch into base.\nConstructorDeclaration\nMerged in the same way as Method is.\nFunctionDeclaration\nMerged in the same way as Method is.\nInput reader\nThe TypeScript input reader is based on the one that the TypeScript merger uses. The current extensions are additional module fields giving from which library any entity originates.\nmodule: null specifies a standard entity or type as string or number.\nObject model\nTo get a first impression of the created object after parsing, let us start with analyzing a small example, namely the parsing of a simple type-orm model written in TypeScript.\nimport {Entity, PrimaryGeneratedColumn, Column} from &quot;typeorm&quot;;\n@Entity()\nexport class User {\n@PrimaryGeneratedColumn()\nid: number;\n@Column()\nfirstName: string;\n@Column()\nlastName: string;\n@Column()\nage: number;\n}\nThe returned object has the following structure\n{\n&quot;importDeclarations&quot;: [\n{\n&quot;module&quot;: &quot;typeorm&quot;,\n&quot;named&quot;: [\n&quot;Entity&quot;,\n&quot;PrimaryGeneratedColumn&quot;,\n&quot;Column&quot;\n],\n&quot;spaceBinding&quot;: true\n}\n],\n&quot;classes&quot;: [\n{\n&quot;identifier&quot;: &quot;User&quot;,\n&quot;modifiers&quot;: [\n&quot;export&quot;\n],\n&quot;decorators&quot;: [\n{\n&quot;identifier&quot;: {\n&quot;name&quot;: &quot;Entity&quot;,\n&quot;module&quot;: &quot;typeorm&quot;\n},\n&quot;isCallExpression&quot;: true\n}\n],\n&quot;properties&quot;: [\n{\n&quot;identifier&quot;: &quot;id&quot;,\n&quot;type&quot;: {\n&quot;name&quot;: &quot;number&quot;,\n&quot;module&quot;: null\n},\n&quot;decorators&quot;: [\n{\n&quot;identifier&quot;: {\n&quot;name&quot;: &quot;PrimaryGeneratedColumn&quot;,\n&quot;module&quot;: &quot;typeorm&quot;\n},\n&quot;isCallExpression&quot;: true\n}\n]\n},\n{\n&quot;identifier&quot;: &quot;firstName&quot;,\n&quot;type&quot;: {\n&quot;name&quot;: &quot;string&quot;,\n&quot;module&quot;: null\n},\n&quot;decorators&quot;: [\n{\n&quot;identifier&quot;: {\n&quot;name&quot;: &quot;Column&quot;,\n&quot;module&quot;: &quot;typeorm&quot;\n},\n&quot;isCallExpression&quot;: true\n}\n]\n},\n{\n&quot;identifier&quot;: &quot;lastName&quot;,\n&quot;type&quot;: {\n&quot;name&quot;: &quot;string&quot;,\n&quot;module&quot;: null\n},\n&quot;decorators&quot;: [\n{\n&quot;identifier&quot;: {\n&quot;name&quot;: &quot;Column&quot;,\n&quot;module&quot;: &quot;typeorm&quot;\n},\n&quot;isCallExpression&quot;: true\n}\n]\n},\n{\n&quot;identifier&quot;: &quot;age&quot;,\n&quot;type&quot;: {\n&quot;name&quot;: &quot;number&quot;,\n&quot;module&quot;: null\n},\n&quot;decorators&quot;: [\n{\n&quot;identifier&quot;: {\n&quot;name&quot;: &quot;Column&quot;,\n&quot;module&quot;: &quot;typeorm&quot;\n},\n&quot;isCallExpression&quot;: true\n}\n]\n}\n]\n}\n]\n}\nIf we only consider the first level of the JSON response, we spot two lists of imports and classes, providing information about the only import statement and the only User class, respectively. Moving one level deeper we observe that:\nEvery import statement is translated to an import declaration entry in the declarations list, containing the module name, as well as a list of entities imported from the given module.\nEvery class entry provides besides the class identifier, its decoration(s), modifier(s), as well as a list of properties that the original class contains.\nNote that, for each given type, the module from which it is imported is also given as in\n&quot;identifier&quot;: {\n&quot;name&quot;: &quot;Column&quot;,\n&quot;module&quot;: &quot;typeorm&quot;\n}\nReturning to the general case, independently from the given TypeScript file, an object having the following Structure will be created.\nimportDeclarations: A list of import statement as described above\nexportDeclarations: A list of export declarations\nclasses: A list of classes extracted from the given file, where each entry is full of class specific fields, describing its properties and decorator for example.\ninterfaces: A list of interfaces.\nvariables: A list of variables.\nfunctions: A list of functions.\nenums: A list of enumerations.\n"},{"id":524,"path":"../website/pages/docs/master-cobigen.asciidoc_cobigen.html#cobigen-htmlplugin.asciidoc","type":"docs","title":"HTML Plug-in","body":"71.2.7. HTML Plug-in\nThe HTML Plug-in enables merging result HTML files to existing ones. This plug-in is used at the moment for generate an Angular2 client. Currently, the generation of Angular2 client requires an ETO java object as input so, there is no need to implement an input reader for ts artifacts for the moment.\nTrigger Extensions\nAs for the Angular2 generation the input is a java object, the trigger expressions (including matchers and variable assignments) are implemented as Java.\nMerger extensions\nThere are currently two merge strategies:\nmerge strategy html-ng* (add the new code respecting the existing is case of conflict)\nmerge strategy html-ng*_override (add the new code overwriting the existent in case of conflict)\nThe merging of two Angular2 files will be processed as follows:\nThe merge algorithm handles the following AST nodes:\nmd-nav-list\na\nform\nmd-input-container\ninput\nname (for name attribute)\nngIf\nWarning\nBe aware, that the HTML merger is not generic and only handles the described tags needed for merging code of a basic Angular client implementation. For future versions, it is planned to implement a more generic solution.\n"},{"id":525,"path":"../website/pages/docs/master-cobigen.asciidoc_cobigen.html#cobigen-openapiplugin.asciidoc","type":"docs","title":"OpenApi Plug-in","body":"71.2.8. OpenApi Plug-in\nThe OpenApi Plug-in enables the support for Swagger files that follows the OpenApi 3.0 standard as input for CobiGen. Until now, CobiGen was thought to follow a &quot;code first&quot; generation, with this plugin, now it can also follow the &quot;contract first&quot; strategy\nCode First\nGenerating from a file with code (Java/XML code in our case)\nContract First\nGeneration from a full definition file (Swagger in this case). This file contains all the information about entities, operations, etc&#x2026;&#x200B;\nNote\nIf you are not a CobiGen developer, you will be more interested in usage.\nTrigger Extensions\nThe OpenApi Plug-in provides a new trigger for Swagger OpenApi 3.0 related inputs. It accepts different representations as inputs (see OpenApi input reader) and provides additional matching and variable assignment mechanisms. The configuration in the context.xml for this trigger looks like this:\ntype &apos;openapi&apos;\nListing 126. Example of a openapi trigger definition\n&lt;trigger id=&quot;...&quot; type=&quot;openapi&quot; templateFolder=&quot;...&quot;&gt;\n...\n&lt;/trigger&gt;\nThis trigger type enables OpenApi elements as inputs.\nMatcher type\nWith the trigger you might define matchers, which restrict the input upon specific aspects:\ntype &apos;element&apos; &#x2192; An object\nThis trigger will be enabled if the element (Java Object) of the input file is and EntityDef (value).\nContainerMatcher type\nAdditionally, the java plugin provides the ability to match packages (containers) as follows:\ntype &apos;element&apos;\nThe container matcher matches elements as Java Objects, in this case will be always an OpenApiFile object. (See containerMatcher semantics to get more information about containerMatchers itself.)\nVariableAssignment types\nFurthermore, it provides the ability to extract information from each input for further processing in the templates. The values assigned by variable assignments will be made available in template and the destinationPath of context.xml through the namespace variables.&lt;key&gt;. The OpenApi Plug-in currently provides two different mechanisms:\ntype &apos;constant&apos; &#x2192; constant parameter\n&lt;trigger id=&quot;...&quot; type=&quot;openapi&quot; templateFolder=&quot;...&quot;&gt;\n&lt;containerMatcher type=&quot;element&quot; value=&quot;OpenApiFile&quot;/&gt;\n&lt;matcher type=&quot;element&quot; value=&quot;EntityDef&quot;&gt;\n&lt;variableAssignment type=&quot;constant&quot; key=&quot;rootPackage&quot; value=&quot;com.capgemini.demo&quot; /&gt;\n&lt;/matcher&gt;\n&lt;/trigger&gt;\nThis variable assignment assigns the value of the given regular expression group number to the given key.\nIn this case, the constant type variableAssignment is used to specify the root package where the generate will place the files generated.\ntype &apos;extension&apos; &#x2192; Extraction of the info extensions and the extensions of each entity. (the tags that start with &quot;x-&#x2026;&#x200B;&quot;).\n&lt;trigger id=&quot;...&quot; type=&quot;openapi&quot; templateFolder=&quot;...&quot;&gt;\n&lt;containerMatcher type=&quot;element&quot; value=&quot;OpenAPIFile&quot;/&gt;\n&lt;matcher type=&quot;element&quot; value=&quot;EntityDef&quot;&gt;\n&lt;variableAssignment type=&quot;extension&quot; key=&quot;testingAttribute&quot; value=&quot;x-test&quot;/&gt;\n&lt;variableAssignment type=&quot;extension&quot; key=&quot;rootPackage&quot; value=&quot;x-rootpackage&quot;/&gt;\n&lt;variableAssignment type=&quot;extension&quot; key=&quot;globalVariable&quot; value=&quot;x-global&quot;/&gt;\n&lt;/matcher&gt;\n&lt;/trigger&gt;\nThe &apos;extension&apos; variable assignment tries to find &apos;extensions&apos; (tags that start with &quot;x-&#x2026;&#x200B;&quot;) on the &apos;info&apos;\npart of your file and on the extensions of each entity. value is the extension that our plug-in will try to find on your OpenAPI file. The result will\nbe stored in the variable key.\nAs you will see on the figure below, there are two types of variables: The global ones, that are defined\non the &apos;info&apos; part of the file, and the local ones, that are defined inside each entity.\nTherefore, if you want to define the root package, then you will have to declare it on the &apos;info&apos; part.\nThat way, all your entities will be generated under the same root package (e.g. com.devonfw.project).\nIf no extension with that name was found, then an empty string will be assigned. In the case of not defining the root package, then the code will be generated into src/main/java.\ntype &apos;property&apos; &#x2192; property of the Java Object\n&lt;trigger id=&quot;...&quot; type=&quot;openapi&quot; templateFolder=&quot;...&quot;&gt;\n&lt;containerMatcher type=&quot;element&quot; value=&quot;OpenApiFile&quot;/&gt;\n&lt;matcher type=&quot;element&quot; value=&quot;EntityDef&quot;&gt;\n&lt;variableAssignment type=&quot;property&quot; key=&quot;entityName&quot; value=&quot;name&quot; /&gt;\n&lt;/matcher&gt;\n&lt;/trigger&gt;\nThe &apos;property&apos; variable assignment tries to find the property value of the entities defined on the schema.\nThe value is assigned to the key. The current properties that you will able to get are:\nComponentDef component: It is an object that stores the configuration of an devon4j component. Its only\nproperty is List&lt;PathDef&gt; paths which contains the paths as the ones shown here.\nString componentName: Stores the name of the x-component tag for this entity.\nString name: Name of this entity (as shown on the example above).\nString description: Description of this entity.\nList&lt;PropertyDef&gt; properties: List containing all the properties of this entity. PropertyDef is an object that has the next properties:\nString name.\nString type.\nString format.\nString description.\nBoolean isCollection.\nBoolean isEntity.\nBoolean required.\nMap&lt;String, Object&gt; constraints\nIf no property with that name was found, then it will be set to null.\nFull trigger configuration\n&lt;trigger id=&quot;...&quot; type=&quot;openapi&quot; templateFolder=&quot;...&quot;&gt;\n&lt;containerMatcher type=&quot;element&quot; value=&quot;OpenApiFile&quot;&gt;\n&lt;matcher type=&quot;element&quot; value=&quot;EntityDef&quot;&gt;\n&lt;variableAssignment type=&quot;constant&quot; key=&quot;rootPackage&quot; value=&quot;com.capgemini.demo&quot; /&gt;\n&lt;variableAssignment type=&quot;property&quot; key=&quot;component&quot; value=&quot;componentName&quot; /&gt;\n&lt;variableAssignment type=&quot;property&quot; key=&quot;entityName&quot; value=&quot;name&quot; /&gt;\n&lt;/matcher&gt;\n&lt;/trigger&gt;\nInput reader\nThe Cobigen OpenApi Plug-in implements an input reader for OpenApi 3.0 files. The XML input reader will create the following object model for template creation:\nmodel (&apos;Map&lt;String, Object&gt;&apos; :: common element structure)\nheader (&apos;HeaderDef&apos; :: Definition of the header found at the top of the file)\nname (&apos;String&apos; :: Name of the current Entity)\ncomponentName (&apos;String&apos; :: name of the component the entity belongs to)\ncomponent (&apos;ComponentDef&apos; :: Full definition of the component that entity belongs to)\ndescription (&apos;String&apos; :: Description of the Entity)\nproperties (&apos;List&lt;PropertyDef&gt;&apos; :: List of properties the entity has)\nrelationShips (&apos;List&lt;RelationShip&apos; :: List of Relationships the entity has)\nHeaderDef (&apos;Map&lt;String, Object&gt;&apos; :: common element structure)\ninfo (&apos;InfoDef&apos; :: Definition of the info found in the header)\nservers (&apos;List&lt;ServerDef&gt;&apos; :: List of servers the specification uses)\nInfoDef (&apos;Map&lt;String, Object&gt;&apos; :: common element structure)\ntitle (&apos;String&apos; :: The title of the specification)\ndescription (&apos;String&apos; :: The description of the specification)\nServerDef (&apos;Map&lt;String, Object&gt;&apos; :: common element structure)\nURI (&apos;String&apos; :: String representation of the Server location)\ndescription (&apos;String&apos; :: description of the server)\nComponentDef (&apos;Map&lt;String, Object&gt;&apos; :: common element structure)\npaths (&apos;List&lt;PathDef&gt;&apos; :: List of services for this component)\nPropertyDef (&apos;Map&lt;String, Object&gt;&apos; :: common element structure)\nname (&apos;String&apos; :: Name of the property)\ntype (&apos;String&apos; :: type of the property)\nformat (&apos;String&apos; :: format of the property (i.e. int64))\nisCollection (&apos;boolean&apos; :: true if the property is a collection, false by default)\nisEntity (&apos;boolean&apos; :: true if the property refers to another entity, false by default)\nsameComponent (&apos;boolean&apos; :: true if the entity that the property refers to belongs to the same component, false by default)\ndescription (&apos;String&apos; :: Description of the property)\nrequired (&apos;boolean&apos; :: true if the property is set as required)\nconstraints (&apos;Map&lt;String, Object&gt;&apos;)\nRelationShip (&apos;Map&lt;String, Object&gt;&apos; :: common element structure)\ntype (&apos;String&apos; :: type of the relationship (OneToOne, ManyToMany, etc&#x2026;&#x200B;))\nentity (&apos;String&apos; :: destination entity name)\nsameComponent (&apos;boolean&apos; :: true if the destination entity belongs to the same component of the source entity, false by default)\nunidirectional (&apos;boolean&apos; :: true if the relationship is unidirectional, false by default)\nPathDef (&apos;Map&lt;String, Object&gt;&apos; :: common element structure)\nrootComponent (&apos;String&apos; :: the first segment of the path)\nversion (&apos;String&apos; :: version of the service)\npathURI (&apos;String&apos; :: URI of the path, the segment after the version)\noperations (&apos;List&lt;OperationDef&gt;&apos; :: List of operations for this path)\nOperationDef (&apos;Map&lt;String, Object&gt;&apos; :: common element structure)\ntype (&apos;String&apos; :: type of the operation (GET, PUT, etc&#x2026;&#x200B;))\nparameters (&apos;List&lt;ParameterDef&gt;&apos; :: List of parameters)\noperationId (&apos;String&apos; :: name of the operation prototype)\ndescription (&apos;String&apos; :: JavaDoc Description of the operation)\nsummary (&apos;List&lt;PropertyDef&gt;&apos; :: JavaDoc operation Summary)\ntags (&apos;List&lt;String&gt;&apos; :: List of different tags)\nresponses (&apos;List&lt;ResponseDef&gt;&apos; :: Responses of the operation)\nParameterDef (&apos;Map&lt;String, Object&gt;&apos; :: common element structure)\nisSearchCriteria (&apos;boolean&apos; :: true if the response is an SearchCriteria object)\ninPath (&apos;boolean&apos; :: true if this parameter is contained in the request path)\ninQuery (&apos;boolean&apos; :: true if this parameter is contained in a query)\nisBody (&apos;boolean&apos; :: true if this parameter is a response body)\ninHeader (&apos;boolean&apos; :: true if this parameter is contained in a header)\nmediaType (&apos;String&apos; :: String representation of the media type of the parameter)\nResponseDef (&apos;Map&lt;String, Object&gt;&apos; :: common element structure)\nisArray (&apos;boolean&apos; :: true if the type of the response is an Array)\nisPaginated (&apos;boolean&apos; :: true if the type of the response is paginated)\nisVoid (&apos;boolean&apos; :: true if there is no type/an empty type)\nisEntity (&apos;boolean&apos; :: true if the type of the response is an Entity)\nentityRef (&apos;EntityDef&apos; :: Incomplete EntityDef containing the name and properties of the referenced Entity)\ntype (&apos;String&apos; :: String representation of the attribute&#x2019;s value)\ncode (&apos;String&apos; :: String representation of the HTTP status code)\nmediaTypes (&apos;List&lt;String&gt;&apos; :: List of media types that can be returned)\ndescription (&apos;String&apos; :: Description of the response)\nMerger extensions\nThis plugin only provides an input reader, there is no support for OpenApi merging. Nevertheless, the files generated from an OpenApi file will be Java, XML, JSON, TS, etc&#x2026;&#x200B; so,\nfor each file to be generated defined at templates.xml, must set the mergeStrategy for the specific language (javamerge, javamerge_override, jsonmerge, etc&#x2026;&#x200B;)\n&lt;templates&gt;\n...\n&lt;templateExtension ref=&quot;${variables.entityName}.java&quot; mergeStrategy=&quot;javamerge&quot;/&gt;\n...\n&lt;templateExtension ref=&quot;${variables.entityName}dataGrid.component.ts&quot; mergeStrategy=&quot;tsmerge&quot;/&gt;\n...\n&lt;templateExtension ref=&quot;en.json&quot; mergeStrategy=&quot;jsonmerge&quot;/&gt;\n&lt;/templates&gt;\nUsage\nWriting OpenApi 3.0 contract file\nThe Swagger file must follow the OpenApi 3.0 standard to be readable by CobiGen, otherwise and error will be thrown.\nA full documentation about how to follow this standard can be found Swagger3 Docs.\nThe Swagger file must be at the core folder of your devon4j project, like shown below:\nTo be compatible with CobiGen and devon4j, it must follow some specific configurations. This configurations allows us to avoid redundant definitions as SearchCriteria and PaginatedList objects are used at the services definitions.\nPaths\nJust adding the tags property at the end of the service definitions with the items SearchCriteria and/or paginated put into CobiGen knowledge that an standard devon4j SearchCriteria and/or PaginateListTo object must be generated. That way, the Swagger file will be easier to write and even more understandable.\nThe path must start with the component name, and define an x-component tag with the component name. That way this service will be included into the component services list.\n/componentnamemanagement/v1/entityname/customOperation/:\nx-component: componentnamemanagement\npost:\nsummary: &apos;Summary of the operation&apos;\ndescription: Description of the operation.\noperationId: customOperation\nresponses:\n&apos;200&apos;:\ndescription: Description of the response.\ncontent:\napplication/json:\nschema:\ntype: array\nitems:\n$ref: &apos;#/components/schemas/EntityName&apos;\nrequestBody:\n$ref: &apos;#/components/requestBodies/EntityName&apos;\ntags:\n- searchCriteria\n- paginated\nThat way, CobiGen will be able to generate the endpoint (REST service) customOperation on componentmanagement. If you do not specify the component to generate to (the x-component tag) then this service will not be taken into account for generation.\nService based generation\nIn previous CobiGen versions, we were able to generate code from a contract-first OpenApi specification only when we defined components like the following:\ncomponents:\nschemas:\nShop:\nx-component: shopmanagement\ndescription: Entity definition of Shop\ntype: object\nproperties:\nshopExample:\ntype: string\nmaxLength: 100\nminLength: 5\nuniqueItems: true\nWe could not generate services without the definition of those components.\nIn our current version, we have overcome it, so that now we are able to generate all the services independently. You just need to add an x-component tag with the name of the component that will make use of that service. See here.\nAn small OpenAPI example defining only services can be found below:\nopenapi: 3.0.0\nservers:\n- url: &apos;https://localhost:8081/server/services/rest&apos;\ndescription: Just some data\ninfo:\ntitle: Devon Example\ndescription: Example of a API definition\nversion: 1.0.0\nx-rootpackage: com.capgemini.spoc.openapi\npaths:\n/salemanagement/v1/sale/{saleId}:\nx-component: salemanagement\nget:\noperationId: findSale\nparameters:\n- name: saleId\nin: path\nrequired: true\ndescription: The id of the pet to retrieve\nschema:\ntype: string\nresponses:\n&apos;200&apos;:\ndescription: Any\n/salemanagement/v1/sale/{bla}:\nx-component: salemanagement\nget:\noperationId: findSaleBla\nparameters:\n- name: bla\nin: path\nrequired: true\nschema:\ntype: integer\nformat: int64\nminimum: 10\nmaximum: 200\nresponses:\n&apos;200&apos;:\ndescription: Any\nThen, the increment that you need to select for generating those services is Crud devon4ng Service based Angular:\nFull example\nThis example yaml file can be download from here.\nWarning\nAs you will see on the file, &quot;x-component&quot; tags are obligatory if you want to generate components (entities). They have to be defined for each one.\nIn addition, you will find the global variable &quot;x-rootpackage&quot; that are explained here.\nopenapi: 3.0.0\nservers:\n- url: &apos;https://localhost:8081/server/services/rest&apos;\ndescription: Just some data\ninfo:\ntitle: Devon Example\ndescription: Example of a API definition\nversion: 1.0.0\nx-rootpackage: com.devonfw.angular.test\npaths:\n/shopmanagement/v1/shop/{shopId}:\nx-component: shopmanagement\nget:\noperationId: findShop\nparameters:\n- name: shopId\nin: path\nrequired: true\nschema:\ntype: integer\nformat: int64\nminimum: 0\nmaximum: 50\nresponses:\n&apos;200&apos;:\ndescription: Any\ncontent:\napplication/json:\nschema:\n$ref: &apos;#/components/schemas/Shop&apos;\ntext/plain:\nschema:\ntype: string\n&apos;404&apos;:\ndescription: Not found\n/salemanagement/v1/sale/{saleId}:\nx-component: salemanagement\nget:\noperationId: findSale\nparameters:\n- name: saleId\nin: path\nrequired: true\ndescription: The id of the pet to retrieve\nschema:\ntype: string\nresponses:\n&apos;200&apos;:\ndescription: Any\n/salemanagement/v1/sale/:\nx-component: salemanagement\npost:\nresponses:\n&apos;200&apos;:\ndescription: Any\nrequestBody:\n$ref: &apos;#/components/requestBodies/SaleData&apos;\ntags:\n- searchCriteria\n/shopmanagement/v1/shop/new:\nx-component: shopmanagement\npost:\nresponses:\n&apos;200&apos;:\ndescription: Any\nrequestBody:\n$ref: &apos;#/components/requestBodies/ShopData&apos;\ncomponents:\nschemas:\nShop:\nx-component: shopmanagement\ndescription: Entity definition of Shop\ntype: object\nproperties:\nshopExample:\ntype: string\nmaxLength: 100\nminLength: 5\nuniqueItems: true\nsales:\ntype: array # Many to One relationship\nitems:\n$ref: &apos;#/components/schemas/Sale&apos;\nSale:\nx-component: salemanagement\ndescription: Entity definition of Shop\ntype: object\nproperties:\nsaleExample:\ntype: number\nformat: int64\nmaximum: 100\nminimum: 0\nrequired:\n- saleExample\nrequestBodies:\nShopData:\ncontent:\napplication/json:\nschema:\n$ref: &apos;#/components/schemas/Shop&apos;\nrequired: true\nSaleData:\ncontent:\napplication/json:\nschema:\n$ref: &apos;#/components/schemas/Sale&apos;\nrequired: true\n&#x2190;&#xA0;Previous:&#xA0;Document Description&#xA0;| &#x2191;&#xA0;Up:&#xA0;CobiGen&#x2009;&#x2014;&#x2009;Code-based incremental Generator&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;CobiGen CLI&#xA0;&#x2192;\n"},{"id":526,"path":"../website/pages/docs/master-cobigen.asciidoc_document-description.html#master-cobigen.asciidoc_document-description","type":"docs","title":"Document Description","body":"70. Document Description\nThis document contains the documentation of the CobiGen core module as well as all CobiGen plug-ins and the CobiGen eclipse integration.\nImportant\nDISCLAIMER: All Cobigen plugins are compatible with the latest release of Devonfw unless otherwise denoted.\nCurrent versions:\nCobiGen - Eclipse Plug-in v7.1.0\nCobiGen - Maven Build Plug-in v7.1.0\nCobiGen CLI v1.2.0\nCobiGen v7.1.0\nCobiGen - Java Plug-in v7.1.0\nCobiGen - XML Plug-in v7.0.0\nCobiGen - TypeScript Plug-in v7.1.0\nCobiGen - Property Plug-in v7.1.0\nCobiGen - Text Merger v7.1.1\nCobiGen - JSON Plug-in v7.0.0\nCobiGen - HTML Plug-in v7.0.0\nCobiGen - Open API Plug-in v7.1.0\nCobiGen - FreeMaker Template Engine v7.0.0\nCobiGen - Velocity Template Engine v7.0.0\nAuthors:\nMalte Brunnlieb\nJaime Diaz Gonzalez\nSteffen Holzer\nRuben Diaz Martinez\nJoerg Hohwiller\nFabian Kreis\nLukas Goerlach\nKrati Shah\nChristian Richter\nErik Gr&#xFC;ner\nMike Schumacher\nMarco Rose\nMohamed Ghanmi\n"},{"id":527,"path":"../website/pages/docs/master-cobigen.asciidoc_document-description.html#Guide-to-the-Reader.asciidoc","type":"docs","title":"Guide to the Reader","body":"70.1. Guide to the Reader\nDependent on the intention you are reading this document, you might be most interested in the following chapters:\nIf this is your first contact with CobiGen, you will be interested in the general purpose of CobiGen, in the licensing of CobiGen, as well as in the Shared Service provided for CobiGen. Additionally, there are some general use cases, which are currently implemented and maintained to be used out of the box.\nAs a user of the CobiGen Eclipse integration, you should focus on the Installation and Usage chapters to get a good introduction how to use CobiGen in eclipse.\nAs a user of the Maven integration, you should focus on the Maven configuration chapter, which guides you through the integration if CobiGen into your build configuration.\nIf you like to adapt the configuration of CobiGen, you have to step deeper into the configuration guide as well as into the plug-in configuration extensions for the Java Plug-in, XML-Plugin, Java Property Plug-in, as well as for the Text-Merger Plug-in.\nFinally, if want to develop your own templates, you will be thankful for helpful links in addition to the plug-ins documentation as referenced in the previous point.\n"},{"id":528,"path":"../website/pages/docs/master-cobigen.asciidoc_document-description.html#h894b02d36170f9e1c7734d06b412c465.asciidoc","type":"docs","title":"CobiGen - Code-based incremental Generator","body":"70.2. CobiGen - Code-based incremental Generator\n"},{"id":529,"path":"../website/pages/docs/master-cobigen.asciidoc_document-description.html#h894b02d36170f9e1c7734d06b412c465.asciidoc_overview","type":"docs","title":"Overview","body":"70.2.1. Overview\nCobiGen is a generic incremental generator for end to end code generation tasks, mostly used in Java projects.\nDue to a template-based approach, CobiGen generates any set of text-based documents and document fragments.\nInput (currently):\nJava classes\nXML-based files\nOpenAPI documents\nPossibly more inputs like WSDL, which is currently not implemented.\nOutput:\nany text-based document or document fragments specified by templates\n"},{"id":530,"path":"../website/pages/docs/master-cobigen.asciidoc_document-description.html#h894b02d36170f9e1c7734d06b412c465.asciidoc_architecture","type":"docs","title":"Architecture","body":"70.2.2. Architecture\nCobiGen is build as an extensible framework for incremental code generation. It provides extension points for new input readers which allow reading new input types and converting them to an internally processed model. The model is used to process templates of different kinds to generate patches. The template processing will be done by different template engines. There is an extension point for template engines to support multiple ones as well. Finally, the patch will be structurally merged into potentially already existing code. To allow structural merge on different programming languages, the extension point for structural mergers has been introduced. Here you will see an overview of the currently available extension points and plug-ins:\n"},{"id":531,"path":"../website/pages/docs/master-cobigen.asciidoc_document-description.html#h894b02d36170f9e1c7734d06b412c465.asciidoc_features-and-characteristics","type":"docs","title":"Features and Characteristics","body":"70.2.3. Features and Characteristics\nGenerate fresh files across all the layers of a application - ready to run.\nAdd on to existing files merging code into it. E.g. generate new methods into existing java classes or adding nodes to an XML file. Merging of contents into existing files will be done using structural merge mechanisms.\nStructural merge mechanisms are currently implemented for Java, XML, Java Property Syntax, JSON, Basic HTML, Text Append, TypeScript.\nConflicts can be resolved individually but automatically by former configuration for each template.\nCobiGen provides an Eclipse integration as well as a Maven Integration.\nCobiGen comes with an extensive documentation for users and developers.\nTemplates can be fully tailored to project needs - this is considered as a simple task.\n"},{"id":532,"path":"../website/pages/docs/master-cobigen.asciidoc_document-description.html#h894b02d36170f9e1c7734d06b412c465.asciidoc_selection-of-current-and-past-cobigen-applications","type":"docs","title":"Selection of current and past CobiGen applications","body":"70.2.4. Selection of current and past CobiGen applications\nGeneral applications:\nGeneration of a Java CRUD application based on devonfw architecture including all software-layers on the server plus code for js-clients (Angular). You can find details here.\nGeneration of a Java CRUD application according to the Register Factory architecture. Persistence entities are the input for generation.\nGeneration of builder classes for generating test data for JUnit-Tests. Input are the persistence entities.\nGeneration of a EXT JS 6 client with full CRUD operations connected a devon4j server.\nGeneration of a Angular 6 client with full CRUD operations connected a devon4j server.\nProject-specific applications in the past:\nGeneration of an additional Java type hierarchy on top of existing Java classes in combination with additional methods to be integrated in the modified classes. Hibernate entities were considered as input as well as output of the generation. The rational in this case, was to generate an additional business object hierarchy on top of an existing data model for efficient business processing.\nGeneration of hash- and equals-methods as well as copy constructors depending on the field types of the input Java class. Furthermore, CobiGen is able to re-generate these methods/constructors triggered by the user, i.e, when fields have been changed.\nExtraction of JavaDoc of test classes and their methods for generating a csv test documentation. This test documentation has been further processed manually in Excel to provide a good overview about the currently available tests in the software system, which enables further human analysis.\n"},{"id":533,"path":"../website/pages/docs/master-cobigen.asciidoc_document-description.html#cobigen-usecases.asciidoc","type":"docs","title":"General use cases","body":"70.3. General use cases\nIn addition to the selection of CobiGen applications introduced before, this chapter provides a more detailed overview about the currently implemented and maintained general use cases. These can be used by any project following a supported reference architecture as e.g. the devonfw or Register Factory.\n"},{"id":534,"path":"../website/pages/docs/master-cobigen.asciidoc_document-description.html#cobigen-usecases.asciidoc_devon4j","type":"docs","title":"devon4j","body":"70.3.1. devon4j\nWith our templates for devon4j, you can generate a whole CRUD application from a single Entity class. You save the effort for creating, DAOs, Transfer Objects, simple CRUD use cases with REST services and even the client application can be generated.\nCRUD server application for devon4j\nFor the server, the required files for all architectural layers (Data access, logic, and service layer) can be created based on your Entity class. After the generation, you have CRUD functionality for the entity from bottom to top which can be accessed via a RESTful web service. Details are provided in the Devon wiki.\nCRUD client application for devon4ng\nBased on the REST services on the server, you can also generate an Angular client based on devon4ng. With the help of Node.js, you have a working client application for displaying your entities within minutes!\nTestdata Builder for devon4j\nGenerating a builder pattern for POJOs to easily create test data in your tests. CobiGen is not only able to generate a plain builder pattern but rather builder, which follow a specific concept to minimize test data generation efforts in your unit tests. The following Person class as an example:\nListing 94. Person class\npublic class Person {\nprivate String firstname;\nprivate String lastname;\nprivate int birthyear;\n@NotNull\nprivate Address address;\n@NotNull\npublic String getFirstname() {\nreturn this.firstname;\n}\n// additional default setter and getter\n}\nIt is a simple POJO with a validation annotation, to indicate, that firstname should never be null. Creating this object in a test would imply to call every setter, which is kind of nasty. Therefore, the Builder Pattern has been introduced for quite a long time in software engineering, allowing to easily create POJOs with a fluent API. See below.\nListing 95. Builder pattern example\nPerson person = new PersonBuilder()\n.firstname(&quot;Heinz&quot;)\n.lastname(&quot;Erhardt&quot;)\n.birthyear(1909)\n.address(\nnew AddressBuilder().postcode(&quot;22222&quot;)\n.city(&quot;Hamburg&quot;).street(&quot;Luebecker Str. 123&quot;)\n.createNew())\n.addChild(\nnew PersonBuilder()[...].createNew()).createNew();\nThe Builder API generated by CobiGen allows you to set any setter accessible field of a POJO in a fluent way. But in addition lets assume a test, which should check the birth year as precondition for any business operation. So specifying all other fields of Person, especially firstname as it is mandatory to enter business code, would not make sense. The test behavior should just depend on the specification of the birth year and on no other data. So we would like to just provide this data to the test.\nThe Builder classes generated by CobiGen try to tackle this inconvenience by providing the ability to declare default values for any mandatory field due to validation or database constraints.\nListing 96. Builder Outline\npublic class PersonBuilder {\nprivate void fillMandatoryFields() {\nfirstname(&quot;lasdjfa&#xF6;skdlfja&quot;);\naddress(new AddressBuilder().createNew());\n};\nprivate void fillMandatoryFields_custom() {...};\npublic PersonBuilder firstname(String value);\npublic PersonBuilder lastname(String value);\n...\npublic Person createNew();\npublic Person persist(EntityManager em);\npublic List&lt;Person&gt; persistAndDuplicate(EntityManager em, int count);\n}\nLooking at the plotted builder API generated by CobiGen, you will find two private methods. The method fillMandatoryFields will be generated by CobiGen and regenerated every time CobiGen generation will be triggered for the Person class. This method will set every automatically detected field with not null constraints to a default value. However, by implementing fillMandatoryFields_custom on your own, you can reset these values or even specify more default values for any other field of the object. Thus, running new PersonBuilder().birthyear(1909).createNew(); will create a valid object of Person, which is already pre-filled such that it does not influence the test execution besides the fact that it circumvents database and validation issues.\nThis even holds for complex data structures as indicated by address(new AddressBuilder().createNew());. Due to the use of the AddressBuilder for setting the default value for the field address, also the default values for Address will be set automatically.\nFinally, the builder API provides different methods to create new objects.\ncreateNew() just creates a new object from the builder specification and returns it.\npersist(EntityManager) will create a new object from the builder specification and persists it to the database.\npersistAndDuplicate(EntityManager, int) will create the given amount of objects form the builder specification and persists all of these. After the initial generation of each builder, you might want to adapt the method body as you will most probably not be able to persist more than one object with the same field assignments to the database due to unique constraints. Thus, please see the generated comment in the method to adapt unqiue fields accordingly before persisting to the database.\nCustom Builder for Business Needs\nCobiGen just generates basic builder for any POJO. However, for project needs you probably would like to have even more complex builders, which enable the easy generation of more complex test data which are encoded in a large object hierarchy. Therefore, the generated builders can just be seen as a tool to achieve this. You can define your own business driven builders in the same way as the generated builders, but explicitly focusing on your business needs. Just take this example as a demonstration of that idea:\nUniversity uni = new ComplexUniversityBuilder()\n.withStudents(200)\n.withProfessors(4)\n.withExternalStudent()\n.createNew();\nE.g. the method withExternalStudent() might create a person, which is a student and is flagged to be an external student. Basing this implementation on the generated builders will even assure that you would benefit from any default values you have set before. In addition, you can even imagine any more complex builder methods setting values driven your reusable testing needs based on the specific business knowledge.\n"},{"id":535,"path":"../website/pages/docs/master-cobigen.asciidoc_document-description.html#cobigen-usecases.asciidoc_register-factory","type":"docs","title":"Register Factory","body":"70.3.2. Register Factory\nCRUD server application\nGenerates a CRUD application with persistence entities as inputs. This includes DAOs, TOs, use cases, as well as a CRUD JSF user interface if needed.\nTestdata Builder\nAnalogous to Testdata Builder for devon4J\nTest documentation\nGenerate test documentation from test classes. The input are the doclet tags of several test classes, which e.g. can specify a description, a cross-reference, or a test target description. The result currently is a csv file, which lists all tests with the corresponding meta-information. Afterwards, this file might be styled and passed to the customer if needed and it will be up-to-date every time!\n&#x2191;&#xA0;Up:&#xA0;CobiGen&#x2009;&#x2014;&#x2009;Code-based incremental Generator&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;CobiGen&#xA0;&#x2192;\n"},{"id":536,"path":"../website/pages/docs/master-cobigen.asciidoc_eclipse-integration.html#master-cobigen.asciidoc_eclipse-integration","type":"docs","title":"Eclipse Integration","body":"74. Eclipse Integration\n"},{"id":537,"path":"../website/pages/docs/master-cobigen.asciidoc_eclipse-integration.html#cobigen-eclipse_installation.asciidoc","type":"docs","title":"Installation","body":"74.1. Installation\nRemark: CobiGen is preinstalled in the devonfw/devon-ide.\n"},{"id":538,"path":"../website/pages/docs/master-cobigen.asciidoc_eclipse-integration.html#cobigen-eclipse_installation.asciidoc_preconditions","type":"docs","title":"Preconditions","body":"74.1.1. Preconditions\nEclipse 4.x\nJava 7 Runtime (for starting eclipse with CobiGen). This is independent from the target version of your developed code.\n"},{"id":539,"path":"../website/pages/docs/master-cobigen.asciidoc_eclipse-integration.html#cobigen-eclipse_installation.asciidoc_installation-steps","type":"docs","title":"Installation steps","body":"74.1.2. Installation steps\nOpen the eclipse installation dialog\nmenu bar &#x2192; Help &#x2192; Install new Software&#x2026;&#x200B;\nOpen CobiGen&#x2019;s update site\nInsert the update site of your interest into the filed Work with and press Add &#x2026;&#x200B;\nStable releases: https://devonfw.com/cobigen/updatesite/stable/\nFollow the installation wizard\nSelect CobiGen Eclipse Plug-in &#x2192; Next &#x2192; Next &#x2192; accept the license &#x2192; Finish &#x2192; OK &#x2192; Yes\nOnce installed, a new menu entry named &quot;CobiGen&quot; will show up in the Package Explorer&#x2019;s context menu. In the sub menu there will the Generate&#x2026;&#x200B; command, which may ask you to update the templates, and then you can start the generation wizard of CobiGen. You can adapt the templates by clicking on Adapt Templates which will give you the possibility to import the CobiGen_Templates automatically so that you can modified them.\nCheckout (clone) your project&#x2019;s templates folder or use the current templates released with CobiGen (https://github.com/devonfw/cobigen/tree/master/cobigen-templates) and then choose Import -&gt; General -&gt; Existing Projects into Workspace to import the templates into your workspace.\nNow you can start generating. To get an introduction of CobiGen try the devon4j templates and work on the devon4j sample application. There you might want to start with Entity objects as a selection to run CobiGen with, which will give you a good overview of what CobiGen can be used for right out of the box in devon4j based development. If you need some more introduction in how to come up with your templates and increments, please be referred to the documentation of the context configuration and the templates configuration\nDependent on your context configuration menu entry Generate&#x2026;&#x200B; may be greyed out or not. See for more information about valid selections for generation.\n"},{"id":540,"path":"../website/pages/docs/master-cobigen.asciidoc_eclipse-integration.html#cobigen-eclipse_installation.asciidoc_updating","type":"docs","title":"Updating","body":"74.1.3. Updating\nIn general updating CobiGen for eclipse is done via the update mechanism of eclipse directly, as shown on image below:\nUpgrading eclipse CobiGen plug-in to v3.0.0 needs some more attention of the user due to a changed plug-in architecture of CobiGen&#x2019;s core module and the eclipse integration. Eventually, we were able to provide any plug-in of CobiGen separately as its own eclipse bundle (fragment), which is automatically discovered by the main CobiGen Eclipse plug-in after installation.\n"},{"id":541,"path":"../website/pages/docs/master-cobigen.asciidoc_eclipse-integration.html#cobigen-eclipse_usage.asciidoc","type":"docs","title":"Usage","body":"74.2. Usage\nCobiGen has two different generation modes depending on the input selected for generation. The first one is the simple mode, which will be started if the input contains only one input artifact, e.g. for Java an input artifact currently is a Java file. The second one is the batch mode, which will be started if the input contains multiple input artifacts, e.g. for Java this means a list of files. In general this means also that the batch mode might be started when selecting complex models as inputs, which contain multiple input artifacts. The latter scenario has only been covered in the research group,yet.\n"},{"id":542,"path":"../website/pages/docs/master-cobigen.asciidoc_eclipse-integration.html#cobigen-eclipse_usage.asciidoc_simple-mode","type":"docs","title":"Simple Mode","body":"74.2.1. Simple Mode\nSelecting the menu entry Generate&#x2026;&#x200B; the generation wizard will be opened:\nThe left side of the wizard shows all available increments, which can be selected to be generated. Increments are a container like concept encompassing multiple files to be generated, which should result in a semantically closed generation output.\nOn the right side of the wizard all files are shown, which might be effected by the generation - dependent on the increment selection of files on the left side. The type of modification of each file will be encoded into following color scheme if the files are selected for generation:\ngreen: files, which are currently non-existent in the file system. These files will be created during generation\nyellow: files, which are currently existent in the file system and which are configured to be merged with generated contents.\nred: files, which are currently existent in the file system. These files will be overwritten if manually selected.\nno color: files, which are currently existent in the file system. Additionally files, which were unselected and thus will be ignored during generation.\nSelecting an increment on the left side will initialize the selection of all shown files to be generated on the right side, whereas green and yellow categorized files will be selected initially. A manual modification of the pre-selection can be performed by switching to the customization tree using the Customize button on the right lower corner.\nOptional: If you want to customize the generation object model of a Java input class, you might continue with the Next &gt; button instead of finishing the generation wizard. The next generation wizard page is currently available for Java file inputs and lists all non-static fields of the input. Unselecting entries will lead to an adapted object model for generation, such that unselected fields will be removed in the object model for generation. By default all fields will be included in the object model.\nUsing the Finish button, the generation will be performed. Finally, CobiGen runs the eclipse internal organize imports and format source code for all generated sources and modified sources. Thus it is possible, that---especially organize imports opens a dialog if some types could not be determined automatically. This dialog can be easily closed by pressing on Continue. If the generation is finished, the Success! dialog will pop up.\n"},{"id":543,"path":"../website/pages/docs/master-cobigen.asciidoc_eclipse-integration.html#cobigen-eclipse_usage.asciidoc_batch-mode","type":"docs","title":"Batch mode","body":"74.2.2. Batch mode\nIf there are multiple input elements selected, e.g., Java files, CobiGen will be started in batch mode. For the generation wizard dialog this means, that the generation preview will be constrained to the first selected input element. It does not preview the generation for each element of the selection or of a complex input. The selection of the files to be generated will be generated for each input element analogously afterwards.\nThus the color encoding differs also a little bit:\nyellow: files, which are configured to be merged.\nred: files, which are not configured with any merge strategy and thus will be created if the file does not exist or overwritten if the file already exists\nno color: files, which will be ignored during generation\nInitially all possible files to be generated will be selected.\n"},{"id":544,"path":"../website/pages/docs/master-cobigen.asciidoc_eclipse-integration.html#cobigen-eclipse_usage.asciidoc_health-check","type":"docs","title":"Health Check","body":"74.2.3. Health Check\nTo check whether CobiGen runs appropriately for the selected element(s) the user can perform a Health Check by activating the respective menu entry as shown below.\nThe simple Health Check includes 3 checks. As long as any of these steps fails, the Generate menu entry is grayed out.\nThe first step is to check whether the generation configuration is available at all. If this check fails you will see the following message:\nThis indicates, that there is no Project named CobiGen_Templates available in the current workspace. To run CobiGen appropriately, it is necessary to have a configuration project named CobiGen_Templates imported into your workspace. For more information see chapter Eclipse Installation.\nThe second step is to check whether the template project includes a valid context.xml. If this check fails, you will see the following message:\nThis means that either your context.xml\ndoes not exist (or has another name)\nor it is not valid one in any released version of CobiGen\nor there is simply no automatic routine of upgrading your context configuration to a valid state.\nIf all this is not the case, such as, there is a context.xml, which can be successfully read by CobiGen, you might get the following information:\nThis means that your context.xml is available with the correct name but it is outdated (belongs to an older CobiGen version). In this case just click on Upgrade Context Configuration to get the latest version.\nRemark: This will create a backup of your current context configuration and converts your old configuration to the new format. The upgrade will remove all comments from the file, which could be retrieved later on again from the backup.\nIf the creation of the backup fails, you will be asked to continue or to abort.\nThe third step checks whether there are templates for the selected element(s). If this check fails, you will see the following message:\nThis indicates, that there no trigger has been activated, which matches the current selection. The reason might be that your selection is faulty or that you imported the wrong template project (e.g. you are working on a devon4j project, but imported the Templates for the Register Factory). If you are a template developer, have a look at the trigger configuration and at the corresponding available plug-in implementations of triggers, like e.g., Java Plug-in or XML Plug-in.\nIf all the checks are passed you see the following message:\nIn this case everything is OK and the Generate button is not grayed out anymore so that you are able to trigger it and see the simple-mode.\nIn addition to the basic check of the context configuration, you also have the opportunity to perform an Advanced Health Check, which will check all available templates configurations (templates.xml) of path-depth=1 from the configuration project root according to their compatibility.\nAnalogous to the upgrade of the context configuration, the Advanced Health Check will also provide upgrade functionality for templates configurations if available.\n"},{"id":545,"path":"../website/pages/docs/master-cobigen.asciidoc_eclipse-integration.html#cobigen-eclipse_usage.asciidoc_update-templates","type":"docs","title":"Update Templates","body":"74.2.4. Update Templates\nUpdate Template: Select Entity file and right click then select cobigen Update Templates after that click on download then download successfully message will be come .\n"},{"id":546,"path":"../website/pages/docs/master-cobigen.asciidoc_eclipse-integration.html#cobigen-eclipse_usage.asciidoc_adapt-templates","type":"docs","title":"Adapt Templates","body":"74.2.5. Adapt Templates\nAdapt Template: Select any file and right click, then select cobigen &#x2192; Adapt Templates .If cobigen templates jar is not available then it downloads them automatically. If Cobigen templates is already present then it will override existing template in workspace and click on OK then imported template successfully message will be come.\nFinally, please change the Java version of the project to 1.8 so that you don&#x2019;t have any compilation errors.\n"},{"id":547,"path":"../website/pages/docs/master-cobigen.asciidoc_eclipse-integration.html#cobigen-eclipse_logging.asciidoc","type":"docs","title":"Logging","body":"74.3. Logging\nIf you have any problem with the CobiGen eclipse plug-in, you might want to enable logging to provide more information for further problem analysis. This can be done easily by adding the logback.xml to the root of the CobiGen_templates configuration folder. The file should contain at least the following contents, whereas you should specify an absolute path to the target log file (at the TODO). If you are using the (cobigen-templates project, you might have the contents already specified but partially commented.\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;\n&lt;!-- This file is for logback classic. The file contains the configuration for sl4j logging --&gt;\n&lt;configuration&gt;\n&lt;appender name=&quot;FILE&quot; class=&quot;ch.qos.logback.core.FileAppender&quot;&gt;\n&lt;file&gt;&lt;!-- TODO choose your log file location --&gt;&lt;/file&gt;\n&lt;encoder class=&quot;ch.qos.logback.classic.encoder.PatternLayoutEncoder&quot;&gt;\n&lt;Pattern&gt;%n%date %d{HH:mm:ss.SSS} [%thread] %-5level %logger - %msg%n\n&lt;/Pattern&gt;\n&lt;/encoder&gt;\n&lt;/appender&gt;\n&lt;root level=&quot;DEBUG&quot;&gt;\n&lt;appender-ref ref=&quot;FILE&quot; /&gt;\n&lt;/root&gt;\n&lt;/configuration&gt;\n&#x2190;&#xA0;Previous:&#xA0;Maven Build Integration&#xA0;| &#x2191;&#xA0;Up:&#xA0;CobiGen&#x2009;&#x2014;&#x2009;Code-based incremental Generator&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;How to&#xA0;&#x2192;\n"},{"id":548,"path":"../website/pages/docs/master-cobigen.asciidoc_how-to.html#master-cobigen.asciidoc_how-to","type":"docs","title":"How to","body":"75. How to\n"},{"id":549,"path":"../website/pages/docs/master-cobigen.asciidoc_how-to.html#howto_EA-client-generation.asciidoc","type":"docs","title":"Enterprise Architect client generation","body":"75.1. Enterprise Architect client generation\nWe are going to show you how to generate source code from an Enterprise Architect diagram\nusing CobiGen.\n"},{"id":550,"path":"../website/pages/docs/master-cobigen.asciidoc_how-to.html#howto_ea-client-generation.asciidoc_prerequisites","type":"docs","title":"Prerequisites","body":"75.1.1. Prerequisites\nIf CobiGen_Templates is not already imported into your workspace, follow the next steps:\nClick on the Eclipse&#x2019;s menu File &gt; Import &gt; Existing Projects into Workspace and browse to select the workspaces/main/CobiGen_Templates directory.\nClick Finish and you should have the CobiGen_Templates as a new project in Eclipse&#x2019;s workspace.\nAlso verify that you have the latest templates of CobiGen. Your templates folder must contain the crud_java_ea_uml folder.\nIf you do not see it, please follow the next steps:\nDownload the accumulative patch.\nOpen the zip file and extract its content inside the root folder of your Devonfw distribution Devon-dist_2.4.0/\nAfter following those steps correctly, you should have the latest version of the templates ready to use.\n"},{"id":551,"path":"../website/pages/docs/master-cobigen.asciidoc_how-to.html#howto_ea-client-generation.asciidoc_generation","type":"docs","title":"Generation","body":"75.1.2. Generation\nIn this tutorial, we are going to generate the entity infrastructure using as input a class diagram, modelled with Enterprise Architect (EA). First, create a class diagram, an example is shown on figure below:\nWhen you are finished, you will have to export that UML diagram into an XMI version 2.1 file. This is the file format that CobiGen understands. See below a figure showing this process:\nTo open that window, see this tutorial.\nAfter having that exported file, change its extension from xmi to xml. Then create an devon4j project and import the exported file into the core of your devon4j project.\nNow we are going to start the generation, right-click your exported file and select CobiGen &gt; Generate, finally select the entity infrastructure increment:\nAfter following all these steps, your generated files should be inside src\\main\\java folder. If you want an XMI example, you will find it here.\n"},{"id":552,"path":"../website/pages/docs/master-cobigen.asciidoc_how-to.html#howto_angular-client-generation.asciidoc","type":"docs","title":"Angular 8 Client Generation","body":"75.2. Angular 8 Client Generation\nThe generation can create a full Angular 8 client using the devon4ng-application-template package located at workspaces/examples folder of the distribution. For more details about this package, please refer here.\nYou can also try out the katacoda tutorial for angular client generation.\nCobiGen Angular Katacoda Scenario\nTake into account that the TypeScript merging for CobiGen needs Node 6 or higher to be installed at your machine.\nNote\nThis is a short introduction to the Angular generation. For a deeper tutorial including the generation of the backend, we strongly recommend you to follow this document.\n"},{"id":553,"path":"../website/pages/docs/master-cobigen.asciidoc_how-to.html#howto_angular-client-generation.asciidoc_requisites","type":"docs","title":"Requisites","body":"75.2.1. Requisites\nInstall yarn globally:\nnpm install -g yarn\n"},{"id":554,"path":"../website/pages/docs/master-cobigen.asciidoc_how-to.html#howto_angular-client-generation.asciidoc_angular-8-workspace","type":"docs","title":"Angular 8 workspace","body":"75.2.2. Angular 8 workspace\nThe output location of the generation can be defined editing the cobigen.properties file located at crud_angular_client_app/templates folder of the CobiGen_Templates project.\nBy default, the output path would be into the devon4ng-application-template folder at the root of the devon4j project parent folder:\nroot/\n|- devon4ng-application-template/\n|- devon4j-project-parent/\n|- core/\n|- server/\nHowever, this path can be changed, for example to src/main/client folder of the devon4j project:\nrelocate: ./src/main/client/${cwd}\nroot/\n|- devon4j-project-parent/\n|- core/\n|- src\n|- main\n|- client\n|- server/\nOnce the output path is chosen, copy the files of DEVON4NG-APPLICATION-TEMPLATE repository into this output path.\n"},{"id":555,"path":"../website/pages/docs/master-cobigen.asciidoc_how-to.html#howto_angular-client-generation.asciidoc_install-node-dependencies","type":"docs","title":"Install Node dependencies","body":"75.2.3. Install Node dependencies\nOpen a terminal into devon4ng-application-template copied and just run the command:\nyarn\nThis will start the installation of all node packages needed by the project into the node_modules folder.\n"},{"id":556,"path":"../website/pages/docs/master-cobigen.asciidoc_how-to.html#howto_angular-client-generation.asciidoc_generating","type":"docs","title":"Generating","body":"75.2.4. Generating\nFrom an Eto object, right click, CobiGen &#x2192; Generate will show the CobiGen wizard relative to client generation:\nCheck all the increments relative to Angular:\nNote\nThe Angular devon4j URL increment is only needed for the first generations however, checking it again on next generation will not cause any problem.\nAs we done on other generations, we click Next to choose which fields to include at the generation or simply clicking Finish will start the generation.\n"},{"id":557,"path":"../website/pages/docs/master-cobigen.asciidoc_how-to.html#howto_angular-client-generation.asciidoc_routing","type":"docs","title":"Routing","body":"75.2.5. Routing\nDue to the nature of the TypeScript merger, currently is not possible to merge properly the array of paths objects of the routings at app.routing.ts file so, this modification should be done by hand on this file. However, the import related to the new component generated is added.\nThis would be the generated app-routing.module file:\nimport { Routes, RouterModule } from &apos;@angular/router&apos;;\nimport { LoginComponent } from &apos;./login/login.component&apos;;\nimport { AuthGuard } from &apos;./shared/security/auth-guard.service&apos;;\nimport { InitialPageComponent } from &apos;./initial-page/initial-page.component&apos;;\nimport { HomeComponent } from &apos;./home/home.component&apos;;\nimport { SampleDataGridComponent } from &apos;./sampledata/sampledata-grid/sampledata-grid.component&apos;;\n//Routing array\nconst appRoutes: Routes = [{\npath: &apos;login&apos;,\ncomponent: LoginComponent\n}, {\npath: &apos;home&apos;,\ncomponent: HomeComponent,\ncanActivate: [AuthGuard],\nchildren: [{\npath: &apos;&apos;,\nredirectTo: &apos;/home/initialPage&apos;,\npathMatch: &apos;full&apos;,\ncanActivate: [AuthGuard]\n}, {\npath: &apos;initialPage&apos;,\ncomponent: InitialPageComponent,\ncanActivate: [AuthGuard]\n}]\n}, {\npath: &apos;**&apos;,\nredirectTo: &apos;/login&apos;,\npathMatch: &apos;full&apos;\n}];\nexport const routing = RouterModule.forRoot(appRoutes);\nAdding the following into the children object of home, will add into the side menu the entry for the component generated:\n{\npath: &apos;sampleData&apos;,\ncomponent: SampleDataGridComponent,\ncanActivate: [AuthGuard],\n}\nimport { Routes, RouterModule } from &apos;@angular/router&apos;;\nimport { LoginComponent } from &apos;./login/login.component&apos;;\nimport { AuthGuard } from &apos;./shared/security/auth-guard.service&apos;;\nimport { InitialPageComponent } from &apos;./initial-page/initial-page.component&apos;;\nimport { HomeComponent } from &apos;./home/home.component&apos;;\nimport { SampleDataGridComponent } from &apos;./sampledata/sampledata-grid/sampledata-grid.component&apos;;\n//Routing array\nconst appRoutes: Routes = [{\npath: &apos;login&apos;,\ncomponent: LoginComponent\n}, {\npath: &apos;home&apos;,\ncomponent: HomeComponent,\ncanActivate: [AuthGuard],\nchildren: [{\npath: &apos;&apos;,\nredirectTo: &apos;/home/initialPage&apos;,\npathMatch: &apos;full&apos;,\ncanActivate: [AuthGuard]\n}, {\npath: &apos;initialPage&apos;,\ncomponent: InitialPageComponent,\ncanActivate: [AuthGuard]\n}, {\npath: &apos;sampleData&apos;,\ncomponent: SampleDataGridComponent,\ncanActivate: [AuthGuard],\n}]\n}, {\npath: &apos;**&apos;,\nredirectTo: &apos;/login&apos;,\npathMatch: &apos;full&apos;\n}];\nexport const routing = RouterModule.forRoot(appRoutes);\n"},{"id":558,"path":"../website/pages/docs/master-cobigen.asciidoc_how-to.html#howto_angular-client-generation.asciidoc_jwt-authentication","type":"docs","title":"JWT Authentication","body":"75.2.6. JWT Authentication\nIf you are using a back end server with JWT Authentication (there is a sample in workspaces/folder called sampleJwt) you have to specify the Angular application to use this kind of authentication.\nBy default the variable is set to &#x2018;csrf&#x2019; but you can change it to JWT by going to the Enviroment.ts and setting security: &apos;jwt&apos;.\n"},{"id":559,"path":"../website/pages/docs/master-cobigen.asciidoc_how-to.html#howto_angular-client-generation.asciidoc_running","type":"docs","title":"Running","body":"75.2.7. Running\nFirst of all, run your devon4j java server by right clicking over SpringBootApp.java Run As &#x2192; Java Application. This will start to run the SpringBoot server. Once you see the Started SpringBoot in XX seconds, the backend is running.\nOnce the the server is running, open a Devon console at the output directory defined previously and run:\nng serve --open\nThis will run the Angular 8 application at:\nhttp://localhost:4200\nOnce finished, the browser will open automatically at the previous localhost URL showing the Angular 8 application, using the credentials set at the devon4j java server you will be able to access.\n"},{"id":560,"path":"../website/pages/docs/master-cobigen.asciidoc_how-to.html#howto_ionic-client-generation.asciidoc","type":"docs","title":"Ionic client generation","body":"75.3. Ionic client generation\nWe are going to show you how to generate a CRUD Ionic application from an ETO\nusing CobiGen.\nNote\nThis is a short introduction to the Ionic generation. For a deeper tutorial including the generation of the backend, we strongly recommend you to follow this document.\n"},{"id":561,"path":"../website/pages/docs/master-cobigen.asciidoc_how-to.html#howto_ionic-client-generation.asciidoc_prerequisites","type":"docs","title":"Prerequisites","body":"75.3.1. Prerequisites\nBefore starting, make sure you already have in your computer:\nIonic: by following the steps defined on that page.\nIt includes installing:\nNodeJS: We have to use &quot;NPM&quot; for downloading packages.\nIonic CLI.\nCapacitor: Necessary to access to native device features.\nIf CobiGen_Templates are not already downloaded, follow the next steps:\nRight click on any file of your workspace CobiGen &gt; Update Templates and now you are able to start the generation.\nIf you want to adapt them, click Adapt Templates and you should have the CobiGen_Templates as a new project in Eclipse&#x2019;s workspace.\nAfter following those steps correctly, you should have the latest version of the templates ready to use.\n"},{"id":562,"path":"../website/pages/docs/master-cobigen.asciidoc_how-to.html#howto_ionic-client-generation.asciidoc_generation","type":"docs","title":"Generation","body":"75.3.2. Generation\nWe are going to generate the CRUD into a sample application that we have developed for\ntesting this functionality. It is present on your workspaces/examples folder (devon4ng-ionic-application-template). If you do not see it, you can clone or download it from here.\nAfter having that sample app, please create an devon4j project and then start implementing the ETO: You will find an example here.\nAs you can see, TableEto contains 3 attributes: 2 of them are Long and the third one TableState is an enum that you will find\nhere.\nThe Ionic generation works fine for any Java primitive attribute (Strings, floats, chars, boolean&#x2026;&#x200B;) and enums. However, if you want to use your own objects, you should\noverride the toString() method, as explained here.\nThe attributes explained above will be used for generating a page that shows a list. Each item of that list\nwill show the values of those attributes.\nFor generating the files:\nRight click your ETO file and click on CobiGen &gt; Generate as shown on the figure below.\nSelect the Ionic increments for generating as shown below. Increments group a set of templates for generating\ndifferent projects.\nIonic List used for generating the page containing the list.\nIonic devon4ng environments is for stating the server path.\nIonic i18n used for generating the different language translations for the translationService (currently English and Spanish).\nIonic routing adds an app-routing.module.ts file to allow navigation similar to the one available in Angular.\nIonic theme generates the variables.scss file which contains variables to style the application.\nNote\nBy default, the generated files will be placed inside &quot;devon4ng-ionic-application-template&quot;, next to the root of your project&#x2019;s folder.\nSee the image below to know where they are generated. For changing the generation path and the name of the application go to CobiGen_Templates/crud_ionic_client_app/cobigen.properties.\nNow that we have generated the files, lets start testing them:\nFirst change the SERVER_URL of your application. For doing that, modify src/environments/environments.ts, also modify src/environments/environments.android.ts (android) and src/environments/environments.prod.ts (production) if you want to test in different environments.\nCheck that there are no duplicated imports. Sometimes there are duplicated imports in src/app/app.module.ts.\nThis happens because the merger of CobiGen prefers to duplicate rather than to delete.\nRun npm install to install all the required dependencies.\nRun `ionic serve on your console.\nAfter following all these steps your application should start. However, remember that you will need your server to be running for access to the list page.\n"},{"id":563,"path":"../website/pages/docs/master-cobigen.asciidoc_how-to.html#howto_ionic-client-generation.asciidoc_running-it-on-android","type":"docs","title":"Running it on Android","body":"75.3.3. Running it on Android\nTo run the application in an android emulated device, it is necessary to have Android Studio and Android SDK. After its installation, the following commands have to be run on your console:\nnpx cap init &quot;name-for-the-app (between quotes)&quot; &quot;id-for-the-app (between quotes)&quot;\nionic build --configuration=android. To use this command, you must add an android build configuration at angular.json\n&quot;build&quot;: {\n...\n&quot;configurations&quot;: {\n...\n&quot;android&quot;: {\n&quot;fileReplacements&quot;: [\n{\n&quot;replace&quot;: &quot;src/environments/environment.ts&quot;,\n&quot;with&quot;: &quot;src/environments/environment.android.ts&quot;\n}\n]\n},\n}\n}\nnpx cap add android\nnpx cap copy\nnpx cap open android\nThe last steps are done in Android studio: make the project, make the app, build and APK and run in a device.\n"},{"id":564,"path":"../website/pages/docs/master-cobigen.asciidoc_how-to.html#howto_create-a-new-plugin.asciidoc","type":"docs","title":"Implementing a new Plug-in","body":"75.4. Implementing a new Plug-in\nNew plug-ins can implement an input reader, a merger, a matcher, a trigger interpreter, and/or a template engine as explained here.\nNote\nIt is discouraged to have cobigen-core dependencies at runtime, except for cobigen-core-api which definitely must be present.\n"},{"id":565,"path":"../website/pages/docs/master-cobigen.asciidoc_how-to.html#howto_create-a-new-plugin.asciidoc_plugin-activator","type":"docs","title":"Plugin Activator","body":"75.4.1. Plugin Activator\nEach plug-in has to have an plug-in activator class implementing the interface GeneratorPluginActivator from the core-api. This class will be used to load the plug-in using the PluginRegistry as explained here. This class implements two methods:\nbindMerger() &#x2192; returns a mapping of merge strategies and its implementation to be registered.\nbindTriggerInterpreter()&#x2192; returns the trigger interpreters to be provided by this plug-in.\nBoth methods create and register instances of mergers and trigger interpreters to be provided by the new plug-in.\n"},{"id":566,"path":"../website/pages/docs/master-cobigen.asciidoc_how-to.html#howto_create-a-new-plugin.asciidoc_adding-triggerinterpreter","type":"docs","title":"Adding TriggerInterpreter","body":"75.4.2. Adding TriggerInterpreter\nThe trigger interpreter has to implement the TriggerInterpreter interface from the core. The trigger interpreter defines the type for the new plugin and creates new InputReader and new Matcher objects.\n"},{"id":567,"path":"../website/pages/docs/master-cobigen.asciidoc_how-to.html#howto_create-a-new-plugin.asciidoc_adding-inputreader","type":"docs","title":"Adding InputReader","body":"75.4.3. Adding InputReader\nThe input reader is responsible of read the input object and parse it into\nFreeMarker models. The input reader must be implemented for the type of the\ninput file. If there is any existent plugin that has the same file type as input,\nthere will be no need to add a new input reader to the new plug-in.\nInputReader Interface\nThe interface needed to add a new input reader is defined at the core. Each new\nsub plug-in must implements this interface if is needed an input reader for it.\nThe interface implements the basic methods that an input reader must have,\nbut if additional methods are required, the developer must add a new interface\nthat extends the original interface InputReader.java from the core-api\nand implement that on the sub plug-in.\nThe methods to be implemented by the input reader of the new sub plugin are:\nMethod\nReturn Type\nDescription\nisValidInput(Object input)\nboolean\nThis function will be called if matching triggers or matching templates should be retrieved for a given input object.\ncreateModel(Object input)\nMap&lt;String, Object&gt;\nThis function should create the FreeMarker object model from the given input.\ncombinesMultipleInputObjects(Object input)\nboolean\nStates whether the given input object combines multiple input objects to be used for generation.\ngetInputObjects(Object input, Charset inputCharset)\nList&lt;Object&gt;\nWill return the set of combined input objects if the given input combines multiple input objects.\ngetTemplateMethods(Object input)\nMap&lt;String, Object&gt;\nThis method returns available template methods from the plugins as Map. If the plugin which corresponds to the input does not provide any template methods an empty Map will be returned.\ngetInputObjectsRecursively(Object input, Charset inputCharset)\nList&lt;Object&gt;\nWill return the set of combined input objects if the given input combines multiple input objects.\nModel Constants\nThe Input reader will create a model for FreeMarker. A Freemarker model must\nhave variables to use them at the .ftl template file. Refer to Java Model to see the FreeMarker model example for java input files.\nRegistering the Input Reader\nThe input reader is an object that can be retrieved using the correspondent get\nmethod of the trigger interpreter object. The trigger interpreter object is\nloaded at the eclipse plug-in using the load plug-in method explained\nhere.\nThat way, when the core needs the input reader, only needs to call that getInputReader method.\n"},{"id":568,"path":"../website/pages/docs/master-cobigen.asciidoc_how-to.html#howto_create-a-new-plugin.asciidoc_adding-matcher","type":"docs","title":"Adding Matcher","body":"75.4.4. Adding Matcher\nThe matcher implements the MatcherInterpreter interface from the core-api.\nShould be implemented for providing a new input matcher. Input matcher are\ndefined as part of a trigger and provide the ability to restrict specific\ninputs to a set of templates.\nThis restriction is implemented with a MatcherType enum.\nE.g JavaPlugin\nprivate enum MatcherType {\n/** Full Qualified Name Matching */\nFQN,\n/** Package Name Matching */\nPACKAGE,\n/** Expression interpretation */\nEXPRESSION\n}\nFurthermore, matchers may provide several variable assignments, which might be\ndependent on any information of the matched input and thus should be resolvable\nby the defined matcher.\nE.g JavaPlugin\nprivate enum VariableType {\n/** Constant variable assignment */\nCONSTANT,\n/** Regular expression group assignment */\nREGEX\n}\n"},{"id":569,"path":"../website/pages/docs/master-cobigen.asciidoc_how-to.html#howto_create-a-new-plugin.asciidoc_adding-merger","type":"docs","title":"Adding Merger","body":"75.4.5. Adding Merger\nThe merger is responsible to perform merge action between new output with the\nexistent data at the file if it already exists. Must implement the Merger\ninterface from the core-api.\nThe implementation of the Merge interface must override the following methods:\nMethod\nReturn Type\nDescription\ngetType()\nString\nReturns the type, this merger should handle.\nmerge(File base, String patch, String targetCharset)\nString\nMerges the patch into the base file.\nIs important to know that any exception caused by the merger must throw a MergeException from the core-api to the eclipse-plugin handle it.\n"},{"id":570,"path":"../website/pages/docs/master-cobigen.asciidoc_how-to.html#howto_create-a-new-plugin.asciidoc_changes-since-eclipse--maven-3.x","type":"docs","title":"Changes since Eclipse / Maven 3.x","body":"75.4.6. Changes since Eclipse / Maven 3.x\nSince version 3.x the Eclipse and Maven plugins of CobiGen utilize the Java ServiceLoader mechanic to find and register plugins at runtime. To enable a new plugin to be discovered by this mechanic the following steps are needed:\ncreate the file META-INF/services/com.capgemini.cobigen.api.extension.GeneratorPluginActivator containing just the full qualified name of the class implementing the GeneratorPluginActivator interface, if the plugin provides a Merger and/or a TriggerInterpreter\ncreate the file META-INF/services/com.capgemini.cobigen.api.extension.TextTemplateEngine containing just the full qualified name of the class implementing the TextTemplateEngine interface, if provided by the plugin\ninclude META-INF into the target bundle (i.e. the folder META-INF has to be present in the target jar file)\nExample: Java Plugin\nThe java plugin provides both a Merger and a TriggerInterpreter. It contains therefore a com.capgemini.cobigen.api.extension.GeneratorPluginActivator file with the following content:\ncom.capgemini.cobigen.javaplugin.JavaPluginActivator\nThis makes the JavaPluginActivator class discoverable by the ServiceLoader at runtime.\nto properly include the plugin into the current system and use existing infrastructure, you need to add the plugin as a module in /cobigen/pom.xml (in case of a Merger/TriggerInterpreter providing plugin) and declare that as the plugin&#x2019;s parent in it&#x2019;s own pom.xml via\n&lt;parent&gt;\n&lt;groupId&gt;com.capgemini&lt;/groupId&gt;\n&lt;artifactId&gt;cobigen-parent&lt;/artifactId&gt;\n&lt;version&gt;dev-SNAPSHOT&lt;/version&gt;\n&lt;/parent&gt;\nor /cobigen/cobigen-templateengines/pom.xml (in case of a Merger/TriggerInterpreter providing plugin) and declare that as the plugin&#x2019;s parent in it&#x2019;s own pom.xml via\n&lt;parent&gt;\n&lt;groupId&gt;com.capgemini&lt;/groupId&gt;\n&lt;artifactId&gt;cobigen-tempeng-parent&lt;/artifactId&gt;\n&lt;version&gt;dev-SNAPSHOT&lt;/version&gt;\n&lt;/parent&gt;\nIf the plugin provides both just use the /cobigen/pom.xml.\nThe dependencies of the plugin are included in the bundle\nTo make the plugin available to the Eclipse plugin it must be included into the current compositeContent.xml and compositeArtifacts.xml files. Both files are located in http://de-mucevolve02/files/cobigen/updatesite/{experimental|nightly|stable}. To do so, add an &lt;child&gt; entry to the &lt;children&gt; tag in both files and adapt the size attribute to match the new number of references. The location attribute of the new &lt;child&gt; tag needs to be the artifact id of the plugins pom.xml.\nExample: Java Plugin\nIn case of the Java plugin, the entry is\n&lt;child location=&quot;cobigen-javaplugin&quot;/&gt;\nDeployment\nFor the Maven Plugin\nExecute mvn clean deploy from the plugins project folder. You need to configure write access to the devon nexus (e.g in the CobiGen IDE via the variables-customized script)\nFor the Eclipse Plugin\nDepending on the kind of release you want to publish you can chose from the following maven profiles:\nexperimental is for, as the name suggests, experimental snapshot builds. In case of new plugins this is a good place to upload first drafts.\nnightly is for periodically CI deployment.\nstable is solely for releases.\nE.g. you want an experimental release you need to follow these steps:\n# Builds the Manifest and bundles the dependencies\nmvn clean package bundle:bundle -Pp2-bundle\n# Uses the created bundle and builds a p2 update site for it. Do NOT use clean\nmvn install bundle:bundle -Pp2-bundle,p2-build-mars,p2-build-experimental p2:site\n# Uploads the p2 update site to the experimental repository. Do NOT use clean\nmvn deploy -Pp2-build-mars,p2-build-experimental -Dp2.upload=experimental\nYou need write access to the iCSD file server configured (e.g in the CobiGen IDE via the variables-customized script).\n"},{"id":571,"path":"../website/pages/docs/master-cobigen.asciidoc_how-to.html#howto_create-external-plugin.asciidoc","type":"docs","title":"Introduction to CobiGen external plug-ins","body":"75.5. Introduction to CobiGen external plug-ins\nSince September of 2019, a major change on CobiGen has taken place. CobiGen is written in Java code and previously, it was very hard for developers to create new plug-ins in other languages.\nCreating a new plug-in means:\nBeing able to parse a file in that language.\nCreate a human readable model that can be used to generate templates (by retrieving properties from the model).\nEnable merging files, so that user&#x2019;s code does not get removed.\nFor the Java plug-in it was relatively easy. As you are inside the Java world, you can use multiple utilities or libraries in order to get the AST or to merge Java code. With this new feature, we wanted that behaviour to be possible for any programming language.\n"},{"id":572,"path":"../website/pages/docs/master-cobigen.asciidoc_how-to.html#howto_create-external-plugin.asciidoc_general-intuition","type":"docs","title":"General intuition","body":"75.5.1. General intuition\nBelow you will find a very high level description of how CobiGen worked in previous versions:\nBasically, when a new input file was sent to CobiGen, it called the input reader to create a model of it (see here an example of a model). That model was sent to the template engine.\nAfterwards, the template engine generated a new file which had to be merged with the original one. All this code was implemented in Java.\nOn the new version, we have implemented a handler (ExternalProcessHandler) which connects through TCP/IP connection to a server (normally on localhost:5000). This server can be implemented in any language (.Net, Node.js, Python&#x2026;&#x200B;) it just needs to implement a REST API defined here. The most important services are the input reading and merging:\nCobiGen acts as a client that sends requests to the server in order to read the input file and create a model. The model is returned to the template engine so that it generates a new file. Finally, it is sent back to get merged with the original file.\n"},{"id":573,"path":"../website/pages/docs/master-cobigen.asciidoc_how-to.html#howto_create-external-plugin.asciidoc_how-to-create-new-external-plug-in","type":"docs","title":"How to create new external plug-in","body":"75.5.2. How to create new external plug-in\nThe creation of a new plug-in consists mainly in three steps:\nCreation of the server (external process).\nCreation of a CobiGen plug-in.\nCreation of templates.\nServer (external process)\nThe server can be programmed in any language that is able to implement REST services endpoints. The API that needs to implement is defined with this contract. You can paste the content to https://editor.swagger.io/ for a better look.\nWe have already created a NestJS server that implements the API defined above. You can find the code here which you can use as an example.\nAs you can see, the endpoints have the following naming convention: processmanagement/todoplugin/nameOfService where you will have to change todo to your plug-in name (e.g. rustplugin, pyplugin, goplugin&#x2026;&#x200B;)\nWhen implementing service getInputModel which returns a model from the input file there are only two restrictions:\nA path key must be added. Its value can be the full path of the input file or just the file name. It is needed because in CobiGen there is a batch mode, in which you can have multiple input objects inside the same input file. You do not need to worry about batch mode for now.\nOn the root of your model, for each found key that is an object (defined with brackets [{}]), CobiGen will try to use it as an input object. For example, this could be a valid model:\n{\n&quot;path&quot;: &quot;example/path/employee.entity.ts&quot;\n&quot;classes&quot;: [\n{\n&quot;identifier&quot;: &quot;Employee&quot;,\n&quot;modifiers&quot;: [\n&quot;export&quot;\n],\n&quot;decorators&quot;: [\n{\n&quot;identifier&quot;: {\n&quot;name&quot;: &quot;Entity&quot;,\n&quot;module&quot;: &quot;typeorm&quot;\n},\n&quot;isCallExpression&quot;: true\n}\n],\n&quot;properties&quot;: [\n{\n&quot;identifier&quot;: &quot;id&quot;,\n...\n...\n...\n}]\n&quot;interfaces&quot;: [{\n...\n}]\n}\nFor this model, CobiGen would use as input objects all the classes and interfaces defined. On the templates we would be able to do model.classes[0].identifier to get the class name. These input objects depend on the language, therefore you can use any key.\nIn order to test the server, you will have to deploy it on your local machine (localhost), default port is 5000. If that port is already in use, you can deploy it on higher port values (5001, 5002&#x2026;&#x200B;). Nevertheless, we explain later the testing process as you need to complete the next step before.\nImportant\nYour server must accept one argument when running it. The argument will be the port number (as an integer). This will be used for CobiGen in order to handle blocked ports when deploying your server. Check this code to see how we implemented that argument on our NestJS server.\nCobiGen plug-in\nYou will have to create a new CobiGen plug-in that connects to the server. But do not worry, you will not have to implement anything new. We have a CobiGen plug-in template available, the only changes needed are renaming files and setting some properties on the pom.xml. Please follow these steps:\nGet the CobiGen plug-in template from here. It is a template repository (new GitHub feature), so you can click on &quot;Use this template&quot; as shown below:\nName your repo as cobigen-name-plugin where name can be python, rust, go&#x2026;&#x200B; In our case we will create a nest plug-in. It will create a repo with only one commit which contains all the needed files.\nClone your just created repo and import folder cobigen-todoplugin as a Maven project on any Java IDE, though we recommend you devonfw ;)\nRename all the todoplugin folders, files and class names to nameplugin. In our case nestplugin. In Eclipse you can easily rename by right clicking and then refactor &#x2192; rename:\nNote\nWe recommend you to select all the checkboxes\nRemember to change in src/main/java and src/test/java all the package, files and class names to use your plug-in name. The final result would be:\nNow we just need to change some strings, this is needed for CobiGen to register all the different plugins (they need unique names). In class TodoPluginActivator (in our case NestPluginActivator), change all the todo to your plug-in name. See below the 3 strings that need to be changed:\nFinally, we will change some properties from the pom.xml of the project. These properties define the server (external process) that is going to be used:\nInside pom.xml, press Ctrl + F to perform a find and replace operation. Replace all todo with your plugin name:\nWe are going to explain the server properties:\nartifactId: This is the name of your plug-in, that will be used for a future release on Maven Central.\nplugin.name: does not need to be changed as it uses the property from the artifactId. When connecting to the server, it will send a request to localhost:5000/{plugin.name}plugin/isConnectionReady, that is why it is important to use an unique name for the plug-in.\nserver.name: This defines how the server executable (.exe) file will be named. This .exe file contains all the needed resources for deploying the server. You can use any name you want.\nserver.version: You will specify here the server version that needs to be used. The .exe file will be named as {server.name}-{server.version}.exe.\nserver.url: This will define from where to download the server. We really recommend you using NPM which is a package manager we know it works well. We explain here how to release the server on NPM. This will download the .exe file for Windows.\nserver.url.linux: Same as before, but this should download the .exe file for Linux systems. If you do not want to implement a Linux version of the plug-in, just use the same URL from Windows or MacOS.\nserver.url.macos: Same as before, but this should download the .exe file for MacOS systems. If you do not want to implement a MacOS version of the plug-in, just use the same URL from Linux or Windows.\n"},{"id":574,"path":"../website/pages/docs/master-cobigen.asciidoc_how-to.html#howto_create-external-plugin.asciidoc_testing-phase","type":"docs","title":"Testing phase","body":"75.5.3. Testing phase\nNow that you have finished with the implementation of the server and the creation of a new CobiGen plug-in, we are going to explain how you can test that everything works fine:\nDeploy the server on port 5000.\nRun mvn clean test on the CobiGen-plugin or run the JUnit tests directly on Eclipse.\nIf the server and the plug-in are working properly, some tests will pass and other will fail (we need to tweak them).\nIf every test fails, something is wrong in your code.\nIn order to fix the failing tests, go to src/test/java. The failing tests make use of sample input files that we added in sake of example:\nReplace those files (on src/test/resources/testadata/unittest/files/&#x2026;&#x200B;) with the correct input files for your server.\n"},{"id":575,"path":"../website/pages/docs/master-cobigen.asciidoc_how-to.html#howto_create-external-plugin.asciidoc_releasing","type":"docs","title":"Releasing","body":"75.5.4. Releasing\nNow that you have already tested that everything works fine, we are going to explain how to release the server and the plug-in.\nRelease the server\nWe are going to use NPM to store the executable of our server. Even though NPM is a package manager for JavaScript, it can be used for our purpose.\nGet the CobiGen server template from here. It is a template repository (new GitHub feature), so you can click on &quot;Use this template&quot; as shown below:\nName your repo as cobigen-name-server where name can be python, rust, go&#x2026;&#x200B; In our case we will create a nest plug-in. It will create a repo with only one commit which contains all the needed files.\nClone your just created repo and go to folder cobigen-todo-server. It will just contain two files: ExternalProcessContract.yml is the OpenAPI definition which you can modify with your own server definition (this step is optional), and package.json is a file needed for NPM in order to define where to publish this package:\n{\n&quot;name&quot;: &quot;@devonfw/cobigen-todo-server&quot;,\n&quot;version&quot;: &quot;1.0.0&quot;,\n&quot;description&quot;: &quot;Todo server to implement the input reader and merger for CobiGen&quot;,\n&quot;author&quot;: &quot;CobiGen Team&quot;,\n&quot;license&quot;: &quot;Apache&quot;\n}\nThose are the default properties. This would push a new package cobigen-todo-server on the devonfw organization, with version 1.0.0. We have no restrictions here, you can use any organization, though we always recommend devonfw.\nNote\nRemember to change all the todo to your server name.\nAdd your executable file into the cobigen-todo-server folder, just like below. As we said previously, this .exe is the server ready to be deployed.\ncobigen-template-server/\n|- cobigen-todo-server/\n|- ExternalProcessContract.yml\n|- package.json\n|- todoserver-1.0.0.exe\nFinally, we have to publish to NPM. If you have never done it, you can follow this tutorial. Basically you need to login into NPM and run:\ncd cobigen-todo-server/\nnpm publish --access=public\nNote\nTo release Linux and MacOS versions of your plug-in, just add the suffix into the package name (e.g. @devonfw/cobigen-todo-server-linux)\nThat&#x2019;s it! You have published the first version of your server. Now you just need to modify the properties defined on the pom of your CobiGen plug-in. Please see next section for more information.\nReleasing CobiGen plug-in\nChange the pom.xml to define all the properties. You can see below a final example for nest:\n...\n&lt;groupId&gt;com.devonfw.cobigen&lt;/groupId&gt;\n&lt;artifactId&gt;nestplugin&lt;/artifactId&gt;\n&lt;name&gt;CobiGen - Nest Plug-in&lt;/name&gt;\n&lt;version&gt;1.0.0&lt;/version&gt;\n&lt;packaging&gt;jar&lt;/packaging&gt;\n&lt;description&gt;CobiGen - nest Plug-in&lt;/description&gt;\n&lt;properties&gt;\n&lt;!-- External server properties --&gt;\n&lt;plugin.name&gt;parent&lt;/plugin.name&gt;\n&lt;server.name&gt;nestserver&lt;/server.name&gt;\n&lt;server.version&gt;1.0.0&lt;/server.version&gt;\n&lt;server.url&gt;https\\://registry.npmjs.org/@devonfw/cobigen-nest-server/-/cobigen-nest-server-${server.version}.tgz&lt;/server.url&gt;\n&lt;server.url.linux&gt;https\\://registry.npmjs.org/@devonfw/cobigen-nest-server-linux/-/cobigen-nest-server-linux-${server.version}.tgz&lt;/server.url.linux&gt;\n&lt;server.url.macos&gt;https\\://registry.npmjs.org/@devonfw/cobigen-nest-server-macos/-/cobigen-nest-server-macos-${server.version}.tgz&lt;/server.url.macos&gt;\n...\nDeploy to Maven Central.\n"},{"id":576,"path":"../website/pages/docs/master-cobigen.asciidoc_how-to.html#howto_create-external-plugin.asciidoc_templates-creation","type":"docs","title":"Templates creation","body":"75.5.5. Templates creation\nAfter following above steps, we now have a CobiGen plug-in that connects to a server (external process) which reads your input files, returns a model and is able to merge files.\nHowever, we need a key component for our plug-in to be useful. We need to define templates:\nFork our CobiGen main repository, from here and clone it into your PC. Stay in the master branch and import into your IDE cobigen-templates\\templates-devon4j. Set the Java version of the project to 1.8 if needed.\nCreate a new folder on src/main/templates, this will contain all your templates. You can use any name, but please use underscores as separators. In our case, we created a folder crud_typescript_angular_client_app to generate an Angular client from a TypeORM entity (NodeJS entity).\nInside your folder, create a templates folder. As you can see below, the folder structure of the generated files starts here (the sources). Also we need a configuration file templates.xml that should be on the same level as templates/ folder. For now, copy and paste a templates.xml file from any of the templates folder.\nStart creating your own templates. Our default templates language is Freemarker, but you can also use Velocity. Add the extension to the file (.ftl) and start developing templates! You can find useful documentation here.\nAfter creating all the templates, you need to modify context.xml which is located on the root of src/main/templates. There you need to define a trigger, which is used for CobiGen to know when to trigger a plug-in. I recommend you to copy and paste the following trigger:\n&lt;trigger id=&quot;crud_typescript_angular_client_app&quot; type=&quot;nest&quot; templateFolder=&quot;crud_typescript_angular_client_app&quot;&gt;\n&lt;matcher type=&quot;fqn&quot; value=&quot;([^\\.]+).entity.ts&quot;&gt;\n&lt;variableAssignment type=&quot;regex&quot; key=&quot;entityName&quot; value=&quot;1&quot;/&gt;\n&lt;variableAssignment type=&quot;regex&quot; key=&quot;component&quot; value=&quot;1&quot;/&gt;\n&lt;variableAssignment type=&quot;constant&quot; key=&quot;domain&quot; value=&quot;demo&quot;/&gt;\n&lt;/matcher&gt;\n&lt;/trigger&gt;\nChange templateFolder to your templates folder name. id you can use any, but it is recommendable to use the same as the template folder name. type is the TRIGGER_TYPE we defined above on the NestPluginActivator class. On matcher just change the value: ([^\\.]+).entity.ts means that we will only accept input files that contain &quot;anyString.entity.ts&quot;. This improves usability, so that users only generate using the correct input files. You will find more info about variableAssignment here.\nFinally, is time to configure templates.xml. It is needed for organizing templates into increments, please take a look into this documentation.\nTesting templates\nWhen you have finished your templates you will like to test them. On the templates-devon4j pom.xml remove the SNAPSHOT from the version (in our case the version will be 3.1.8). Run mvn clean install -DskipTests on the project. We skip tests because you need special permissions to download artifacts from our Nexus. Remember the version that has just been installed:\nNote\nWe always recommend using the devonfw console, which already contains a working Maven version.\nNow we have your last version of the templates ready to be used. We need to use that latest version in CobiGen. We will use the CobiGen CLI that you will find in your cloned repo, at cobigen-cli/cli. Import the project into your IDE.\nInside the project, go to src/main/resources/pom.xml. This pom.xml is used on runtime in order to install all the CobiGen plug-ins and templates. Add there your latest templates version and the previously created plug-in:\nAfterwards, run mvn clean install -DskipTests and CobiGen will get your plug-ins. Now you have three options to test templates:\nUsing Eclipse run as:\nInside Eclipse, you can run the CobiGen-CLI as a Java application. Right click class CobiGenCLI.java &#x2192; run as &#x2192; run configurations&#x2026;&#x200B; and create a new Java application as shown below:\nThat will create a CobiGenCLI configuration where we can set arguments to the CLI. Let&#x2019;s first begin with showing the CLI version, which should print a list of all plug-ins, including ours.\n...\nname:= propertyplugin version = 2.0.0\nname:= jsonplugin version = 2.0.0\nname:= templates-devon4j version = 3.1.8\nname:= nestplugin version = 1.0.0\n...\nIf that worked, now you can send any arguments to the CLI in order to generate with your templates. Please follow this guide that explains all the CLI commands.\nModify the already present JUnit tests on the CLI project: They test the generation of templates from multiple plug-ins, you can add your own tests and input files.\nUse the CLI jar to execute commands:\nThe mvn clean install -DskipTests command will have created a Cobigen.jar inside your target folder (cobigen-cli/cli/target). Open the jar with any unzipper and extract to the current location class-loader-agent.jar, cobigen.bat and cg.bat:\nNow you can run any CobiGen CLI commands using a console. This guide explains all the CLI commands.\n"},{"id":577,"path":"../website/pages/docs/master-cobigen.asciidoc_how-to.html#howto_devon4net.asciidoc_navydevon4net-cobigen-guide","type":"docs","title":"How to update CobiGen","body":"75.5.6. devon4net Cobigen Guide\nOverview\nIn this guide we will explain how to generate a new WebApi project from an OpenAPI 3.0.0 specification. This means that we are going to use a &#x201C;contract first&#x201D; strategy. This is going to be possible due to these type of files that contain all the information about entities, operations, etc&#x2026;\nIn order to make it work we are using CobiGen, a powerful tool for generating source code. CobiGen allows users to generate all the structure and code of the components, helping to save a lot of time otherwise waisted on repetitive tasks.\nGetting things ready\ndevonfw-ide\nFirst, we will install the devonfw-ide. It is a tool that will setup your IDE within minutes. Please follow the install guide here.\ndevon4net Templates\nWe are going to use the template of devon4net as a base to generate all the code, so what we have to do now is to download said template using the following steps.\nFirst of all you have to set up all the environment for .NET, you can do this using the following tutorial. Next we are going to create a new folder where we want to have the WebAPI project, lastly we are going to open the terminal there.\nType the following:\ndotnet new -i Devon4Net.WebAPI.Template\nand then:\ndotnet new Devon4NetAPI\nOpenAPI File\nIn order to let CobiGen generate all the files, we first have to make some modifications to our OpenAPI file.\nIt is obligatory to put the &#x201C;x-rootpackage&#x201D; tag to indicate where CobiGen will place the generated files as well as the &quot;x-component&quot; tags for each component, keep in mind that due to CobiGen&#x2019;s limitations each component must have its own entity.\nYou can read more information about how to configure your OpenAPI file and a working example here.\nGenerating files\nCobigen allow us to generate the files in two different ways. One of them is using Eclipse which it can be done by using the its grafical interface. The other way to generate the code is using the Cobigen CLI tool.\nGenerating files through Eclipse\nIn order to generate the files using Eclipse we need to follow some simple steps.\nFirst we are going to import our basic devon4net WebAPI Project into Eclipse. to do so open Eclipse with the &#x201C;eclipse-main.bat&#x201D; file that can be found in the devon distribution root folder. Once we are inside of Eclipse we go to File &gt; Open projects from file system&#x2026;&#x200B; and, under &quot;Directory&quot;, search for your project.\nNext we copy our OpenAPI file into the root folder of the project.\nAnd then we right click on OpenAPI file and then select CobiGen &gt; Generate&#x2026;&#x200B; It will display a window like this:\nTo select all .NET features choose CRUD devon4net Server otherwise you can select only those that interest you.\nOnes you select all the files that you want to generate, click on the &#x201C;Finish&#x201D; button to generate all the source code.\nGenerating files through Cobigen CLI\nIn ordet to generate the files using the Cobigen CLI it is needed to do the following steps:\nGo to devonfw distribution folder\nRun console.bat, this will open a console.\nGo to the folder you downloaded the devon4net template and your yml file.\nRun the command:\ncobigen generate {yourOpenAPIFile}.yml\nA list of increments will be printed so that you can start the generation. It has to be selected CRUD devon4net Server increment.\nConfiguration\nData base\nCobigen is generating an empty context that has to be filled with manualy in order to be able to work with the database. The context can be found in [Project_Name]/Devon4Net.WebAPI.Implementation/Domain/Database/CobigenContext.cs.\nRun the application\nAfter the configuration of the database, open a terminal in path: [Project_Name]/Devon4Net.Application.WebAPI and then type:\ndotnet run\nThis will deploy our application in our localhost with the port 8082, so when you click here (https://localhost:8082/swagger) you can see, in swagger, all the services and the data model.\n75.6. How to update CobiGen\nIn order to update CobiGen from our devonfw distribution, we have two options:\nOpen Eclipse, click on Help &#x2192; Check for updates\nSelect all the CobiGen plugins listed and click on Next.\nIf this option is not working properly, then you can try the second option:\nOpen Eclipse, click on Help &#x2192; About Eclipse IDE:\nClick on Installation details:\nSelect all the CobiGen plugins and click on Update:\nAfter the update process finishes, remember to restart Eclipse.\n"},{"id":578,"path":"../website/pages/docs/master-cobigen.asciidoc_how-to.html#howto_update_cobigen.asciidoc_updating-templates","type":"docs","title":"Updating templates:","body":"75.6.1. Updating templates:\nTo update your CobiGen templates to the latest version, you just need to do one step:\nRight click any file on your package explorer, click on CobiGen &#x2192; Update templates, then click on download:\nNow you will have the latest templates ready!\nUnresolved directive in cobigen.wiki/master-cobigen.asciidoc - include::howto-Cobigen-CLI-generation.asciidoc[leveloffset=2]\n"},{"id":579,"path":"../website/pages/docs/master-cobigen.asciidoc_how-to.html#howto-devonfw-ide-CobiGen-PoC-E2E.asciidoc","type":"docs","title":"End to End POC Code generation using Entity class","body":"75.7. End to End POC Code generation using Entity class\nThis article helps to create a sample application using cobigen.\n"},{"id":580,"path":"../website/pages/docs/master-cobigen.asciidoc_how-to.html#howto-devonfw-ide-cobigen-poc-e2e.asciidoc_prerequisites","type":"docs","title":"Prerequisites","body":"75.7.1. Prerequisites\nDownload and install devonnfw IDE here,\n"},{"id":581,"path":"../website/pages/docs/master-cobigen.asciidoc_how-to.html#howto-devonfw-ide-cobigen-poc-e2e.asciidoc_steps-to-create-a-sample-project-using-cobigen","type":"docs","title":"Steps to create a Sample Project using Cobigen","body":"75.7.2. Steps to create a Sample Project using Cobigen\nThe HOW_TO is divided in 2 parts:\nBE-Back End generator (DB + DAO + services) &#x2013; CONTRACT FIRST APPROACH\nFE-Front End generator (Web App Angular + Ionic App) &#x2013; CONTRACT FIRST APPROACH\nSo, ready to go! We&#x2019;re going to start from the BE part &#x2026;\nBack End\nUnder your path installation of DevonFW, you can find the eclipe-main.bat script and you can run it:\nrun installation_path\\eclipse-main.bat\nIt will open eclipse\nCreate a project using below command from the command prompt.\nTo made it, it&#x2019;s necessary to open a CMD and open the folder where it&#x2019;s installed DevonFW and launch this command under the path workspaces/main\ndevon java create com.example.domain.myapp\nImport the project to eclipse as maven project\nClick FINISH\nNow We have the following 4 projects.\nBEFORE to start to create an Entity class, remember to create the tables, for this POC it&#x2019;s used an H2 Database!\nCreate a new SQL file (i.e: V0002__CreateTables_myapp.sql) inside myapp-core , under the folder path /myapp-core/src/main/resources/db/migration/1.0 and insert the following script:\nCREATE TABLE EMPLOYEE (\nid BIGINT auto_increment, modificationCounter INTEGER NOT NULL,\nemployeeid BIGINT auto_increment,\nname VARCHAR(255),\nsurname VARCHAR(255),\nemail VARCHAR(255),\nPRIMARY KEY (employeeid)\n);\nWARNING 1: please note that there in that folder is present only one file, 0001, and you have to add the other files in progressive number order (i.e. 0002)!\nWARNING 2: please note that there are 2 underscore in the name!\nNow create another SQL file (i.e: V0003__PopulateTables-myapp.sql) and add following script about the INSERT in order to populate the table created before.\nThe script must be inserted at the same path used before: /myapp-core/src/main/resources/db/migration/1.0\nWARNING 1: please note that there in that folder is present only one file, 0001, and you have to add the other files in progressive number order (i.e. 0003)!\nWARNING 2: please note that there are 2 underscore in the name!\nINSERT INTO EMPLOYEE (id, modificationCounter, employeeid, name, surname,email) VALUES (1, 1, 1, &apos;John&apos;,&apos;Doe&apos;,&apos;john.doe@example.com&apos;);\nINSERT INTO EMPLOYEE (id, modificationCounter, employeeid, name, surname,email) VALUES (2, 2, 2, &apos;Tom&apos;,&apos;Smith&apos;, &apos;tom.smith@example.com&apos;);\nINSERT INTO EMPLOYEE (id, modificationCounter, employeeid, name, surname,email) VALUES (3, 3, 3, &apos;Joe&apos;,&apos;Schmoe&apos;, &apos;joe.schmoe@example.com&apos;);\nLet&#x2019;s create the Entity Class for the code generation\nCreate a package employeemanagement.dataaccess.api under the folder myapp-core.\nNote: It is important to follow this naming convention for CobiGen to work properly.\nNow create a JPA Entity class in this package\nimport javax.persistence.Entity;\nimport javax.persistence.GeneratedValue;\nimport javax.persistence.GenerationType;\nimport javax.persistence.Column;\n@Entity\n@javax.persistence.Table(name = &quot;EMPLOYEE&quot;)\npublic class EmployeeEntity {\n@Column(name = &quot;EMPLOYEEID&quot;)\n@GeneratedValue(strategy = GenerationType.IDENTITY)\nprivate Long employeeId;\n@Column(name = &quot;NAME&quot;)\nprivate String name;\n@Column(name = &quot;SURNAME&quot;)\nprivate String surname;\n@Column(name = &quot;EMAIL&quot;)\nprivate String email;\n}\nthen generate getters and setters for all attribute, as you can see in the image below:\nUse Cobigen to generate code. Right click on EmployeeEntity. CobiGen &#x2192; Generate\nIf it will ask you to download the templates, click on update:\nIt will automatically download the latest version of CobiGen_Templates.\nAttention: If you want to adapt the CobiGen_Templates, (normally this is not neccessary), you will find at the end of this document (in a separate chapter) a tutorial on how to import them and adapt them!\nClick on all the option selected as below:\nClick on finish. Below Screen would be seen. Click on continue\nThe entire BE layer structure having CRUD operation methods will be auto generated.\nSome classes will be generated on the api part (myapp-api), normally it will be interfaces, as shown below:\nSome other classes will be generated on the core part (myapp-core), normally it will be implementations as shown below:\nThe last step is to add the Cross Domain process, because when you are developing Javascript client and server application separately, you have to deal with cross domain issues.\nSo, we need to prepare server side to accept request from other domains. We need to cover the following points:\nAccept request from other domains.\nAccept devonfw used headers like X-CSRF-TOKEN or correlationId.\nBe prepared to receive secured request (cookies).\nTo do this it&#x2019;s necessary to add two kind of dependecies in the pom.xml of the myapp-core folder, at the end of the list of dependecies:\n&lt;dependency&gt;\n&lt;groupId&gt;com.devonfw.java.starters&lt;/groupId&gt;\n&lt;artifactId&gt;devon4j-starter-security-cors&lt;/artifactId&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n&lt;groupId&gt;com.devonfw.java.starters&lt;/groupId&gt;\n&lt;artifactId&gt;devon4j-starter-security-csrf&lt;/artifactId&gt;\n&lt;/dependency&gt;\nNext step is to add some prperties under your application.properties file, in the myapp-core folder in the resources/config:\nsecurity.cors.spring.allowCredentials=true\nsecurity.cors.spring.allowedOriginPatterns=*\nsecurity.cors.spring.allowedHeaders=*\nsecurity.cors.spring.allowedMethods=OPTIONS,HEAD,GET,PUT,POST,DELETE,PATCH\nsecurity.cors.pathPattern=/**\nBEFORE to generate the FE, please start the Tomcat server to check that BE Layer has been generated properly.\nTo start a server you just have to right click on SpringBootApp.java &#x2192; run as &#x2192; Java Application\nBE DONE\nLast but not least: We make a quick REST services test !\nSee in the application.properties the TCP Port and the PATH\nNow compose the Rest service URL:\nservice class &lt;path&gt;/&lt;service method path&gt;\n&lt;server&gt; refers to server with port no. (ie: localhost:8081)\n&lt;app&gt; is in the application.properties (empty in our case, see above)\n&lt;rest service class path&gt; refers to EmployeemanagementRestService: (i.e: /employeemanagement/v1)\n&lt;service method path&gt;/employee/{id} (i.e: for getEmployee method)\nURL of getEmployee for this example is:\nFor all employees (POST)\nhttp://localhost:8081/services/rest/employeemanagement/v1/employee/search\nFor the specific employee (GET)\nhttp://localhost:8081/services/rest/employeemanagement/v1/employee/1\nNow download Postman to test the rest services.\nOnce done, you have to create a POST Request for the LOGIN and insert in the body the JSON containing the username and password admin\nWARNING: please note that the body of the request must be JSON type!\nOnce done with success (Status: 200 OK) - you can see the status of the response in the top right corner of Postman - we can create a NEW GET Request in order to get one employee.\nTo do this you have to create a new request in Postman, GET type, and insert the URL specified before:\nhttp://localhost:8081/services/rest/employeemanagement/v1/employee/1\nThenk click on &quot;SEND&quot; button&#x2026;&#x200B;\nNow you&#x2018;ve to check that response has got Status: 200 OK and to see the below Employee\nNow that We have successfully tested the BE is time to go to create the FE !\nFront End\nLet&#x2019;s start now with angular Web and then Ionic app.\nAngular Web App\nTo generate angular structure, download or clone devon4ng-application-template from\nhttps://github.com/devonfw/devon4ng-application-template\nIMPORTANT when you download the zip of the source code of your FE application, the name of the app MUST BE devon4ng-application-template and you can extract it in youe DevonFW folder, under workspaces/main\nOnce downloaded the APP, you can open the application with your favourite IDE (Intellij or Visual Studio Code)\nOnce done, right click on EmployeeEto.java file present under the package com.devonfw.poc.employeemanagement.logic.api.to, in the Back End part.\nClick on the selected options as seen in the screenshot:\nClick on Finish\nThe entire ANGULAR structure has been auto generated. The generated code will be merged to the existing.\nIMPORTANT now you have to check in the app-routing.module.ts file, if the content corresponding to the code below:\nimport { NgModule } from &apos;@angular/core&apos;;\nimport { RouterModule, Routes } from &apos;@angular/router&apos;;\nimport { AuthGuard } from &apos;./core/security/auth-guard.service&apos;;\nimport { NavBarComponent } from &apos;./layout/nav-bar/nav-bar.component&apos;;\nconst routes: Routes = [{\npath: &apos;&apos;,\nredirectTo: &apos;/login&apos;,\npathMatch: &apos;full&apos;\n},\n{\npath: &apos;login&apos;,\nloadChildren: () =&gt;\nimport(&apos;./auth/auth.module&apos;).then(m =&gt; m.AuthDataModule)\n},\n{\npath: &apos;home&apos;,\ncomponent: NavBarComponent,\ncanActivateChild: [\nAuthGuard\n],\nchildren: [{\npath: &apos;initial&apos;,\nloadChildren: () =&gt;\nimport(&apos;./home/initial-page/initial-page.module&apos;).then(\nm =&gt; m.InitialPageModule,\n)\n},\n{\npath: &apos;employee&apos;,\nloadChildren: () =&gt;\nimport(&apos;./employee/employee.module&apos;).then(\nm =&gt; m.EmployeeModule,\n)\n}\n]\n},\n{\npath: &apos;**&apos;,\nredirectTo: &apos;/login&apos;\n},\n];\n@NgModule({\nimports: [\nRouterModule.forRoot(routes)\n],\nexports: [\nRouterModule\n]\n})\nexport class AppRoutingModule {\n}\nAfter that, if you want to make visible the Employee Grid in you FE application, you have to modify the nav-bar.component.html, to add the Employee grid in the section:\n&lt;div class=&quot;home-container-outer&quot;&gt;\n&lt;div class=&quot;home-container-inner&quot;&gt;\n&lt;mat-toolbar class=&quot;app-header-container&quot; color=&quot;primary&quot;&gt;\n&lt;app-header (toggle)=&quot;onToggle($event)&quot; [sideNavOpened]=&quot;sideNavOpened&quot;&gt;&lt;/app-header&gt;\n&lt;/mat-toolbar&gt;\n&lt;div class=&quot;sidenav-container-outer&quot;&gt;\n&lt;div class=&quot;sidenav-container-inner&quot;&gt;\n&lt;mat-sidenav-container&gt;\n&lt;mat-sidenav [disableClose]=&quot;false&quot; [mode]=&quot;isMobile ? &apos;over&apos; : &apos;side&apos;&quot; [opened]=&quot;!isMobile || sideNavOpened&quot;\n#sidenav&gt;\n&lt;mat-nav-list&gt;\n&lt;!-- Sidenav links --&gt;\n&lt;a id=&quot;home&quot; mat-list-item [routerLink]=&quot;[&apos;./initial&apos;]&quot; (click)=&quot;close()&quot;&gt;\n&lt;mat-icon matListAvatar&gt;\nhome\n&lt;/mat-icon&gt;\n&lt;h3 matLine&gt;{{ &apos;home&apos; | transloco }}&lt;/h3&gt;\n&lt;p matLine class=&quot;desc&quot;&gt;{{ &apos;description&apos; | transloco }}&lt;/p&gt;&lt;/a&gt;\n&lt;a id=&quot;employee&quot; mat-list-item [routerLink]=&quot;[&apos;./employee&apos;]&quot; (click)=&quot;close()&quot;&gt;\n&lt;mat-icon matListAvatar&gt;\ngrid_on\n&lt;/mat-icon&gt;\n&lt;h3 matLine&gt; {{ &apos;employeemanagement.Employee.navData&apos; | transloco }} &lt;/h3&gt;\n&lt;p matLine class=&quot;desc&quot;&gt; {{ &apos;employeemanagement.Employee.navDataSub&apos; | transloco }} &lt;/p&gt;&lt;/a&gt;\n&lt;/mat-nav-list&gt;\n&lt;/mat-sidenav&gt;\n&lt;mat-sidenav-content&gt;\n&lt;div class=&quot;content-container-outer&quot;&gt;\n&lt;div class=&quot;content-container-inner&quot;&gt;\n&lt;router-outlet&gt;&lt;/router-outlet&gt;\n&lt;/div&gt;\n&lt;mat-toolbar class=&quot;public-footer&quot;&gt;\n&lt;span&gt;devonfw Application&lt;/span&gt;\n&lt;span&gt;devonfw&lt;/span&gt;\n&lt;/mat-toolbar&gt;\n&lt;/div&gt;\n&lt;/mat-sidenav-content&gt;\n&lt;/mat-sidenav-container&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;/div&gt;\nOpen the command prompt and execute devon npm install from your application folder, which would download all the required libraries.\nCheck the file environment.ts if the server path is correct. (for production you will have to change also the environment.prod.ts file)\nIn order to do that it&#x2019;s important to look at the application.properties to see the values as PATH, TCP port etc &#x2026;\nFor example in this case the URL should be since the context path is empty the server URLS should be like:\nexport const environment = {\nproduction: false,\nrestPathRoot: &apos;http://localhost:8081/&apos;,\nrestServiceRoot: &apos;http://localhost:8081/services/rest/&apos;,\nsecurity: &apos;csrf&apos;\n};\nWarning: REMEMBER to set security filed to csrf , if it is not configured already.\nNow run the devon ng serve -o command to run the Angular Application, from your application folder, as done before.\nIf the command execution is successful, the below screen will appear and it would be automatically redirected to the url:\nhttp://localhost:4200/login\nYou can login in the Web Application, with admin user and password.\nObviosuly, the BackEnd part must be online during this test!\nANGULAR WebApp DONE\nIonic Mobile App\nTo generate Ionic structure, download or clone *devon4ng-application-template* from\nhttps://github.com/devonfw/devon4ng-ionic-application-template\nOnce downloaded the zip (or cloned) the name of the folder used, must be: devon4ng-ionic-application-template\nOnce done, Right click on the EmployeeEto as you already did before in order to use CobiGen.\nClick on the selected options as seen in the screenshot:\nClick on Finish\nThe entire ionic structure will be auto generated.\nChange (if necessary) the server url (with correct serve url) in environment.ts, environment.prod.ts and environment.android.ts files (i.e: itapoc\\devon4ng-ionic-application-template\\src\\environments\\).\nThe angular.json file inside the project has already a build configuration for android.\nThe only TWO thing that you have to modify, in this IONIC app is in employee-list.page.html and business-operator.service.ts.y\n1:\nYou have to change this line:\n&lt;layoutheader Title=&quot;Employee&quot;&gt;&lt;/layoutheader&gt;\nwith this line:\n&lt;app-layout-header title=&quot;Employee&quot;&gt;&lt;/app-layout-header&gt;\n2:\nYou have to change this line:\nreturn this.restPath + &apos;/security/v1/csrftoken&apos;;\nwith this line:\nreturn this.restPath + &apos;csrf/v1/token/&apos;;\nOnce checked if all the files are correct, open a CMD devon CLI on the folder of the ionic template application, under your devonFW workspace.\nIn this folder:\nRun the command *devon npm install* in the root folder to download the dependecies.\nOnce finished, run the command *devon ionic serve*\nOnce the execution is successful, you can make the LOGIN with admin/admin and&#x2026;&#x200B;\nIONIC Mobile App DONE\nSo: Well Done!!!\nStarting from an Entity class you&#x2019;ve successfully generated the Back-End layer (REST, SOAP, DTO, Spring services, Hibernate DAO), the Angular Web App and the Ionic mobile App!\nBuild APK\nSince We&#x2019;re going to create apk remember the following pre-conditions:\nGradle\nAndroid Studio\nAndroid sdk\nCapacitor\nNow, open cmd and type the path where your devon4ng-ionic-application-template project is present.\nRun the following commands:\nnpx cap init\nionic build --configuration=android\nnpx cap add android\nnpx cap copy\nnpx cap open android\nBuild the APK using Android studio.\nYou can find your apk file in:\n/devon4ng-ionic-application-template/android/app/build/outputs/apk/debug\n"},{"id":582,"path":"../website/pages/docs/master-cobigen.asciidoc_how-to.html#howto-devonfw-CobiGen-OpenAPI.asciidoc","type":"docs","title":"End to End POC Code generation using OpenAPI","body":"75.8. End to End POC Code generation using OpenAPI\nThis article helps to create a sample application using cobigen.\n"},{"id":583,"path":"../website/pages/docs/master-cobigen.asciidoc_how-to.html#howto-devonfw-cobigen-openapi.asciidoc_prerequisites","type":"docs","title":"Prerequisites","body":"75.8.1. Prerequisites\nDownload and install devonnfw IDE here,\n"},{"id":584,"path":"../website/pages/docs/master-cobigen.asciidoc_how-to.html#howto-devonfw-cobigen-openapi.asciidoc_steps-to-create-a-sample-project-using-cobigen","type":"docs","title":"Steps to create a Sample Project using Cobigen","body":"75.8.2. Steps to create a Sample Project using Cobigen\nThe HOW_TO is divided in 2 parts:\nBE-Back End generator (DB + DAO + services) &#x2013; CONTRACT FIRST APPROACH\nFE-Front End generator (Web App Angular + Ionic App) &#x2013; CONTRACT FIRST APPROACH\nSo, ready to go! We&#x2019;re going to start from the BE part &#x2026;\nBack End\nUnder your path installation of DevonFW, you can find the eclipe-main.bat script and you can run it:\nrun installation_path\\eclipse-main.bat\nIt will open eclipse\nCreate a project using below command from the command prompt.\nTo made it, it&#x2019;s necessary to open a CMD and open the folder where it&#x2019;s installed DevonFW and launch this command under the path workspaces/main\ndevon java create com.example.domain.myapp\nImport the project to eclipse as maven project\nClick FINISH\nNow We have the following 4 projects.\nBEFORE to start to create an Entity class, remember to create the tables, for this POC it&#x2019;s used an H2 Database!\nCreate a new SQL file (i.e: V0002__CreateTables_myapp.sql) inside myapp-core , under the folder path /myapp-core/src/main/resources/db/migration/1.0 and insert the following script:\nCREATE TABLE EMPLOYEE (\nid BIGINT auto_increment, modificationCounter INTEGER NOT NULL,\nemployeeid BIGINT auto_increment,\nname VARCHAR(255),\nsurname VARCHAR(255),\nemail VARCHAR(255),\nPRIMARY KEY (employeeid)\n);\nWARNING 1: please note that there in that folder is present only one file, 0001, and you have to add the other files in progressive number order (i.e. 0002)!\nWARNING 2: please note that there are 2 underscore in the name!\nNow create another SQL file (i.e: V0003__PopulateTables-myapp.sql) and add following script about the INSERT in order to populate the table created before.\nThe script must be inserted at the same path used before: /myapp-core/src/main/resources/db/migration/1.0\nWARNING 1: please note that there in that folder is present only one file, 0001, and you have to add the other files in progressive number order (i.e. 0003)!\nWARNING 2: please note that there are 2 underscore in the name!\nINSERT INTO EMPLOYEE (id, modificationCounter, employeeid, name, surname,email) VALUES (1, 1, 1, &apos;John&apos;,&apos;Doe&apos;,&apos;john.doe@example.com&apos;);\nINSERT INTO EMPLOYEE (id, modificationCounter, employeeid, name, surname,email) VALUES (2, 2, 2, &apos;Tom&apos;,&apos;Smith&apos;, &apos;tom.smith@example.com&apos;);\nINSERT INTO EMPLOYEE (id, modificationCounter, employeeid, name, surname,email) VALUES (3, 3, 3, &apos;Joe&apos;,&apos;Schmoe&apos;, &apos;joe.schmoe@example.com&apos;);\nLet&#x2019;s create the yml file for the code generation\nNow create a new file devonfw.yml in the root of your core folder. This will be our OpenAPI contract, like shown below. Then, copy the contents of this file into your OpenAPI. It defines some REST service endpoints and a EmployeeEntity with its properties defined.\nImportant 1: Please pay attention to the content of the devonfw.yml file.\nThe section x-rootpackage it must be filled with the same package used when you have created the java application.\nSo i.e. if you have creaated the BE Java Application with:\ndevon java create com.example.domain.myapp\nYou have to populate the devonfw.yml in this way:\nx-rootpackage: com.example.domain.myapp\nImportant 2: if you want to know how to write an OpenAPI contract compatible with CobiGen, please read this tutorial.\nUse Cobigen to generate code. Right click devonfw.yml. CobiGen &#x2192; Generate\nIf it will ask you to download the templates, click on update:\nIt will automatically download the latest version of CobiGen_Templates.\nAttention: If you want to adapt the CobiGen_Templates, (normally this is not neccessary), you will find at the end of this document (in a separate chapter) a tutorial on how to import them and adapt them!\nClick on all the option selected as below:\nClick on finish. Below Screen would be seen. Click on continue\nThe entire BE layer structure having CRUD operation methods will be auto generated.\nSome classes will be generated on the api part (myapp-api), normally it will be interfaces, as shown below:\nSome other classes will be generated on the core part (myapp-core), normally it will be implementations as shown below:\nThe last step is to add the Cross Domain process, because when you are developing Javascript client and server application separately, you have to deal with cross domain issues.\nSo, we need to prepare server side to accept request from other domains. We need to cover the following points:\nAccept request from other domains.\nAccept devonfw used headers like X-CSRF-TOKEN or correlationId.\nBe prepared to receive secured request (cookies).\nTo do this it&#x2019;s necessary to add two kind of dependecies in the pom.xml of the myapp-core folder, at the end of the list of dependecies:\n&lt;dependency&gt;\n&lt;groupId&gt;com.devonfw.java.starters&lt;/groupId&gt;\n&lt;artifactId&gt;devon4j-starter-security-cors&lt;/artifactId&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n&lt;groupId&gt;com.devonfw.java.starters&lt;/groupId&gt;\n&lt;artifactId&gt;devon4j-starter-security-csrf&lt;/artifactId&gt;\n&lt;/dependency&gt;\nNext step is to add some prperties under your application.properties file, in the myapp-core folder in the resources/config:\nsecurity.cors.spring.allowCredentials=true\nsecurity.cors.spring.allowedOriginPatterns=*\nsecurity.cors.spring.allowedHeaders=*\nsecurity.cors.spring.allowedMethods=OPTIONS,HEAD,GET,PUT,POST,DELETE,PATCH\nsecurity.cors.pathPattern=/**\nBEFORE to generate the FE, please start the Tomcat server to check that BE Layer has been generated properly.\nTo start a server you just have to right click on SpringBootApp.java &#x2192; run as &#x2192; Java Application\nBE DONE\nLast but not least: We make a quick REST services test !\nSee in the application.properties the TCP Port and the PATH\nNow compose the Rest service URL:\nservice class &lt;path&gt;/&lt;service method path&gt;\n&lt;server&gt; refers to server with port no. (ie: localhost:8081)\n&lt;app&gt; is in the application.properties (empty in our case, see above)\n&lt;rest service class path&gt; refers to EmployeemanagementRestService: (i.e: /employeemanagement/v1)\n&lt;service method path&gt;/employee/{id} (i.e: for getEmployee method)\nURL of getEmployee for this example is:\nFor all employees (POST)\nhttp://localhost:8081/services/rest/employeemanagement/v1/employee/search\nFor the specific employee (GET)\nhttp://localhost:8081/services/rest/employeemanagement/v1/employee/1\nNow download Postman to test the rest services.\nOnce done, you have to create a POST Request for the LOGIN and insert in the body the JSON containing the username and password admin\nWARNING: please note that the body of the request must be JSON type!\nOnce done with success (Status: 200 OK) - you can see the status of the response in the top right corner of Postman - we can create a NEW GET Request in order to get one employee.\nTo do this you have to create a new request in Postman, GET type, and insert the URL specified before:\nhttp://localhost:8081/services/rest/employeemanagement/v1/employee/1\nThenk click on &quot;SEND&quot; button&#x2026;&#x200B;\nNow you&#x2018;ve to check that response has got Status: 200 OK and to see the below Employee\nNow that We have successfully tested the BE is time to go to create the FE !\nFront End\nLet&#x2019;s start now with angular Web and then Ionic app.\nAngular Web App\nTo generate angular structure, download or clone devon4ng-application-template from\nhttps://github.com/devonfw/devon4ng-application-template\nIMPORTANT when you download the zip of the source code of your FE application, the name of the app MUST BE devon4ng-application-template and you can extract it in youe DevonFW folder, under workspaces/main\nOnce downloaded the APP, you can open the application with your favourite IDE (Intellij or Visual Studio Code)\nOnce done, Right click on the devonfw.yml in order to use CobiGen.\nClick on the selected options as seen in the screenshot:\nClick on Finish\nThe entire ANGULAR structure has been auto generated. The generated code will be merged to the existing.\nIMPORTANT now you have to check in the app-routing.module.ts file, if the content corresponding to the code below:\nimport { NgModule } from &apos;@angular/core&apos;;\nimport { RouterModule, Routes } from &apos;@angular/router&apos;;\nimport { AuthGuard } from &apos;./core/security/auth-guard.service&apos;;\nimport { NavBarComponent } from &apos;./layout/nav-bar/nav-bar.component&apos;;\nconst routes: Routes = [{\npath: &apos;&apos;,\nredirectTo: &apos;/login&apos;,\npathMatch: &apos;full&apos;\n},\n{\npath: &apos;login&apos;,\nloadChildren: () =&gt;\nimport(&apos;./auth/auth.module&apos;).then(m =&gt; m.AuthDataModule)\n},\n{\npath: &apos;home&apos;,\ncomponent: NavBarComponent,\ncanActivateChild: [\nAuthGuard\n],\nchildren: [{\npath: &apos;initial&apos;,\nloadChildren: () =&gt;\nimport(&apos;./home/initial-page/initial-page.module&apos;).then(\nm =&gt; m.InitialPageModule,\n)\n},\n{\npath: &apos;employee&apos;,\nloadChildren: () =&gt;\nimport(&apos;./employee/employee.module&apos;).then(\nm =&gt; m.EmployeeModule,\n)\n}\n]\n},\n{\npath: &apos;**&apos;,\nredirectTo: &apos;/login&apos;\n},\n];\n@NgModule({\nimports: [\nRouterModule.forRoot(routes)\n],\nexports: [\nRouterModule\n]\n})\nexport class AppRoutingModule {\n}\nAfter that, if you want to make visible the Employee Grid in you FE application, you have to modify the nav-bar.component.html, to add the Employee grid in the section:\n&lt;div class=&quot;home-container-outer&quot;&gt;\n&lt;div class=&quot;home-container-inner&quot;&gt;\n&lt;mat-toolbar class=&quot;app-header-container&quot; color=&quot;primary&quot;&gt;\n&lt;app-header (toggle)=&quot;onToggle($event)&quot; [sideNavOpened]=&quot;sideNavOpened&quot;&gt;&lt;/app-header&gt;\n&lt;/mat-toolbar&gt;\n&lt;div class=&quot;sidenav-container-outer&quot;&gt;\n&lt;div class=&quot;sidenav-container-inner&quot;&gt;\n&lt;mat-sidenav-container&gt;\n&lt;mat-sidenav [disableClose]=&quot;false&quot; [mode]=&quot;isMobile ? &apos;over&apos; : &apos;side&apos;&quot; [opened]=&quot;!isMobile || sideNavOpened&quot;\n#sidenav&gt;\n&lt;mat-nav-list&gt;\n&lt;!-- Sidenav links --&gt;\n&lt;a id=&quot;home&quot; mat-list-item [routerLink]=&quot;[&apos;./initial&apos;]&quot; (click)=&quot;close()&quot;&gt;\n&lt;mat-icon matListAvatar&gt;\nhome\n&lt;/mat-icon&gt;\n&lt;h3 matLine&gt;{{ &apos;home&apos; | transloco }}&lt;/h3&gt;\n&lt;p matLine class=&quot;desc&quot;&gt;{{ &apos;description&apos; | transloco }}&lt;/p&gt;&lt;/a&gt;\n&lt;a id=&quot;employee&quot; mat-list-item [routerLink]=&quot;[&apos;./employee&apos;]&quot; (click)=&quot;close()&quot;&gt;\n&lt;mat-icon matListAvatar&gt;\ngrid_on\n&lt;/mat-icon&gt;\n&lt;h3 matLine&gt; {{ &apos;employeemanagement.Employee.navData&apos; | transloco }} &lt;/h3&gt;\n&lt;p matLine class=&quot;desc&quot;&gt; {{ &apos;employeemanagement.Employee.navDataSub&apos; | transloco }} &lt;/p&gt;&lt;/a&gt;\n&lt;/mat-nav-list&gt;\n&lt;/mat-sidenav&gt;\n&lt;mat-sidenav-content&gt;\n&lt;div class=&quot;content-container-outer&quot;&gt;\n&lt;div class=&quot;content-container-inner&quot;&gt;\n&lt;router-outlet&gt;&lt;/router-outlet&gt;\n&lt;/div&gt;\n&lt;mat-toolbar class=&quot;public-footer&quot;&gt;\n&lt;span&gt;devonfw Application&lt;/span&gt;\n&lt;span&gt;devonfw&lt;/span&gt;\n&lt;/mat-toolbar&gt;\n&lt;/div&gt;\n&lt;/mat-sidenav-content&gt;\n&lt;/mat-sidenav-container&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;/div&gt;\nOpen the command prompt and execute devon npm install from your application folder, which would download all the required libraries.\nCheck the file environment.ts if the server path is correct. (for production you will have to change also the environment.prod.ts file)\nIn order to do that it&#x2019;s important to look at the application.properties to see the values as PATH, TCP port etc &#x2026;\nFor example in this case the URL should be since the context path is empty the server URLS should be like:\nexport const environment = {\nproduction: false,\nrestPathRoot: &apos;http://localhost:8081/&apos;,\nrestServiceRoot: &apos;http://localhost:8081/services/rest/&apos;,\nsecurity: &apos;csrf&apos;\n};\nWarning: REMEMBER to set security filed to csrf , if it is not configured already.\nNow run the devon ng serve -o command to run the Angular Application, from your application folder, as done before.\nIf the command execution is successful, the below screen will appear and it would be automatically redirected to the url:\nhttp://localhost:4200/login\nYou can login in the Web Application, with admin user and password.\nObviosuly, the BackEnd part must be online during this test!\nANGULAR WebApp DONE\nIonic Mobile App\nTo generate Ionic structure, download or clone *devon4ng-application-template* from\nhttps://github.com/devonfw/devon4ng-ionic-application-template\nOnce downloaded the zip (or cloned) the name of the folder used, must be: devon4ng-ionic-application-template\nOnce done, Right click on the devonfw.yml as you already did before in order to use CobiGen.\nClick on the selected options as seen in the screenshot:\nClick on Finish\nThe entire ionic structure will be auto generated.\nChange (if necessary) the server url (with correct serve url) in environment.ts, environment.prod.ts and environment.android.ts files (i.e: itapoc\\devon4ng-ionic-application-template\\src\\environments\\).\nThe angular.json file inside the project has already a build configuration for android.\nThe only TWO thing that you have to modify, in this IONIC app is in employee-list.page.html and business-operator.service.ts.y\n1:\nYou have to change this line:\n&lt;layoutheader Title=&quot;Employee&quot;&gt;&lt;/layoutheader&gt;\nwith this line:\n&lt;app-layout-header title=&quot;Employee&quot;&gt;&lt;/app-layout-header&gt;\n2:\nYou have to change this line:\nreturn this.restPath + &apos;/security/v1/csrftoken&apos;;\nwith this line:\nreturn this.restPath + &apos;csrf/v1/token/&apos;;\nOnce checked if all the files are correct, open a CMD devon CLI on the folder of the ionic template application, under your devonFW workspace.\nIn this folder:\nRun the command *devon npm install* in the root folder to download the dependecies.\nOnce finished, run the command *devon ionic serve*\nOnce the execution is successful, you can make the LOGIN with admin/admin and&#x2026;&#x200B;\nIONIC Mobile App DONE\nSo: Well Done!!!\nStarting from an Entity class you&#x2019;ve successfully generated the Back-End layer (REST, SOAP, DTO, Spring services, Hibernate DAO), the Angular Web App and the Ionic mobile App!\nBuild APK\nSince We&#x2019;re going to create apk remember the following pre-conditions:\nGradle\nAndroid Studio\nAndroid sdk\nCapacitor\nNow, open cmd and type the path where your devon4ng-ionic-application-template project is present.\nRun the following commands:\nnpx cap init\nionic build --configuration=android\nnpx cap add android\nnpx cap copy\nnpx cap open android\nBuild the APK using Android studio.\nYou can find your apk file in:\n/devon4ng-ionic-application-template/android/app/build/outputs/apk/debug\n"},{"id":585,"path":"../website/pages/docs/master-cobigen.asciidoc_how-to.html#howto-devonfw-adapt_template.asciidoc","type":"docs","title":"Adapt Templates from Cobigen","body":"75.9. Adapt Templates from Cobigen\n"},{"id":586,"path":"../website/pages/docs/master-cobigen.asciidoc_how-to.html#howto-devonfw-adapt_template.asciidoc_adapt-cobigen_templates","type":"docs","title":"Adapt CobiGen_Templates","body":"75.9.1. Adapt CobiGen_Templates\nAfter following this tutorial, you will have the CobiGen_Templates downloaded on your local machine. To import these templates you need to do the following:\nRight click in any part of the package explorer, then click on CobiGen &#x2192; Adapt templates\nClick Ok:\nNow the CobiGen_Templates project will be automatically imported into your workspace, as shown on the image below:\nNow you just need to change the Java version of the project to JRE 1.8. Right click on the JRE system library, and then on Properties:\nNow change the version to Java 1.8\nNow you have successfully imported the CobiGen templates. If you want to edit them, you will find them in the folder src/main/templates. For instance, the Java templates are located here:\nNow you can adapt the templates as much as you want. Documentation about this can be found on:\nhttps://github.com/devonfw/tools-cobigen/wiki/Guide-to-the-Reader\n"},{"id":587,"path":"../website/pages/docs/master-cobigen.asciidoc_how-to.html#howto_enable_composite_primary_keys_in_entity.asciidoc","type":"docs","title":"Enable Composite Primary Keys in Entity","body":"75.10. Enable Composite Primary Keys in Entity\nIn order to enable Composite Primary Keys in entity in CobiGen, the below approach is suggested\nThe templates in cobigen have been enhanced to support Composite primary keys while still supporting the default devonfw/Cobigen values with Long id.\nAlso, the current generation from Entity still holds good - right click from an Entity object, CobiGen &#x2192; Generate will show the CobiGen wizard relative to the entity generation.\nAfter generating, below example shows how composite primary keys can be enabled.\n@Entity\n@Table(name = &quot;employee&quot;)\npublic class EmployeeEntity {\nprivate CompositeEmployeeKey id;\nprivate String name;\nprivate String lastName;\n@Override\n@EmbeddedId\npublic CompositeEmployeeKey getId() {\nreturn id;\n}\n@Override\npublic void setId(CompositeEmployeeKey id) {\nthis.id = id;\n}\n.\n.\n.\npublic class CompositeEmployeeKey implements Serializable {\nprivate String companyId;\nprivate String employeeId;\nOnce the generation is complete, implement PersistenceEntity&lt;ID&gt;.java in the EmployeeEntity and pass the composite primary key object which is CompositeEmployeeKey in this case as the parameter ID.\nimport com.devonfw.module.basic.common.api.entity.PersistenceEntity;\n@Entity\n@Table(name = &quot;employee&quot;)\npublic class EmployeeEntity implements PersistenceEntity&lt;CompositeEmployeeKey&gt; {\nprivate CompositeEmployeeKey id;\nprivate String name;\nprivate String lastName;\nAlso, the modificationCounter methods needs to be implemented from the interface PersistenceEntity&lt;ID&gt;. The sample implementation of the modification counter can be referred below.\n@Override\npublic int getModificationCounter() {\nif (this.persistentEntity != null) {\n// JPA implementations will update modification counter only after the transaction has been committed.\n// Conversion will typically happen before and would result in the wrong (old) modification counter.\n// Therefore we update the modification counter here (that has to be called before serialization takes\n// place).\nthis.modificationCounter = this.persistentEntity.getModificationCounter();\n}\nreturn this.modificationCounter;\n}\n@Override\npublic void setModificationCounter(int version) {\nthis.modificationCounter = version;\n}\n&#x2190;&#xA0;Previous:&#xA0;Eclipse Integration&#xA0;| &#x2191;&#xA0;Up:&#xA0;CobiGen&#x2009;&#x2014;&#x2009;Code-based incremental Generator&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Template Development&#xA0;&#x2192;\n"},{"id":588,"path":"../website/pages/docs/master-cobigen.asciidoc_maven-build-integration.html#master-cobigen.asciidoc_maven-build-integration","type":"docs","title":"Maven Build Integration","body":"73. Maven Build Integration\n"},{"id":589,"path":"../website/pages/docs/master-cobigen.asciidoc_maven-build-integration.html#cobigen-maven_configuration.asciidoc","type":"docs","title":"Maven Build Integration","body":"73.1. Maven Build Integration\nFor maven integration of CobiGen you can include the following build plugin into your build:\nListing 127. Build integration of CobiGen\n&lt;build&gt;\n&lt;plugins&gt;\n&lt;plugin&gt;\n&lt;groupId&gt;com.devonfw.cobigen&lt;/groupId&gt;\n&lt;artifactId&gt;cobigen-maven-plugin&lt;/artifactId&gt;\n&lt;version&gt;VERSION-YOU-LIKE&lt;/version&gt;\n&lt;executions&gt;\n&lt;execution&gt;\n&lt;id&gt;cobigen-generate&lt;/id&gt;\n&lt;phase&gt;generate-resources&lt;/phase&gt;\n&lt;goals&gt;\n&lt;goal&gt;generate&lt;/goal&gt;\n&lt;/goals&gt;\n&lt;/execution&gt;\n&lt;/executions&gt;\n&lt;/plugin&gt;\n&lt;/plugins&gt;\n&lt;/build&gt;\nAvailable goals\ngenerate: Generates contents configured by the standard non-compiled configuration folder. Thus generation can be controlled/configured due to an location URI of the configuration and template or increment ids to be generated for a set of inputs.\nAvailable phases are all phases, which already provide compiled sources such that CobiGen can perform reflection on it. Thus possible phases are for example package, site.\n"},{"id":590,"path":"../website/pages/docs/master-cobigen.asciidoc_maven-build-integration.html#cobigen-maven_configuration.asciidoc_provide-template-set","type":"docs","title":"Provide Template Set","body":"73.1.1. Provide Template Set\nFor generation using the CobiGen maven plug-in, the CobiGen configuration can be provided in two different styles:\nBy a configurationFolder, which should be available on the file system whenever you are running the generation. The value of configurationFolder should correspond to the maven file path syntax.\nListing 128. Provide CobiGen configuration by configuration folder (file)\n&lt;build&gt;\n&lt;plugins&gt;\n&lt;plugin&gt;\n...\n&lt;configuration&gt;\n&lt;configurationFolder&gt;cobigen-templates&lt;/configurationFolder&gt;\n&lt;/configuration&gt;\n...\n&lt;/plugin&gt;\n&lt;/plugins&gt;\n&lt;/build&gt;\nBy maven dependency, whereas the maven dependency should stick on the same conventions as the configuration folder. This explicitly means that it should contain non-compiled resources as well as the context.xml on top-level.\nListing 129. Provide CobiGen configuration by maven dependency (jar)\n&lt;build&gt;\n&lt;plugins&gt;\n&lt;plugin&gt;\n...\n&lt;dependencies&gt;\n&lt;dependency&gt;\n&lt;groupId&gt;com.devonfw.cobigen&lt;/groupId&gt;\n&lt;artifactId&gt;templates-XYZ&lt;/artifactId&gt;\n&lt;version&gt;VERSION-YOU-LIKE&lt;/version&gt;\n&lt;/dependency&gt;\n&lt;/dependencies&gt;\n...\n&lt;/plugin&gt;\n&lt;/plugins&gt;\n&lt;/build&gt;\nWe currently provide a generic deployed version of the templates on the devonfw-nexus for Register Factory (&lt;artifactId&gt;cobigen-templates-rf&lt;/artifactId&gt;) and for the devonfw itself (&lt;artifactId&gt;cobigen-templates-devonfw&lt;/artifactId&gt;).\n"},{"id":591,"path":"../website/pages/docs/master-cobigen.asciidoc_maven-build-integration.html#cobigen-maven_configuration.asciidoc_build-configuration","type":"docs","title":"Build Configuration","body":"73.1.2. Build Configuration\nUsing the following configuration you will be able to customize your generation as follows:\n&lt;destinationRoot&gt; specifies the root directory the relative destinationPath of CobiGen templates configuration should depend on. Default ${basedir}\n&lt;inputPackage&gt; declares a package name to be used as input for batch generation. This refers directly to the CobiGen Java Plug-in container matchers of type package configuration.\n&lt;inputFile&gt; declares a file to be used as input. The CobiGen maven plug-in will try to parse this file to get an appropriate input to be interpreted by any CobiGen plug-in.\n&lt;increment&gt; specifies an increment ID to be generated. You can specify one single increment with content ALL to generate all increments matching the input(s).\n&lt;template&gt; specifies a template ID to be generated. You can specify one single template with content ALL to generate all templates matching the input(s).\n&lt;forceOverride&gt; specifies an overriding behavior, which enables non-mergeable resources to be completely rewritten by generated contents. For mergeable resources this flag indicates, that conflicting fragments during merge will be replaced by generated content. Default: false\n&lt;failOnNothingGenerated&gt; specifies whether the build should fail if the execution does not generate anything.\nListing 130. Example for a simple build configuration\n&lt;build&gt;\n&lt;plugins&gt;\n&lt;plugin&gt;\n...\n&lt;configuration&gt;\n&lt;destinationRoot&gt;${basedir}&lt;/destinationRoot&gt;\n&lt;inputPackages&gt;\n&lt;inputPackage&gt;package.to.be.used.as.input&lt;/inputPackage&gt;\n&lt;/inputPackages&gt;\n&lt;inputFiles&gt;\n&lt;inputFile&gt;path/to/file/to/be/used/as/input&lt;/inputFile&gt;\n&lt;/inputFiles&gt;\n&lt;increments&gt;\n&lt;increment&gt;IncrementID&lt;/increment&gt;\n&lt;/increments&gt;\n&lt;templates&gt;\n&lt;template&gt;TemplateID&lt;/template&gt;\n&lt;/templates&gt;\n&lt;forceOverride&gt;false&lt;/forceOverride&gt;\n&lt;/configuration&gt;\n...\n&lt;/plugin&gt;\n&lt;/plugins&gt;\n&lt;/build&gt;\n"},{"id":592,"path":"../website/pages/docs/master-cobigen.asciidoc_maven-build-integration.html#cobigen-maven_configuration.asciidoc_plugin-injection-since-v3","type":"docs","title":"Plugin Injection Since v3","body":"73.1.3. Plugin Injection Since v3\nSince version 3.0.0, the plug-in mechanism has changed to support modular releases of the CobiGen plug-ins. Therefore, you need to add all plug-ins to be used for generation. Take the following example to get the idea:\nListing 131. Example of a full configuration including plugins\n&lt;build&gt;\n&lt;plugins&gt;\n&lt;plugin&gt;\n&lt;groupId&gt;com.devonfw.cobigen&lt;/groupId&gt;\n&lt;artifactId&gt;cobigen-maven-plugin&lt;/artifactId&gt;\n&lt;version&gt;VERSION-YOU-LIKE&lt;/version&gt;\n&lt;executions&gt;\n...\n&lt;/executions&gt;\n&lt;configuration&gt;\n...\n&lt;/configuration&gt;\n&lt;dependencies&gt;\n&lt;dependency&gt;\n&lt;groupId&gt;com.devonfw.cobigen&lt;groupId&gt;\n&lt;artifactId&gt;templates-devon4j&lt;/artifactId&gt;\n&lt;version&gt;2.0.0&lt;/version&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n&lt;groupId&gt;com.devonfw.cobigen&lt;/groupId&gt;\n&lt;artifactId&gt;tempeng-freemarker&lt;/artifactId&gt;\n&lt;version&gt;1.0.0&lt;/version&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n&lt;groupId&gt;com.devonfw.cobigen&lt;/groupId&gt;\n&lt;artifactId&gt;javaplugin&lt;/artifactId&gt;\n&lt;version&gt;1.6.0&lt;/version&gt;\n&lt;/dependency&gt;\n&lt;/dependencies&gt;\n&lt;/plugin&gt;\n&lt;/plugins&gt;\n&lt;/build&gt;\n"},{"id":593,"path":"../website/pages/docs/master-cobigen.asciidoc_maven-build-integration.html#cobigen-maven_configuration.asciidoc_a-full-example","type":"docs","title":"A full example","body":"73.1.4. A full example\nA complete maven configuration example\n&lt;build&gt;\n&lt;plugins&gt;\n&lt;plugin&gt;\n&lt;groupId&gt;com.devonfw.cobigen&lt;/groupId&gt;\n&lt;artifactId&gt;cobigen-maven-plugin&lt;/artifactId&gt;\n&lt;version&gt;6.0.0&lt;/version&gt;\n&lt;executions&gt;\n&lt;execution&gt;\n&lt;id&gt;generate&lt;/id&gt;\n&lt;phase&gt;package&lt;/phase&gt;\n&lt;goals&gt;\n&lt;goal&gt;generate&lt;/goal&gt;\n&lt;/goals&gt;\n&lt;/execution&gt;\n&lt;/executions&gt;\n&lt;configuration&gt;\n&lt;inputFiles&gt;\n&lt;inputFile&gt;src/main/java/io/github/devonfw/cobigen/generator/dataaccess/api/InputEntity.java&lt;/inputFile&gt;\n&lt;/inputFiles&gt;\n&lt;increments&gt;\n&lt;increment&gt;dataaccess_infrastructure&lt;/increment&gt;\n&lt;increment&gt;daos&lt;/increment&gt;\n&lt;/increments&gt;\n&lt;failOnNothingGenerated&gt;false&lt;/failOnNothingGenerated&gt;\n&lt;/configuration&gt;\n&lt;dependencies&gt;\n&lt;dependency&gt;\n&lt;groupId&gt;com.devonfw.cobigen&lt;/groupId&gt;\n&lt;artifactId&gt;templates-devon4j&lt;/artifactId&gt;\n&lt;version&gt;2.0.0&lt;/version&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n&lt;groupId&gt;com.devonfw.cobigen&lt;/groupId&gt;\n&lt;artifactId&gt;tempeng-freemarker&lt;/artifactId&gt;\n&lt;version&gt;2.0.0&lt;/version&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n&lt;groupId&gt;com.devonfw.cobigen&lt;/groupId&gt;\n&lt;artifactId&gt;javaplugin&lt;/artifactId&gt;\n&lt;version&gt;1.6.0&lt;/version&gt;\n&lt;/dependency&gt;\n&lt;/dependencies&gt;\n&lt;/plugin&gt;\n&lt;/plugins&gt;\n&lt;/build&gt;\n&#x2190;&#xA0;Previous:&#xA0;CobiGen CLI&#xA0;| &#x2191;&#xA0;Up:&#xA0;CobiGen&#x2009;&#x2014;&#x2009;Code-based incremental Generator&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Eclipse Integration&#xA0;&#x2192;\n"},{"id":594,"path":"../website/pages/docs/master-cobigen.asciidoc_template-development.html#master-cobigen.asciidoc_template-development","type":"docs","title":"Template Development","body":"76. Template Development\n"},{"id":595,"path":"../website/pages/docs/master-cobigen.asciidoc_template-development.html#cobigen-templates_helpful-links.asciidoc","type":"docs","title":"Helpful links for template development","body":"76.1. Helpful links for template development\nFreeMarker Root Page\nExpressions Cheat Sheet\nComplete Language reference\nFreeMarker Template Tester\nVariables to access Java source model\n&#x2190;&#xA0;Previous:&#xA0;How to&#xA0;| &#x2191;&#xA0;Up:&#xA0;CobiGen&#x2009;&#x2014;&#x2009;Code-based incremental Generator&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;MrChecker - devonfw testing tool&#xA0;&#x2192;\n"},{"id":596,"path":"../website/pages/docs/master-contributing.asciidoc.html#master-contributing.asciidoc","type":"docs","title":"XVI. Contributing","body":"XVI. Contributing\nContributing\nContributor Covenant Code of Conduct\nOSS Compliance\n&#x2190;&#xA0;Previous:&#xA0;Release Notes&#xA0;| &#x2191;&#xA0;Up:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Contributing&#xA0;&#x2192;\n"},{"id":597,"path":"../website/pages/docs/master-dashboard.asciidoc.html#master-dashboard.asciidoc","type":"docs","title":"XIV. devonfw dashboard","body":"XIV. devonfw dashboard\nLanding page\nHome\nProjects\nRepositories\nWiki\nSettings\n&#x2190;&#xA0;Previous:&#xA0;CI/CD&#xA0;| &#x2191;&#xA0;Up:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Landing page&#xA0;&#x2192;\n"},{"id":598,"path":"../website/pages/docs/master-dashboard.asciidoc_home.html#master-dashboard.asciidoc_home","type":"docs","title":"Home","body":"92. Home\n"},{"id":599,"path":"../website/pages/docs/master-dashboard.asciidoc_home.html#home-page.asciidoc","type":"docs","title":"Home page","body":"92.1. Home page\nThis is the main page that you will find after your profile creation and the page where you will start from henceforth.\nIt contains three sections as below:\nToolbar\nSidebar\nContent\n[[home-page.asciidoc_topbar-+]]\n== Topbar\nThis section is at the top of the page, it contains devonfw instance dropdown to select devonfw-ide that can be used as a base for the projects.\nNext to the devonfw instance dropdown, there is a quick help icon, clicking on it will open a popup which gives some tips for how to use Devon Dashboard IDE.\n[[home-page.asciidoc_sidebar-+]]\n== Sidebar\nThe sidebar has divided into two sections:\nUser Profile - Users can see his/her pic, name, and role.\nLinks to access to different sections of the dashboard.\n"},{"id":600,"path":"../website/pages/docs/master-dashboard.asciidoc_home.html#home-page.asciidoc_content-section","type":"docs","title":"Content Section","body":"92.1.1. Content Section\nThe Content section has also divided into three sections:\nA small introduction about the devonfw IDE\nA button to Download latest version of devonfw IDE\nA &quot;Project&quot; block which shows the total number of Projects which are available in different devonfw IDE\n[[home-page.asciidoc_steps-to-download-and-install-devonfw-ide-+]]\n== Steps to download and Install devonfw IDE\nStep 1: Click on Download latest version button which is in the Content section. Check the below screen for the reference.\nStep 2: By clicking Download latest version button, Installing devonfw popup will open.\nStep 3: Installing devonfw popup will automatically trigger one more popup to specify the location for downloading Devonfw IDE. Specify the location and click the Save button to download.\nStep 3: Once the download completes successfully, the Next button will be enabled for the further installation process.\nStep 4: By Clicking Next button in the Installing devonfw pop up, two options are shown:\n1: Select the Git url for the installation setup.\n2: Skip this process.\nStep 5: Select one of the above options.\nIf the selection is Git url, then Configuration file url should be filled in the input box and needs to click Next button to start the further installation process.\nIn case the user doesn&#x2019;t have Git url, then simply Skip the process and click the Next button to start the further installation process.\nStep 6: Click on the Next button for the final installation process. Wait for some time to complete the installation setup. Once the installation setup completes, the Close button will appear. Just click on it and go to the specified folder location.\n&#x2190;&#xA0;Previous:&#xA0;Landing page&#xA0;| &#x2191;&#xA0;Up:&#xA0;devonfw dashboard&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Projects&#xA0;&#x2192;\n"},{"id":601,"path":"../website/pages/docs/master-dashboard.asciidoc_landing-page.html#master-dashboard.asciidoc_landing-page","type":"docs","title":"Landing page","body":"91. Landing page\n"},{"id":602,"path":"../website/pages/docs/master-dashboard.asciidoc_landing-page.html#landing-page.asciidoc","type":"docs","title":"Landing page","body":"91.1. Landing page\nThis is the entry point of the devonfw dashboard. Click on GET STARTED NOW to start using it.\nFigure 89. Get Started\n"},{"id":603,"path":"../website/pages/docs/master-dashboard.asciidoc_landing-page.html#landing-page.asciidoc_your-devonfw-distributions","type":"docs","title":"Your devonfw distributions","body":"91.1.1. Your devonfw distributions\nThe first time you open the application you will get a dialog with all the devonfw distributions found on your machine. Click on OK GOT IT to continue.\nFigure 90. devon-ide distributions\n"},{"id":604,"path":"../website/pages/docs/master-dashboard.asciidoc_landing-page.html#landing-page.asciidoc_profile-form","type":"docs","title":"Profile form","body":"91.1.2. Profile form\nHere you will find a screen that allows you to create a profile. This is just for the purpose of customizing your dashboard.\nFigure 91. Profile\nFill the data and click on CREATE MY PROFILE if you want to create the profile at the moment or click WILL DO IT LATER to skip the creation.\n&#x2191;&#xA0;Up:&#xA0;devonfw dashboard&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Home&#xA0;&#x2192;\n"},{"id":605,"path":"../website/pages/docs/master-dashboard.asciidoc_projects.html#master-dashboard.asciidoc_projects","type":"docs","title":"Projects","body":"93. Projects\n"},{"id":606,"path":"../website/pages/docs/master-dashboard.asciidoc_projects.html#projects-page.asciidoc_introduction-to-project-management-in-the-dashboard","type":"docs","title":"Introduction to project management in the dashboard","body":"93.1. Introduction to project management in the dashboard\nThe dashboard manages multiple projects in multiple workspaces that include Angular, JAVA, and Node.\nThe dashboard provides rich UI for creating multiple projects, abstracting all the functionality which is usually required while creating an application like opening a command terminal, specifying workspace, and executing commands.\nThe dashboard makes it easy to see all the projects which are in different devonfw-ide workspace, just by changing the &quot;devonfw Instance&quot; dropdown.\nThe dashboard makes it very easy to open a project in a different IDE like Visual Studio or Eclipse respectively just by right click on the Project folder and open option.\nThe dashboard also makes it easy to delete the project, explore the project location.\n"},{"id":607,"path":"../website/pages/docs/master-dashboard.asciidoc_projects.html#projects-page.asciidoc_projects","type":"docs","title":"Projects","body":"93.2. Projects\nClick on the Projects link on the sidebar to navigate to the project&#x2019;s screen. The screen displays all the projects in the currently selected devonfw-ide, grouped by the workspaces in which they exist.\nNote: Currently it only displays projects created through the dashboard.\nIt shows the total number of projects available in each devonfw-ide.\nFiltering and searching the projects.\nAdd New Project - For creating a Project.\nProject folder which gives information about the project like which technology the project belongs to, the name of the project, and when it has created.\nThere are many operations that are available on right-click on Project folder they are :\nOpening a project in different IDE ( Visual Studio or Eclipse )\nEnclosing Folder, and\nDeleting the project.\nUsers can see projects of different devonfw-ide workspace just by changing the option in the devonfw instance dropdown which is set globally at the top of the screen.\nClick on Add New Project to start creating a new project.\n"},{"id":608,"path":"../website/pages/docs/master-dashboard.asciidoc_projects.html#projects-page.asciidoc_how-to-create-a-project","type":"docs","title":"How to create a project","body":"93.3. How to create a project\nThree main steps are involved in creating any devonfw project. They are:\nStep 1. Project Type\nIn this first step the user has to choose the language technology to start the project with, e.g. Angular, Java or Node and click the Next button for to continue to the next step.\nStep 2. Project Data\nAfter the Project type selection, the second screen will appear for the user to fill up all the required fields. User can select the workspace in the active devonfw-ide for the project in this step. Once the user enters all the required fields, the Next button will be enabled for the final step.\nUser can change the devonfw-ide workspace where the project is going to generate, just by changing the option in the devonfw instance dropdown which is set globally in the header of the dashboard.\nStep 3. Execution\nThe execution step takes all the user entered data from the Project Data step and executes the respective commands to generate the project.\nExecution has divided into two sections:\n- Creation\n- Setup Installation\n3.1 Creation\nCreates only source code and notify the user if the project creation fails or success.\nIn case any network issue or technical issue and the user wants to re-run the Project execution process, then the Retry button will help to start the process again.\n3.2 Setup installation\nAllows user to install the dependencies of application (maven modules for java, node modules for node, angular) by clicking Proceed button.\nThe installation can be skipped by clicking cancel button.\nStep 4. Click on Finish button to go to Project Details Screen.\n&#x2190;&#xA0;Previous:&#xA0;Home&#xA0;| &#x2191;&#xA0;Up:&#xA0;devonfw dashboard&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Repositories&#xA0;&#x2192;\n"},{"id":609,"path":"../website/pages/docs/master-dashboard.asciidoc_repositories.html#master-dashboard.asciidoc_repositories","type":"docs","title":"Repositories","body":"94. Repositories\n"},{"id":610,"path":"../website/pages/docs/master-dashboard.asciidoc_repositories.html#repositories-page.asciidoc","type":"docs","title":"Repositories","body":"94.1. Repositories\nThis page lists the different repositories under devonfw organization.\nFigure 92. Repositories\nThe list updates as you type in the search bar.\nFigure 93. Search Repositories\nYou can click COPY GITHUB URL for any of the repository list item to copy its github URL to your clipboard and clone it locally.\nYou can also click the OPEN REPOSITORY button to view its github repository page in your default browser.\n&#x2190;&#xA0;Previous:&#xA0;Projects&#xA0;| &#x2191;&#xA0;Up:&#xA0;devonfw dashboard&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Wiki&#xA0;&#x2192;\n"},{"id":611,"path":"../website/pages/docs/master-dashboard.asciidoc_settings.html#master-dashboard.asciidoc_settings","type":"docs","title":"Settings","body":"96. Settings\n"},{"id":612,"path":"../website/pages/docs/master-dashboard.asciidoc_settings.html#settings-page.asciidoc","type":"docs","title":"Settings","body":"96.1. Settings\n"},{"id":613,"path":"../website/pages/docs/master-dashboard.asciidoc_settings.html#settings-page.asciidoc_account-settings","type":"docs","title":"Account settings","body":"96.1.1. Account settings\nHere you get a screen that allows you to create a profile. This is the same screen which you see during the intial setup of the dashboard. It is completely optional.\nFigure 95. Account settings\nFill the data and click on Save if you want to create the profile.\n"},{"id":614,"path":"../website/pages/docs/master-dashboard.asciidoc_settings.html#settings-page.asciidoc_installed-versions","type":"docs","title":"Installed versions","body":"96.1.2. Installed versions\nThe installed versions subsection allows you to manage the different versions of devonfw-ide available.\nFigure 96. Installed versions\nIt lists the devonfw-ide you have installed in your system, along with the ones available for download from our maven repository\nIf you want to install specific version, you can search it here and DOWNLOAD it\nTo check the release notes for a version, simply click on Consolidated list of features\nFor the installed versions:\nHovering over the eye icon shows you the path for the devonfw-ide in a tooltip\nYou can view it in your system explorer by clicking the eye icon\nYou can update its settings and softwares by clicking on UPDATE\nYou can also UNINSTALL an installed version, after which the dashboard will no longer keep track of the projects and IDEs belonging to that devonfw-ide\n&#x2190;&#xA0;Previous:&#xA0;Wiki&#xA0;| &#x2191;&#xA0;Up:&#xA0;devonfw dashboard&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Solicitor User Guide&#xA0;&#x2192;\n"},{"id":615,"path":"../website/pages/docs/master-dashboard.asciidoc_wiki.html#master-dashboard.asciidoc_wiki","type":"docs","title":"Wiki","body":"95. Wiki\n"},{"id":616,"path":"../website/pages/docs/master-dashboard.asciidoc_wiki.html#wiki-page.asciidoc","type":"docs","title":"Wiki page.","body":"95.1. Wiki page.\nThis page displays the documentation of devonfw. You can also find it at https://devonfw.com/\nFigure 94. Wiki\n&#x2190;&#xA0;Previous:&#xA0;Repositories&#xA0;| &#x2191;&#xA0;Up:&#xA0;devonfw dashboard&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Settings&#xA0;&#x2192;\n"},{"id":617,"path":"../website/pages/docs/master-database.asciidoc.html#master-database.asciidoc","type":"docs","title":"VII. Choosing your Database","body":"VII. Choosing your Database\nDatabase\nSAP HANA\nOracle RDBMS\nMS-SQL-Server\nPostgreSQL\nMariaDB\nDatabase\nCassandra\nneo4j\nMongoDB\nCouchDB\nRedis\nOrientDB\nBlazegraph\nHBase\nRavenDB\nGigaSpaces XAP (Smart Cache)\n&#x2190;&#xA0;Previous:&#xA0;devon4node applications&#xA0;| &#x2191;&#xA0;Up:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Database&#xA0;&#x2192;\n"},{"id":618,"path":"../website/pages/docs/master-devon4net.asciidoc.html#master-devon4net.asciidoc","type":"docs","title":"V. devon4net","body":"V. devon4net\nArchitecture basics\nUser guide\nHow To section\nCobigen guide\nCoding conventions\nEnvironment\nPackages\nTemplates\nSamples\n&#x2190;&#xA0;Previous:&#xA0;Cookbook&#xA0;| &#x2191;&#xA0;Up:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Architecture basics&#xA0;&#x2192;\n"},{"id":619,"path":"../website/pages/docs/master-devon4net.asciidoc_architecture-basics.html#master-devon4net.asciidoc_architecture-basics","type":"docs","title":"Architecture basics","body":"23. Architecture basics\n"},{"id":620,"path":"../website/pages/docs/master-devon4net.asciidoc_architecture-basics.html#architecture_guide.asciidoc","type":"docs","title":"Introduction","body":"23.1. Introduction\nThe devonfw platform provides a solution to building applications which combine best-in-class frameworks and libraries as well as industry proven practices and code conventions.\nIt massively speeds up development, reduces risks and helps you to deliver better results.\n"},{"id":621,"path":"../website/pages/docs/master-devon4net.asciidoc_architecture-basics.html#architecture_guide.asciidoc_overview-onion-design","type":"docs","title":"Overview Onion Design","body":"23.1.1. Overview Onion Design\nThis guide shows the overall proposed architecture in terms of separated layers making use the Onion architecture pattern. Each layers represents a logical group of components and functionality. In this guide you will learn the basics of the proposed architecture based in layers in order to develop software making use of the best practices.\n"},{"id":622,"path":"../website/pages/docs/master-devon4net.asciidoc_architecture-basics.html#architecture_guide.asciidoc_layer-specification","type":"docs","title":"Layer specification","body":"23.1.2. Layer specification\nIt is important to understand the distinction between layers and tiers. Layers describe the logical groupings of the functionality and components in an application; whereas tiers describe the physical distribution of the functionality and components on separate servers, computers, networks, or remote locations. Although both layers and tiers use the same set of names (presentation, business, services, and data), remember that only tiers imply a physical separation. It is quite common to locate more than one layer on the same physical machine (the same tier). You can think of the term tier as referring to physical distribution patterns such as two-tier, three-tier, and n-tier.\n&#x2014; Layered Application Guidelines\nMSDN Microsoft\nThe proposed architecture makes use of cooperating components called layers. To develop specific functionality each layer contains a set of components which is capable to develop such functionalities.\nThe next figure represents the different layers:\nFigure 75. High level architecture representation\nThe layers are separated in physical tiers making use of interfaces. This pattern makes possible to be flexible in different kind of projects maximizing performance and deployment strategies (synchronous/asynchronous access, security, component deployment in different environments, microservices&#x2026;&#x200B;). Another important point is to provide automated unit testing or test-driven development (TDD) facilities.\nApplication layer\nThe Application Layer encapsulates the different .Net projects and its resource dependencies and manages the user interaction depending on the project&#x2019;s nature.\nFigure 76. Net application stack\nThe provided application template implements an dotnet API application. Also integrates by default the Swagger client. This provides the possibility to share the contract with external applications (angular, mobile apps, external services&#x2026;&#x200B;).\nBusiness layer\nThe business layer implements the core functionality of the application and encapsulates the component&#x2019;s logic.\nThis layer provides the interface between the data transformation and the application exposition. This allow the data to be optimized and ready for different data consumers.\nThis layer may implement for each main entity the API controller, the entity related service and other classes to support the application logic.\nIn order to implement the service logic, the services class must follow the next specification:\npublic class Service&lt;TContext&gt; : IService where TContext: DbContext\nPE: devon4Net API template shows how to implement the TODOs service as follows:\npublic class TodoService: Service&lt;TodoContext&gt;, ITodoService\nWhere Service is the base service class to be inherited and have full access for the Unit of work, TodoContext is the TODOs database context and ITodoService is the interface of the service, which exposes the public extended methods to be implemented.\nData layer\nThe data layer orchestrates the data obtained between the Domain Layer and the Business Layer. Also transforms the data to be used more efficiently between layers.\nSo, if a service needs the help of another service or repository, the implemented Dependency Injection is the solution to accomplish the task.\nThe main aim of this layer is to implement the repository for each entity. The repository&#x2019;s interface is defined in the Domain layer.\nIn order to implement the repository logic, the repository class must follow the next specification:\nRepository&lt;T&gt; : IRepository&lt;T&gt; where T : class\nPE: devon4Net API template shows how to implement the TODOs repository as follows:\npublic class TodoRepository : Repository&lt;Todos&gt;, ITodoRepository\nWhere Repository is the the base repository class to be inherited and have full access for the basic CRUD operations, Todos is the entity defined in the database context. ITodoRepository is the interface of the repository, which exposes the public extended methods to be implemented.\nPlease remember that &lt;T&gt; is the mapped class which reference the entity from the database context. This abstraction allows to write services implementation with different database contexts\nDomain layer\nThe domain layer provides access to data directly exposed from other systems. The main source is used to be a data base system. The provided template makes use of Entity Framework solution from Microsoft in order to achieve this functionality.\nTo make a good use of this technology, Repository Pattern has been implemented with the help of Unit Of Work pattern. Also, the use of generic types are makes this solution to be the most flexible.\nRegarding to data base source, each entity is mapped as a class. Repository pattern allows to use this mapped classes to access the data base via Entity framework:\npublic class UnitOfWork&lt;TContext&gt; : IUnitOfWork&lt;TContext&gt; where TContext : DbContext\nWhere &lt;T&gt; is the mapped class which reference the entity from the database.\nThe repository and unit of work patterns are create an abstraction layer between the data access layer and the business logic layer of an application.\nDomain Layer has no dependencies with other layers. It contains the Entities, datasources and the Repository Interfaces.\ndevon4Net architecture layer implementaion\nThe next picture shows how the devon4Net API template implements the architectured described in previous points:\nFigure 77. devon4Net architecture implementations\nCross-Cutting concerns\nCross-cutting provides the implementation functionality that spans layers. Each functionality is implemented through components able to work stand alone. This approach provides better reusability and maintainability.\nA common component set of cross cutting components include different types of functionality regarding to authentication, authorization, security, caching, configuration, logging, and communication.\n"},{"id":623,"path":"../website/pages/docs/master-devon4net.asciidoc_architecture-basics.html#architecture_guide.asciidoc_communication-between-layers-interfaces","type":"docs","title":"Communication between Layers: Interfaces","body":"23.1.3. Communication between Layers: Interfaces\nThe main target of the use of interfaces is to loose coupling between layers and minimize dependencies.\nPublic interfaces allow to hide implementation details of the components within the layers making use of dependency inversion.\nIn order to make this possible, we make use of Dependency Injection Pattern (implementation of dependency inversion) given by default in .Net Core.\nThe provided Data Layer contains the abstract classes to inherit from. All new repository and service classes must inherit from them, also the must implement their own interfaces.\nFigure 78. Architecture representation in deep\n"},{"id":624,"path":"../website/pages/docs/master-devon4net.asciidoc_architecture-basics.html#architecture_guide.asciidoc_templates","type":"docs","title":"Templates","body":"23.1.4. Templates\nState of the art\nThe provided bundle contains the devon4Net API template based on .net core. The template allows to create a microservice solution with minimal configuration.\nAlso, the devon4Net framework can be added to third party templates such as the Amazon API template to use lambdas in serverless envirnments.\nIncluded features:\nLogging:\nText File\nSqlite database support\nSerilog Seq Server support\nGraylog integration ready through TCP/UDP/HTTP protocols\nAPI Call params interception (simple and compose objects)\nAPI error exception management\nSwagger:\nSwagger autogenerating client from comments and annotations on controller classes\nFull swagger client customization (Version, Title, Description, Terms, License, Json end point definition)\nEasy configuration with just one configuration node in your settings file\nJWT:\nIssuer, audience, token expiration customization by external file configuration\nToken generation via certificate\nMVC inherited classes to access JWT user properties\nAPI method security access based on JWT Claims\nCORS:\nSimple CORS definition ready\nMultiple CORS domain origin definition with specific headers and verbs\nHeaders:\nAutomatic header injection with middleware.\nSupported header definitions: AccessControlExposeHeader, StrictTransportSecurityHeader, XFrameOptionsHeader, XssProtectionHeader, XContentTypeOptionsHeader, ContentSecurityPolicyHeader, PermittedCrossDomainPoliciesHeader, ReferrerPolicyHeader\nReporting server:\nPartial implementation of reporting server based on My-FyiReporting (now runs on linux container)\nTesting:\nIntegration test template with sqlite support\nUnit test template\nMoq, xunit frameworks integrated\nCircuit breaker:\nIntegrated with HttpClient factory\nClient Certificate customization\nNumber of retries customizables\nLiteDb:\nSupport for LiteDB\nProvided basic repository for CRUD operations\nRabbitMq:\nUse of EasyQNet library to perform CQRS main functions between different microservices\nSend commands / Subscribe queues with one C# sentence\nEvents management: Handled received commands to subscribed messages\nAutomatic messaging backup when sent and handled (Internal database via LiteDB and database backup via Entity Framework)\nMediatR:\nUse of MediatR library to perform CQRS main functions in memory\nSend commands / Subscribe queues with one C# sentence\nEvents management: Handled received commands to subscribed messages\nAutomatic messaging backup when sent and handled (Internal database via LiteDB and database backup via Entity Framework)\nSmaxHcm:\nComponent to manage Microfocus SMAX for cloud infrastructure services management\nCyberArk:\nManage safe credentials with CyberArk\nAnsibleTower:\nAnsible automates the cloud infrastructure. devon4net integrates with Ansible Tower via API consumption endpoints\ngRPC+Protobuf:\nAdded Client + Server basic templates sample gRPC with Google&#x2019;s Protobuf protocol using devon4net\nKafka:\nAdded Apache Kafka support for deliver/consume messages and create/delete topics as well\nSoftware stack\nTable 46. Technology Stack of devon4Net\nTopic\nDetail\nImplementation\nruntime\nlanguage &amp; VM\n.Net Core Version 3.0\npersistence\nOR-mapper\nEntity Framework Core\nservice\nREST services\nWeb API\nservice - integration to external systems - optional\nSOAP services\nWCF\nlogging\nframework\nSerilog\nvalidation\nframework\nNewtonSoft Json, DataAnnotations\ncomponent management\ndependency injection\nUnity\nsecurity\nAuthentication &amp; Authorization\nJWT .Net Security - Token based, local Authentication Provider\nunit tests\nframework\nxUnit\nCircuit breaker\nframework, allows retry pattern on http calls\nPolly\nCQRS\nMemory events and queue events\nMediatR - EasyNetQ - Kafka\nKafka\nKafka support for enterprise applications\nConfluent.Kafka\nFluent Validation\nFluent validation for class instances\nFluent validation\nTarget platforms\nThanks to the new .Net Core platform from Microsoft, the developed software can be published Windows, Linux, OS X and Android platforms.\n"},{"id":625,"path":"../website/pages/docs/master-devon4net.asciidoc_architecture-basics.html#architecture_guide.asciidoc_external-links","type":"docs","title":"External links","body":"23.1.5. External links\n.Net Frameworks\nEntity Framework documentation from Microsoft\nSwagger API tooling\nDependency Injection in .NET Core\nJson Web Token\nUnit Testing (xUnit)\nRuntime IDentifier for publishing\n&#x2191;&#xA0;Up:&#xA0;devon4net&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;User guide&#xA0;&#x2192;\n"},{"id":626,"path":"../website/pages/docs/master-devon4net.asciidoc_cobigen-guide.html#master-devon4net.asciidoc_cobigen-guide","type":"docs","title":"Cobigen guide","body":"26. Cobigen guide\n"},{"id":627,"path":"../website/pages/docs/master-devon4net.asciidoc_coding-conventions.html#master-devon4net.asciidoc_coding-conventions","type":"docs","title":"Coding conventions","body":"27. Coding conventions\n"},{"id":628,"path":"../website/pages/docs/master-devon4net.asciidoc_coding-conventions.html#codeconvention.asciidoc","type":"docs","title":"Code conventions","body":"27.1. Code conventions\n"},{"id":629,"path":"../website/pages/docs/master-devon4net.asciidoc_environment.html#master-devon4net.asciidoc_environment","type":"docs","title":"Environment","body":"28. Environment\n"},{"id":630,"path":"../website/pages/docs/master-devon4net.asciidoc_environment.html#environment.asciidoc","type":"docs","title":"Environment","body":"28.1. Environment\n"},{"id":631,"path":"../website/pages/docs/master-devon4net.asciidoc_how-to-section.html#master-devon4net.asciidoc_how-to-section","type":"tutorial","title":"How To section","body":"25. How To section\n"},{"id":632,"path":"../website/pages/docs/master-devon4net.asciidoc_how-to-section.html#howto.asciidoc","type":"tutorial","title":"Introduction","body":"25.1. Introduction\nThe aim of this document is to show how to get devon4net things done in a easy way.\n"},{"id":633,"path":"../website/pages/docs/master-devon4net.asciidoc_how-to-section.html#howto.asciidoc","type":"tutorial","title":"How to","body":"25.2. How to\n"},{"id":634,"path":"../website/pages/docs/master-devon4net.asciidoc_how-to-section.html#howto.asciidoc_start-a-new-devonfw-project","type":"tutorial","title":"Start a new devonfw project","body":"25.2.1. Start a new devonfw project\nThe .Net Core 3.1 template allows you to start developing an n-layer server application to provide the latest features. The template can be used in Visual Studio Code and Visual Studio 2019.\nThe application result can be deployed as a console application, microservice or web page.\nTo start developing with devon4Net template, please follow this instructions:\nUsing devon4Net template\nOption 1\nOpen your favourite terminal (Win/Linux/iOS)\nGo to future project&apos;s path\nType dotnet new --install Devon4Net.WebAPI.Template\nType dotnet new Devon4NetAPI\nGo to project&apos;s path\nYou are ready to start developing with devon4Net\nOption 2\nCreate a new dotnet API project from scracht\nAdd the nuget package reference to your project:\nInstall-Package Devon4Net.Application.WebAPI.Configuration\nSet up your project as follows in program.cs file:\npublic static void Main(string[] args)\n{\n// Please use\n// Devonfw.Configure&lt;Startup&gt;(args);\n// Or :\nWebHost.CreateDefaultBuilder(args)\n.UseStartup&lt;Startup&gt;()\n.InitializeDevonFw()\n.Build()\n.Run();\n}\nSet up your project as follows in startup.cs file:\nprivate IConfiguration Configuration { get; }\npublic Startup(IConfiguration configuration)\n{\nConfiguration = configuration;\n}\npublic void ConfigureServices(IServiceCollection services)\n{\nservices.ConfigureDevonFw(Configuration);\nSetupDatabase(services);\n...\n}\nprivate void SetupDatabase(IServiceCollection services)\n{\n// Default is the database connection name in appsettings.json file\nservices.SetupDatabase&lt;TodoContext&gt;(Configuration, &quot;Default&quot;, DatabaseType.InMemory);\n}\npublic void Configure(IApplicationBuilder app, IWebHostEnvironment env)\n{\napp.ConfigureDevonFw();\n...\n}\nAdd the devonfw configuration options in your appsettings.json file\ndevon4net configuration files\nTo start usinf devon4net in your .net core application add this configuration in your appsettings.json file:\n&quot;devonfw&quot;: {\n&quot;UseDetailedErrorsKey&quot;: true,\n&quot;UseIIS&quot;: false,\n&quot;UseSwagger&quot;: true,\n&quot;Environment&quot;: &quot;Development&quot;,\n&quot;KillSwitch&quot;: {\n&quot;killSwitchSettingsFile&quot;: &quot;killswitch.appsettings.json&quot;\n},\n&quot;Kestrel&quot;: {\n&quot;UseHttps&quot;: true,\n&quot;HttpProtocol&quot;: &quot;Http2&quot;, //Http1, Http2, Http1AndHttp2, none\n&quot;ApplicationPort&quot;: 8082,\n&quot;KeepAliveTimeout&quot;: 120, //in seconds\n&quot;MaxConcurrentConnections&quot;: 100,\n&quot;MaxConcurrentUpgradedConnections&quot;: 100,\n&quot;MaxRequestBodySize&quot;: 28.6, //In MB. The default maximum request body size is 30,000,000 bytes, which is approximately 28.6 MB\n&quot;Http2MaxStreamsPerConnection&quot;: 100,\n&quot;Http2InitialConnectionWindowSize&quot;: 131072, // From 65,535 and less than 2^31 (2,147,483,648)\n&quot;Http2InitialStreamWindowSize&quot;: 98304, // From 65,535 and less than 2^31 (2,147,483,648)\n&quot;AllowSynchronousIO&quot;: true,\n&quot;SslProtocol&quot;: &quot;Tls12&quot;, //Tls, Tls11,Tls12, Tls13, Ssl2, Ssl3, none. For Https2 Tls12 is needed\n&quot;ServerCertificate&quot;: {\n&quot;Certificate&quot;: &quot;localhost.pfx&quot;,\n&quot;CertificatePassword&quot;: &quot;localhost&quot;\n},\n&quot;ClientCertificate&quot;: {\n&quot;DisableClientCertificateCheck&quot;: true,\n&quot;RequireClientCertificate&quot;: false,\n&quot;CheckCertificateRevocation&quot;: true,\n&quot;ClientCertificates&quot;: {\n&quot;Whitelist&quot;: [\n&quot;3A87A49460E8FE0E2A198E63D408DC58435BC501&quot;\n],\n&quot;DisableClientCertificateCheck&quot;: false\n}\n}\n},\n&quot;IIS&quot;: {\n&quot;ForwardClientCertificate&quot;: true,\n&quot;AutomaticAuthentication&quot;: true,\n&quot;AuthenticationDisplayName&quot; : &quot;&quot;\n}\n}\nAlso, for start using the devon4net components, you should add the next json options in your appsettings.json or appsettings.Development.json file:\n{\n&quot;ExtraSettingsFiles&quot;: [\n&quot;Put a directory path (relative/absolute/linux-like) like /run/secrets/global where there are many settings/secret files to load&quot;,\n&quot;Put a specific file name (with/without path) like /app-configs/app/extra-settings.json&quot;\n],\n&quot;ConnectionStrings&quot;: {\n&quot;Default&quot;: &quot;Todos&quot;,\n&quot;Employee&quot;: &quot;Employee&quot;,\n&quot;RabbitMqBackup&quot;: &quot;Add your database connection string here for messaging backup&quot;,\n&quot;MediatRBackup&quot;: &quot;Add your database connection string here for messaging backup&quot;\n},\n&quot;Logging&quot;: {\n&quot;LogLevel&quot;: {\n&quot;Default&quot;: &quot;Debug&quot;,\n&quot;System&quot;: &quot;Information&quot;,\n&quot;Microsoft&quot;: &quot;Information&quot;\n}\n},\n&quot;Swagger&quot;: {\n&quot;Version&quot;: &quot;v1&quot;,\n&quot;Title&quot;: &quot;devon4net API&quot;,\n&quot;Description&quot;: &quot;devon4net API Contract&quot;,\n&quot;Terms&quot;: &quot;https://www.devonfw.com/terms-of-use/&quot;,\n&quot;Contact&quot;: {\n&quot;Name&quot;: &quot;devonfw&quot;,\n&quot;Email&quot;: &quot;sample@mail.com&quot;,\n&quot;Url&quot;: &quot;https://www.devonfw.com&quot;\n},\n&quot;License&quot;: {\n&quot;Name&quot;: &quot;devonfw - Terms of Use&quot;,\n&quot;Url&quot;: &quot;https://www.devonfw.com/terms-of-use/&quot;\n},\n&quot;Endpoint&quot;: {\n&quot;Name&quot;: &quot;V1 Docs&quot;,\n&quot;Url&quot;: &quot;/swagger/v1/swagger.json&quot;,\n&quot;UrlUi&quot;: &quot;swagger&quot;,\n&quot;RouteTemplate&quot;: &quot;swagger/v1/{documentName}/swagger.json&quot;\n}\n},\n&quot;JWT&quot;: {\n&quot;Audience&quot;: &quot;devon4Net&quot;,\n&quot;Issuer&quot;: &quot;devon4Net&quot;,\n&quot;TokenExpirationTime&quot;: 60,\n&quot;ValidateIssuerSigningKey&quot;: true,\n&quot;ValidateLifetime&quot;: true,\n&quot;ClockSkew&quot;: 5,\n&quot;Security&quot;: {\n&quot;SecretKeyLengthAlgorithm&quot;: &quot;&quot;,\n&quot;SecretKeyEncryptionAlgorithm&quot;: &quot;&quot;,\n&quot;SecretKey&quot;: &quot;&quot;,\n&quot;Certificate&quot;: &quot;&quot;,\n&quot;CertificatePassword&quot;: &quot;&quot;,\n&quot;CertificateEncryptionAlgorithm&quot;: &quot;&quot;\n}\n},\n&quot;Cors&quot;: []\n//[\n// {\n// &quot;CorsPolicy&quot;: &quot;CorsPolicy1&quot;,\n// &quot;Origins&quot;: &quot;http://example.com,http://www.contoso.com&quot;,\n// &quot;Headers&quot;: &quot;accept,content-type,origin,x-custom-header&quot;,\n// &quot;Methods&quot;: &quot;GET,POST,HEAD&quot;,\n// &quot;AllowCredentials&quot;: true\n// },\n// {\n// &quot;CorsPolicy&quot;: &quot;CorsPolicy2&quot;,\n// &quot;Origins&quot;: &quot;http://example.com,http://www.contoso.com&quot;,\n// &quot;Headers&quot;: &quot;accept,content-type,origin,x-custom-header&quot;,\n// &quot;Methods&quot;: &quot;GET,POST,HEAD&quot;,\n// &quot;AllowCredentials&quot;: true\n// }\n//]\n,\n&quot;CircuitBreaker&quot;: {\n&quot;CheckCertificate&quot;: false,\n&quot;Endpoints&quot;: [\n{\n&quot;Name&quot;: &quot;AnsibleTower&quot;,\n&quot;BaseAddress&quot;: &quot;PUT THE IP ADDRESS HERE&quot;,\n&quot;Headers&quot;: {\n},\n&quot;WaitAndRetrySeconds&quot;: [\n0.0001,\n0.0005,\n0.001\n],\n&quot;DurationOfBreak&quot;: 0.0005,\n&quot;UseCertificate&quot;: false,\n&quot;Certificate&quot;: &quot;localhost.pfx&quot;,\n&quot;CertificatePassword&quot;: &quot;localhost&quot;,\n&quot;SslProtocol&quot;: &quot;3072&quot; //TLS12\n},\n{\n&quot;Name&quot;: &quot;CyberArk&quot;,\n&quot;BaseAddress&quot;: &quot;PUT THE IP ADDRESS HERE&quot;,\n&quot;Headers&quot;: {\n},\n&quot;WaitAndRetrySeconds&quot;: [\n0.0001,\n0.0005,\n0.001\n],\n&quot;DurationOfBreak&quot;: 0.0005,\n&quot;UseCertificate&quot;: false,\n&quot;Certificate&quot;: &quot;localhost.pfx&quot;,\n&quot;CertificatePassword&quot;: &quot;localhost&quot;,\n&quot;SslProtocol&quot;: &quot;3072&quot; //TLS12\n},\n{\n&quot;Name&quot;: &quot;SmaxHcm&quot;,\n&quot;BaseAddress&quot;: &quot;PUT THE IP ADDRESS HERE&quot;,\n&quot;Headers&quot;: {\n},\n&quot;WaitAndRetrySeconds&quot;: [\n0.0001,\n0.0005,\n0.001\n],\n&quot;DurationOfBreak&quot;: 0.0005,\n&quot;UseCertificate&quot;: false,\n&quot;Certificate&quot;: &quot;localhost.pfx&quot;,\n&quot;CertificatePassword&quot;: &quot;localhost&quot;,\n&quot;SslProtocol&quot;: &quot;3072&quot; //TLS12\n}\n]\n},\n&quot;Headers&quot;: {\n&quot;AccessControlExposeHeader&quot;: &quot;Authorization&quot;,\n&quot;StrictTransportSecurityHeader&quot;: &quot;&quot;,\n&quot;XFrameOptionsHeader&quot;: &quot;DENY&quot;,\n&quot;XssProtectionHeader&quot;: &quot;1;mode=block&quot;,\n&quot;XContentTypeOptionsHeader&quot;: &quot;nosniff&quot;,\n&quot;ContentSecurityPolicyHeader&quot;: &quot;&quot;,\n&quot;PermittedCrossDomainPoliciesHeader&quot;: &quot;&quot;,\n&quot;ReferrerPolicyHeader&quot;: &quot;&quot;\n},\n&quot;Log&quot;: {\n&quot;UseAOPTrace&quot;: false,\n&quot;LogLevel&quot;: &quot;Debug&quot;,\n&quot;SqliteDatabase&quot;: &quot;logs/log.db&quot;,\n&quot;LogFile&quot;: &quot;logs/{0}_devonfw.log&quot;,\n&quot;SeqLogServerHost&quot;: &quot;http://127.0.0.1:5341&quot;,\n&quot;GrayLog&quot;: {\n&quot;GrayLogHost&quot;: &quot;127.0.0.1&quot;,\n&quot;GrayLogPort&quot;: &quot;12201&quot;,\n&quot;GrayLogProtocol&quot;: &quot;UDP&quot;,\n&quot;UseSecureConnection&quot;: true,\n&quot;UseAsyncLogging&quot;: true,\n&quot;RetryCount&quot;: 5,\n&quot;RetryIntervalMs&quot;: 15,\n&quot;MaxUdpMessageSize&quot;: 8192\n}\n},\n&quot;RabbitMq&quot;: {\n&quot;EnableRabbitMq&quot;: false,\n&quot;Hosts&quot;: [\n{\n&quot;Host&quot;: &quot;127.0.0.1&quot;,\n&quot;Port&quot;: 5672,\n&quot;Ssl&quot;: false,\n&quot;SslServerName&quot;: &quot;localhost&quot;,\n&quot;SslCertPath&quot;: &quot;localhost.pfx&quot;,\n&quot;SslCertPassPhrase&quot;: &quot;localhost&quot;,\n&quot;SslPolicyErrors&quot;: &quot;RemoteCertificateNotAvailable&quot; //None, RemoteCertificateNotAvailable, RemoteCertificateNameMismatch, RemoteCertificateChainErrors\n}\n],\n&quot;VirtualHost&quot;: &quot;/&quot;,\n&quot;UserName&quot;: &quot;admin&quot;,\n&quot;Password&quot;: &quot;password&quot;,\n&quot;Product&quot;: &quot;devon4net&quot;,\n&quot;RequestedHeartbeat&quot;: 10, //Set to zero for no heartbeat\n&quot;PrefetchCount&quot;: 50,\n&quot;PublisherConfirms&quot;: false,\n&quot;PersistentMessages&quot;: true,\n&quot;Platform&quot;: &quot;localhost&quot;,\n&quot;Timeout&quot;: 10,\n&quot;Backup&quot;: {\n&quot;UseLocalBackup&quot;: false,\n&quot;DatabaseName&quot;: &quot;devon4netMessageBackup.db&quot;\n}\n},\n&quot;MediatR&quot;: {\n&quot;EnableMediatR&quot;: false,\n&quot;Backup&quot;: {\n&quot;UseLocalBackup&quot;: false,\n&quot;DatabaseName&quot;: &quot;devon4netMessageBackup.db&quot;\n}\n},\n&quot;LiteDb&quot;: {\n&quot;DatabaseLocation&quot;: &quot;devon4net.db&quot;\n},\n&quot;AnsibleTower&quot;: {\n&quot;EnableAnsible&quot;: false,\n&quot;Name&quot;: &quot;AnsibleTower&quot;,\n&quot;CircuitBreakerName&quot;: &quot;AnsibleTower&quot;,\n&quot;ApiUrlBase&quot;: &quot;/api/v2/?format=json&quot;,\n&quot;Version&quot;: &quot;1.0.5.29&quot;,\n&quot;Username&quot;: &quot;&quot;,\n&quot;Password&quot;: &quot;&quot;\n},\n&quot;CyberArk&quot;: {\n&quot;EnableCyberArk&quot;: false,\n&quot;Username&quot;: &quot;&quot;,\n&quot;Password&quot;: &quot;&quot;,\n&quot;CircuitBreakerName&quot;: &quot;CyberArk&quot;\n},\n&quot;SmaxHcm&quot;: {\n&quot;EnableSmax&quot;: false,\n&quot;Username&quot;: &quot;&quot;,\n&quot;Password&quot;: &quot;&quot;,\n&quot;TenantId&quot;: &quot;&quot;,\n&quot;CircuitBreakerName&quot;: &quot;SmaxHcm&quot;,\n&quot;ProviderId&quot;: &quot;&quot;\n},\n&quot;Kafka&quot;: {\n&quot;EnableKafka&quot;: true,\n&quot;Administration&quot;: [\n{\n&quot;AdminId&quot;: &quot;Admin1&quot;,\n&quot;Servers&quot;: &quot;127.0.0.1:9092&quot;\n}\n],\n&quot;Producers&quot;: [\n{\n&quot;ProducerId&quot;: &quot;Producer1&quot;, // devon identifier\n&quot;Servers&quot;: &quot;127.0.0.1:9092&quot;, // Initial list of brokers as a CSV list of broker host or host:port. The application may also use `rd_kafka_brokers_add()` to add brokers during runtime\n&quot;ClientId&quot;: &quot;client1&quot;, //Client identifier\n&quot;Topic&quot;: &quot;devonfw&quot;, // topics to deliver the message\n&quot;MessageMaxBytes&quot;: 1000000, //Maximum Kafka protocol request message size. Due to differing framing overhead between protocol versions the producer is unable to reliably enforce a strict max message limit at produce time and may exceed the maximum size by one message in protocol ProduceRequests, the broker will enforce the the topic&apos;s `max.message.bytes` limit (see Apache Kafka documentation)\n&quot;CompressionLevel&quot;: -1, // [0-9] for gzip; [0-12] for lz4; only 0 for snappy; -1 = codec-dependent default compression level\n&quot;CompressionType&quot;: &quot;None&quot;, // None, Gzip, Snappy, Lz4, Zstd\n&quot;ReceiveMessageMaxBytes&quot;: 100000000,\n&quot;EnableSslCertificateVerification&quot;: false,\n&quot;CancellationDelayMaxMs&quot;: 100, // The maximum length of time (in milliseconds) before a cancellation request is acted on. Low values may result in measurably higher CPU usage\n&quot;Ack&quot;: &quot;None&quot;, //Zero=Broker does not send any response/ack to client, One=The leader will write the record to its local log but will respond without awaiting full acknowledgement from all followers. All=Broker will block until message is committed by all in sync replicas (ISRs). If there are less than min.insync.replicas (broker configuration) in the ISR set the produce request will fail\n&quot;Debug&quot;: &quot;&quot;, //A comma-separated list of debug contexts to enable. Detailed Producer debugging: broker,topic,msg. Consumer: consumer,cgrp,topic,fetch\n&quot;BrokerAddressTtl&quot;: 1000, //How long to cache the broker address resolving results (milliseconds)\n&quot;BatchNumMessages&quot;: 1000000, // Maximum size (in bytes) of all messages batched in one MessageSet, including protocol framing overhead. This limit is applied after the first message has been added to the batch, regardless of the first message&apos;s size, this is to ensure that messages that exceed batch.size are produced. The total MessageSet size is also limited by batch.num.messages and message.max.bytes\n&quot;EnableIdempotence&quot;: false, //When set to `true`, the producer will ensure that messages are successfully produced exactly once and in the original produce order. The following configuration properties are adjusted automatically (if not modified by the user) when idempotence is enabled: `max.in.flight.requests.per.connection=5` (must be less than or equal to 5), `retries=INT32_MAX` (must be greater than 0), `acks=all`, `queuing.strategy=fifo`. Producer instantation will fail if user-supplied configuration is incompatible\n&quot;MaxInFlight&quot;: 5,\n&quot;MessageSendMaxRetries&quot;: 5,\n&quot;BatchSize&quot;: 100000000 // Maximum size (in bytes) of all messages batched in one MessageSet, including protocol framing overhead. This limit is applied after the first message has been added to the batch, regardless of the first message&apos;s size, this is to ensure that messages that exceed batch.size are produced. The total MessageSet size is also limited by batch.num.messages and message.max.bytes\n}\n],\n&quot;Consumers&quot;: [\n{\n&quot;ConsumerId&quot;: &quot;Consumer1&quot;, // devon identifier\n&quot;Servers&quot;: &quot;127.0.0.1:9092&quot;,\n&quot;GroupId&quot;: &quot;group1&quot;,\n&quot;Topics&quot;: &quot;devonfw&quot;, // Comma separated topics to subscribe\n&quot;AutoCommit&quot;: true, //Automatically and periodically commit offsets in the background. Note: setting this to false does not prevent the consumer from fetching previously committed start offsets. To circumvent this behaviour set specific start offsets per partition in the call to assign()\n&quot;StatisticsIntervalMs&quot;: 0, //librdkafka statistics emit interval. The application also needs to register a stats callback using `rd_kafka_conf_set_stats_cb()`. The granularity is 1000ms. A value of 0 disables statistics\n&quot;SessionTimeoutMs&quot;: 10000, //Client group session and failure detection timeout. The consumer sends periodic heartbeats (heartbeat.interval.ms) to indicate its liveness to the broker. If no hearts are received by the broker for a group member within the session timeout, the broker will remove the consumer from the group and trigger a rebalance. The allowed range is configured with the **broker** configuration properties `group.min.session.timeout.ms` and `group.max.session.timeout.ms`. Also see `max.poll.interval.ms`\n&quot;AutoOffsetReset&quot;: &quot;Largest&quot;, //Action to take when there is no initial offset in offset store or the desired offset is out of range: &apos;smallest&apos;,&apos;earliest&apos; - automatically reset the offset to the smallest offset, &apos;largest&apos;,&apos;latest&apos; - automatically reset the offset to the largest offset, &apos;error&apos; - trigger an error which is retrieved by consuming messages and checking &apos;message-&amp;gt;err&apos;\n&quot;EnablePartitionEof&quot;: true, //Verify CRC32 of consumed messages, ensuring no on-the-wire or on-disk corruption to the messages occurred. This check comes at slightly increased CPU usage\n&quot;IsolationLevel&quot;: &quot;ReadCommitted&quot;, //Controls how to read messages written transactionally: `ReadCommitted` - only return transactional messages which have been committed. `ReadUncommitted` - return all messages, even transactional messages which have been aborted.\n&quot;EnableSslCertificateVerification&quot;: false,\n&quot;Debug&quot;: &quot;&quot; //A comma-separated list of debug contexts to enable. Detailed Producer debugging: broker,topic,msg. Consumer: consumer,cgrp,topic,fetch\n}\n]\n}\n}\n"},{"id":635,"path":"../website/pages/docs/master-devon4net.asciidoc_how-to-section.html#howto.asciidoc_devon4net-cobigen-guide","type":"tutorial","title":"devon4net Cobigen Guide","body":"25.2.2. devon4net Cobigen Guide\nOverview\nIn this guide we will explain how to generate a new WebApi project from an OpenAPI 3.0.0 specification. This means that we are going to use a &#x201C;contract first&#x201D; strategy. This is going to be possible due to these type of files that contain all the information about entities, operations, etc&#x2026;\nIn order to make it work we are using CobiGen, a powerful tool for generating source code. CobiGen allows users to generate all the structure and code of the components, helping to save a lot of time otherwise waisted on repetitive tasks.\nGetting things ready\ndevonfw Distribution\nThe devonfw distributions can be obtained from the TeamForge releases library and are packaged in zips files that include all the needed tools, software and configurations.\nIt is not necessary to install nor configure anything. Just extracting the zip content is enough to have a fully functional devonfw. The only thing you have to do is run create-or-update-workspace.bat and then update-all-workspaces.bat to set up all the needed tools.\ndevon4net Templates\nWe are going to use the template of devon4net as a base to generate all the code, so what we have to do now is to download said template using the following steps.\nFirst of all you have to set up all the environment for .NET, you can do this using the following tutorial. Next we are going to create a new folder where we want to have the WebAPI project, lastly we are going to open the terminal there.\nType the following:\ndotnet new -i Devon4Net.WebAPI.Template\nand then:\ndotnet new Devon4NetAPI\nOpenAPI File\nIn order to let CobiGen generate all the files, we first have to make some modifications to our OpenAPI file.\nIt is obligatory to put the &#x201C;x-rootpackage&#x201D; tag to indicate where CobiGen will place the generated files as well as the &quot;x-component&quot; tags for each component, keep in mind that due to CobiGen&#x2019;s limitations each component must have its own entity.\nYou can read more information about how to configure your OpenAPI file and a working example here.\nGenerating files\nCobigen allow us to generate the files in two different ways. One of them is using Eclipse which it can be done by using the its grafical interface. The other way to generate the code is using the Cobigen CLI tool.\nGenerating files through Eclipse\nIn order to generate the files using Eclipse we need to follow some simple steps.\nFirst we are going to import our basic devon4net WebAPI Project into Eclipse. to do so open Eclipse with the &#x201C;eclipse-main.bat&#x201D; file that can be found in the devon distribution root folder. Once we are inside of Eclipse we go to File &gt; Open projects from file system&#x2026;&#x200B; and, under &quot;Directory&quot;, search for your project.\nNext we copy our OpenAPI file into the root folder of the project.\nAnd then we right click on OpenAPI file and then select CobiGen &gt; Generate&#x2026;&#x200B; It will display a window like this:\nTo select all .NET features choose CRUD devon4net Server otherwise you can select only those that interest you.\nOnes you select all the files that you want to generate, click on the &#x201C;Finish&#x201D; button to generate all the source code.\nGenerating files through Cobigen CLI\nIn ordet to generate the files using the Cobigen CLI it is needed to do the following steps:\nGo to devonfw distribution folder\nRun console.bat, this will open a console.\nGo to the folder you downloaded the devon4net template and your yml file.\nRun the command:\ncobigen generate {yourOpenAPIFile}.yml\nA list of increments will be printed so that you can start the generation. It has to be selected CRUD devon4net Server increment.\nConfiguration\nDependency Injection configuration\nAt this point it is needed to make some modifications in the code in order to configure correctly the server. To do so it is needed to locate the services and the repositories files that were created in Devon4Net.WebAPI.Implementation\nServices location:\nRepositories location:\nNow, we are going to open the following file Devon4Net.WebAPI.Implementation\\Configure\\DevonConfiguration.cs.\nIn there we have to add the Dependency Inyection for the services and the repositories that Cobigen has generated. The following image is an example of what is needed to add.\nMoreover it is needed to remove the last line in order to be able to run the application:\nthrow new NotImplementedException(...);\nConfigure data base\nCobigen is generating an empty context that has to be filled with manualy in order to be able to work with the database. The context can be found in [Project_Name]/Devon4Net.WebAPI.Implementation/Domain/Database/CobigenContext.cs.\nConfigure services\nIn order to finish the configuration of the services it is needed to go to each service file of the managements generated.\nIn there we will see some &quot;NotImplementedExceptions&quot;, so it is needed to read carefuly each coment inside of each exception in order to be able to use the service. It can be shown an example of the service with its NotImplementedExceptions comments:\nRun the application\nAfter doing all the steps defined avobe, open a terminal in path: [Project_Name]/Devon4Net.Application.WebAPI and then type:\ndotnet run\nThis will deploy our application in our localhost with the port 8081, so when you click here (https://localhost:8082/swagger) you can see, in swagger, all the services and the data model.\n"},{"id":636,"path":"../website/pages/docs/master-devon4net.asciidoc_how-to-section.html#howto.asciidoc_use-http2-protocol","type":"tutorial","title":"Use HTTP2 protocol","body":"25.2.3. Use HTTP2 protocol\nYou can specify the HTTP protocol to be used on your devon4net application modifying some node values at devonfw node in your appsettings configuration file.\nHttpProtocol\nThe supported protocols are:\nProtocl\nDescription\nHttp1\nHttp1 protocol\nHttp2\nHttp2 Protocol\nHttp1AndHttp2\nBoth supported\nSSL\nTo activate the HTTP2, the SslProtocol node must be set to Tls12 value.\nThe SSL protocol supported version values are:\nTls\nTls11\nTls12\nTls13\nSsl2\nSsl3\n"},{"id":637,"path":"../website/pages/docs/master-devon4net.asciidoc_how-to-section.html#howto.asciidoc_create-a-certificate-for-development-purposes","type":"tutorial","title":"Create a certificate for development purposes","body":"25.2.4. Create a certificate for development purposes\nIn order to create a valid certificate for development purposes the Open SSL tools are needed.\nCertificate authority (CA)\nRun the next commands in a shell:\n1. openssl req -x509 -nodes -new -sha256 -days 1024 -newkey rsa:2048 -keyout RootCA.key -out RootCA.pem -subj &quot;/C=ES/ST=Valencia/L=Valencia/O=Certificates/CN=localhost.local&quot;\n2. openssl x509 -outform pem -in RootCA.pem -out RootCA.crt\nIf you want to convert your certificate run the command:\nopenssl pkcs12 -export -out localhost.pfx -inkey RootCA.key -in RootCA.crt\nDomain name certificate\nRun the next commands in a shell:\n1. openssl req -new -nodes -newkey rsa:2048 -keyout localhost.key -out localhost.csr -subj &quot;/C=ES/ST=Valencia/L=Valencia/O=Certificates/CN=localhost.local&quot;\n2. openssl x509 -req -sha256 -days 1024 -in localhost.csr -CA RootCA.pem -CAkey RootCA.key -CAcreateserial -extfile domains.ext -out localhost.crt\nWhere the domains.ext file should contain:\nauthorityKeyIdentifier=keyid,issuer\nbasicConstraints=CA:FALSE\nkeyUsage = digitalSignature, nonRepudiation, keyEncipherment, dataEncipherment\nsubjectAltName = @alt_names\n[alt_names]\nDNS.1 = localhost\nDNS.2 = localhost.local\nDNS.3 = 127.0.0.1\nDNS.4 = fake1.local\nDNS.5 = fake2.local\nIf you want to convert your certificate run the command:\nopenssl pkcs12 -export -out localhost.pfx -inkey localhost.key -in localhost.crt\n"},{"id":638,"path":"../website/pages/docs/master-devon4net.asciidoc_how-to-section.html#howto.asciidoc_setup-the-database-driver","type":"tutorial","title":"Setup the database driver","body":"25.2.5. Setup the database driver\nAdd the databse connection on the SetupDatabase method at Startup.cs\nprivate void SetupDatabase(IServiceCollection services)\n{\nservices.SetupDatabase&lt;TodoContext&gt;(Configuration, &quot;Default&quot;, WebAPI.Configuration.Enums.DatabaseType.InMemory);\n}\nWhere:\nParam\nDescription\nTodoContext\nIs the database context definition\nDefault\nIs the connection string defined at ConnectionString node at the appsettings configuration file\nWebAPI.Configuration.Enums.DatabaseType.InMemory\nIs the database driver selection. In this case InMemory data base is chosen\nThe supported databases are:\nSqlServer\nSqlite\nInMemory\nCosmos\nPostgreSQL\nMySql\nMariaDb\nFireBird\nOracle\nMSAccess\n"},{"id":639,"path":"../website/pages/docs/master-devon4net.asciidoc_how-to-section.html#howto.asciidoc_change-the-jwt-encryption-algorithm","type":"tutorial","title":"Change the JWT encryption algorithm","body":"25.2.6. Change the JWT encryption algorithm\nIn the appsettings.json configuration file, you can use the next values on the SecretKeyLengthAlgorithm and SecretKeyEncryptionAlgorithm nodes at JWT configuration:\nAlgorithm\nDescription\nAes128Encryption\n&quot;http://www.w3.org/2001/04/xmlenc#aes128-cbc&quot;\nAes192Encryption\n&quot;http://www.w3.org/2001/04/xmlenc#aes192-cbc&quot;\nAes256Encryption\n&quot;http://www.w3.org/2001/04/xmlenc#aes256-cbc&quot;\nDesEncryption\n&quot;http://www.w3.org/2001/04/xmlenc#des-cbc&quot;\nAes128KeyWrap\n&quot;http://www.w3.org/2001/04/xmlenc#kw-aes128&quot;\nAes192KeyWrap\n&quot;http://www.w3.org/2001/04/xmlenc#kw-aes192&quot;\nAes256KeyWrap\n&quot;http://www.w3.org/2001/04/xmlenc#kw-aes256&quot;\nRsaV15KeyWrap\n&quot;http://www.w3.org/2001/04/xmlenc#rsa-1_5&quot;\nRipemd160Digest\n&quot;http://www.w3.org/2001/04/xmlenc#ripemd160&quot;\nRsaOaepKeyWrap\n&quot;http://www.w3.org/2001/04/xmlenc#rsa-oaep&quot;\nAes128KW\n&quot;A128KW&quot;\nAes256KW\n&quot;A256KW&quot;\nRsaPKCS1\n&quot;RSA1_5&quot;\nRsaOAEP\n&quot;RSA-OAEP&quot;\nExclusiveC14n\n&quot;http://www.w3.org/2001/10/xml-exc-c14n#&quot;\nExclusiveC14nWithComments\n&quot;http://www.w3.org/2001/10/xml-exc-c14n#WithComments&quot;\nEnvelopedSignature\n&quot;http://www.w3.org/2000/09/xmldsig#enveloped-signature&quot;\nSha256Digest\n&quot;http://www.w3.org/2001/04/xmlenc#sha256&quot;\nSha384Digest\n&quot;http://www.w3.org/2001/04/xmldsig-more#sha384&quot;\nSha512Digest\n&quot;http://www.w3.org/2001/04/xmlenc#sha512&quot;\nSha256\n&quot;SHA256&quot;\nSha384\n&quot;SHA384&quot;\nSha512\n&quot;SHA512&quot;\nEcdsaSha256Signature\n&quot;http://www.w3.org/2001/04/xmldsig-more#ecdsa-sha256&quot;\nEcdsaSha384Signature\n&quot;http://www.w3.org/2001/04/xmldsig-more#ecdsa-sha384&quot;\nEcdsaSha512Signature\n&quot;http://www.w3.org/2001/04/xmldsig-more#ecdsa-sha512&quot;\nHmacSha256Signature\n&quot;http://www.w3.org/2001/04/xmldsig-more#hmac-sha256&quot;\nHmacSha384Signature\n&quot;http://www.w3.org/2001/04/xmldsig-more#hmac-sha384&quot;\nHmacSha512Signature\n&quot;http://www.w3.org/2001/04/xmldsig-more#hmac-sha512&quot;\nRsaSha256Signature\n&quot;http://www.w3.org/2001/04/xmldsig-more#rsa-sha256&quot;\nRsaSha384Signature\n&quot;http://www.w3.org/2001/04/xmldsig-more#rsa-sha384&quot;\nRsaSha512Signature\n&quot;http://www.w3.org/2001/04/xmldsig-more#rsa-sha512&quot;\nRsaSsaPssSha256Signature\n&quot;http://www.w3.org/2007/05/xmldsig-more#sha256-rsa-MGF1&quot;\nRsaSsaPssSha384Signature\n&quot;http://www.w3.org/2007/05/xmldsig-more#sha384-rsa-MGF1&quot;\nRsaSsaPssSha512Signature\n&quot;http://www.w3.org/2007/05/xmldsig-more#sha512-rsa-MGF1&quot;\nEcdsaSha256\n&quot;ES256&quot;\nEcdsaSha384\n&quot;ES384&quot;\nEcdsaSha512\n&quot;ES512&quot;\nHmacSha256\n&quot;HS256&quot;\nHmacSha384\n&quot;HS384&quot;\nHmacSha512\n&quot;HS512&quot;\nNone\n&quot;none&quot;\nRsaSha256\n&quot;RS256&quot;\nRsaSha384\n&quot;RS384&quot;\nRsaSha512\n&quot;RS512&quot;\nRsaSsaPssSha256\n&quot;PS256&quot;\nRsaSsaPssSha384\n&quot;PS384&quot;\nRsaSsaPssSha512\n&quot;PS512&quot;\nAes128CbcHmacSha256\n&quot;A128CBC-HS256&quot;\nAes192CbcHmacSha384\n&quot;A192CBC-HS384&quot;\nAes256CbcHmacSha512\n&quot;A256CBC-HS512&quot;\n&#x2190;&#xA0;Previous:&#xA0;User guide&#xA0;| &#x2191;&#xA0;Up:&#xA0;devon4net&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Cobigen guide&#xA0;&#x2192;\n"},{"id":640,"path":"../website/pages/docs/master-devon4net.asciidoc_packages.html#master-devon4net.asciidoc_packages","type":"docs","title":"Packages","body":"29. Packages\n"},{"id":641,"path":"../website/pages/docs/master-devon4net.asciidoc_packages.html#packages.asciidoc","type":"docs","title":"Packages","body":"29.1. Packages\n"},{"id":642,"path":"../website/pages/docs/master-devon4net.asciidoc_packages.html#packages.asciidoc_packages-overview","type":"docs","title":"Packages overview","body":"29.1.1. Packages overview\ndevon4Net is composed by a number of packages that increases the functionality and boosts time development. Each package has it&#x2019;s own configuration to make them work properly. In appsettings.json set up your environment. On appsettings.{environment}.json you can configure each component.\n"},{"id":643,"path":"../website/pages/docs/master-devon4net.asciidoc_packages.html#packages.asciidoc_the-packages","type":"docs","title":"The packages","body":"29.1.2. The packages\nYou can get the devon4Net packages on nuget.org.\nDevon4Net.Application.WebAPI.Configuration\nDescription\nThe devon4Net web API configuration core.\nConfiguration\nInstall package on your solution:\nPM&gt; Install-Package Devon4Net.Application.WebAPI.Configuration\nDefaul configuration values\n&quot;devonfw&quot;: {\n&quot;UseDetailedErrorsKey&quot;: true,\n&quot;UseIIS&quot;: false,\n&quot;UseSwagger&quot;: true,\n&quot;Environment&quot;: &quot;Development&quot;,\n&quot;KillSwitch&quot;: {\n&quot;killSwitchSettingsFile&quot;: &quot;killswitch.appsettings.json&quot;\n},\n&quot;Kestrel&quot;: {\n&quot;UseHttps&quot;: true,\n&quot;HttpProtocol&quot;: &quot;Http2&quot;, //Http1, Http2, Http1AndHttp2, none\n&quot;ApplicationPort&quot;: 8082,\n&quot;KeepAliveTimeout&quot;: 120, //in seconds\n&quot;MaxConcurrentConnections&quot;: 100,\n&quot;MaxConcurrentUpgradedConnections&quot;: 100,\n&quot;MaxRequestBodySize&quot;: 28.6, //In MB. The default maximum request body size is 30,000,000 bytes, which is approximately 28.6 MB\n&quot;Http2MaxStreamsPerConnection&quot;: 100,\n&quot;Http2InitialConnectionWindowSize&quot;: 131072, // From 65,535 and less than 2^31 (2,147,483,648)\n&quot;Http2InitialStreamWindowSize&quot;: 98304, // From 65,535 and less than 2^31 (2,147,483,648)\n&quot;AllowSynchronousIO&quot;: true,\n&quot;SslProtocol&quot;: &quot;Tls12&quot;, //Tls, Tls11,Tls12, Tls13, Ssl2, Ssl3, none. For Https2 Tls12 is needed\n&quot;ServerCertificate&quot;: {\n&quot;Certificate&quot;: &quot;localhost.pfx&quot;,\n&quot;CertificatePassword&quot;: &quot;localhost&quot;\n},\n&quot;ClientCertificate&quot;: {\n&quot;DisableClientCertificateCheck&quot;: true,\n&quot;RequireClientCertificate&quot;: false,\n&quot;CheckCertificateRevocation&quot;: true,\n&quot;ClientCertificates&quot;: {\n&quot;Whitelist&quot;: [\n&quot;3A87A49460E8FE0E2A198E63D408DC58435BC501&quot;\n],\n&quot;DisableClientCertificateCheck&quot;: false\n}\n}\n},\n&quot;IIS&quot;: {\n&quot;ForwardClientCertificate&quot;: true,\n&quot;AutomaticAuthentication&quot;: true,\n&quot;AuthenticationDisplayName&quot; : &quot;&quot;\n}\n}\nDevon4Net.Infrastructure.CircuitBreaker\nDescription\nThe Devon4Net.Infrastructure.CircuitBreaker componnet implements the retry pattern for HTTP/HTTPS calls.\nConfiguration\nInstall package on your solution:\nPM&gt; Install-Package Devon4Net.Infrastructure.CircuitBreaker\nDefaul configuration values\n&quot;CircuitBreaker&quot;: {\n&quot;CheckCertificate&quot;: true,\n&quot;Endpoints&quot;: [\n{\n&quot;Name&quot;: &quot;SampleService&quot;,\n&quot;BaseAddress&quot;: &quot;https://localhost:5001/&quot;,\n&quot;Headers&quot;: {\n},\n&quot;WaitAndRetrySeconds&quot;: [\n0.0001,\n0.0005,\n0.001\n],\n&quot;DurationOfBreak&quot;: 0.0005,\n&quot;UseCertificate&quot;: true,\n&quot;Certificate&quot;: &quot;localhost.pfx&quot;,\n&quot;CertificatePassword&quot;: &quot;localhost&quot;,\n&quot;SslProtocol&quot;: &quot;3072&quot; //TLS12\n}\n]\n}\nProperty\nDescription\nCheckCertificate\nTrue if HTTPS is requiered. This is usefull when developing an API Gateway needs a secured HTTP, disabling this on development we can use communications with a valid server certificate\nEndpoints\nArray with predefined sites to connect with\nName\nThe name key to identificate the destination URL\nHeaders\nNot ready yet\nWaitAndRetrySeconds\nArray wich determinates the number of retruies and the lapse period between each retry. The value is in milliseconds.\nCertificate\nCeritificate client to use to perform the HTTP call\nSslProtocol\nThe secure protocol to use on the call\nProtocols\nProtocol\nKey\nDescription\nSSl3\n48\nSpecifies the Secure Socket Layer (SSL) 3.0 security protocol. SSL 3.0 has been superseded by the Transport Layer Security (TLS) protocol and is provided for backward compatibility only.\nTLS\n192\nSpecifies the Transport Layer Security (TLS) 1.0 security protocol. The TLS 1.0 protocol is defined in IETF RFC 2246.\nTLS11\n768\nSpecifies the Transport Layer Security (TLS) 1.1 security protocol. The TLS 1.1 protocol is defined in IETF RFC 4346. On Windows systems, this value is supported starting with Windows 7.\nTLS12\n3072\nSpecifies the Transport Layer Security (TLS) 1.2 security protocol. The TLS 1.2 protocol is defined in IETF RFC 5246. On Windows systems, this value is supported starting with Windows 7.\nTLS13\n12288\nSpecifies the TLS 1.3 security protocol. The TLS protocol is defined in IETF RFC 8446.\nUsage\nAdd via Dependency Injection the circuit breaker instance. PE:\npublic class FooService : Service&lt;TodosContext&gt;, ILoginService\n{\npublic FooService(IUnitOfWork&lt;AUTContext&gt; uoW, ICircuitBreakerHttpClient circuitBreakerClient,\nILogger&lt;LoginService&gt; logger) : base(uoW)\n{\n...\n}\n}\nAt this point you can use the circuit breaker functionality in your code.\nTo perform a POST call you should use your circuit breaker instance as follows:\nawait circuitBreakerClient.PostAsync&lt;YourOutputClass&gt;(NameOftheService, EndPoint, InputData, MediaType.ApplicationJson).ConfigureAwait(false);\nWhere:\nProperty\nDescription\nYourOutputClass\nThe type of the class that you are expecting to retrieve from the POST call\nNameOftheService\nThe key name of the endpoint provided in the appsettings.json file at Endpoints[] node\nEndPoint\nPart of the url to use with the base address. PE: /validate\nInputData\nYour instance of the class with values that you want to use in the POST call\nMediaType.ApplicationJson\nThe media type flag for the POST call\ndevon4Net.Domain.UnitOfWork\nDescription\nUnit of work implementation for devon4net solution. This unit of work provides the different methods to access the data layer with an atomic context. Sync and Async repository operations are provided. Customized Eager Loading method also provided for custom entity properties.\nThis component will move on next releases to Infrastructure instead of being part of Domain components\nConfiguration\nInstall package on your solution:\nPM&gt; Install-Package devon4Net.Domain.UnitOfWork\nAdding the database connection information:\nAdd the databse connection on the SetupDatabase method at Startup.cs\nprivate void SetupDatabase(IServiceCollection services)\n{\nservices.SetupDatabase&lt;TodoContext&gt;(Configuration, &quot;Default&quot;, WebAPI.Configuration.Enums.DatabaseType.InMemory);\n}\nWhere:\nParam\nDescription\nTodoContext\nIs the database context definition\nDefault\nIs the connection string defined at ConnectionString node at the appsettings configuration file\nWebAPI.Configuration.Enums.DatabaseType.InMemory\nIs the database driver selection. In this case InMemory data base is chosen\nThe supported databases are:\nSqlServer\nSqlite\nInMemory\nCosmos\nPostgreSQL\nMySql\nMariaDb\nFireBird\nOracle\nMSAccess\nNotes\nNow you can use the unit of work via dependency injection on your classes:\nFigure 82. Use of Unit of work via dependency injection\nAs you can see in the image, you can use Unit Of Work class with your defined ModelContext classes.\nPredicate expression builder\nUse this expression builder to generate lambda expressions dynamically.\nvar predicate = PredicateBuilder.True&lt;T&gt;();\nWhere T is a class. At this moment, you can build your expression and apply it to obtain your results in a efficient way and not retrieving data each time you apply an expression.\nExample from My Thai Star .Net Core implementation:\npublic async Task&lt;PaginationResult&lt;Dish&gt;&gt; GetpagedDishListFromFilter(int currentpage, int pageSize, bool isFav, decimal maxPrice, int minLikes, string searchBy, IList&lt;long&gt; categoryIdList, long userId)\n{\nvar includeList = new List&lt;string&gt;{&quot;DishCategory&quot;,&quot;DishCategory.IdCategoryNavigation&quot;, &quot;DishIngredient&quot;,&quot;DishIngredient.IdIngredientNavigation&quot;,&quot;IdImageNavigation&quot;};\n//Here we create our predicate builder\nvar dishPredicate = PredicateBuilder.True&lt;Dish&gt;();\n//Now we start applying the different criteria:\nif (!string.IsNullOrEmpty(searchBy))\n{\nvar criteria = searchBy.ToLower();\ndishPredicate = dishPredicate.And(d =&gt; d.Name.ToLower().Contains(criteria) || d.Description.ToLower().Contains(criteria));\n}\nif (maxPrice &gt; 0) dishPredicate = dishPredicate.And(d=&gt;d.Price&lt;=maxPrice);\nif (categoryIdList.Any())\n{\ndishPredicate = dishPredicate.And(r =&gt; r.DishCategory.Any(a =&gt; categoryIdList.Contains(a.IdCategory)));\n}\nif (isFav &amp;&amp; userId &gt;= 0)\n{\nvar favourites = await UoW.Repository&lt;UserFavourite&gt;().GetAllAsync(w=&gt;w.IdUser == userId);\nvar dishes = favourites.Select(s =&gt; s.IdDish);\ndishPredicate = dishPredicate.And(r=&gt; dishes.Contains(r.Id));\n}\n// Now we can use the predicate to retrieve data from database with just one call\nreturn await UoW.Repository&lt;Dish&gt;().GetAllIncludePagedAsync(currentpage, pageSize, includeList, dishPredicate);\n}\ndevon4Net.Infrastructure.Extensions\nDescription\nMiscellaneous extension library which contains :\n- Predicate expression builder\n- DateTime formatter\n- HttpClient\n- HttpContext (Middleware support)\nConfiguration\nInstall package on your solution:\nPM&gt; Install-Package devon4Net.Infrastructure.Extensions\nHttpContext\nTryAddHeader method is used on devon4Net.Infrastructure.Middleware component to add automatically response header options such authorization.\ndevon4Net.Infrastructure.JWT\nDescription\nJSON Web Token (JWT) is an open standard (RFC 7519) that defines a compact and self-contained way for securely transmitting information between parties as a JSON object. This information can be verified and trusted because it is digitally signed. JWTs can be signed using a secret (with the HMAC algorithm) or a public/private key pair using RSA or ECDSA.\n&#x2014; What is JSON Web Token?\nhttps://jwt.io/introduction/\ndevon4Net component to manage JWT standard to provide security to .Net API applications.\nConfiguration\nInstall package on your solution:\nPM&gt; devon4Net.Infrastructure.JWT\nDefaul configuration values\n&quot;JWT&quot;: {\n&quot;Audience&quot;: &quot;devon4Net&quot;,\n&quot;Issuer&quot;: &quot;devon4Net&quot;,\n&quot;TokenExpirationTime&quot;: 60,\n&quot;ValidateIssuerSigningKey&quot;: true,\n&quot;ValidateLifetime&quot;: true,\n&quot;ClockSkew&quot;: 5,\n&quot;Security&quot;: {\n&quot;SecretKeyLengthAlgorithm&quot;: &quot;&quot;,\n&quot;SecretKeyEncryptionAlgorithm&quot;: &quot;&quot;,\n&quot;SecretKey&quot;: &quot;&quot;,\n&quot;Certificate&quot;: &quot;&quot;,\n&quot;CertificatePassword&quot;: &quot;&quot;,\n&quot;CertificateEncryptionAlgorithm&quot;: &quot;&quot;\n}\n}\nClockSkew indicates the token expiration time in minutes\nCertificate you can specify the name of your certificate (if it is on the same path) or the full path of the certificate. If the certificate does not exists an exception will be raised.\nSecretKeyLengthAlgorithm, SecretKeyEncryptionAlgorithm and CertificateEncryptionAlgorithm supported algorithms are:\nAlgorithm\nDescription\nAes128Encryption\n&quot;http://www.w3.org/2001/04/xmlenc#aes128-cbc&quot;\nAes192Encryption\n&quot;http://www.w3.org/2001/04/xmlenc#aes192-cbc&quot;\nAes256Encryption\n&quot;http://www.w3.org/2001/04/xmlenc#aes256-cbc&quot;\nDesEncryption\n&quot;http://www.w3.org/2001/04/xmlenc#des-cbc&quot;\nAes128KeyWrap\n&quot;http://www.w3.org/2001/04/xmlenc#kw-aes128&quot;\nAes192KeyWrap\n&quot;http://www.w3.org/2001/04/xmlenc#kw-aes192&quot;\nAes256KeyWrap\n&quot;http://www.w3.org/2001/04/xmlenc#kw-aes256&quot;\nRsaV15KeyWrap\n&quot;http://www.w3.org/2001/04/xmlenc#rsa-1_5&quot;\nRipemd160Digest\n&quot;http://www.w3.org/2001/04/xmlenc#ripemd160&quot;\nRsaOaepKeyWrap\n&quot;http://www.w3.org/2001/04/xmlenc#rsa-oaep&quot;\nAes128KW\n&quot;A128KW&quot;\nAes256KW\n&quot;A256KW&quot;\nRsaPKCS1\n&quot;RSA1_5&quot;\nRsaOAEP\n&quot;RSA-OAEP&quot;\nExclusiveC14n\n&quot;http://www.w3.org/2001/10/xml-exc-c14n#&quot;\nExclusiveC14nWithComments\n&quot;http://www.w3.org/2001/10/xml-exc-c14n#WithComments&quot;\nEnvelopedSignature\n&quot;http://www.w3.org/2000/09/xmldsig#enveloped-signature&quot;\nSha256Digest\n&quot;http://www.w3.org/2001/04/xmlenc#sha256&quot;\nSha384Digest\n&quot;http://www.w3.org/2001/04/xmldsig-more#sha384&quot;\nSha512Digest\n&quot;http://www.w3.org/2001/04/xmlenc#sha512&quot;\nSha256\n&quot;SHA256&quot;\nSha384\n&quot;SHA384&quot;\nSha512\n&quot;SHA512&quot;\nEcdsaSha256Signature\n&quot;http://www.w3.org/2001/04/xmldsig-more#ecdsa-sha256&quot;\nEcdsaSha384Signature\n&quot;http://www.w3.org/2001/04/xmldsig-more#ecdsa-sha384&quot;\nEcdsaSha512Signature\n&quot;http://www.w3.org/2001/04/xmldsig-more#ecdsa-sha512&quot;\nHmacSha256Signature\n&quot;http://www.w3.org/2001/04/xmldsig-more#hmac-sha256&quot;\nHmacSha384Signature\n&quot;http://www.w3.org/2001/04/xmldsig-more#hmac-sha384&quot;\nHmacSha512Signature\n&quot;http://www.w3.org/2001/04/xmldsig-more#hmac-sha512&quot;\nRsaSha256Signature\n&quot;http://www.w3.org/2001/04/xmldsig-more#rsa-sha256&quot;\nRsaSha384Signature\n&quot;http://www.w3.org/2001/04/xmldsig-more#rsa-sha384&quot;\nRsaSha512Signature\n&quot;http://www.w3.org/2001/04/xmldsig-more#rsa-sha512&quot;\nRsaSsaPssSha256Signature\n&quot;http://www.w3.org/2007/05/xmldsig-more#sha256-rsa-MGF1&quot;\nRsaSsaPssSha384Signature\n&quot;http://www.w3.org/2007/05/xmldsig-more#sha384-rsa-MGF1&quot;\nRsaSsaPssSha512Signature\n&quot;http://www.w3.org/2007/05/xmldsig-more#sha512-rsa-MGF1&quot;\nEcdsaSha256\n&quot;ES256&quot;\nEcdsaSha384\n&quot;ES384&quot;\nEcdsaSha512\n&quot;ES512&quot;\nHmacSha256\n&quot;HS256&quot;\nHmacSha384\n&quot;HS384&quot;\nHmacSha512\n&quot;HS512&quot;\nNone\n&quot;none&quot;\nRsaSha256\n&quot;RS256&quot;\nRsaSha384\n&quot;RS384&quot;\nRsaSha512\n&quot;RS512&quot;\nRsaSsaPssSha256\n&quot;PS256&quot;\nRsaSsaPssSha384\n&quot;PS384&quot;\nRsaSsaPssSha512\n&quot;PS512&quot;\nAes128CbcHmacSha256\n&quot;A128CBC-HS256&quot;\nAes192CbcHmacSha384\n&quot;A192CBC-HS384&quot;\nAes256CbcHmacSha512\n&quot;A256CBC-HS512&quot;\nPlease check Microsoft documentation to get the lastest updates on supported encryption algorithms\nAdd this line of code (only if you use this component stand alone):\nservices.AddBusinessCommonJwtPolicy();\nOn\nStartup.cs\nor on:\ndevon4Net.Application.Configuration.Startup/JwtApplicationConfiguration/ConfigureJwtPolicy method.\nInside the AddBusinessCommonJwtPolicy method you can add your JWT Policy like in My Thai Star application sample:\nservices.ConfigureJwtAddPolicy(&quot;MTSWaiterPolicy&quot;, &quot;role&quot;, &quot;waiter&quot;);\nNotes\nThe certificate will be used to generate the key to encrypt the json web token.\ndevon4Net.Infrastructure.Middleware\nDescription\ndevon4Net support for middleware classes.\nIn ASP.NET Core, middleware classes can handle an HTTP request or response. Middleware can either:\nHandle an incoming HTTP request by generating an HTTP response.\nProcess an incoming HTTP request, modify it, and pass it on to another piece of middleware.\nProcess an outgoing HTTP response, modify it, and pass it on to either another piece of middleware, or the ASP.NET Core web server.\ndevon4Net supports the following automatic response headers:\nAccessControlExposeHeader\nStrictTransportSecurityHeader\nXFrameOptionsHeader\nXssProtectionHeader\nXContentTypeOptionsHeader\nContentSecurityPolicyHeader\nPermittedCrossDomainPoliciesHeader\nReferrerPolicyHeader:toc: macro\nConfiguration\nInstall package on your solution:\nPM&gt; Install-Package devon4Net.Infrastructure.Middleware\nYou can configure your Middleware configuration on appsettings.{environment}.json:\n&quot;Middleware&quot;: {\n&quot;Headers&quot;: {\n&quot;AccessControlExposeHeader&quot;: &quot;Authorization&quot;,\n&quot;StrictTransportSecurityHeader&quot;: &quot;&quot;,\n&quot;XFrameOptionsHeader&quot;: &quot;DENY&quot;,\n&quot;XssProtectionHeader&quot;: &quot;1;mode=block&quot;,\n&quot;XContentTypeOptionsHeader&quot;: &quot;nosniff&quot;,\n&quot;ContentSecurityPolicyHeader&quot;: &quot;&quot;,\n&quot;PermittedCrossDomainPoliciesHeader&quot;: &quot;&quot;,\n&quot;ReferrerPolicyHeader&quot;: &quot;&quot;\n}\n}\nOn the above sample, the server application will add to response header the AccessControlExposeHeader, XFrameOptionsHeader, XssProtectionHeader and XContentTypeOptionsHeader headers.\nIf the header response type does not have a value, it will not be added to the response headers.\ndevon4Net.Infrastructure.Swagger\nDescription\ndevon4net Swagger abstraction to provide full externalized easy configuration.\nSwagger offers the easiest to use tools to take full advantage of all the capabilities of the OpenAPI Specification (OAS).\nConfiguration\nInstall package on your solution:\nPM&gt; devon4Net.Infrastructure.Swagger\nYou can configure your Swagger configuration on appsettings.{environment}.json:\n&quot;Swagger&quot;: {\n&quot;Version&quot;: &quot;v1&quot;,\n&quot;Title&quot;: &quot;devon4net API&quot;,\n&quot;Description&quot;: &quot;devon4net API Contract&quot;,\n&quot;Terms&quot;: &quot;https://www.devonfw.com/terms-of-use/&quot;,\n&quot;Contact&quot;: {\n&quot;Name&quot;: &quot;devonfw&quot;,\n&quot;Email&quot;: &quot;sample@mail.com&quot;,\n&quot;Url&quot;: &quot;https://www.devonfw.com&quot;\n},\n&quot;License&quot;: {\n&quot;Name&quot;: &quot;devonfw - Terms of Use&quot;,\n&quot;Url&quot;: &quot;https://www.devonfw.com/terms-of-use/&quot;\n},\n&quot;Endpoint&quot;: {\n&quot;Name&quot;: &quot;V1 Docs&quot;,\n&quot;Url&quot;: &quot;/swagger/v1/swagger.json&quot;,\n&quot;UrlUi&quot;: &quot;swagger&quot;,\n&quot;RouteTemplate&quot;: &quot;swagger/v1/{documentName}/swagger.json&quot;\n}\n}\nAdd this line of code (only if you use this component stand alone):\nservices.ConfigureSwaggerService();\nOn\nStartup.cs\nAlso add this line of code (only if you use this component stand alone):\napp.ConfigureSwaggerApplication();\nOn\nStartup.cs/Configure(IApplicationBuilder app, IHostingEnvironment env)\nEnsure your API actions and non-route parameters are decorated with explicit &quot;Http&quot; and &quot;From&quot; bindings.\nNotes\nTo access to swagger UI launch your API project and type in your html browser the url http://localhost:yourPort/swagger.\nIn order to generate the documentation annotate your actions with summary, remarks and response tags:\n/// &lt;summary&gt;\n/// Method to make a reservation with potential guests. The method returns the reservation token with the format: {(CB_|GB_)}{now.Year}{now.Month:00}{now.Day:00}{_}{MD5({Host/Guest-email}{now.Year}{now.Month:00}{now.Day:00}{now.Hour:00}{now.Minute:00}{now.Second:00})}\n/// &lt;/summary&gt;\n/// &lt;param name=&quot;bookingDto&quot;&gt;&lt;/param&gt;\n/// &lt;response code=&quot;201&quot;&gt;Ok.&lt;/response&gt;\n/// &lt;response code=&quot;400&quot;&gt;Bad request. Parser data error.&lt;/response&gt;\n/// &lt;response code=&quot;401&quot;&gt;Unauthorized. Authentication fail.&lt;/response&gt;\n/// &lt;response code=&quot;403&quot;&gt;Forbidden. Authorization error.&lt;/response&gt;\n/// &lt;response code=&quot;500&quot;&gt;Internal Server Error. The search process ended with error.&lt;/response&gt;\n[HttpPost]\n[HttpOptions]\n[Route(&quot;/mythaistar/services/rest/bookingmanagement/v1/booking&quot;)]\n[AllowAnonymous]\n[EnableCors(&quot;CorsPolicy&quot;)]\npublic async Task&lt;IActionResult&gt; BookingBooking([FromBody]BookingDto bookingDto)\n{\ntry\n{\n...\nEnsure that your project has the generate XML documentation file check active on build menu:\nFigure 83. Swagger documentation\nEnsure that your XML files has the attribute copy always to true:\nFigure 84. Swagger documentation\ndevon4Net.Infrastructure.Test\nDescription\ndevon4Net Base classes to create unit tests and integration tests with Moq and xUnit.\nConfiguration\nLoad the template:\n&gt; dotnet new -i devon4Net.Test.Template\n&gt; dotnet new devon4NetTest\nNotes\nAt this point you can find this classes:\nBaseManagementTest\nDatabaseManagementTest&lt;T&gt; (Where T is a devon4NetBaseContext class)\nFor unit testing, inherit a class from BaseManagementTest.\nFor integration tests, inherit a class from DatabaseManagementTest.\nThe recommended databases in integration test are in memory database or SQlite database.\nPlease check My thai Star test project.\n"},{"id":644,"path":"../website/pages/docs/master-devon4net.asciidoc_packages.html#packages.asciidoc_deperecated-packages","type":"docs","title":"Deperecated packages","body":"29.1.3. Deperecated packages\ndevon4Net.Domain.Context\nDescription\ndevon4Net.Domain.Context contains the extended class devon4NetBaseContext in order to make easier the process of having a model context configured against different database engines. This configuration allows an easier testing configuration against local and in memory databases.\nConfiguration\nInstall package on your solution:\nPM&gt; Install-Package devon4Net.Domain.Context\nAdd to appsettings.{environment}.json file your database connections:\n&quot;ConnectionStrings&quot;:\n{\n&quot;DefaultConnection&quot;:\n&quot;Server=localhost;Database=MyThaiStar;User Id=sa;Password=sa;MultipleActiveResultSets=True;&quot;,\n&quot;AuthConnection&quot;:\n&quot;Server=(localdb)\\\\mssqllocaldb;Database=aspnet-DualAuthCore-5E206A0B-D4DA-4E71-92D3-87FD6B120C5E;Trusted_Connection=True;MultipleActiveResultSets=true&quot;,\n&quot;SqliteConnection&quot;: &quot;Data Source=c:\\\\tmp\\\\membership.db;&quot;\n}\nOn Startup.cs :\nvoid ConfigureServices(IServiceCollection services)\nAdd your database connections defined on previous point:\nservices.ConfigureDataBase(\nnew Dictionary&lt;string, string&gt; {\n{ConfigurationConst.DefaultConnection, Configuration.GetConnectionString(ConfigurationConst.DefaultConnection) }});\nOn devon4Net.Application.Configuration.Startup/DataBaseConfiguration/ConfigureDataBase configure your connections.\ndevon4Net.Infrastructure.ApplicationUser\nDescription\ndevon4Net Application user classes to implement basic Microsoft&#x2019;s basic authentication in order to be used on authentication methodologies such Jason Web Token (JWT).\nConfiguration\nInstall package on your solution:\nPM&gt; devon4Net.Infrastructure.ApplicationUser\nAdd the database connection string for user management on appsettings.{environment}.json:\n&quot;ConnectionStrings&quot;:\n{\n&quot;AuthConnection&quot;:\n&quot;Server=(localdb)\\\\mssqllocaldb;Database=aspnet-DualAuthCore-5E206A0B-D4DA-4E71-92D3-87FD6B120C5E;Trusted_Connection=True;MultipleActiveResultSets=true&quot;\n}\nAdd the following line of code\nservices.AddApplicationUserDependencyInjection();\nOn\nStartup.cs/ConfigureServices(IServiceCollection services)\nor on:\ndevon4Net.Application.Configuration.Startup/DependencyInjectionConfiguration/ConfigureDependencyInjectionService method.\nAdd the data seeder on Configure method on start.cs class:\npublic void Configure(IApplicationBuilder app, IHostingEnvironment env, DataSeeder seeder)\n{\n...\napp.UseAuthentication();\nseeder.SeedAsync().Wait();\n...\n}\nNotes\nYou can use the following methods to set up the database configuration:\npublic static void AddApplicationUserDbContextInMemoryService(this IServiceCollection services)\npublic static void AddApplicationUserDbContextSQliteService(this IServiceCollection services, string connectionString)\npublic static void AddApplicationUserDbContextSQlServerService(this IServiceCollection services, string connectionString)\nThe method AddApplicationUserDbContextInMemoryService uses the AuthContext connection string name to set up the database.\nThis component is used with the components devon4Net.Infrastructure.JWT and devon4Net.Infrastructure.JWT.MVC.\ndevon4Net.Infrastructure.Communication\nDescription\nBasic client classes to invoke GET/POST methods asynchronously. This component has the minimal classes to send basic data. For more complex operations please use ASP4Net.Infrastructure.Extensions.\nConfiguration\nInstall package on your solution:\nPM&gt; devon4Net.Infrastructure.Communication\nCreate an instance of RestManagementService class.\nUse next methods to use GET/POST basic options:\npublic Task&lt;string&gt; CallGetMethod(string url);\npublic Task&lt;Stream&gt; CallGetMethodAsStream(string url);\npublic Task&lt;string&gt; CallPostMethod&lt;T&gt;(string url, T dataToSend);\npublic Task&lt;string&gt; CallPutMethod&lt;T&gt;(string url, T dataToSend);\nNotes\nExample:\nprivate async Task RestManagementServiceSample(EmailDto dataToSend)\n{\nvar url = Configuration[&quot;EmailServiceUrl&quot;];\nvar restManagementService = new RestManagementService();\nawait restManagementService.CallPostMethod(url, dataToSend);\n}\ndevon4Net.Infrastructure.JWT.MVC\nDescription\ndevon4Net Extended controller to interact with JWT features\nConfiguration\nExtend your _ Microsoft.AspNetCore.Mvc.Controller_ class with devon4NetJWTController class:\npublic class LoginController : devon4NetJWTController\n{\nprivate readonly ILoginService _loginService;\npublic LoginController(ILoginService loginService, SignInManager&lt;ApplicationUser&gt; signInManager, UserManager&lt;ApplicationUser&gt; userManager, ILogger&lt;LoginController&gt; logger, IMapper mapper) : base(logger,mapper)\n{\n_loginService = loginService;\n}\n....\nNotes\nIn order to generate a JWT, you should implement the JWT generation on user login. For example, in My Thai Star is created as follows:\npublic async Task&lt;IActionResult&gt; Login([FromBody]LoginDto loginDto)\n{\ntry\n{\nif (loginDto == null) return Ok();\nvar logged = await _loginService.LoginAsync(loginDto.UserName, loginDto.Password);\nif (logged)\n{\nvar user = await _loginService.GetUserByUserNameAsync(loginDto.UserName);\nvar encodedJwt = new JwtClientToken().CreateClientToken(_loginService.GetUserClaimsAsync(user));\nResponse.Headers.Add(&quot;Access-Control-Expose-Headers&quot;, &quot;Authorization&quot;);\nResponse.Headers.Add(&quot;Authorization&quot;, $&quot;{JwtBearerDefaults.AuthenticationScheme} {encodedJwt}&quot;);\nreturn Ok(encodedJwt);\n}\nelse\n{\nResponse.Headers.Clear();\nreturn StatusCode((int)HttpStatusCode.Unauthorized, &quot;Login Error&quot;);\n}\n}\ncatch (Exception ex)\n{\nreturn StatusCode((int)HttpStatusCode.InternalServerError, $&quot;{ex.Message} : {ex.InnerException}&quot;);\n}\n}\nIn My Thai Star the JWT will contain the user information such id, roles&#x2026;&#x200B;\nOnce you extend your controller with devon4NetJWTController you will have available these methods to simplify user management:\npublic interface Idevon4NetJWTController\n{\n// Gets the current user\nJwtSecurityToken GetCurrentUser();\n// Gets an specific assigned claim of current user\nClaim GetUserClaim(string claimName, JwtSecurityToken jwtUser = null);\n// Gets all the assigned claims of current user\nIEnumerable&lt;Claim&gt; GetUserClaims(JwtSecurityToken jwtUser = null);\n}\ndevon4Net.Infrastructure.MVC\nDescription\nCommon classes to extend controller functionality on API. Also provides support for paged results in devon4Net applications and automapper injected class.\nConfiguration\nInstall package on your solution:\nPM&gt; devon4Net.Infrastructure.MVC\nNotes\nThe generic class ResultObjectDto&lt;T&gt; provides a typed result object with pagination.\nThe extended class provides the following methods:\nResultObjectDto&lt;T&gt; GenerateResultDto&lt;T&gt;(int? page, int? size, int? total);\nResultObjectDto&lt;T&gt; GenerateResultDto&lt;T&gt;(List&lt;T&gt; result, int? page = null, int? size = null);\nGenerateResultDto provides typed ResultObjectDto object or a list of typed ResultObjectDto object. The aim of this methods is to provide a clean management for result objects and not repeating code through the different controller classes.\nThe following sample from My Thai Star shows how to use it:\npublic async Task&lt;IActionResult&gt; Search([FromBody] FilterDtoSearchObject filterDto)\n{\nif (filterDto == null) filterDto = new FilterDtoSearchObject();\ntry\n{\nvar dishList = await _dishService.GetDishListFromFilter(false, filterDto.GetMaxPrice(), filterDto.GetMinLikes(), filterDto.GetSearchBy(),filterDto.GetCategories(), -1);\nreturn new OkObjectResult(GenerateResultDto(dishList).ToJson());\n}\ncatch (Exception ex)\n{\nreturn StatusCode((int)HttpStatusCode.InternalServerError, $&quot;{ex.Message} : {ex.InnerException}&quot;);\n}\n}\ndevon4Net.Infrastructure.AOP\nDescription\nSimple AOP Exception handler for .Net Controller classes integrated with Serilog.\nConfiguration\nInstall package on your solution:\nPM&gt; Install-Package devon4Net.Domain.AOP\nAdd this line of code on ConfigureServices method on Startup.cs\nservices.AddAopAttributeService();\nNotes\nNow automatically your exposed API methods exposed on controller classes will be tracked on the methods:\nOnActionExecuting\nOnActionExecuted\nOnResultExecuting\nOnResultExecuted\nIf an exception occurs, a message will be displayed on log with the stack trace.\ndevon4Net.Infrastructure.Cors\nDescription\nEnables CORS configuration for devon4Net application. Multiple domains can be configured from configuration. Mandatory to web clients (p.e. Angular) to prevent making AJAX requests to another domain.\nCross-Origin Resource Sharing (CORS) is a mechanism that uses additional HTTP headers to tell a browser to let a web application running at one origin (domain) have permission to access selected resources from a server at a different origin. A web application makes a cross-origin HTTP request when it requests a resource that has a different origin (domain, protocol, and port) than its own origin.\nPlease refer to this link to get more information about CORS and .Net core.\nConfiguration\nInstall package on your solution:\nPM&gt; devon4Net.Infrastructure.Cors\nYou can configure your Cors configuration on appsettings.{environment}.json:\nCorsPolicy: indicates the name of the policy. You can use this name to add security headers on your API exposed methods.\nOrigins: The allowed domains\nHeaders: The allowed headers such accept,content-type,origin,x-custom-header\nIf you specify the cors configuration as empty array, a default cors-policy will be used with all origins enabled:\n&quot;Cors&quot;: []\nOn the other hand, you can specify different Cors policies in your solution as follows:\n&quot;Cors&quot;: []\n[\n{\n&quot;CorsPolicy&quot;: &quot;CorsPolicy1&quot;,\n&quot;Origins&quot;: &quot;http:example.com,http:www.contoso.com&quot;,\n&quot;Headers&quot;: &quot;accept,content-type,origin,x-custom-header&quot;,\n&quot;Methods&quot;: &quot;GET,POST,HEAD&quot;,\n&quot;AllowCredentials&quot;: true\n},\n{\n&quot;CorsPolicy&quot;: &quot;CorsPolicy2&quot;,\n&quot;Origins&quot;: &quot;http:example.com,http:www.contoso.com&quot;,\n&quot;Headers&quot;: &quot;accept,content-type,origin,x-custom-header&quot;,\n&quot;Methods&quot;: &quot;GET,POST,HEAD&quot;,\n&quot;AllowCredentials&quot;: true\n}\n]\nNotes\nTo use CORS in your API methods, use the next notation:\n[EnableCors(&quot;YourCorsPolicy&quot;)]\npublic IActionResult Index() {\nreturn View();\n}\nif you want to disable the CORS check use the following annotation:\n[DisableCors]\npublic IActionResult Index() {\nreturn View();\n}\n"},{"id":645,"path":"../website/pages/docs/master-devon4net.asciidoc_packages.html#packages.asciidoc","type":"docs","title":"Required software","body":"29.2. Required software\nVisual Studio Code\nC# Extension for VS Code\n.Net Core SDK\nCORS in .Net Core\n&#x2190;&#xA0;Previous:&#xA0;Environment&#xA0;| &#x2191;&#xA0;Up:&#xA0;devon4net&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Templates&#xA0;&#x2192;\n"},{"id":646,"path":"../website/pages/docs/master-devon4net.asciidoc_samples.html#master-devon4net.asciidoc_samples","type":"docs","title":"Samples","body":"31. Samples\n"},{"id":647,"path":"../website/pages/docs/master-devon4net.asciidoc_templates.html#master-devon4net.asciidoc_templates","type":"docs","title":"Templates","body":"30. Templates\n"},{"id":648,"path":"../website/pages/docs/master-devon4net.asciidoc_templates.html#templates.asciidoc","type":"docs","title":"Templates","body":"30.1. Templates\n"},{"id":649,"path":"../website/pages/docs/master-devon4net.asciidoc_templates.html#templates.asciidoc_overview","type":"docs","title":"Overview","body":"30.1.1. Overview\nThe .Net Core and .Net Framework given templates allows to start coding an application with the following functionality ready to use:\nPlease refer to User guide in order to start developing.\n"},{"id":650,"path":"../website/pages/docs/master-devon4net.asciidoc_templates.html#templates.asciidoc_net-core-3.0","type":"docs","title":"Net Core 3.0","body":"30.1.2. Net Core 3.0\nThe .Net Core 3.0 template allows you to start developing an n-layer server application to provide the latest features. The template can be used in Visual Studio Code and Visual Studio 2019.\nThe application result can be deployed as a console application, microservice or web page.\nTo start developing with devon4Net template, please follow this instructions:\nUsing devon4Net template\nOption 1\nOpen your favourite terminal (Win/Linux/iOS)\nGo to future project&#x2019;s path\nType dotnet new --install Devon4Net.WebAPI.Template\nType dotnet new Devon4NetAPI\nGo to project&#x2019;s path\nYou are ready to start developing with devon4Net\nOption 2\nCreate a new dotnet API project from scracht\nAdd the nuget package reference to your project\nType dotnet new --install Devon4Net.WebAPI.Template\n"},{"id":651,"path":"../website/pages/docs/master-devon4net.asciidoc_templates.html#templates.asciidoc_net-core-2.1.x","type":"docs","title":"Net Core 2.1.x","body":"30.1.3. Net Core 2.1.x\nThe .Net Core 2.1.x template allows you to start developing an n-layer server application to provide the latest features. The template can be used in Visual Studio Code and Visual Studio 2017.\nThe application result can be deployed as a console application, microservice or web page.\nTo start developing with devon4Net template, please follow this instructions:\nUsing devon4Net template\nOpen your favourite terminal (Win/Linux/iOS)\nGo to future project&#x2019;s path\nType dotnet new --install Devon4Net.WebAPI.Template::1.0.8\nType dotnet new Devon4NetAPI\nGo to project&#x2019;s path\nYou are ready to start developing with devon4Net\nFor the latest updates on references packages, please get the sorces from Github\n"},{"id":652,"path":"../website/pages/docs/master-devon4net.asciidoc_templates.html#templates.asciidoc_links","type":"docs","title":"Links","body":"30.1.4. Links\n.Net templates\n&#x2190;&#xA0;Previous:&#xA0;Packages&#xA0;| &#x2191;&#xA0;Up:&#xA0;devon4net&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Samples&#xA0;&#x2192;\n"},{"id":653,"path":"../website/pages/docs/master-devon4net.asciidoc_user-guide.html#master-devon4net.asciidoc_user-guide","type":"docs","title":"User guide","body":"24. User guide\n"},{"id":654,"path":"../website/pages/docs/master-devon4ng.asciidoc.html#master-devon4ng.asciidoc","type":"docs","title":"IV. devon4ng","body":"IV. devon4ng\nIntroduction\nArchitecture\nLayers\nGuides\nAngular\nIonic\nLayouts\nNgRx\nCookbook\n&#x2190;&#xA0;Previous:&#xA0;Tutorials&#xA0;| &#x2191;&#xA0;Up:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Introduction&#xA0;&#x2192;\n"},{"id":655,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#master-devon4ng.asciidoc_angular","type":"docs","title":"Angular","body":"18. Angular\n"},{"id":656,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-accessibility.asciidoc","type":"docs","title":"Accessibility","body":"18.1. Accessibility\nMultiple studies suggest that around 15-20% of the population are living with a disability of some kind. In comparison, that number is higher than any single browser demographic currently, other than Chrome2. Not considering those users when developing an application means excluding a large number of people from being able to use it comfortable or at all.\nSome people are unable to use the mouse, view a screen, see low contrast text, Hear dialogue or music and some people having difficulty to understanding the complex language.This kind of people needed the support like Keyboard support, screen reader support, high contrast text, captions and transcripts and Plain language support. This disability may change the from permanent to the situation.\n"},{"id":657,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-accessibility.asciidoc_key-concerns-of-accessible-web-applications","type":"docs","title":"Key Concerns of Accessible Web Applications","body":"18.1.1. Key Concerns of Accessible Web Applications\nSemantic Markup - Allows the application to be understood on a more general level rather than just details of whats being rendered\nKeyboard Accessibility - Applications must still be usable when using only a keyboard\nVisual Assistance - color contrast, focus of elements and text representations of audio and events\nSemantic Markup\nIf you&#x2019;re creating custom element directives, Web Components or HTML in general, use native elements wherever possible to utilize built-in events and properties. Alternatively, use ARIA to communicate semantic meaning.\nHTML tags have attributes that providers extra context on what&#x2019;s being displayed on the browser. For example, the img tag&#x2019;s alt attribute lets the reader know what is being shown using a short description.However, native tags don&#x2019;t cover all cases. This is where ARIA fits in. ARIA attributes can provide context on what roles specific elements have in the application or on how elements within the document relate to each other.\nA modal component can be given the role of dialog or alertdialog to let the browser know that that component is acting as a modal. The modal component template can use the ARIA attributes aria-labelledby and aria-described to describe to readers what the title and purpose of the modal is.\n@Component({\nselector: &apos;ngc2-app&apos;,\ntemplate: `\n&lt;ngc2-notification-button\nmessage=&quot;Hello!&quot;\nlabel=&quot;Greeting&quot;\nrole=&quot;button&quot;&gt;\n&lt;/ngc2-notification-button&gt;\n&lt;ngc2-modal\n[title]=&quot;modal.title&quot;\n[description]=&quot;modal.description&quot;\n[visible]=&quot;modal.visible&quot;\n(close)=&quot;modal.close()&quot;&gt;\n&lt;/ngc2-modal&gt;\n`\n})\nexport class AppComponent {\nconstructor(private modal: ModalService) { }\n}\nnotification-button.component.ts\n@Component({\nselector: &apos;ngc2-modal&apos;,\ntemplate: `\n&lt;div\nrole=&quot;dialog&quot;\naria-labelledby=&quot;modal-title&quot;\naria-describedby=&quot;modal-description&quot;&gt;\n&lt;div id=&quot;modal-title&quot;&gt;{{title}}&lt;/div&gt;\n&lt;p id=&quot;modal-description&quot;&gt;{{description}}&lt;/p&gt;\n&lt;button (click)=&quot;close.emit()&quot;&gt;OK&lt;/button&gt;\n&lt;/div&gt;\n`\n})\nexport class ModalComponent {\n...\n}\nKeyboard Accessibility\nKeyboard accessibility is the ability of your application to be interacted with using just a keyboard. The more streamlined the site can be used this way, the more keyboard accessible it is. Keyboard accessibility is one of the largest aspects of web accessibility since it targets:\nthose with motor disabilities who can&#x2019;t use a mouse\nusers who rely on screen readers and other assistive technology, which require keyboard navigation\nthose who prefer not to use a mouse\nFocus\nKeyboard interaction is driven by something called focus. In web applications, only one element on a document has focus at a time, and keypresses will activate whatever function is bound to that element.\nFocus element border can be styled with CSS using the outline property, but it should not be removed. Elements can also be styled using the :focus psuedo-selector.\nTabbing\nThe most common way of moving focus along the page is through the tab key. Elements will be traversed in the order they appear in the document outline - so that order must be carefully considered during development.\nThere is way change the default behaviour or tab order. This can be done through the tabindex attribute. The tabindex can be given the values:\n* less than zero - to let readers know that an element should be focusable but not keyboard accessible\n* 0 - to let readers know that that element should be accessible by keyboard\n* greater than zero - to let readers know the order in which the focusable element should be reached using the keyboard. Order is calculated from lowest to highest.\nTransitions\nThe majority of transitions that happen in an Angular application will not involve a page reload. This means that developers will need to carefully manage what happens to focus in these cases.\nFor example:\n@Component({\nselector: &apos;ngc2-modal&apos;,\ntemplate: `\n&lt;div\nrole=&quot;dialog&quot;\naria-labelledby=&quot;modal-title&quot;\naria-describedby=&quot;modal-description&quot;&gt;\n&lt;div id=&quot;modal-title&quot;&gt;{{title}}&lt;/div&gt;\n&lt;p id=&quot;modal-description&quot;&gt;{{description}}&lt;/p&gt;\n&lt;button (click)=&quot;close.emit()&quot;&gt;OK&lt;/button&gt;\n&lt;/div&gt;\n`,\n})\nexport class ModalComponent {\nconstructor(private modal: ModalService, private element: ElementRef) { }\nngOnInit() {\nthis.modal.visible$.subscribe(visible =&gt; {\nif(visible) {\nsetTimeout(() =&gt; {\nthis.element.nativeElement.querySelector(&apos;button&apos;).focus();\n}, 0);\n}\n})\n}\n}\n"},{"id":658,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-accessibility.asciidoc_visual-assistance","type":"docs","title":"Visual Assistance","body":"18.1.2. Visual Assistance\nOne large category of disability is visual impairment. This includes not just the blind, but those who are color blind or partially sighted, and require some additional consideration.\nColor Contrast\nWhen choosing colors for text or elements on a website, the contrast between them needs to be considered. For WCAG 2.0 AA, this means that the contrast ratio for text or visual representations of text needs to be at least 4.5:1. There are tools online to measure the contrast ratio such as this color contrast checker from WebAIM or be checked with using automation tests.\nVisual Information\nColor can help a user&#x2019;s understanding of information, but it should never be the only way to convey information to a user. For example, a user with red/green color-blindness may have trouble discerning at a glance if an alert is informing them of success or failure.\nAudiovisual Media\nAudiovisual elements in the application such as video, sound effects or audio (ie. podcasts) need related textual representations such as transcripts, captions or descriptions. They also should never auto-play and playback controls should be provided to the user.\n"},{"id":659,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-accessibility.asciidoc_accessibility-with-angular-material","type":"docs","title":"Accessibility with Angular Material","body":"18.1.3. Accessibility with Angular Material\nThe a11y package provides a number of tools to improve accessibility. Import\nimport { A11yModule } from &apos;@angular/cdk/a11y&apos;;\nListKeyManager\nListKeyManager manages the active option in a list of items based on keyboard interaction. Intended to be used with components that correspond to a role=&quot;menu&quot; or role=&quot;listbox&quot; pattern . Any component that uses a ListKeyManager will generally do three things:\nCreate a @ViewChildren query for the options being managed.\nInitialize the ListKeyManager, passing in the options.\nForward keyboard events from the managed component to the ListKeyManager.\nEach option should implement the ListKeyManagerOption interface:\ninterface ListKeyManagerOption {\ndisabled?: boolean;\ngetLabel?(): string;\n}\nTypes of ListKeyManager\nThere are two varieties of ListKeyManager, FocusKeyManager and ActiveDescendantKeyManager.\nFocusKeyManager\nUsed when options will directly receive browser focus. Each item managed must implement the FocusableOption interface:\ninterface FocusableOption extends ListKeyManagerOption {\nfocus(): void;\n}\nActiveDescendantKeyManager\nUsed when options will be marked as active via aria-activedescendant. Each item managed must implement the Highlightable interface:\ninterface Highlightable extends ListKeyManagerOption {\nsetActiveStyles(): void;\nsetInactiveStyles(): void;\n}\nEach item must also have an ID bound to the listbox&#x2019;s or menu&#x2019;s aria-activedescendant.\nFocusTrap\nThe cdkTrapFocus directive traps Tab key focus within an element. This is intended to be used to create accessible experience for components like modal dialogs, where focus must be constrained. This directive is declared in A11yModule.\nThis directive will not prevent focus from moving out of the trapped region due to mouse interaction.\nFor example:\n&lt;div class=&quot;my-inner-dialog-content&quot; cdkTrapFocus&gt;\n&lt;!-- Tab and Shift + Tab will not leave this element. --&gt;\n&lt;/div&gt;\nRegions\nRegions can be declared explicitly with an initial focus element by using the cdkFocusRegionStart, cdkFocusRegionEnd and cdkFocusInitial DOM attributes. When using the tab key, focus will move through this region and wrap around on either end.\nFor example:\n&lt;a mat-list-item routerLink cdkFocusRegionStart&gt;Focus region start&lt;/a&gt;\n&lt;a mat-list-item routerLink&gt;Link&lt;/a&gt;\n&lt;a mat-list-item routerLink cdkFocusInitial&gt;Initially focused&lt;/a&gt;\n&lt;a mat-list-item routerLink cdkFocusRegionEnd&gt;Focus region end&lt;/a&gt;\nInteractivityChecker\nInteractivityChecker is used to check the interactivity of an element, capturing disabled, visible, tabbable, and focusable states for accessibility purposes.\nLiveAnnouncer\nLiveAnnouncer is used to announce messages for screen-reader users using an aria-live region.\nFor example:\n@Component({...})\nexport class MyComponent {\nconstructor(liveAnnouncer: LiveAnnouncer) {\nliveAnnouncer.announce(&quot;Hey Google&quot;);\n}\n}\nAPI reference for Angular CDK a11y\nAPI reference for Angular CDK a11y\n"},{"id":660,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-angular-elements.asciidoc","type":"docs","title":"Angular Elements","body":"18.2. Angular Elements\n"},{"id":661,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-angular-elements.asciidoc_what-are-angular-elements","type":"docs","title":"What are Angular Elements?","body":"18.2.1. What are Angular Elements?\nAngular elements are Angular components packaged as custom elements, a web standard for defining new HTML elements in a framework-agnostic way.\nCustom elements are a Web Platform feature currently supported by Chrome, Firefox, Opera, and Safari, and available in other browsers through Polyfills. A custom element extends HTML by allowing you to define a tag whose content is created and controlled by JavaScript code. The browser maintains a CustomElementRegistry of defined custom elements (also called Web Components), which maps an instantiable JavaScript class to an HTML tag.\n"},{"id":662,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-angular-elements.asciidoc_why-use-angular-elements","type":"docs","title":"Why use Angular Elements?","body":"18.2.2. Why use Angular Elements?\nAngular Elements allows Angular to work with different frameworks by using input and output elements. This allows Angular to work with many different frameworks if needed. This is an ideal situation if a slow transformation of an application to Angular is needed or some Angular needs to be added in other web applications(For example. ASP.net, JSP etc )\n"},{"id":663,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-angular-elements.asciidoc_negative-points-about-elements","type":"docs","title":"Negative points about Elements","body":"18.2.3. Negative points about Elements\nAngular Elements is really powerful but since, the transition between views between views is going to be handled by another framework or html/javascript, using Angular Router is not possible. the view transitions have to be handled manually. This fact also eliminates the possibility of just porting an application completely.\n"},{"id":664,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-angular-elements.asciidoc_how-to-use-angular-elements","type":"docs","title":"How to use Angular Elements?","body":"18.2.4. How to use Angular Elements?\nIn a generalized way, a simple Angular component could be transformed to an Angular Element with this steps:\nInstalling Angular Elements\nThe first step is going to be install the library using our prefered packet manager:\nNPM\nnpm install @angular/elements\nYARN\nyarn add @angular/elements\nPreparing the components in the modules\nInside the app.module.ts, in addition to the normal declaration of the components inside declarations, the modules inside imports and the services inside providers, the components need to added in entryComponents. If there are components that have their own module, the same logic is going to be applied for them, only adding in the app.module.ts the components that dont have their own module. Here is an example of this:\n....\n@NgModule({\ndeclarations: [\nDishFormComponent,\nDishViewComponent\n],\nimports: [\nCoreModule, // Module containing Angular Materials\nFormsModule\n],\nentryComponents: [\nDishFormComponent,\nDishViewComponent\n],\nproviders: [DishShareService]\n})\n....\nAfter that is done, the constructor of the module is going to be modified to use injector and boostrap the application defining the components. This is going to allow the Angular Element to get the injections and to define a component tag that will be used later:\n....\n})\nexport class AppModule {\nconstructor(private injector: Injector) {\n}\nngDoBootstrap() {\nconst el = createCustomElement(DishFormComponent, {injector: this.injector});\ncustomElements.define(&apos;dish-form&apos;, el);\nconst elView = createCustomElement(DishViewComponent, {injector: this.injector});\ncustomElements.define(&apos;dish-view&apos;, elView);\n}\n}\n....\nA component example\nIn order to be able to use a component, @Input() and @Output() variables are used. These variables are going to be the ones that will allow the Angular Element to communicate with the framework/javascript:\nComponent html\n&lt;mat-card&gt;\n&lt;mat-grid-list cols=&quot;1&quot; rowHeight=&quot;100px&quot; rowWidth=&quot;50%&quot;&gt;\n&lt;mat-grid-tile colspan=&quot;1&quot; rowspan=&quot;1&quot;&gt;\n&lt;span&gt;{{ platename }}&lt;/span&gt;\n&lt;/mat-grid-tile&gt;\n&lt;form (ngSubmit)=&quot;onSubmit(dishForm)&quot; #dishForm=&quot;ngForm&quot;&gt;\n&lt;mat-grid-tile colspan=&quot;1&quot; rowspan=&quot;1&quot;&gt;\n&lt;mat-form-field&gt;\n&lt;input matInput placeholder=&quot;Name&quot; name=&quot;name&quot; [(ngModel)]=&quot;dish.name&quot;&gt;\n&lt;/mat-form-field&gt;\n&lt;/mat-grid-tile&gt;\n&lt;mat-grid-tile colspan=&quot;1&quot; rowspan=&quot;1&quot;&gt;\n&lt;mat-form-field&gt;\n&lt;textarea matInput placeholder=&quot;Description&quot; name=&quot;description&quot; [(ngModel)]=&quot;dish.description&quot;&gt;&lt;/textarea&gt;\n&lt;/mat-form-field&gt;\n&lt;/mat-grid-tile&gt;\n&lt;mat-grid-tile colspan=&quot;1&quot; rowspan=&quot;1&quot;&gt;\n&lt;button mat-raised-button color=&quot;primary&quot; type=&quot;submit&quot;&gt;Submit&lt;/button&gt;\n&lt;/mat-grid-tile&gt;\n&lt;/form&gt;\n&lt;/mat-grid-list&gt;\n&lt;/mat-card&gt;\nComponent ts\n@Component({\ntemplateUrl: &apos;./dish-form.component.html&apos;,\nstyleUrls: [&apos;./dish-form.component.scss&apos;]\n})\nexport class DishFormComponent implements OnInit {\n@Input() platename;\n@Input() platedescription;\n@Output()\nsubmitDishEvent = new EventEmitter();\nsubmitted = false;\ndish = {name: &apos;&apos;, description: &apos;&apos;};\nconstructor(public dishShareService: DishShareService) { }\nngOnInit() {\nthis.dish.name = this.platename;\nthis.dish.description = this.platedescription;\n}\nonSubmit(dishForm: NgForm): void {\nthis.dishShareService.createDish(dishForm.value.name, dishForm.value.description);\nthis.submitDishEvent.emit(&apos;dishSubmited&apos;);\n}\n}\nIn this file there are definitions of multiple variables that will be used as input and output. Since the input variables are going to be used directly by html, only lowercase and underscore strategies can be used for them. On the onSubmit(dishForm: NgForm) a service is used to pass this variables to another component. Finally, as a last thing, the selector inside @Component has been removed since a tag that will be used dynamically was already defined in the last step.\nSolving the error\nIn order to be able to use this Angular Element a Polyfills/Browser support related error needs to solved. This error can be solved in two ways:\nChanging the target\nOne solution is to change the target in tsconfig.json to es2015. This might not be doable for every application since maybe a specific target is required.\nInstalling Polyfaces\nAnother solution is to use AutoPollyfill. In order to do so, the library is going to be installed with a packet manager:\nYarn\nyarn add @webcomponents/webcomponentsjs\nNpm\nnpm install @webcomponents/webcomponentsjs\nAfter the packet manager has finished, inside the src folder a new file polyfills.ts is found. To solve the error, importing the corresponding adapter (custom-elements-es5-adapter.js) is necessary:\n....\n/***************************************************************************************************\n* APPLICATION IMPORTS\n*/\nimport &apos;@webcomponents/webcomponentsjs/custom-elements-es5-adapter.js&apos;;\n....\nIf you want to learn more about polyfills in angular you can do it here\nBuilding the Angular Element\nFirst, before building the Angular Element, every element inside that app component except the module need to be removed. After that, a bash script is created in the root folder,. This script will allow to put every necessary file into a js.\nng build &quot;projectName&quot; --prod --output-hashing=none &amp;&amp; cat dist/&quot;projectName&quot;/runtime.js dist/&quot;projectName&quot;/polyfills.js dist/&quot;projectName&quot;/scripts.js dist/&quot;projectName&quot;/main.js &gt; ./dist/&quot;projectName&quot;/&quot;nameWantedAngularElement&quot;.js\nAfter executing the bash script, it will generate inside the path dist/&quot;projectName&quot; a js file named &quot;nameWantedAngularElement&quot;.js and a css file.\nBuilding with ngx-build-plus (Recommended)\nThe library ngx-build-plus allows to add different options when building. In addition, it solves some errors that will occur when trying to use multiple angular elements in an application. In order to use it, yarn or npm can be used:\nYarn\nyarn add ngx-build-plus\nNpm\nnpm install ngx-build-plus\nIf you want to add it to a specific sub project in your projects folder, use the --project:\n.... ngx-build-plus --project &quot;project-name&quot;\nUsing this library and the following command, an isolated Angular Element which won&#x2019;t have conflict with others can be generated. This Angular Element will not have a polyfill so, the project where we use them will need to include a poliyfill with the Angular Element requirements.\nng build &quot;projectName&quot; --output-hashing none --single-bundle true --prod --bundle-styles false\nThis command will generate three things:\nThe main js bundle\nThe script js\nThe css\nThese files will be used later instead of the single js generated in the last step.\nExtra parameters\nHere are some extra useful parameters that ngx-build-plus provides:\n--keep-polyfills: This paremeter is going to allow us to keep the polyfills. This needs to be used with caution, avoiding using multiple different polyfills that could cause an error is necessary.\n--extraWebpackConfig webpack.extra.js: This parameter allows us to create a javascript file inside our Angular Elements project with the name of different libraries. Using webpack these libraries will not be included in the Angular Element. This is useful to lower the size of our Angular Element by removing libraries shared. Example:\nconst webpack = require(&apos;webpack&apos;);\nmodule.exports = {\n&quot;externals&quot;: {\n&quot;rxjs&quot;: &quot;rxjs&quot;,\n&quot;@angular/core&quot;: &quot;ng.core&quot;,\n&quot;@angular/common&quot;: &quot;ng.common&quot;,\n&quot;@angular/common/http&quot;: &quot;ng.common.http&quot;,\n&quot;@angular/platform-browser&quot;: &quot;ng.platformBrowser&quot;,\n&quot;@angular/platform-browser-dynamic&quot;: &quot;ng.platformBrowserDynamic&quot;,\n&quot;@angular/compiler&quot;: &quot;ng.compiler&quot;,\n&quot;@angular/elements&quot;: &quot;ng.elements&quot;,\n&quot;@angular/router&quot;: &quot;ng.router&quot;,\n&quot;@angular/forms&quot;: &quot;ng.forms&quot;\n}\n}\nNote\nIf some libraries are excluded from the `Angular Element` you will need to add the bundled umd files of those libraries manually.\nUsing the Angular Element\nThe Angular Element that got generated in the last step can be used in almost every framework. In this case, the Angular Element is going to be used in html:\nListing 17. Sample index.html version without ngx-build-plus\n&lt;html&gt;\n&lt;head&gt;\n&lt;link rel=&quot;stylesheet&quot; href=&quot;styles.css&quot;&gt;\n&lt;/head&gt;\n&lt;body&gt;\n&lt;div id=&quot;container&quot;&gt;\n&lt;/div&gt;\n&lt;!--Use of the element non dynamically--&gt;\n&lt;!--&lt;plate-form platename=&quot;test&quot; platedescription=&quot;test&quot;&gt;&lt;/plate-form&gt;--&gt;\n&lt;script src=&quot;./devon4ngAngularElements.js&quot;&gt; &lt;/script&gt;\n&lt;script&gt;\nvar elContainer = document.getElementById(&apos;container&apos;);\nvar el= document.createElement(&apos;dish-form&apos;);\nel.setAttribute(&apos;platename&apos;,&apos;test&apos;);\nel.setAttribute(&apos;platedescription&apos;,&apos;test&apos;);\nel.addEventListener(&apos;submitDishEvent&apos;,(ev)=&gt;{\nvar elView= document.createElement(&apos;dish-view&apos;);\nelContainer.innerHTML = &apos;&apos;;\nelContainer.appendChild(elView);\n});\nelContainer.appendChild(el);\n&lt;/script&gt;\n&lt;/body&gt;\n&lt;/html&gt;\nListing 18. Sample index.html version with ngx-build-plus\n&lt;html&gt;\n&lt;head&gt;\n&lt;link rel=&quot;stylesheet&quot; href=&quot;styles.css&quot;&gt;\n&lt;/head&gt;\n&lt;body&gt;\n&lt;div id=&quot;container&quot;&gt;\n&lt;/div&gt;\n&lt;!--Use of the element non dynamically--&gt;\n&lt;!--&lt;plate-form platename=&quot;test&quot; platedescription=&quot;test&quot;&gt;&lt;/plate-form&gt;--&gt;\n&lt;script src=&quot;./polyfills.js&quot;&gt; &lt;/script&gt; &lt;!-- Created using --keep-polyfills options --&gt;\n&lt;script src=&quot;./scripts.js&quot;&gt; &lt;/script&gt;\n&lt;script src=&quot;./main.js&quot;&gt; &lt;/script&gt;\n&lt;script&gt;\nvar elContainer = document.getElementById(&apos;container&apos;);\nvar el= document.createElement(&apos;dish-form&apos;);\nel.setAttribute(&apos;platename&apos;,&apos;test&apos;);\nel.setAttribute(&apos;platedescription&apos;,&apos;test&apos;);\nel.addEventListener(&apos;submitDishEvent&apos;,(ev)=&gt;{\nvar elView= document.createElement(&apos;dish-view&apos;);\nelContainer.innerHTML = &apos;&apos;;\nelContainer.appendChild(elView);\n});\nelContainer.appendChild(el);\n&lt;/script&gt;\n&lt;/body&gt;\n&lt;/html&gt;\nIn this html, the css generated in the last step is going to be imported inside the &lt;head&gt; and then, the javascript element is going to be imported at the end of the body. After that is done, There is two uses of Angular Elements in the html, one directly whith use of the @input() variables as parameters commented in the html:\n....\n&lt;!--Use of the element non dynamically--&gt;\n&lt;!--&lt;plate-form platename=&quot;test&quot; platedescription=&quot;test&quot;&gt;&lt;/plate-form&gt;--&gt;\n....\nand one dynamically inside the script:\n....\n&lt;script&gt;\nvar elContainer = document.getElementById(&apos;container&apos;);\nvar el= document.createElement(&apos;dish-form&apos;);\nel.setAttribute(&apos;platename&apos;,&apos;test&apos;);\nel.setAttribute(&apos;platedescription&apos;,&apos;test&apos;);\nel.addEventListener(&apos;submitDishEvent&apos;,(ev)=&gt;{\nvar elView= document.createElement(&apos;dish-view&apos;);\nelContainer.innerHTML = &apos;&apos;;\nelContainer.appendChild(elView);\n});\nelContainer.appendChild(el);\n&lt;/script&gt;\n....\nThis javascript is an example of how to create dynamically an Angular Element inserting attributed to fill our @Input() variables and listen to the @Output() that was defined earlier. This is done with:\nel.addEventListener(&apos;submitDishEvent&apos;,(ev)=&gt;{\nvar elView= document.createElement(&apos;dish-view&apos;);\nelContainer.innerHTML = &apos;&apos;;\nelContainer.appendChild(elView);\n});\nThis allows javascript to hook with the @Output() event emitter that was defined. When this event gets called, another component that was defined gets inserted dynamically.\n"},{"id":665,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-angular-elements.asciidoc_angular-element-within-another-angular-project","type":"docs","title":"Angular Element within another Angular project","body":"18.2.5. Angular Element within another Angular project\nIn order to use an Angular Element within another Angular project the following steps need to be followed:\nCopy bundled script and css to resources\nFirst copy the generated .js and .css inside assets in the corresponding folder.\nAdd bundled script to angular.json\nInside angular.json both of the files that were copied in the last step are going to be included. This will be done both, in test and in build. Including it on the test, will allow to perform unitary tests.\n{\n....\n&quot;architect&quot;: {\n....\n&quot;build&quot;: {\n....\n&quot;styles&quot;: [\n....\n&quot;src/assets/css/devon4ngAngularElements.css&quot;\n....\n]\n....\n&quot;scripts&quot;: [\n&quot;src/assets/js/devon4ngAngularElements.js&quot;\n]\n....\n}\n....\n&quot;test&quot;: {\n....\n&quot;styles&quot;: [\n....\n&quot;src/assets/css/devon4ngAngularElements.css&quot;\n....\n]\n....\n&quot;scripts&quot;: [\n&quot;src/assets/js/devon4ngAngularElements.js&quot;\n]\n....\n}\n}\n}\nBy declaring the files in the angular.json angular will take care of including them in a proper way.\nUsing Angular Element\nThere are two ways that Angular Element can be used:\nCreate component dynamicly\nIn order to add the component in a dynamic way, first adding a container is necessary:\napp.component.html\n....\n&lt;div id=&quot;container&quot;&gt;\n&lt;/div&gt;\n....\nWith this container created, inside the app.component.ts a method is going to be created. This method is going to find the container, create the dynamic element and append it into the container.\napp.component.ts\nexport class AppComponent implements OnInit {\n....\nngOnInit(): void {\nthis.createComponent();\n}\n....\ncreateComponent(): void {\nconst container = document.getElementById(&apos;container&apos;);\nconst component = document.createElement(&apos;dish-form&apos;);\ncontainer.appendChild(component);\n}\n....\nUsing it directly\nIn order to use it directly on the templates, in the app.module.ts the CUSTOM_ELEMENTS_SCHEMA needs to be added:\n....\nimport { NgModule, CUSTOM_ELEMENTS_SCHEMA } from &apos;@angular/core&apos;;\n....\n@NgModule({\n....\nschemas: [ CUSTOM_ELEMENTS_SCHEMA ],\nThis is going to allow the use of the Angular Element in the templates directly:\napp.component.html\n....\n&lt;div id=&quot;container&quot;&gt;\n&lt;dish-form&gt;&lt;/dish-form&gt;\n&lt;/div&gt;\n"},{"id":666,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-angular-lazy-loading.asciidoc","type":"docs","title":"Angular Lazy loading","body":"18.3. Angular Lazy loading\nWhen the development of an application starts, it just contains a small set of features so the app usually loads fast. However, as new features are added, the overall application size grows up and its loading speed decreases, is in this context where Lazy loading finds its place.\nLazy loading is a dessign pattern that defers initialization of objects until it is needed so, for example, Users that just access to a website&#x2019;s home page do not need to have other areas loaded.\nAngular handles lazy loading through the routing module which redirect to requested pages. Those pages can be loaded at start or on demand.\n"},{"id":667,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-angular-lazy-loading.asciidoc_an-example-with-angular","type":"docs","title":"An example with Angular","body":"18.3.1. An example with Angular\nTo explain how lazy loading is implemented using angular, a basic sample app is going to be developed. This app will consist in a window named &quot;level 1&quot; that contains two buttons that redirects to other windows in a &quot;second level&quot;. It is a simple example, but useful to understand the relation between angular modules and lazy loading.\nFigure 19. Levels app structure.\nThis graphic shows that modules acts as gates to access components &quot;inside&quot; them.\nBecause the objective of this guide is related mainly with logic, the html structure and scss styles are less relevant, but the complete code can be found as a sample here.\nImplementation\nFirst write in a console ng new level-app --routing, to generate a new project called level-app including an app-routing.module.ts file (--routing flag).\nIn the file app.component.html delete all the content except the router-outlet tag.\nListing 19. File app.component.html\n&lt;router-outlet&gt;&lt;/router-outlet&gt;\nThe next steps consists on creating features modules.\nrun ng generate module first --routing to generate a module named first.\nrun ng generate module first/second-left --routing to generate a module named second-left under first.\nrun ng generate module first/second-right --routing to generate a module second-right under first.\nrun ng generate component first/first to generate a component named first inside the module first.\nrun ng generate component first/second-left/content to generate a component content inside the module second-left.\nrun ng generate component first/second-right/content to generate a component content inside the module second-right.\nTo move between components we have to configure the routes used:\nIn app-routing.module.ts add a path &apos;first&apos; to FirstComponent and a redirection from &apos;&apos; to &apos;first&apos;.\nListing 20. File app-routing.module.ts.\n...\nimport { FirstComponent } from &apos;./first/first/first.component&apos;;\nconst routes: Routes = [\n{\npath: &apos;first&apos;,\ncomponent: FirstComponent\n},\n{\npath: &apos;&apos;,\nredirectTo: &apos;first&apos;,\npathMatch: &apos;full&apos;,\n},\n];\n@NgModule({\nimports: [RouterModule.forRoot(routes)],\nexports: [RouterModule],\n})\nexport class AppRoutingModule {}\nIn app.module.ts import the module which includes FirstComponent.\nListing 21. File app.module.ts\n....\nimport { FirstModule } from &apos;./first/first.module&apos;;\n@NgModule({\n...\nimports: [\n....\nFirstModule\n],\n...\n})\nexport class AppModule { }\nIn first-routing.module.ts add routes that direct to the content of SecondRightModule and SecondLeftModule. The content of both modules have the same name so, in order to avoid conflicts the name of the components are going to be changed using as ( original-name as new-name).\nListing 22. File first-routing.module.ts\n...\nimport { ContentComponent as ContentLeft} from &apos;./second-left/content/content.component&apos;;\nimport { ContentComponent as ContentRight} from &apos;./second-right/content/content.component&apos;;\nimport { FirstComponent } from &apos;./first/first.component&apos;;\nconst routes: Routes = [\n{\npath: &apos;&apos;,\ncomponent: FirstComponent\n},\n{\npath: &apos;first/second-left&apos;,\ncomponent: ContentLeft\n},\n{\npath: &apos;first/second-right&apos;,\ncomponent: ContentRight\n}\n];\n@NgModule({\nimports: [RouterModule.forChild(routes)],\nexports: [RouterModule]\n})\nexport class FirstRoutingModule { }\nIn first.module.ts import SecondLeftModule and SecondRightModule.\nListing 23. File first.module.ts\n...\nimport { SecondLeftModule } from &apos;./second-left/second-left.module&apos;;\nimport { SecondRightModule } from &apos;./second-right/second-right.module&apos;;\n@NgModule({\n...\nimports: [\n...\nSecondLeftModule,\nSecondRightModule,\n]\n})\nexport class FirstModule { }\nUsing the current configuration, we have a project that loads all the modules in a eager way. Run ng serve to see what happens.\nFirst, during the compilation we can see that just a main file is built.\nFigure 20. Compile eager.\nIf we go to http//localhost:4200/first and open developer options (F12 on Chrome), it is found that a document named &quot;first&quot; is loaded.\nFigure 21. First level eager.\nIf we click on [Go to right module] a second level module opens, but there is no &apos;second-right&apos; document.\nFigure 22. Second level right eager.\nBut, typing the url directly will load &apos;second-right&apos; but no &apos;first&apos;, even if we click on [Go back]\nFigure 23. Second level right eager direct url.\nModifying an angular application to load its modules lazily is easy, you have to change the routing configuration of the desired module (for example FirstModule).\nListing 24. File app-routing.module.ts.\nconst routes: Routes = [\n{\npath: &apos;first&apos;,\nloadChildren: () =&gt; import(&apos;./first/first.module&apos;).then(m =&gt; m.FirstModule),\n},\n{\npath: &apos;&apos;,\nredirectTo: &apos;first&apos;,\npathMatch: &apos;full&apos;,\n},\n];\n@NgModule({\nimports: [RouterModule.forRoot(routes)],\nexports: [RouterModule],\n})\nexport class AppRoutingModule {}\nNotice that instead of loading a component, you dynamically import it in a loadChildren attribute because modules acts as gates to access components &quot;inside&quot; them. Updating the app to load lazily has four consecuences:\nNo component attribute.\nNo import of FirstComponent.\nFirstModule import has to be removed from the imports array at app.module.ts.\nChange of context.\nIf we check first-routing.module.ts again, the can see that the path for ContentLeft and ContentRight is set to &apos;first/second-left&apos; and &apos;first/second-right&apos; respectively, so writing &apos;http//localhost:4200/first/second-left&apos; will redirect us to ContentLeft. However, after loading a module with loadChildren setting the path to &apos;second-left&apos; and &apos;second-right&apos; is enough because it adquires the context set by AppRoutingModule.\nListing 25. File first-routing.module.ts\nconst routes: Routes = [\n{\npath: &apos;&apos;,\ncomponent: FirstComponent\n},\n{\npath: &apos;second-left&apos;,\ncomponent: ContentLeft\n},\n{\npath: &apos;second-right&apos;,\ncomponent: ContentRight\n}\n];\nIf we go to &apos;first&apos; then FirstModule is situated in &apos;/first&apos; but also its children ContentLeft and ContentRight, so it is not necessary to write in their path &apos;first/second-left&apos; and &apos;first/second-right&apos;, because that will situate the components on &apos;first/first/second-left&apos; and &apos;first/first/second-right&apos;.\nFigure 24. First level lazy wrong path.\nWhen we compile an app with lazy loaded modules, files containing them will be generated\nFigure 25. First level lazy compilation.\nAnd if we go to developer tools &#x2192; network, we can find those modules loaded (if they are needed).\nFigure 26. First level lazy.\nTo load the component ContentComponent of SecondLeftModule lazily, we have to load SecondLeftModule as a children of FirstModule:\nChange component to loadChildren and reference SecondLeftModule.\nListing 26. File first-routing.module.ts.\nconst routes: Routes = [\n{\npath: &apos;&apos;,\ncomponent: FirstComponent\n},\n{\npath: &apos;second-left&apos;,\nloadChildren: () =&gt; import(&apos;./second-left/second-left.module&apos;).then(m =&gt; m.SecondLeftModule),\n},\n{\npath: &apos;second-right&apos;,\ncomponent: ContentRight\n}\n];\nRemove SecondLeftModule at first.component.ts\nRoute the components inside SecondLeftModule. Without this step nothing would be displayed.\nListing 27. File second-left-routing.module.ts.\n...\nimport { ContentComponent } from &apos;./content/content.component&apos;;\nconst routes: Routes = [\n{\npath: &apos;&apos;,\ncomponent: ContentComponent\n}\n];\n@NgModule({\nimports: [RouterModule.forChild(routes)],\nexports: [RouterModule]\n})\nexport class SecondLeftRoutingModule { }\nrun ng serve to generate files containing the lazy modules.\nFigure 27. Second level lazy loading compilation.\nClicking on [Go to left module] triggers the load of SecondLeftModule.\nFigure 28. Second level lazy loading network.\n"},{"id":668,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-angular-lazy-loading.asciidoc_conclusion","type":"docs","title":"Conclusion","body":"18.3.2. Conclusion\nLazy loading is a pattern useful when new features are added, these features are usually identified as modules which can be loaded only if needed as shown in this document, reducing the time spent loading an application.\n"},{"id":669,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-angular-library.asciidoc","type":"docs","title":"Angular Library","body":"18.4. Angular Library\nAngular CLI provides us with methods that allow the creation of a library. After that, using either packet manager (npm or yarn) the library can be build and packed which will allow later to install/publish it.\n"},{"id":670,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-angular-library.asciidoc_whats-a-library","type":"docs","title":"Whats a library?","body":"18.4.1. Whats a library?\nFrom wikipedia: a library is a collection of non-volatile resources used by computer programs, often for software development. These may include configuration data, documentation, help data, message templates, pre-written code and subroutines, classes, values or type specifications.\n"},{"id":671,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-angular-library.asciidoc_how-to-build-a-library","type":"docs","title":"How to build a library","body":"18.4.2. How to build a library\nIn this section, a library is going to be build step by step.\nCreating an empty application\nFirst, using Angular CLI we are going to generate a empty application which will be later filled with the generated library. In order to do so, Angular CLI allows us to add to ng new &quot;application-name&quot; an option (--create-application). This option is going to tell Angular CLI not to create the initial app project. This is convenient since a library is going to be generated in later steps. Using this command ng new &quot;application-name&quot; --create-application=false an empty project with the name wanted is created.\nng new &quot;application-name&quot; --create-application=false\nGenerating a library\nAfter generating an empty application, a library is going to be generated. Inside the folder of the project, the Angular CLI command ng generate library &quot;library-name&quot; is going to generate the library as a project (projects/&quot;library-name&quot;). As an addition, the option --prefix=&quot;library-prefix-wanted&quot; allows us to switch the default prefix that Angular generated with (lib). Using the option to change the prefix the command will look like this ng generate library &quot;library-name&quot; --prefix=&quot;library-prefix-wanted&quot;.\nng generate library &quot;library-name&quot; --prefix=&quot;library-prefix-wanted&quot;\nGenerating/Modifying in our library\nIn the last step we generated a library. This generates automaticly a module,service and component inside (projects/&quot;library-name&quot;) that we can modify adding new methods, components etc that we want to use in other projects. We can generate other elements, using the usual Angular CLI generate commands adding the option --project=&quot;library-name&quot; is going to allow to generate elements within our project . An example of this is: ng generate service &quot;name&quot; --project=&quot;library-name&quot;.\nng generate &quot;element&quot; &quot;name&quot; --project=&quot;library-name&quot;\nExporting the generated things\nInside the library (projects/&quot;library-name) theres a public_api.ts which is the file that exports the elements inside the library. In case we generated other things, that file needs to be modified adding the extra exports with the generated elements. In addition, changing the library version is possible in the file package.json.\nBuilding our library\nOnce we added the necessary exports, in order to use the library in other applications, we need to build the library. The command ng build &quot;library-name&quot; is going to build the library, generating in &quot;project-name&quot;/dist/&quot;library-name&quot; the necessary files.\nng build &quot;library-name&quot;\nPacking the library\nIn this step we are going to pack the build library. In order to do so, we need to go inside dist/&quot;library-name&quot; and then run either npm pack or yarn pack to generate a &quot;library-name-version.tgz&quot; file.\nListing 28. Packing using npm\nnpm pack\nListing 29. Packing using yarn\nyarn pack\nPublishing to npm repository (optional)\nAdd a README.md and LICENSE file. The text inside README.md will be used in you npm package web page as documentation.\nrun npm adduser if you do not have a npm account to create it, otherwise run npm login and introduce your credentials.\nrun npm publish inside dist/&quot;library-name&quot; folder.\nCheck that the library is published: https://npmjs.com/package/library-name\nInstalling our library in other projects\nIn this step we are going to install/add the library on other projects.\nnpm\nIn order to add the library in other applications, there are two ways:\nOption 1: From inside the application where the library is going to get used, using the command npm install &quot;path-to-tgz&quot;/&quot;library-name-version.tgz&quot; allows us to install the .tgz generated in Packing the library.\nOption 2: run npm install &quot;library-name&quot; to install it from npm repository.\nyarn\nTo add the package using yarn:\nOption 1: From inside the application where the library is going to get used, using the command yarn add &quot;path-to-tgz&quot;/&quot;library-name-version.tgz&quot; allows us to install the .tgz generated in Packing the library.\nOption 2: run yarn add &quot;library-name&quot; to install it from npm repository.\nUsing the library\nFinally, once the library was installed with either packet manager, you can start using the elements from inside like they would be used in a normal element inside the application. Example app.component.ts:\nimport { Component, OnInit } from &apos;@angular/core&apos;;\nimport { MyLibraryService } from &apos;my-library&apos;;\n@Component({\nselector: &apos;app-root&apos;,\ntemplateUrl: &apos;./app.component.html&apos;,\nstyleUrls: [&apos;./app.component.scss&apos;]\n})\nexport class AppComponent implements OnInit {\ntoUpper: string;\nconstructor(private myLibraryService: MyLibraryService) {}\ntitle = &apos;devon4ng library test&apos;;\nngOnInit(): void {\nthis.toUpper = this.myLibraryService.firstLetterToUpper(&apos;test&apos;);\n}\n}\nExample app.component.html:\n&lt;!--The content below is only a placeholder and can be replaced.--&gt;\n&lt;div style=&quot;text-align:center&quot;&gt;\n&lt;h1&gt;\nWelcome to {{ title }}!\n&lt;/h1&gt;\n&lt;img width=&quot;300&quot; alt=&quot;Angular Logo&quot; src=&quot;data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNTAgMjUwIj4KICAgIDxwYXRoIGZpbGw9IiNERDAwMzEiIGQ9Ik0xMjUgMzBMMzEuOSA2My4ybDE0LjIgMTIzLjFMMTI1IDIzMGw3OC45LTQzLjcgMTQuMi0xMjMuMXoiIC8+CiAgICA8cGF0aCBmaWxsPSIjQzMwMDJGIiBkPSJNMTI1IDMwdjIyLjItLjFWMjMwbDc4LjktNDMuNyAxNC4yLTEyMy4xTDEyNSAzMHoiIC8+CiAgICA8cGF0aCAgZmlsbD0iI0ZGRkZGRiIgZD0iTTEyNSA1Mi4xTDY2LjggMTgyLjZoMjEuN2wxMS43LTI5LjJoNDkuNGwxMS43IDI5LjJIMTgzTDEyNSA1Mi4xem0xNyA4My4zaC0zNGwxNy00MC45IDE3IDQwLjl6IiAvPgogIDwvc3ZnPg==&quot;&gt;\n&lt;/div&gt;\n&lt;h2&gt;Here is my library service being used: {{toUpper}}&lt;/h2&gt;\n&lt;lib-my-library&gt;&lt;/lib-my-library&gt;\nExample app.module.ts:\nimport { BrowserModule } from &apos;@angular/platform-browser&apos;;\nimport { NgModule } from &apos;@angular/core&apos;;\nimport { AppRoutingModule } from &apos;./app-routing.module&apos;;\nimport { AppComponent } from &apos;./app.component&apos;;\nimport { MyLibraryModule } from &apos;my-library&apos;;\n@NgModule({\ndeclarations: [\nAppComponent\n],\nimports: [\nBrowserModule,\nAppRoutingModule,\nMyLibraryModule\n],\nproviders: [],\nbootstrap: [AppComponent]\n})\nexport class AppModule { }\nThe result from using the library:\ndevon4ng libraries\nIn devonfw/devon4ng-library you can find some useful libraries:\nAuthorization module: This devon4ng Angular module adds rights-based authorization to your Angular app.\nCache module: Use this devon4ng Angular module when you want to cache requests to server. You may configure it to store in cache only the requests you need and to set the duration you want.\n"},{"id":672,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-angular-theming.asciidoc","type":"docs","title":"Angular Material Theming","body":"18.5. Angular Material Theming\nAngular Material library offers UI components for developers, those components follows Google Material desing baselines but characteristics like colors can be modified in order to adapt them to the needs of the client: corporative colors, corporative identity, dark themes, &#x2026;&#x200B;\n"},{"id":673,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-angular-theming.asciidoc_theming-basics","type":"docs","title":"Theming basics","body":"18.5.1. Theming basics\nIn Angular Material, a theme is created mixing multiple colors. Colors and its light and dark variants conform a palette. In general, a theme consists of the following palettes:\nprimary: Most used across screens and componets.\naccent: Floating action button and interactive elements.\nwarn: Error state.\nforeground: Text and icons.\nbackground: Element backgrounds.\nFigure 29. Palettes and variants.\nIn angular material, a palette is represented as a scss map.\nFigure 30. Scss map and palettes.\nTip\nSome components can be forced to use primary, accent or warn palettes using the attribute color, for example: &lt;mat-toolbar color=&quot;primary&quot;&gt;.\n"},{"id":674,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-angular-theming.asciidoc_prebuilt-themes","type":"docs","title":"Prebuilt themes","body":"18.5.2. Prebuilt themes\nAvailable prebuilt themes:\ndeeppurple-amber.css\nFigure 31. deeppurple-amber theme.\nindigo-pink.css\nFigure 32. indigo-pink theme.\npink-bluegrey.css\nFigure 33. ink-bluegrey theme.\npurple-green.css\nFigure 34. purple-green theme.\nThe prebuilt themes can be added using @import.\n@import &apos;@angular/material/prebuilt-themes/deeppurple-amber.css&apos;;\n"},{"id":675,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-angular-theming.asciidoc_custom-themes","type":"docs","title":"Custom themes","body":"18.5.3. Custom themes\nSomethimes prebuild themes do not meet the needs of a project, because color schemas are too specific or do not incorporate branding colors, in those situations custom themes can be built to offer a better solution to the client.\nFor this topic, we are going to use a basic layout project that can be found in devon4ng repository.\nBasics\nBefore starting writing custom themes, there are some necessary things that have to be mentioned:\nAdd a default theme: The project mentioned before has just one global scss stylesheet styles.scss that includes indigo-pink.scss which will be the default theme.\nAdd @import &apos;~@angular/material/theming&apos;; at the begining of the every stylesheet to be able to use angular material prebuilt color palettes and functions.\nAdd @include mat-core(); once per project, so if you are writing multiple themes in multiple files you could import those files from a &apos;central&apos; one (for example styles.scss). This includes all common styles that are used by multiple components.\nFigure 35. Theme files structure.\nBasic custom theme\nTo create a new custom theme, the .scss file containing it has to have imported the angular _theming.scss file (angular/material/theming) file and mat-core included. _theming.scss includes multiple color palettes and some functions that we are going to see below. The file for this basic theme is going to be named styles-custom-dark.scss.\nFirst, declare new variables for primary, accent and warn palettes. Those variables are going to store the result of the function mat-palette.\nmat-palette accepts four arguments: base color palette, main, lighter and darker variants (See [id_palette_variants]) and returns a new palette including some additional map values: default, lighter and darker ([id_scss_map]). Only the first argument is mandatory.\nListing 30. File styles-custom-dark.scss.\n$custom-dark-theme-primary: mat-palette($mat-pink);\n$custom-dark-theme-accent: mat-palette($mat-blue);\n$custom-dark-theme-warn: mat-palette($mat-red);\n);\nIn this example we are using colors available in _theming.scss: mat-pink, mat-blue, mat-red. If you want to use a custom color you need to define a new map, for instance:\nListing 31. File styles-custom-dark.scss custom pink.\n$my-pink: (\n50 : #fcf3f3,\n100 : #f9e0e0,\n200 : #f5cccc,\n300 : #f0b8b8,\n500 : #ea9999,\n900 : #db6b6b,\nA100 : #ffffff,\nA200 : #ffffff,\nA400 : #ffeaea,\nA700 : #ffd0d0,\ncontrast: (\n50 : #000000,\n100 : #000000,\n200 : #000000,\n300 : #000000,\n900 : #000000,\nA100 : #000000,\nA200 : #000000,\nA400 : #000000,\nA700 : #000000,\n)\n);\n$custom-dark-theme-primary: mat-palette($my-pink);\n...\nTip\nSome pages allows to create these palettes easily, for instance: http://mcg.mbitson.com\nUntil now, we just have defined primary, accent and warn palettes but what about foreground and background? Angular material has two functions to change both:\nmat-light-theme: Receives as arguments primary, accent and warn palettes and return a theme whose foreground is basically black (texts, icons, &#x2026;&#x200B;), the background is white and the other palettes are the received ones.\nFigure 36. Custom light theme.\nmat-dark-theme: Similar to mat-light-theme but returns a theme whose foreground is basically white and background black.\nFigure 37. Custom dark theme.\nFor this example we are going to use mat-dark-theme and save its result in $custom-dark-theme.\nListing 32. File styles-custom-dark.scss updated with mat-dark-theme.\n...\n$custom-dark-theme: mat-dark-theme(\n$custom-dark-theme-primary,\n$custom-dark-theme-accent,\n$custom-dark-theme-warn\n);\nTo apply the saved theme, we have to go to styles.scss and import our styles-custom-dark.scss and include a function called angular-material-theme using the theme variable as argument.\nListing 33. File styles.scss.\n...\n@import &apos;styles-custom-dark.scss&apos;;\n@include angular-material-theme($custom-dark-theme);\nIf we have multiple themes it is necessary to add the include statement inside a css class and use it in src/index.html &#x2192; app-root component.\nListing 34. File styles.scss updated with custom-dark-theme class.\n...\n@import &apos;styles-custom-dark.scss&apos;;\n.custom-dark-theme {\n@include angular-material-theme($custom-dark-theme);\n}\nListing 35. File src/index.html.\n...\n&lt;app-root class=&quot;custom-dark-theme&quot;&gt;&lt;/app-root&gt;\n...\nThis will apply $custom-dark-theme theme for the entire application.\nFull custom theme\nSometimes it is needed to custom different elementsw from background and foreground, in those situations we have to create a new function similar to mat-light-theme and mat-dark-theme. Let&#x2019;s focus con mat-light-theme:\nListing 36. Source code of mat-light-theme\n@function mat-light-theme($primary, $accent, $warn: mat-palette($mat-red)) {\n@return (\nprimary: $primary,\naccent: $accent,\nwarn: $warn,\nis-dark: false,\nforeground: $mat-light-theme-foreground,\nbackground: $mat-light-theme-background,\n);\n}\nAs we can se, mat-light-theme takes three arguments and returs a map including them as primary, accent and warn color; but there are three more keys in that map: is-dark, foreground and background.\nis-dark: Boolean true if it is a dark theme, false otherwise.\nbackground: Map that stores the color for multiple background elements.\nforeground: Map that stores the color for multiple foreground elements.\nTo show which elements can be colored lets create a new theme in a file styles-custom-cap.scss:\nListing 37. File styles-custom-cap.scss: Background and foreground variables.\n@import &apos;~@angular/material/theming&apos;;\n// custom background and foreground palettes\n$my-cap-theme-background: (\nstatus-bar: #0070ad,\napp-bar: map_get($mat-blue, 900),\nbackground: #12abdb,\nhover: rgba(white, 0.04),\ncard: map_get($mat-red, 800),\ndialog: map_get($mat-grey, 800),\ndisabled-button: $white-12-opacity,\nraised-button: map-get($mat-grey, 800),\nfocused-button: $white-6-opacity,\nselected-button: map_get($mat-grey, 900),\nselected-disabled-button: map_get($mat-grey, 800),\ndisabled-button-toggle: black,\nunselected-chip: map_get($mat-grey, 700),\ndisabled-list-option: black,\n);\n$my-cap-theme-foreground: (\nbase: yellow,\ndivider: $white-12-opacity,\ndividers: $white-12-opacity,\ndisabled: rgba(white, 0.3),\ndisabled-button: rgba(white, 0.3),\ndisabled-text: rgba(white, 0.3),\nhint-text: rgba(white, 0.3),\nsecondary-text: rgba(white, 0.7),\nicon: white,\nicons: white,\ntext: white,\nslider-min: white,\nslider-off: rgba(white, 0.3),\nslider-off-active: rgba(white, 0.3),\n);\nFunction which uses the variables defined before to create a new theme:\nListing 38. File styles-custom-cap.scss: Creating a new theme function.\n// instead of creating a theme with mat-light-theme or mat-dark-theme,\n// we will create our own theme-creating function that lets us apply our own foreground and background palettes.\n@function create-my-cap-theme($primary, $accent, $warn: mat-palette($mat-red)) {\n@return (\nprimary: $primary,\naccent: $accent,\nwarn: $warn,\nis-dark: false,\nforeground: $my-cap-theme-foreground,\nbackground: $my-cap-theme-background\n);\n}\nCalling the new function and storing its value in $custom-cap-theme.\nListing 39. File styles-custom-cap.scss: Storing the new theme.\n// We use create-my-cap-theme instead of mat-light-theme or mat-dark-theme\n$custom-cap-theme-primary: mat-palette($mat-green);\n$custom-cap-theme-accent: mat-palette($mat-blue);\n$custom-cap-theme-warn: mat-palette($mat-red);\n$custom-cap-theme: create-my-cap-theme(\n$custom-cap-theme-primary,\n$custom-cap-theme-accent,\n$custom-cap-theme-warn\n);\nAfter defining our new theme, we can import it from styles.scss.\nListing 40. File styles.scss updated with custom-cap-theme class.\n...\n@import &apos;styles-custom-cap.scss&apos;;\n.custom-cap-theme {\n@include angular-material-theme($custom-cap-theme);\n}\nMultiple themes and overlay-based components\nCertain components (e.g. menu, select, dialog, etc.) that are inside of a global overlay container,require an additional step to be affected by the theme&#x2019;s css class selector.\nListing 41. File app.module.ts\nimport {OverlayContainer} from &apos;@angular/cdk/overlay&apos;;\n@NgModule({\n// ...\n})\nexport class AppModule {\nconstructor(overlayContainer: OverlayContainer) {\noverlayContainer.getContainerElement().classList.add(&apos;custom-cap-theme&apos;);\n}\n}\n"},{"id":676,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-angular-theming.asciidoc_useful-resources","type":"docs","title":"Useful resources","body":"18.5.4. Useful resources\nAngular Material&#x2019;s oficial theming guide\nMaterial Desing: Color theme creation\nPalette generator\nSCSS tutorial\n"},{"id":677,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-angular-pwa.asciidoc","type":"docs","title":"Angular Progressive Web App","body":"18.6. Angular Progressive Web App\nProgresive web applications (PWAs) are web application that offer better user experience than the traditional ones. In general, they solve problems related with reliability and speed:\nReliability: PWAs are stable. In this context stability means than even with slow connections or even with no network at all, the application still works. To achieve this, some basic resources like styles, fonts, requests, &#x2026;&#x200B; are stored; due to this caching, it is not possible to assure that the content is always up-to-date.\nSpeed: When an users opens an application, he or she will expect it to load almost inmediately (almost 53% of users abandon sites that take longer that 3 seconds, source: https://developers.google.com/web/progressive-web-apps/#fast).\nPWAs uses a script called service worker, which runs in background and essentially act as proxy between web app and network, intercepting requests and acting depending on the network conditions.\n"},{"id":678,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-angular-pwa.asciidoc_assumptions","type":"docs","title":"Assumptions","body":"18.6.1. Assumptions\nThis guide assumes that you already have installed:\nNode.js\nnpm package manager\nAngular CLI\n"},{"id":679,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-angular-pwa.asciidoc_sample-application","type":"docs","title":"Sample Application","body":"18.6.2. Sample Application\nFigure 38. Basic angular PWA.\nTo explain how to build PWAs using angular, a basic application is going to be built. This app will be able to ask for resources and save in the cache in order to work even offline.\nStep 1: Create a new project and install Angular PWA package\nThis step can be completed with one simple command: ng new &lt;name&gt;, where &lt;names&gt; is the name for the app. In this case, the app is going to be named basic-ng-pwa.\nStep 2: Create a service\nWeb applications usually uses external resources, making necessary the addition of services which can get those resources. This application gets a dish from My Thai Star&#x2019;s back-end and shows it. To do so, a new service is going to be created.\ngo to project folder: cd basic-ng-pwa\nrun ng generate service data\nModify data.service.ts, environment.ts, environment.prod.ts\nTo retrieve data with this service, you have to import the module HttpClient and add it to the service&#x2019;s contructor. Once added, use it to create a function getDishes() that sends http request to My Thai Start&#x2019;s back-end. The URL of the back-end can be stored as an environment variable MY_THAI_STAR_DISH.\ndata.service.ts\n...\nimport { HttpClient } from &apos;@angular/common/http&apos;;\nimport { MY_THAI_STAR_DISH } from &apos;../environments/environment&apos;;\n...\nexport class DataService {\nconstructor(private http: HttpClient) {}\n/* Get data from Back-end */\ngetDishes() {\nreturn this.http.get(MY_THAI_STAR_DISH);\n}\n...\n}\nenvironments.ts\n...\nexport const MY_THAI_STAR_DISH =\n&apos;http://de-mucdevondepl01:8090/api/services/rest/dishmanagement/v1/dish/1&apos;;\n...\nenvironments.prod.ts\n...\nexport const MY_THAI_STAR_DISH =\n&apos;http://de-mucdevondepl01:8090/api/services/rest/dishmanagement/v1/dish/1&apos;;\n...\nStep 3: Use the service\nThe component AppComponent implements the interface OnInit and inside its method ngOnInit() the suscription to the services is done. When a dish arrives, it is saved and shown (app.component.html).\n...\nimport { DataService } from &apos;./data.service&apos;;\nexport class AppComponent implements OnInit {\ndish: { name: string; description: string } = { name: &apos;&apos;, description: &apos;&apos;};\n...\nngOnInit() {\nthis.data\n.getDishes()\n.subscribe(\n(dishToday: { dish: { name: string; description: string } }) =&gt; {\nthis.dish = {\nname: dishToday.dish.name,\ndescription: dishToday.dish.description,\n};\n},\n);\n}\n}\nStep 4: Structures, styles and updates\nThis step shows code interesting inside the sample app. The complete content can be found in devon4ng samples.\nindex.html\nTo use the Montserrat font add the following link inside the tag header.\n&lt;link href=&quot;https://fonts.googleapis.com/css?family=Montserrat&quot; rel=&quot;stylesheet&quot;&gt;\nstyles.scss\nbody {\n...\nfont-family: &apos;Montserrat&apos;, sans-serif;\n}\napp.component.ts\nThis file is also used to reload the app if there are any changes.\nSwUpdate: This object comes inside the @angular/pwa package and it is used to detect changes and reload the page if needed.\n...\nimport { SwUpdate } from &apos;@angular/service-worker&apos;;\nexport class AppComponent implements OnInit {\n...\nconstructor(updates: SwUpdate, private data: DataService) {\nupdates.available.subscribe((event) =&gt; {\nupdates.activateUpdate().then(() =&gt; document.location.reload());\n});\n}\n...\n}\nStep 5: Make it Progressive.\nInstall Angular PWA package with ng add @angular/pwa --project &lt;name&gt;. As before substitute name with basic-ng-pwa.\nThe above command completes the following actions:\nAdds the @angular/service-worker package to your project.\nEnables service worker build support in the CLI.\nImports and registers the service worker in the app module.\nUpdates the index.html file:\nIncludes a link to add the manifest.json file.\nAdds meta tags for theme-color.\nInstalls icon files to support the installed Progressive Web App (PWA).\nCreates the service worker configuration file called ngsw-config.json, which specifies the caching behaviors and other settings.\nmanifest.json\nmanifest.json is a file that allows to control how the app is displayed in places where native apps are displayed.\nFields\nname: Name of the web application.\nshort_name: Short version of name.\ntheme_color: Default theme color for an application context.\nbackground_color: Expected background color of the web application.\ndisplay: Preferred display mode.\nscope: Navigation scope of tghis web application&#x2019;s application context.\nstart_url: URL loaded when the user launches the web application.\nicons: Array of icons that serve as representations of the web app.\nAdditional information can be found here.\nngsw-config.json\nnsgw-config.json specifies which files and data URLs have to be cached and updated by the Angular service worker.\nFields\nindex: File that serves as index page to satisfy navigation requests.\nassetGroups: Resources that are part of the app version that update along with the app.\nname: Identifies the group.\ninstallMode: How the resources are cached (prefetch or lazy).\nupdateMode: Caching behaviour when a new version of the app is found (prefetch or lazy).\nresources: Resources to cache. There are three groups.\nfiles: Lists patterns that match files in the distribution directory.\nurls: URL patterns matched at runtime.\ndataGroups: UsefulIdentifies the group. for API requests.\nname: Identifies the group.\nurls: URL patterns matched at runtime.\nversion: Indicates that the resources being cached have been updated in a backwards-incompatible way.\ncacheConfig: Policy by which matching requests will be cached\nmaxSize: The maximum number of entries, or responses, in the cache.\nmaxAge: How long responses are allowed to remain in the cache.\nd: days. (5d = 5 days).\nh: hours\nm: minutes\ns: seconds. (5m20s = 5 minutes and 20 seconds).\nu: milliseconds\ntimeout: How long the Angular service worker will wait for the network to respond before using a cached response. Same dataformat as maxAge.\nstrategy: Caching strategies (performance or freshness).\nnavigationUrls: List of URLs that will be redirected to the index file.\nAdditional information can be found here.\nStep 6: Configure the app\nmanifest.json\nDefault configuration.\n&#xA0;\n&#xA0;\nngsw-config.json\nAt assetGroups &#x2192; resources &#x2192; urls: In this field the google fonts api is added in order to use Montserrat font even without network.\n&quot;urls&quot;: [\n&quot;https://fonts.googleapis.com/**&quot;\n]\nAt the root of the json: A data group to cache API calls.\n{\n...\n&quot;dataGroups&quot;: [{\n&quot;name&quot;: &quot;mythaistar-dishes&quot;,\n&quot;urls&quot;: [\n&quot;http://de-mucdevondepl01:8090/api/services/rest/dishmanagement/v1/dish/1&quot;\n],\n&quot;cacheConfig&quot;: {\n&quot;maxSize&quot;: 100,\n&quot;maxAge&quot;: &quot;1h&quot;,\n&quot;timeout&quot;: &quot;10s&quot;,\n&quot;strategy&quot;: &quot;freshness&quot;\n}\n}]\n}\nStep 7: Check that your app is a PWA\nTo check if an app is a PWA lets compare its normal behaviour against itself but built for production. Run in the project&#x2019;s root folder the commands below:\nng build --prod to build the app using production settings.\nnpm install http-server to install an npm module that can serve your built application. Documentation here.\nGo to the dist/basic-ng-pwa/ folder running cd dist/basic-ng-pwa.\nhttp-server -o to serve your built app.\nFigure 39. Http server running on localhost:8081.\n&#xA0;\nIn another console instance run ng serve to open the common app (not built).\nFigure 40. Angular server running on localhost:4200.\n&#xA0;\nThe first difference can be found on Developer tools &#x2192; application, here it is seen that the PWA application (left) has a service worker and the common (right) one does not.\nFigure 41. Application service worker comparison.\n&#xA0;\nIf the &quot;offline&quot; box is checked, it will force a disconnection from network. In situations where users do not have connectivity or have a slow, one the PWA can still be accesed and used.\nFigure 42. Offline application.\n&#xA0;\nFinally, browser extensions like Lighthouse can be used to test whether an application is progressive or not.\nFigure 43. Lighthouse report.\n"},{"id":680,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-app-initializer.asciidoc","type":"docs","title":"APP_INITIALIZER","body":"18.7. APP_INITIALIZER\n"},{"id":681,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-app-initializer.asciidoc_what-is-the-app_initializer-pattern","type":"docs","title":"What is the APP_INITIALIZER pattern","body":"18.7.1. What is the APP_INITIALIZER pattern\nThe APP_INITIALIZER pattern allows an aplication to choose which configuration is going to be used in the start of the application, this is useful because it allows to setup different configurations, for example, for docker or a remote configuration. This provides benefits since this is done on runtime, so theres no need to recompile the whole application to switch from configuration.\n"},{"id":682,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-app-initializer.asciidoc_what-is-app_initializer","type":"docs","title":"What is APP_INITIALIZER","body":"18.7.2. What is APP_INITIALIZER\nAPP_INITIALIZER allows to provide a service in the initialization of the application in a @NgModule. It also allows to use a factory, allowing to create a singleton in the same service. An example can be found in MyThaiStar /core/config/config.module.ts:\nNote\nThe provider expects the return of a Promise, if it is using Observables, a change with the method toPromise() will allow a switch from Observable to Promise\nimport { NgModule, APP_INITIALIZER } from &apos;@angular/core&apos;;\nimport { HttpClientModule } from &apos;@angular/common/http&apos;;\nimport { ConfigService } from &apos;./config.service&apos;;\n@NgModule({\nimports: [HttpClientModule],\nproviders: [\nConfigService,\n{\nprovide: APP_INITIALIZER,\nuseFactory: ConfigService.factory,\ndeps: [ConfigService],\nmulti: true,\n},\n],\n})\nexport class ConfigModule {}\nThis is going to allow the creation of a ConfigService where, using a singleton, the service is going to load an external config depending on a route. This dependence with a route, allows to setup diferent configuration for docker etc. This is seen in the ConfigService of MyThaiStar:\nimport { Injectable } from &apos;@angular/core&apos;;\nimport { HttpClient } from &apos;@angular/common/http&apos;;\nimport { Config, config } from &apos;./config&apos;;\n@Injectable()\nexport class ConfigService {\nconstructor(private httpClient: HttpClient) {}\nstatic factory(appLoadService: ConfigService) {\nreturn () =&gt; appLoadService.loadExternalConfig();\n}\n// this method gets external configuration calling /config endpoint\n//and merges into config object\nloadExternalConfig(): Promise&lt;any&gt; {\nif (!environment.loadExternalConfig) {\nreturn Promise.resolve({});\n}\nconst promise = this.httpClient\n.get(&apos;/config&apos;)\n.toPromise()\n.then((settings) =&gt; {\nObject.keys(settings || {}).forEach((k) =&gt; {\nconfig[k] = settings[k];\n});\nreturn settings;\n})\n.catch((error) =&gt; {\nreturn &apos;ok, no external configuration&apos;;\n});\nreturn promise;\n}\ngetValues(): Config {\nreturn config;\n}\n}\nAs it is mentioned earlier, you can see the use of a factory to create a singleton at the start. After that, loadExternalConfig is going to look for a boolean inside the corresponding environment file inside the path src/environments/, this boolean loadExternalConfig is going to easily allow to switch to a external config. If it is true, it generates a promise that overwrites the parameters of the local config, allowing to load the external config. Finally, the last method getValues() is going to allow to return the file config with the values (overwritten or not). The local config file from MyThaiStar can be seen here:\nexport enum BackendType {\nIN_MEMORY,\nREST,\nGRAPHQL,\n}\ninterface Role {\nname: string;\npermission: number;\n}\ninterface Lang {\nlabel: string;\nvalue: string;\n}\nexport interface Config {\nversion: string;\nbackendType: BackendType;\nrestPathRoot: string;\nrestServiceRoot: string;\npageSizes: number[];\npageSizesDialog: number[];\nroles: Role[];\nlangs: Lang[];\n}\nexport const config: Config = {\nversion: &apos;dev&apos;,\nbackendType: BackendType.REST,\nrestPathRoot: &apos;http://localhost:8081/mythaistar/&apos;,\nrestServiceRoot: &apos;http://localhost:8081/mythaistar/services/rest/&apos;,\npageSizes: [8, 16, 24],\npageSizesDialog: [4, 8, 12],\nroles: [\n{ name: &apos;CUSTOMER&apos;, permission: 0 },\n{ name: &apos;WAITER&apos;, permission: 1 },\n],\nlangs: [\n{ label: &apos;English&apos;, value: &apos;en&apos; },\n{ label: &apos;Deutsch&apos;, value: &apos;de&apos; },\n{ label: &apos;Espa&#xF1;ol&apos;, value: &apos;es&apos; },\n{ label: &apos;Catal&#xE0;&apos;, value: &apos;ca&apos; },\n{ label: &apos;Fran&#xE7;ais&apos;, value: &apos;fr&apos; },\n{ label: &apos;Nederlands&apos;, value: &apos;nl&apos; },\n{ label: &apos;&#x939;&#x93F;&#x928;&#x94D;&#x926;&#x940;&apos;, value: &apos;hi&apos; },\n{ label: &apos;Polski&apos;, value: &apos;pl&apos; },\n{ label: &apos;&#x420;&#x443;&#x441;&#x441;&#x43A;&#x438;&#x439;&apos;, value: &apos;ru&apos; },\n{ label: &apos;&#x431;&#x44A;&#x43B;&#x433;&#x430;&#x440;&#x441;&#x43A;&#x438;&apos;, value: &apos;bg&apos; },\n],\n};\nFinally, inside a environment file src/environments/environment.ts the use of the boolean loadExternalConfig is seen:\n// The file contents for the current environment will overwrite these during build.\n// The build system defaults to the dev environment which uses `environment.ts`, but if you do\n// `ng build --env=prod` then `environment.prod.ts` will be used instead.\n// The list of which env maps to which file can be found in `.angular-cli.json`.\nexport const environment: {\nproduction: boolean;\nloadExternalConfig: boolean;\n} = { production: false, loadExternalConfig: false };\n"},{"id":683,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-app-initializer.asciidoc_creating-a-app_initializer-configuration","type":"docs","title":"Creating a APP_INITIALIZER configuration","body":"18.7.3. Creating a APP_INITIALIZER configuration\nThis section is going to be used to create a new APP_INITIALIZER basic example. For this, a basic app with angular is going to be generated using ng new &quot;appname&quot; substituting appname for the name of the app choosed.\n"},{"id":684,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-app-initializer.asciidoc_setting-up-the-config-files","type":"docs","title":"Setting up the config files","body":"18.7.4. Setting up the config files\nDocker external configuration (Optional)\nThis section is only done if theres a docker configuration in the app you are setting up this type of configuration.\n1.- Create in the root folder /docker-external-config.json. This external config is going to be used when the application is loaded with docker (if the boolean to load the external configuration is set to true). Here you need to add all the config parameter you want to load with docker:\n{\n&quot;version&quot;: &quot;docker-version&quot;\n}\n2.- In the root, in the file /Dockerfile angular is going to copy the docker-external-config.json that was created before into the nginx html route:\n....\nCOPY docker-external-config.json /usr/share/nginx/html/docker-external-config.json\n....\nExternal json configuration\n1.- Create a json file in the route /src/external-config.json. This external config is going to be used when the application is loaded with the start script (if the boolean to load the external configuration is set to true). Here you need to add all the config parameter you want to load:\n{\n&quot;version&quot;: &quot;external-config&quot;\n}\n2.- The file named /angular.json located at the root is going to be modified to add the file external-config.json that was just created to both &quot;assets&quot; inside Build and Test:\n....\n&quot;build&quot;: {\n....\n&quot;assets&quot;: [\n&quot;src/assets&quot;,\n&quot;src/data&quot;,\n&quot;src/favicon.ico&quot;,\n&quot;src/manifest.json&quot;,\n&quot;src/external-config.json&quot;\n]\n....\n&quot;test&quot;: {\n....\n&quot;assets&quot;: [\n&quot;src/assets&quot;,\n&quot;src/data&quot;,\n&quot;src/favicon.ico&quot;,\n&quot;src/manifest.json&quot;,\n&quot;src/external-config.json&quot;\n]\n....\n"},{"id":685,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-app-initializer.asciidoc_setting-up-the-proxies","type":"docs","title":"Setting up the proxies","body":"18.7.5. Setting up the proxies\nThis step is going to setup two proxies. This is going to allow to load the config desired by the context, in case that it is using docker to load the app or in case it loads the app with angular. Loading diferent files is made posible by the fact that the ConfigService method loadExternalConfig() looks for the path /config.\nDocker (Optional)\n1.- This step is going to be for docker. Add docker-external-config.json to nginx configuration (/nginx.conf) that is in the root of the application:\n....\nlocation ~ ^/config {\nalias /usr/share/nginx/html/docker-external-config.json;\n}\n....\nExternal Configuration\n1.- Now the file /proxy.conf.json, needs to be created/modified this file can be found in the root of the application. In this file you can add the route of the external configuration in target and the name of the file in ^/config::\n....\n&quot;/config&quot;: {\n&quot;target&quot;: &quot;http://localhost:4200&quot;,\n&quot;secure&quot;: false,\n&quot;pathRewrite&quot;: {\n&quot;^/config&quot;: &quot;/external-config.json&quot;\n}\n}\n....\n2.- The file package.json found in the root of the application is gonna use the start script to load the proxy config that was just created:\n&quot;scripts&quot;: {\n....\n&quot;start&quot;: &quot;ng serve --proxy-config proxy.conf.json -o&quot;,\n....\n"},{"id":686,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-app-initializer.asciidoc_adding-the-loadexternalconfig-boolean-to-the-environments","type":"docs","title":"Adding the loadExternalConfig boolean to the environments","body":"18.7.6. Adding the loadExternalConfig boolean to the environments\nIn order to load an external config we need to add the loadExternalConfig boolean to the environments. To do so, inside the folder environments/ the files are going to get modified adding this boolean to each environment that is going to be used. In this case, only two environments are going to be modified (environment.ts and environment.prod.ts). Down below theres an example of the modification being done in the environment.prod.ts:\nexport const environment: {\nproduction: boolean;\nloadExternalConfig: boolean;\n} = { production: false, loadExternalConfig: false };\nIn the file in first instance theres the declaration of the types of the variables. After that, theres the definition of those variables. This variable loadExternalConfig is going to be used by the service, allowing to setup a external config just by switching the loadExternalConfig to true.\n"},{"id":687,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-app-initializer.asciidoc_creating-core-configuration-service","type":"docs","title":"Creating core configuration service","body":"18.7.7. Creating core configuration service\nIn order to create the whole configuration module three are going to be created:\n1.- Create in the core app/core/config/ a config.ts\nexport interface Config {\nversion: string;\n}\nexport const config: Config = {\nversion: &apos;dev&apos;\n};\nTaking a look to this file, it creates a interface (Config) that is going to be used by the variable that exports (export const config: Config). This variable config is going to be used by the service that is going to be created.\n2.- Create in the core app/core/config/ a config.service.ts:\nimport { Injectable } from &apos;@angular/core&apos;;\nimport { HttpClient } from &apos;@angular/common/http&apos;;\nimport { Config, config } from &apos;./config&apos;;\n@Injectable()\nexport class ConfigService {\nconstructor(private httpClient: HttpClient) {}\nstatic factory(appLoadService: ConfigService) {\nreturn () =&gt; appLoadService.loadExternalConfig();\n}\n// this method gets external configuration calling /config endpoint\n// and merges into config object\nloadExternalConfig(): Promise&lt;any&gt; {\nif (!environment.loadExternalConfig) {\nreturn Promise.resolve({});\n}\nconst promise = this.httpClient\n.get(&apos;/config&apos;)\n.toPromise()\n.then((settings) =&gt; {\nObject.keys(settings || {}).forEach((k) =&gt; {\nconfig[k] = settings[k];\n});\nreturn settings;\n})\n.catch((error) =&gt; {\nreturn &apos;ok, no external configuration&apos;;\n});\nreturn promise;\n}\ngetValues(): Config {\nreturn config;\n}\n}\nAs it was explained in previous steps, at first, there is a factory that uses the method loadExternalConfig(), this factory is going to be used in later steps in the module. After that, the loadExternalConfig() method checks if the boolean in the environment is false. If it is false it will return the promise resolved with the normal config. Else, it is going to load the external config in the path (/config), and overwrite the values from the external config to the config thats going to be used by the app, this is all returned in a promise.\n3.- Create in the core a module for the config app/core/config/ a config.module.ts:\nimport { NgModule, APP_INITIALIZER } from &apos;@angular/core&apos;;\nimport { HttpClientModule } from &apos;@angular/common/http&apos;;\nimport { ConfigService } from &apos;./config.service&apos;;\n@NgModule({\nimports: [HttpClientModule],\nproviders: [\nConfigService,\n{\nprovide: APP_INITIALIZER,\nuseFactory: ConfigService.factory,\ndeps: [ConfigService],\nmulti: true,\n},\n],\n})\nexport class ConfigModule {}\nAs seen earlier, the ConfigService is added to the module. In this addition, the app is initialized(provide) and it uses the factory that was created in the ConfigService loading the config with or without the external values depending on the boolean in the config.\nUsing the Config Service\nAs a first step, in the file /app/app.module.ts the ConfigModule created earlier in the other step is going to be imported:\nimports: [\n....\nConfigModule,\n....\n]\nAfter that, the ConfigService is going to be injected into the app.component.ts\n....\nimport { ConfigService } from &apos;./core/config/config.service&apos;;\n....\nexport class AppComponent {\n....\nconstructor(public configService: ConfigService) { }\n....\nFinally, for this demonstration app, the component app/app.component.html is going to show the version of the config it is using at that moment.\n&lt;div style=&quot;text-align:center&quot;&gt;\n&lt;h1&gt;\nWelcome to {{ title }}!\n&lt;/h1&gt;\n&lt;/div&gt;\n&lt;h2&gt;Here is the configuration version that is using angular right now: {{configService.getValues().version}}&lt;/h2&gt;\nFinal steps\nThe script start that was created earlier in the package.json (npm start) is going to be used to start the application. After that, modifying the boolean loadExternalConfig inside the corresponding environment file inside /app/environments/ should show the different config versions.\n"},{"id":688,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-component-decomposition.asciidoc","type":"docs","title":"Component Decomposition","body":"18.8. Component Decomposition\nWhen implementing a new requirement there are a few design decisions, which need to be considered.\nA decomposition in Smart and Dumb Components should be done first.\nThis includes the definition of state and responsibilities.\nImplementing a new dialog will most likely be done by defining a new Smart Component with multiple Dumb Component children.\nIn the component tree this would translate to the definition of a new subtree.\nFigure 44. Component Tree with highlighted subtree\n"},{"id":689,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-component-decomposition.asciidoc_defining-components","type":"docs","title":"Defining Components","body":"18.8.1. Defining Components\nThe following gives an example for component decomposition.\nShown is a screenshot from a styleguide to be implemented.\nIt is a widget called Listpicker.\nThe basic function is an input field accepting direct input.\nSo typing otto puts otto inside the FormControl.\nWith arrow down key or by clicking the icon displayed in the inputs right edge a dropdown is opened.\nInside possible values can be selected and filtered beforehand.\nAfter pressing arrow down key the focus should move into the filter input field.\nUp and down arrow keys can be used to select an element from the list.\nTyping into the filter input field filters the list from which the elements can be selected.\nThe current selected element is highlighted with green background color.\nFigure 45. Component decomposition example before\nWhat should be done, is to define small reusable Dumb Components.\nThis way the complexity becomes manageable.\nIn the example every colored box describes a component with the purple box being a Smart Component.\nFigure 46. Component decomposition example after\nThis leads to the following component tree.\nFigure 47. Component decomposition example component tree\nNote the uppermost component is a Dumb Component.\nIt is a wrapper for the label and the component to be displayed inside a form.\nThe Smart Component is Listpicker.\nThis way the widget can be reused without a form needed.\nA widgets is a typical Smart Component to be shared across feature modules.\nSo the SharedModule is the place for it to be defined.\n"},{"id":690,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-component-decomposition.asciidoc_defining-state","type":"docs","title":"Defining state","body":"18.8.2. Defining state\nEvery UI has state.\nThere are different kinds of state, for example\nView State: e.g. is a panel open, a css transition pending, etc.\nApplication State: e.g. is a payment pending, current URL, user info, etc.\nBusiness Data: e.g. products loaded from backend\nIt is good practice to base the component decomposition on the state handled by a component and to define a simplified state model beforehand.\nStarting with the parent - the Smart Component:\nWhat overall state does the dialog have: e.g. loading, error, valid data loaded, valid input, invalid input, etc.\nEvery defined value should correspond to an overall appearance of the whole dialog.\nWhat events can occur to the dialog: e.g. submitting a form, changing a filter, pressing buttons, pressing keys, etc.\nFor every Dumb Component:\nWhat data does a component display: e.g. a header text, user information to be displayed, a loading flag, etc.\nThis will be a slice of the overall state of the parent Smart Component.\nIn general a Dumb Component presents a slice of its parent Smart Components state to the user.\nWhat events can occur: keyboard events, mouse events, etc.\nThese events are all handled by its parent Smart Component - every event is passed up the tree to be handled by a Smart Component.\nThese information should be reflected inside the modeled state.\nThe implementation is a TypeScript type - an interface or a class describing the model.\nSo there should be a type describing all state relevant for a Smart Component.\nAn instance of that type is send down the component tree at runtime.\nNot every Dumb Component will need the whole state.\nFor instance a single Dumb Component could only need a single string.\nThe state model for the previous Listpicker example is shown in the following listing.\nListing 42. Listpicker state model\nexport class ListpickerState {\nitems: {}[]|undefined;\ncolumns = [&apos;key&apos;, &apos;value&apos;];\nkeyColumn = &apos;key&apos;;\ndisplayValueColumn = &apos;value&apos;;\nfilteredItems: {}[]|undefined;\nfilter = &apos;&apos;;\nplaceholder = &apos;&apos;;\ncaseSensitive = true;\nisDisabled = false;\nisDropdownOpen = false;\nselectedItem: {}|undefined;\ndisplayValue = &apos;&apos;;\n}\nListpicker holds an instance of ListpickerState which is passed down the component tree via @Input() bindings in the Dumb Components.\nEvents emitted by children - Dumb Components - create a new instance of ListpickerState based on the current instance and the event and its data.\nSo a state transition is just setting a new instance of ListpickerState.\nAngular Bindings propagate the value down the tree after exchanging the state.\nListing 43. Listpicker State transition\nexport class ListpickerComponent {\n// initial default values are set\nstate = new ListpickerState();\n/** User changes filter */\nonFilterChange(filter: string): void {\n// apply filter ...\nconst filteredList = this.filterService.filter(...);\n// important: A new instance is created, instead of altering the existing one.\n// This makes change detection easier and prevents hard to find bugs.\nthis.state = Object.assing({}, this.state, {\nfilteredItems: filteredList,\nfilter: filter\n});\n}\n}\nNote:\nIt is not always necessary to define the model as independent type.\nSo there would be no state property and just properties for every state defined directly in the component class.\nWhen complexity grows and state becomes larger this is usually a good idea.\nIf the state should be shared between Smart Components a store is to be used.\n"},{"id":691,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-component-decomposition.asciidoc_when-are-dumb-components-needed","type":"docs","title":"When are Dumb Components needed","body":"18.8.3. When are Dumb Components needed\nSometimes it is not necessary to perform a full decomposition. The architecture does not enforce it generally. What you should keep in mind is, that there is always a point when it becomes recommendable.\nFor example a template with 800 loc is:\nnot understandable\nnot maintanable\nnot testable\nnot reusable\nSo when implementing a template with more than 50 loc you should think about decomposition.\n"},{"id":692,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-consuming-rest-services.asciidoc","type":"docs","title":"Consuming REST services","body":"18.9. Consuming REST services\nA good introduction to working with Angular HttpClient can be found in Angular Docs\nThis guide will cover, how to embed Angular HttpClient in the application architecture.\nFor backend request a special service with the suffix Adapter needs to be defined.\n"},{"id":693,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-consuming-rest-services.asciidoc_defining-adapters","type":"docs","title":"Defining Adapters","body":"18.9.1. Defining Adapters\nIt is a good practice to have a Angular service whose single responsibility is to call the backend and parse the received value to a transfer data model (e.g. Swagger generated TOs).\nThose services need to have the suffix Adapter to make them easy to recognize.\nFigure 48. Adapters handle backend communication\nAs illustrated in the figure a Use Case service does not use Angular HttpClient directly but uses an adapter.\nA basic adapter could look like this:\nListing 44. Example adapter\nimport { Injectable } from &apos;@angular/core&apos;;\nimport { HttpClient } from &apos;@angular/common/http&apos;;\nimport { Observable } from &apos;rxjs/Observable&apos;;\nimport { FlightTo } from &apos;./flight-to&apos;;\n@Injectable({\nprovidedIn: &apos;root&apos;,\n})\nexport class FlightsAdapter {\nconstructor(\nprivate httpClient: HttpClient\n) {}\ngetFlights(): Observable&lt;FlightTo&gt; {\nreturn this.httpClient.get&lt;FlightTo&gt;(&apos;/relative/url/to/flights&apos;);\n}\n}\nThe adapters should use a well-defined transfer data model.\nThis could be generated from server endpoints with CobiGen, Swagger, typescript-maven-plugin, etc.\nIf inside the application there is a business model defined, the adapter has to parse to the transfer model.\nThis is illustrated in the following listing.\nListing 45. Example adapter mapping from business model to transfer model\nimport { Injectable } from &apos;@angular/core&apos;;\nimport { HttpClient } from &apos;@angular/common/http&apos;;\nimport { Observable } from &apos;rxjs/Observable&apos;;\nimport { map } from &apos;rxjs/operators&apos;;\nimport { FlightTo } from &apos;./flight-to&apos;;\nimport { Flight } from &apos;../../../model/flight&apos;;\n@Injectable({\nprovidedIn: &apos;root&apos;,\n})\nexport class FlightsAdapter {\nconstructor(\nprivate httpClient: HttpClient\n) {}\nupdateFlight(flight: Flight): Observable&lt;Flight&gt; {\nconst to = this.mapFlight(flight);\nreturn this.httpClient.post&lt;FlightTo&gt;(&apos;/relative/url/to/flights&apos;, to).pipe(\nmap(to =&gt; this.mapFlightTo(to))\n);\n}\nprivate mapFlight(flight: Flight): FlightTo {\n// mapping logic\n}\nprivate mapFlightTo(flightTo: FlightTo): Flight {\n// mapping logic\n}\n}\n"},{"id":694,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-consuming-rest-services.asciidoc_token-management","type":"docs","title":"Token management","body":"18.9.2. Token management\nIn most cases the access to backend API is secured using well konwn mechanisms as CSRF, JWT or both. In these cases the frontend application must manage the tokens that are generated when the user authenticates. More concretely it must store them to include them in every request automatically. Obviously, when user logs out these tokens must be removed from localStorage, memory, etc.\nStore security token\nIn order to make this guide simple we are going to store the token in memory. Therefore, if we consider that we already have a login mechanism implemented we would like to store the token using a auth.service.ts:\nimport { Injectable } from &apos;@angular/core&apos;;\nimport { Router } from &apos;@angular/router&apos;;\n@Injectable({\nprovidedIn: &apos;root&apos;,\n})\nexport class AuthService {\nprivate loggedIn = false;\nprivate token: string;\nconstructor(public router: Router) {}\npublic isLogged(): boolean {\nreturn this.loggedIn || false;\n}\npublic setLogged(login: boolean): void {\nthis.loggedIn = login;\n}\npublic getToken(): string {\nreturn this.token;\n}\npublic setToken(token: string): void {\nthis.token = token;\n}\n}\nUsing the previous service we will be able to store the token obtained in the login request using the method setToken(token). Please consider that, if you want a more sofisticated approach using localStorage API, you will need to modify this service accordingly.\nInclude token in every request\nNow that the token is available in the application it is necessary to include it in every request to a protected API endpoint. Instead of modifying all the http requests in our application, Angular provides a class to intercept every request (and every response if we need to) called HttpInterceptor. Let&#x2019;s create a service called http-interceptor.service.ts to implement the intercept method of this class:\nimport {\nHttpEvent,\nHttpHandler,\nHttpInterceptor,\nHttpRequest,\n} from &apos;@angular/common/http&apos;;\nimport { Injectable } from &apos;@angular/core&apos;;\nimport { Observable } from &apos;rxjs&apos;;\nimport { environment } from &apos;../../../environments/environment&apos;;\nimport { AuthService } from &apos;./auth.service&apos;;\n@Injectable()\nexport class HttpRequestInterceptorService implements HttpInterceptor {\nconstructor(private auth: AuthService) {}\nintercept(\nreq: HttpRequest&lt;any&gt;,\nnext: HttpHandler,\n): Observable&lt;HttpEvent&lt;any&gt;&gt; {\n// Get the auth header from the service.\nconst authHeader: string = this.auth.getToken();\nif (authHeader) {\nlet authReq: HttpRequest&lt;any&gt;;\n// CSRF\nif (environment.security === &apos;csrf&apos;) {\nauthReq = req.clone({\nwithCredentials: true,\nsetHeaders: { &apos;x-csrf-token&apos;: authHeader },\n});\n}\n// JWT\nif (environment.security === &apos;jwt&apos;) {\nauthReq = req.clone({\nsetHeaders: { Authorization: authHeader },\n});\n}\nreturn next.handle(authReq);\n} else {\nreturn next.handle(req);\n}\n}\n}\nAs you may notice, this service is making use of an environment field environment.security to determine if we are using JWT or CSRF in order to inject the token accordingly. In your application you can combine both if necessary.\nConfigure environment.ts file to use the CSRF/JWT.\nsecurity: &apos;csrf&apos;\nThe authHeader used is obtained using the injected service AuthService already presented above.\nIn order to activate the interceptor we need to provide it in our app.module.ts or core.module.ts depending on the application structure. Let&#x2019;s assume that we are using the latter and the interceptor file is inside a security folder:\n...\nimport { HttpRequestInterceptorService } from &apos;./security/http-request-interceptor.service&apos;;\n...\n@NgModule({\nimports: [...],\nexports: [...],\ndeclarations: [],\nproviders: [\n...\n{\nprovide: HTTP_INTERCEPTORS,\nuseClass: HttpRequestInterceptorService,\nmulti: true,\n},\n],\n})\nexport class CoreModule {}\nAngular automatically will now modify every request and include in the header the token if it is convenient.\n"},{"id":695,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-error-handler.asciidoc","type":"docs","title":"Error Handler in angular","body":"18.10. Error Handler in angular\nAngular allows us to set up a custom error handler that can be used to control the different errors and them in a correct way. Using a global error handler will avoid mistakes and provide a use friendly interface allowing us to indicate the user what problem is happening.\n"},{"id":696,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-error-handler.asciidoc_what-is-errorhandler","type":"docs","title":"What is ErrorHandler","body":"18.10.1. What is ErrorHandler\nErrorHandler is the class that Angular uses by default to control the errors. This means that, even if the application doesnt have a ErrorHandler it is going to use the one setup by default in Angular. This can be tested by trying to find a page not existing in any app, instantly Angular will print the error in the console.\n"},{"id":697,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-error-handler.asciidoc_creating-your-custom-errorhandler-step-by-step","type":"docs","title":"Creating your custom ErrorHandler step by step","body":"18.10.2. Creating your custom ErrorHandler step by step\nIn order to create a custom ErrorHandler three steps are going to be needed:\nCreating the custom ErrorHandler class\nIn this first step the custom ErrorHandler class is going to be created inside the folder /app/core/errors/errors-handler.ts:\nimport { ErrorHandler, Injectable, Injector } from &apos;@angular/core&apos;;\nimport { HttpErrorResponse } from &apos;@angular/common/http&apos;;\n@Injectable()\nexport class ErrorsHandler implements ErrorHandler {\nconstructor(private injector: Injector) {}\nhandleError(error: Error | HttpErrorResponse) {\n// To do: Use injector to get the necessary services to redirect or\n// show a message to the user\nconst classname = error.constructor.name;\nswitch ( classname ) {\ncase &apos;HttpErrorResponse&apos;:\nconsole.error(&apos;HttpError:&apos; + error.message);\nif (!navigator.onLine) {\nconsole.error(&apos;Theres no internet connection&apos;);\n// To do: control here in internet what you wanna do if user has no internet\n} else {\nconsole.error(&apos;Server Error:&apos; + error.message);\n// To do: control here if the server gave an error\n}\nbreak;\ndefault:\nconsole.error(&apos;Error:&apos; + error.message);\n// To do: control here if the client/other things gave an error\n}\n}\n}\nThis class can be used to control the different type of errors. If wanted, the classname variable could be used to add more switch cases. This would allow control of more specific situations.\nCreating a ErrorInterceptor\nInside the same folder created in the last step we are going to create the ErrorInterceptor(errors-handler-interceptor.ts). This ErrorInterceptor is going to retry any failed calls to the server to make sure it is not being found before showing the error:\nimport { HttpInterceptor, HttpRequest, HttpHandler, HttpEvent } from &apos;@angular/common/http&apos;;\nimport { Injectable } from &apos;@angular/core&apos;;\nimport { Observable } from &apos;rxjs&apos;;\nimport { retry } from &apos;rxjs/operators&apos;;\n@Injectable()\nexport class ErrorsHandlerInterceptor implements HttpInterceptor {\nconstructor() {}\nintercept(req: HttpRequest&lt;any&gt;, next: HttpHandler): Observable&lt;HttpEvent&lt;any&gt;&gt; {\nreturn next.handle(req).pipe(\nretryWhen((errors: Observable&lt;any&gt;) =&gt; errors.pipe(\ndelay(500),\ntake(5),\nconcatMap((error: any, retryIndex: number) =&gt; {\nif (++retryIndex === 5) {\nthrow error;\n}\nreturn of(error);\n})\n))\n);\n}\n}\nThis custom made interceptor is implementing the HttpInterceptor and inside the method intercept using the method pipe,retryWhen,delay,take and concatMap from RxJs it is going to do the next things if there is errors:\nWith delay(500) do a delay to allow some time in between requests\nWith take(5) retry five times.\nWith concatMap if the index that take() gives is not 5 it returns the error, else, it throws the error.\nCreating a Error Module\nFinally, creating a module(errors-handler.module.ts) is necessary to include the interceptor and the custom error handler. In this case, the module is going to be created in the same folder as the last two:\nimport { NgModule, ErrorHandler } from &apos;@angular/core&apos;;\nimport { CommonModule } from &apos;@angular/common&apos;;\nimport { ErrorsHandler } from &apos;./errors-handler&apos;;\nimport { HTTP_INTERCEPTORS } from &apos;@angular/common/http&apos;;\nimport { ErrorsHandlerInterceptor } from &apos;./errors-handler-interceptor&apos;;\n@NgModule({\ndeclarations: [], // Declare here component if you want to use routing to error component\nimports: [\nCommonModule\n],\nproviders: [\n{\nprovide: ErrorHandler,\nuseClass: ErrorsHandler,\n},\n{\nprovide: HTTP_INTERCEPTORS,\nuseClass: ErrorsHandlerInterceptor,\nmulti: true,\n}\n]\n})\nexport class ErrorsHandlerModule { }\nThis module simply is providing the services that are implemented by our custom classes and then telling angular to use our custom made classes instead of the default ones. After doing this, the module has to be included in the app module app.module.ts in order to be used.\n....\nimports: [\nErrorsHandlerModule,\n....\n"},{"id":698,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-error-handler.asciidoc_handling-errors","type":"docs","title":"Handling Errors","body":"18.10.3. Handling Errors\nAs a final step, handling these errors is necessary. Theres different ways that can be used to control the errors, here are a few:\nCreating a custom page and using with Router to redirect to a page showing an error.\nCreating a service in the server side or Backend to create a log with the error and calling it with HttpClient.\nShowing a custom made SnackBar with the error message.\nUsing SnackBarService and NgZone\nIf the SnackBar is used directly, some errors can ocurr, this is due to SnackBar being out of the Angular zone. In order to use this service properly, NgZone is necessary. The method run() from NgZone will allow the service to be inside the Angular Zone. An example on how to use it:\nimport { ErrorHandler, Injectable, Injector, NgZone } from &apos;@angular/core&apos;;\nimport { HttpErrorResponse } from &apos;@angular/common/http&apos;;\nimport { MatSnackBar } from &apos;@angular/material&apos;;\n@Injectable()\nexport class ErrorsHandler implements ErrorHandler {\nconstructor(private injector: Injector, private zone: NgZone) {}\nhandleError(error: Error | HttpErrorResponse) {\n// Use injector to get the necessary services to redirect or\nconst snackBar: MatSnackBar = this.injector.get(MatSnackBar);\nconst classname = error.constructor.name;\nlet message: string;\nswitch ( classname ) {\ncase &apos;HttpErrorResponse&apos;:\nmessage = !(navigator.onLine) ? &apos;There is no internet connection&apos; : error.message;\nbreak;\ndefault:\nmessage = error.message;\n}\nthis.zone.run(\n() =&gt; snackBar.open(message, &apos;danger&apos;, { duration : 4000})\n);\n}\n}\nUsing Injector the MatSnackBar is obtained, then the correct message is obtained inside the switch. Finally, using NgZone and run(), we open the SnackBar passing the message, and the paremeters wanted.\n"},{"id":699,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-file-structure.asciidoc","type":"docs","title":"File Structure","body":"18.11. File Structure\n"},{"id":700,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-file-structure.asciidoc_toplevel","type":"docs","title":"Toplevel","body":"18.11.1. Toplevel\nThe toplevel file structure is defined by Angular CLI. You might put this &quot;toplevel file structure&quot; into a subdirectory to facilitate your build, but this is not relevant for this guide. So the applications file structure relevant to this guide is the folder /src/app inside the part managed by Angular CLI.\nListing 46. Toplevel file structure shows feature modules\n/src\n&#x2514;&#x2500;&#x2500; /app\n&#x251C;&#x2500;&#x2500; /account-management\n&#x251C;&#x2500;&#x2500; /billing\n&#x251C;&#x2500;&#x2500; /booking\n&#x251C;&#x2500;&#x2500; /core\n&#x251C;&#x2500;&#x2500; /shared\n&#x251C;&#x2500;&#x2500; /status\n|\n&#x251C;&#x2500;&#x2500; app.module.ts\n&#x251C;&#x2500;&#x2500; app.component.spec.ts\n&#x251C;&#x2500;&#x2500; app.component.ts\n&#x2514;&#x2500;&#x2500; app.routing-module.ts\nBesides the definition of app module the app folder has feature modules on toplevel.\nThe special modules shared and core are present as well.\n"},{"id":701,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-file-structure.asciidoc_feature-modules","type":"docs","title":"Feature Modules","body":"18.11.2. Feature Modules\nA feature module contains the modules definition and two folders representing both layers.\nListing 47. Feature module file structure has both layers\n/src\n&#x2514;&#x2500;&#x2500; /app\n&#x2514;&#x2500;&#x2500; /account-management\n&#x251C;&#x2500;&#x2500; /components\n&#x251C;&#x2500;&#x2500; /services\n|\n&#x251C;&#x2500;&#x2500; account-management.module.ts\n&#x251C;&#x2500;&#x2500; account-management.component.spec.ts\n&#x251C;&#x2500;&#x2500; account-management.component.ts\n&#x2514;&#x2500;&#x2500; account-management.routing-module.ts\nAdditionally an entry component is possible. This would be the case in lazy loading scenarios.\nSo account-management.component.ts would be only present if account-management is lazy loaded.\nOtherwise, the module&#x2019;s routes would be defined Component-less\n(see vsavkin blog post).\n"},{"id":702,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-file-structure.asciidoc_components-layer","type":"docs","title":"Components Layer","body":"18.11.3. Components Layer\nThe component layer reflects the distinction between Smart Components and Dumb Components.\nListing 48. Components layer file structure shows Smart Components on toplevel\n/src\n&#x2514;&#x2500;&#x2500; /app\n&#x2514;&#x2500;&#x2500; /account-management\n&#x2514;&#x2500;&#x2500; /components\n&#x251C;&#x2500;&#x2500; /account-overview\n&#x251C;&#x2500;&#x2500; /confirm-modal\n&#x251C;&#x2500;&#x2500; /create-account\n&#x251C;&#x2500;&#x2500; /forgot-password\n&#x2514;&#x2500;&#x2500; /shared\nEvery folder inside the /components folder represents a smart component. The only exception is /shared.\n/shared contains Dumb Components shared across Smart Components inside the components layer.\nListing 49. Smart components contain Dumb components\n/src\n&#x2514;&#x2500;&#x2500; /app\n&#x2514;&#x2500;&#x2500; /account-management\n&#x2514;&#x2500;&#x2500; /components\n&#x2514;&#x2500;&#x2500; /account-overview\n&#x251C;&#x2500;&#x2500; /user-info-panel\n| &#x251C;&#x2500;&#x2500; /address-tab\n| &#x251C;&#x2500;&#x2500; /last-activities-tab\n| |\n| &#x251C;&#x2500;&#x2500; user-info-panel.component.html\n| &#x251C;&#x2500;&#x2500; user-info-panel.component.scss\n| &#x251C;&#x2500;&#x2500; user-info-panel.component.spec.ts\n| &#x2514;&#x2500;&#x2500; user-info-panel.component.ts\n|\n&#x251C;&#x2500;&#x2500; /user-header\n&#x251C;&#x2500;&#x2500; /user-toolbar\n|\n&#x251C;&#x2500;&#x2500; account-overview.component.html\n&#x251C;&#x2500;&#x2500; account-overview.component.scss\n&#x251C;&#x2500;&#x2500; account-overview.component.spec.ts\n&#x2514;&#x2500;&#x2500; account-overview.component.ts\nInside the folder of a Smart Component the component is defined.\nBesides that are folders containing the Dumb Components the Smart Component consists of.\nThis can be recursive - a Dumb Component can consist of other Dumb Components.\nThis is reflected by the file structure as well. This way the structure of a view becomes very readable.\nAs mentioned before, if a Dumb Component is used by multiple Smart Components inside the components layer\nit is put inside the /shared folder inside the components layer.\nWith this way of thinking the shared module makes a lot of sense. If a Dumb Component is used by multiple Smart Components\nfrom different feature modules, the Dumb Component is placed into the shared module.\nListing 50. The shared module contains Dumb Components shared across Smart Components from different feature modules\n/src\n&#x2514;&#x2500;&#x2500; /app\n&#x2514;&#x2500;&#x2500; /shared\n&#x2514;&#x2500;&#x2500; /user-panel\n|\n&#x251C;&#x2500;&#x2500; user-panel.component.html\n&#x251C;&#x2500;&#x2500; user-panel.component.scss\n&#x251C;&#x2500;&#x2500; user-panel.component.spec.ts\n&#x2514;&#x2500;&#x2500; user-panel.component.ts\nThe layer folder /components is not necessary inside the shared module.\nThe shared module only contains components!\n"},{"id":703,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-internationalization.asciidoc","type":"docs","title":"Internationalization","body":"18.12. Internationalization\nNowadays, a common scenario in front-end applications is to have the ability to translate labels and locate numbers, dates, currency and so on when the user clicks over a language selector or similar. devon4ng and specifically Angular has a default mechanism in order to fill the gap of such features, and besides there are some wide used libraries that make even easier to translate applications.\nMore info at Angular i18n official documentation\n"},{"id":704,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-internationalization.asciidoc_devon4ng-i18n-approach","type":"docs","title":"devon4ng i18n approach","body":"18.12.1. devon4ng i18n approach\nThe official approach could be a bit complicated, therefore the recommended one is to use the recommended library Transloco from https://netbasal.gitbook.io/transloco/.\nInstall and configure Transloco\nIn order to include this library in your devon4ng Angular &gt;= 7.2 project you will need to execute in a terminal:\n$ ng add @ngneat/transloco\nAs part of the installation process you&#x2019;ll be presented with questions; Once you answer them, everything you need will automatically be created for you.\nFirst, Transloco creates boilerplate files for the requested translations.\nNext, it will create a new file, transloco-root.module.ts which exposes an Angular&#x2019;s module with a default configuration, and inject it into the AppModule.\nimport { HttpClient } from &apos;@angular/common/http&apos;;\nimport {\nTRANSLOCO_LOADER,\nTranslation,\nTranslocoLoader,\nTRANSLOCO_CONFIG,\ntranslocoConfig,\nTranslocoModule\n} from &apos;@ngneat/transloco&apos;;\nimport { Injectable, NgModule } from &apos;@angular/core&apos;;\nimport { environment } from &apos;../environments/environment&apos;;\n@Injectable({ providedIn: &apos;root&apos; })\nexport class TranslocoHttpLoader implements TranslocoLoader {\nconstructor(private http: HttpClient) {}\ngetTranslation(lang: string) {\nreturn this.http.get&lt;Translation&gt;(`/assets/i18n/${lang}.json`);\n}\n}\n@NgModule({\nexports: [ TranslocoModule ],\nproviders: [\n{\nprovide: TRANSLOCO_CONFIG,\nuseValue: translocoConfig({\navailableLangs: [&apos;en&apos;, &apos;es&apos;],\ndefaultLang: &apos;en&apos;,\n// Remove this option if your application doesn&apos;t support changing language in runtime.\nreRenderOnLangChange: true,\nprodMode: environment.production,\n})\n},\n{ provide: TRANSLOCO_LOADER, useClass: TranslocoHttpLoader }\n]\n})\nexport class TranslocoRootModule {}\nNote\nAs you might have noticed it also set an HttpLoader into the module&#x2019;s providers. The HttpLoader is a class that implements the TranslocoLoader interface. It&#x2019;s responsible for instructing Transloco how to load the translation files. It uses Angular HTTP client to fetch the files, based on the given path.\nUsage\nIn order to translate any label in any HTML template you will need to use the transloco pipe available:\n{{ &apos;HELLO&apos; | transloco }}\nAn optional parameter from the component TypeScript class could be included as follows:\n{{ &apos;HELLO&apos; | transloco: { value: dynamic } }}\nIt is possible to use with inputs:\n&lt;span [attr.alt]=&quot;&apos;hello&apos; | transloco&quot;&gt;Attribute&lt;/span&gt;\n&lt;span [title]=&quot;&apos;hello&apos; | transloco&quot;&gt;Property&lt;/span&gt;\nIn order to change the language used you will need to create a button or selector that calls the this.translocoService.use(language: string) method from TranslocoService. For example:\nexport class AppComponent {\nconstructor(private translocoService: TranslocoService) {}\nchangeLanguage(lang) {\nthis.translocoService.setActiveLang(lang);\n}\n}\nThe translations will be included in the en.json, es.json, de.json, etc. files inside the /assets/i18n folder. For example en.json would be (using the previous param):\n{\n&quot;HELLO&quot;: &quot;hello&quot;\n}\nOr with an optional param:\n{\n&quot;HELLO&quot;: &quot;hello {{value}}&quot;\n}\nTransloco understands nested JSON objects. This means that you can have a translation that looks like this:\n{\n&quot;HOME&quot;: {\n&quot;HELLO&quot;: &quot;hello {{value}}&quot;\n}\n}\nIn order to access access the value, use the dot notation, in this case HOME.HELLO.\nUsing the service, pipe or directive\nStructural Directive\nUsing a structural directive is the recommended approach. It&#x2019;s DRY and efficient, as it creates one subscription per template:\n&lt;ng-container *transloco=&quot;let t&quot;&gt;\n&lt;p&gt;{{ t(&apos;title&apos;) }}&lt;/p&gt;\n&lt;comp [title]=&quot;t(&apos;title&apos;)&quot;&gt;&lt;/comp&gt;\n&lt;/ng-container&gt;\nNote that the t function is memoized. It means that given the same key it will return the result directly from the cache.\nWe can pass a params object as the second parameter:\n&lt;ng-container *transloco=&quot;let t&quot;&gt;\n&lt;p&gt;{{ t(&apos;name&apos;, { name: &apos;Transloco&apos; }) }}&lt;/p&gt;\n&lt;/ng-container&gt;\nWe can instruct the directive to use a different language in our template:\n&lt;ng-container *transloco=&quot;let t; lang: &apos;es&apos;&quot;&gt;\n&lt;p&gt;{{ t(&apos;title&apos;) }}&lt;/p&gt;\n&lt;/ng-container&gt;\nPipe\nThe use of pipes can be possible too:\ntemplate:\n&lt;div&gt;{{ &apos;HELLO&apos; | transloco:param }}&lt;/div&gt;\ncomponent:\nparam = {value: &apos;world&apos;};\nAttribute Directive\nThe last option available with transloco is the attribute directive:\n&lt;div transloco=&quot;HELLO&quot; [translocoParams]=&quot;{ value: &apos;world&apos; }&quot;&gt;&lt;/div&gt;\nService\nIf you need to access translations in any component or service you can do it injecting the TranslocoService into them:\n// Sync translation\ntranslocoService.translate(&apos;HELLO&apos;, {value: &apos;world&apos;});\n// Async translation\ntranslocoService.selectTranslate(&apos;HELLO&apos;, { value: &apos;world&apos; }).subscribe(res =&gt; {\nconsole.log(res);\n//=&gt; &apos;hello world&apos;\n});\nImportant\nYou can find a complete example at https://github.com/devonfw/devon4ng-application-template.\nPlease, visit https://netbasal.gitbook.io/transloco for more info.\n"},{"id":705,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-routing.asciidoc","type":"docs","title":"Routing","body":"18.13. Routing\nA basic introduction to the Angular Router can be found in Angular Docs.\nThis guide will show common tasks and best practices.\n"},{"id":706,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-routing.asciidoc_defining-routes","type":"docs","title":"Defining Routes","body":"18.13.1. Defining Routes\nFor each feature module and the app module all routes should be defined in a seperate module with the suffix RoutingModule.\nThis way the routing modules are the only place where routes are defined.\nThis pattern achieves a clear seperation of concernes.\nThe following figure illustrates this.\nFigure 49. Routing module declaration\nIt is important to define routes inside app routing module with .forRoot() and in feature routing modules with .forChild().\nExample 1 - No Lazy Loading\nIn this example two modules need to be configured with routes - AppModule and FlightModule.\nThe following routes will be configured\n/ will redirect to /search\n/search displays FlightSearchComponent (FlightModule)\n/search/print/:flightId/:date displays FlightPrintComponent (FlightModule)\n/search/details/:flightId/:date displays FlightDetailsComponent (FlightModule)\nAll other routes will display ErrorPage404 (AppModule)\nListing 51. app-routing.module.ts\nconst routes: Routes = [\n{ path: &apos;&apos;, redirectTo: &apos;search&apos;, pathMatch: &apos;full&apos; },\n{ path: &apos;**&apos;, component: ErrorPage404 }\n];\n@NgModule({\nimports: [RouterModule.forRoot(routes)],\nexports: [RouterModule]\n})\nexport class AppRoutingModule { }\nListing 52. flight-search-routing.module.ts\nconst routes: Routes = [\n{\npath: &apos;search&apos;, children: [\n{ path: &apos;&apos;, component: FlightSearchComponent },\n{ path: &apos;print/:flightId/:date&apos;, component: FlightPrintComponent },\n{ path: &apos;details/:flightId/:date&apos;, component: FlightDetailsComponent }\n]\n}\n];\n@NgModule({\nimports: [RouterModule.forChild(routes)],\nexports: [RouterModule],\n})\nexport class FlightSearchRoutingModule { }\nTip\nThe import order inside AppModule is important.\nAppRoutingModule needs to be imported after FlightModule.\nExample 2 - Lazy Loading\nLazy Loading is a good practice when the application has multiple feature areas and a user might not visit every dialog.\nOr at least he might not need every dialog up front.\nThe following example will configure the same routes as example 1 but will lazy load FlightModule.\nListing 53. app-routing.module.ts\nconst routes: Routes = [\n{ path: &apos;/search&apos;, loadChildren: &apos;app/flight-search/flight-search.module#FlightSearchModule&apos; },\n{ path: &apos;**&apos;, component: ErrorPage404 }\n];\n@NgModule({\nimports: [RouterModule.forRoot(routes)],\nexports: [RouterModule]\n})\nexport class AppRoutingModule { }\nListing 54. flight-search-routing.module.ts\nconst routes: Routes = [\n{\npath: &apos;&apos;, children: [\n{ path: &apos;&apos;, component: FlightSearchComponent },\n{ path: &apos;print/:flightId/:date&apos;, component: FlightPrintComponent },\n{ path: &apos;details/:flightId/:date&apos;, component: FlightDetailsComponent }\n]\n}\n];\n@NgModule({\nimports: [RouterModule.forChild(routes)],\nexports: [RouterModule],\n})\nexport class FlightSearchRoutingModule { }\n"},{"id":707,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-routing.asciidoc_triggering-route-changes","type":"docs","title":"Triggering Route Changes","body":"18.13.2. Triggering Route Changes\nWith Angular you have two ways of triggering route changes.\nDeclarative with bindings in component HTML templates\nProgrammatic with Angular Router service inside component classes\nOn the one hand, architecture-wise it is a much cleaner solution to trigger route changes in Smart Components.\nThis way you have every UI event that should trigger a navigation handled in one place - in a Smart Component.\nIt becomes very easy to look inside the code for every navigation, that can occure.\nRefactoring is also much easier, as there are no navigation events &quot;hidden&quot; in the HTML templates\nOn the other hand, in terms of accessibility and SEO it is a better solution to rely on bindings in the view - e.g. by using Angulars router-link directive.\nThis way screen readers and the Google crawler can move through the page easily.\nTip\nIf you do not have to support accessibility (screen readers, etc.) and to care about SEO (Google rank, etc.),\nthen you should aim for triggering navigations only in Smart Components.\nFigure 50. Triggering navigation\n"},{"id":708,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-routing.asciidoc_guards","type":"docs","title":"Guards","body":"18.13.3. Guards\nGuards are Angular services implemented on routes which determines whether a user can naviagate to/from the route. There are examples below which will explain things better. We have the following types of Guards:\nCanActivate: It is used to determine whether a user can visit a route. The most common scenario for this guard is to check if the user is authenticated. For example, if we want only logged in users to be able to go to a particular route, we will implement the CanActivate guard on this route.\nCanActivateChild: Same as above, only implemented on child routes.\nCanDeactivate: It is used to determine if a user can naviagate away from a route. Most common example is when a user tries to go to a different page after filling up a form and does not save/submit the changes, we can use this guard to confirm whether the user really wants to leave the page without saving/submiting.\nResolve: For resolving dynamic data.\nCanLoad: It is used to determine whether an Angular module can be loaded lazily. Example below will be helpful to understand it.\nLet&#x2019;s have a look at some examples.\nExample 1 - CanActivate and CanActivateChild guards\nCanActivate guard\nAs mentioned earlier, a guard is an Angular service and services are simply TypeScript classes. So we begin by creating a class. This class has to implement the CanActivate interface (imported from angular/router), and therefore, must have a canActivate function. The logic of this function determines whether the requested route can be navigated to or not. It returns either a boolean value or an Observable or a Promise which resolves to a boolean value. If it is true, the route is loaded, else not.\nListing 55. CanActivate example\n...\nimport {CanActivate} from &quot;@angular/router&quot;;\n@Injectable()\nclass ExampleAuthGuard implements CanActivate {\nconstructor(private authService: AuthService) {}\ncanActivate(route: ActivatedRouterSnapshot, state: RouterStateSnapshot) {\nif (this.authService.isLoggedIn()) {\nreturn true;\n} else {\nwindow.alert(&apos;Please log in first&apos;);\nreturn false;\n}\n}\n}\nIn the above example, let&#x2019;s assume we have a AuthService which has a isLoggedIn() method which returns a boolean value depending on whether the user is logged in. We use it to return true or false from the canActivate function.\nThe canActivate function accepts two parameters (provided by Angular). The first parameter of type ActivatedRouterSnapshot is the snapshot of the route the user is trying to naviagate to (where the guard is implemented); we can extract the route parameters from this instance. The second parameter of type RouterStateSnapshot is a snapshot of the router state the user is trying to naviagate to; we can fetch the URL from it&#x2019;s url property.\nTip\nWe can also redirect the user to another page (maybe a login page) if the authService returns false. To do that, inject Router and use it&#x2019;s naviagate function to redirect to the appropriate page.\nSince it is a service, it needs to be provided in our module:\nListing 56. provide the guard in a module\n@NgModule({\n...\nproviders: [\n...\nExampleAuthGuard\n]\n})\nNow this guard is ready to use on our routes. We implement it where we define our array of routes in the application:\nListing 57. Implementing the guard\n...\nconst routes: Routes = [\n{ path: &apos;&apos;, redirectTo: &apos;home&apos;, pathMatch: &apos;full&apos; },\n{ path: &apos;home&apos;, component: HomeComponent },\n{ path: &apos;page1&apos;, component: Page1Component, canActivate: [ExampleAuthGuard] }\n];\nAs you can see, the canActivate property accepts an array of guards. So we can implement more than one guard on a route.\nCanActivateChild guard\nTo use the guard on nested (children) routes, we add it to the canActivateChild property like so:\nListing 58. Implementing the guard on child routes\n...\nconst routes: Routes = [\n{ path: &apos;&apos;, redirectTo: &apos;home&apos;, pathMatch: &apos;full&apos; },\n{ path: &apos;home&apos;, component: HomeComponent },\n{ path: &apos;page1&apos;, component: Page1Component, canActivateChild: [ExampleAuthGuard], children: [\n{path: &apos;sub-page1&apos;, component: SubPageComponent},\n{path: &apos;sub-page2&apos;, component: SubPageComponent}\n] }\n];\nExample 2 - CanLoad guard\nSimilar to CanActivate, to use this guard we implement the CanLoad interface and overwrite it&#x2019;s canLoad function. Again, this function returns either a boolean value or an Observable or a Promise which resolves to a boolean value. The fundamental difference between CanActivate and CanLoad is that CanLoad is used to determine whether an entire module can be lazily loaded or not. If the guard returns false for a module protected by CanLoad, the entire module is not loaded.\nListing 59. CanLoad example\n...\nimport {CanLoad, Route} from &quot;@angular/router&quot;;\n@Injectable()\nclass ExampleCanLoadGuard implements CanLoad {\nconstructor(private authService: AuthService) {}\ncanLoad(route: Route) {\nif (this.authService.isLoggedIn()) {\nreturn true;\n} else {\nwindow.alert(&apos;Please log in first&apos;);\nreturn false;\n}\n}\n}\nAgain, let&#x2019;s assume we have a AuthService which has a isLoggedIn() method which returns a boolean value depending on whether the user is logged in. The canLoad function accepts a parameter of type Route which we can use to fetch the path a user is trying to navigate to (using the path property of Route).\nThis guard needs to be provided in our module like any other service.\nTo implement the guard, we use the canLoad property:\nListing 60. Implementing the guard\n...\nconst routes: Routes = [\n{ path: &apos;home&apos;, component: HomeComponent },\n{ path: &apos;admin&apos;, loadChildren: &apos;app/admin/admin.module#AdminModule&apos;, canLoad: [ExampleCanLoadGuard] }\n];\n"},{"id":709,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-testing.asciidoc","type":"docs","title":"Testing","body":"18.14. Testing\nThis guide will cover the basics of testing logic inside your code with UnitTests.\nThe guide assumes that you are familiar with Angular CLI (see the guide)\nFor testing your Angular application with UnitTests there are two main strategies:\nIsolated UnitTests\nIsolated unit tests examine an instance of a class all by itself without any dependence on Angular or any injected values.\nThe amount of code and effort needed to create such tests in minimal.\nAngular Testing Utilities\nLet you test components including their interaction with Angular.\nThe amount of code and effort needed to create such tests is a little higher.\n"},{"id":710,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-testing.asciidoc_testing-concept","type":"docs","title":"Testing Concept","body":"18.14.1. Testing Concept\nThe following figure shows you an overview of the application architecture devided in testing areas.\nFigure 51. Testing Areas\nThere are three areas, which need to be covered by different testing strategies.\nComponents:\nSmart Components need to be tested because they contain view logic.\nAlso the interaction with 3rd party components needs to be tested.\nWhen a 3rd party component changes with an upgrade a test will be failing and warn you, that there is something wrong with the new version.\nMost of the time Dumb Components do not need to be teste because they mainly display data and do not contain any logic.\nSmart Components are alway tested with Angular Testing Utilities.\nFor example selectors, which select data from the store and transform it further, need to be tested.\nStores:\nA store contains methods representing state transitions.\nIf these methods contain logic, they need to be tested.\nStores are always testet using Isolated UnitTests.\nServices:\nServices contain Business Logic, which needs to be tested.\nUseCase Services represent a whole business use case.\nFor instance this could be initializing a store with all the data that is needed for a dialog - loading, transforming, storing.\nOften Angular Testing Utilities are the optimal solution for testing UseCase Services, because they allow for an easy stubbing of the backend.\nAll other services should be tested with Isolated UnitTests as they are much easier to write and maintain.\n"},{"id":711,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-testing.asciidoc_testing-smart-components","type":"docs","title":"Testing Smart Components","body":"18.14.2. Testing Smart Components\nTesting Smart Components should assure the following.\nBindings are correct.\nSelectors which load data from the store are correct.\nAsynchronous behavior is correct (loading state, error state, &quot;normal&quot; state).\nOftentimes through testing one realizes, that important edge cases are forgotten.\nDo these test become very complex, it is often an indicator for poor code quality in the component.\nThen the implementation is to be adjusted / refactored.\nWhen testing values received from the native DOM, you will test also that 3rd party libraries did not change with a version upgrade.\nA failing test will show you what part of a 3rd party library has changed.\nThis is much better than the users doing this for you.\nFor example a binding might fail because the property name was changed with a newer version of a 3rd party library.\nIn the function beforeEach() the TestBed imported from Angular Testing Utilities needs to be initialized.\nThe goal should be to define a minimal test-module with TestBed.\nThe following code gives you an example.\nListing 61. Example test setup for Smart Components\ndescribe(&apos;PrintFlightComponent&apos;, () =&gt; {\nlet fixture: ComponentFixture&lt;PrintCPrintFlightComponentomponent&gt;;\nlet store: FlightStore;\nlet printServiceSpy: jasmine.SpyObj&lt;FlightPrintService&gt;;\nbeforeEach(() =&gt; {\nconst urlParam = &apos;1337&apos;;\nconst activatedRouteStub = { params: of({ id: urlParam }) };\nprintServiceSpy = jasmine.createSpyObj(&apos;FlightPrintService&apos;, [&apos;initializePrintDialog&apos;]);\nTestBed.configureTestingModule({\nimports: [\nTranslateModule.forRoot(),\nRouterTestingModule\n],\ndeclarations: [\nPrintFlightComponent,\nPrintContentComponent,\nGeneralInformationPrintPanelComponent,\nPassengersPrintPanelComponent\n],\nproviders: [\nFlightStore,\n{provide: FlightPrintService, useValue: printServiceSpy},\n{provide: ActivatedRoute, useValue: activatedRouteStub}\n]\n});\nfixture = TestBed.createComponent(PrintFlightComponent);\nstore = fixture.debugElement.injector.get(FlightStore);\nfixture.detectChanges();\n});\n// ... test cases\n})\nIt is important:\nUse RouterTestingModule` instead of RouterModule\nUse TranslateModule.forRoot() without translations\nThis way you can test language-neutral without translation marks.\nDo not add a whole module from your application - in declarations add the tested Smart Component with all its Dumb Components\nThe store should never be stubbed.\nIf you need a complex test setup, just use the regular methods defined on the store.\nStub all services used by the Smart Component.\nThese are mostly UseCase services.\nThey should not be tested by these tests.\nOnly the correct call to their functions should be assured.\nThe logic inside the UseCase services is tested with seperate tests.\ndetectChanges() performance an Angular Change Detection cycle (Angular refreshes all the bindings present in the view)\ntick() performance a virtual marco task, tick(1000) is equal to the virtual passing of 1s.\nThe following test cases show the testing strategy in action.\nListing 62. Example\nit(&apos;calls initializePrintDialog for url parameter 1337&apos;, fakeAsync(() =&gt; {\nexpect(printServiceSpy.initializePrintDialog).toHaveBeenCalledWith(1337);\n}));\nit(&apos;creates correct loading subtitle&apos;, fakeAsync(() =&gt; {\nstore.setPrintStateLoading(123);\ntick();\nfixture.detectChanges();\nconst subtitle = fixture.debugElement.query(By.css(&apos;app-header-element .print-header-container span:last-child&apos;));\nexpect(subtitle.nativeElement.textContent).toBe(&apos;PRINT_HEADER.FLIGHT STATE.IS_LOADING&apos;);\n}));\nit(&apos;creates correct subtitle for loaded flight&apos;, fakeAsync(() =&gt; {\nstore.setPrintStateLoadedSuccess({\nid: 123,\ndescription: &apos;Description&apos;,\niata: &apos;FRA&apos;,\nname: &apos;Frankfurt&apos;,\n// ...\n});\ntick();\nfixture.detectChanges();\nconst subtitle = fixture.debugElement.query(By.css(&apos;app-header-element .print-header-container span:last-child&apos;));\nexpect(subtitle.nativeElement.textContent).toBe(&apos;PRINT_HEADER.FLIGHT &quot;FRA (Frankfurt)&quot; (ID: 123)&apos;);\n}));\nThe examples show the basic testing method\nSet the store to a well-defined state\ncheck if the component displays the correct values\n&#x2026;&#x200B; via checking values inside the native DOM.\n"},{"id":712,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-testing.asciidoc_testing-state-transitions-performed-by-stores","type":"docs","title":"Testing state transitions performed by stores","body":"18.14.3. Testing state transitions performed by stores\nStores are always tested with Isolated UnitTests.\nActions triggered by dispatchAction() calls are asynchronously performed to alter the state.\nA good solution to test such a state transition is to use the done callback from Jasmine.\nListing 63. Example for testing a store\nlet sut: FlightStore;\nbeforeEach(() =&gt; {\nsut = new FlightStore();\n});\nit(&apos;setPrintStateLoading sets print state to loading&apos;, (done: Function) =&gt; {\nsut.setPrintStateLoading(4711);\nsut.state$.pipe(first()).subscribe(result =&gt; {\nexpect(result.print.isLoading).toBe(true);\nexpect(result.print.loadingId).toBe(4711);\ndone();\n});\n});\nit(&apos;toggleRowChecked adds flight with given id to selectedValues Property&apos;, (done: Function) =&gt; {\nconst flight: FlightTO = {\nid: 12\n// dummy data\n};\nsut.setRegisterabgleichListe([flight]);\nsut.toggleRowChecked(12);\nsut.state$.pipe(first()).subscribe(result =&gt; {\nexpect(result.selectedValues).toContain(flight);\ndone();\n});\n});\n"},{"id":713,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-testing.asciidoc_testing-services","type":"docs","title":"Testing services","body":"18.14.4. Testing services\nWhen testing services both strategies - Isolated UnitTests and Angular Testing Utilities - are valid options.\nThe goal of such tests are\nassuring the behavior for valid data.\nassuring the behavior for invalid data.\ndocumenting functionality\nsavely performing refactorings\nthinking about edge case behavior while testing\nFor simple services Isolated UnitTests can be written.\nWriting these tests takes lesser effort and they can be written very fast.\nThe following listing gives an example of such tests.\nListing 64. Testing a simple services with Isolated UnitTests\nlet sut: IsyDatePipe;\nbeforeEach(() =&gt; {\nsut = new IsyDatePipe();\n});\nit(&apos;transform should return empty string if input value is empty&apos;, () =&gt; {\nexpect(sut.transform(&apos;&apos;)).toBe(&apos;&apos;);\n});\nit(&apos;transform should return empty string if input value is null&apos;, () =&gt; {\nexpect(sut.transform(undefined)).toBe(&apos;&apos;);\n});\n// ...more tests\nFor testing Use Case services the Angular Testing Utilities should be used.\nThe following listing gives an example.\nListing 65. Test setup for testing use case services with Angular Testing Utilities\nlet sut: FlightPrintService;\nlet store: FlightStore;\nlet httpController: HttpTestingController;\nlet flightCalculationServiceStub: jasmine.SpyObj&lt;FlightCalculationService&gt;;\nconst flight: FlightTo = {\n// ... valid dummy data\n};\nbeforeEach(() =&gt; {\nflightCalculationServiceStub = jasmine.createSpyObj(&apos;FlightCalculationService&apos;, [&apos;getFlightType&apos;]);\nflightCalculationServiceStub.getFlightType.and.callFake((catalog: string, type: string, key: string) =&gt; of(`${key}_long`));\nTestBed.configureTestingModule({\nimports: [\nHttpClientTestingModule,\nRouterTestingModule,\n],\nproviders: [\nFlightPrintService,\nFlightStore,\nFlightAdapter,\n{provide: FlightCalculationService, useValue: flightCalculationServiceStub}\n]\n});\nsut = TestBed.get(FlightPrintService);\nstore = TestBed.get(FlightStore);\nhttpController = TestBed.get(HttpTestingController);\n});\nWhen using TestBed, it is important\nto import HttpClientTestingModule for stubbing the backend\nto import RouterTestingModule for stubbing the Angular router\nnot to stub stores, adapters and business services\nto stub services from libraries like FlightCalculationService - the correct implementation of libraries should not be tested by these tests.\nTesting backend communication looks like this:\nListing 66. Testing backend communication with Angular HttpTestingController\nit(&apos;loads flight if not present in store&apos;, fakeAsync(() =&gt; {\nsut.initializePrintDialog(1337);\nconst processRequest = httpController.expectOne(&apos;/path/to/flight&apos;);\nprocessRequest.flush(flight);\nhttpController.verify();\n}));\nit(&apos;does not load flight if present in store&apos;, fakeAsync(() =&gt; {\nconst flight = {...flight, id: 4711};\nstore.setRegisterabgleich(flight);\nsut.initializePrintDialog(4711);\nhttpController.expectNone(&apos;/path/to/flight&apos;);\nhttpController.verify();\n}));\nThe first test assures a correct XHR request is performed if initializePrintDialog() is called and no data is in the store.\nThe second test assures no XHR request ist performed if the needed data is already in the store.\nThe next steps are checks for the correct implementation of logic.\nListing 67. Example testing a Use Case service\nit(&apos;creates flight destination for valid key in svz&apos;, fakeAsync(() =&gt; {\nconst flightTo: FlightTo = {\n...flight,\nid: 4712,\nprofile: &apos;77&apos;\n};\nstore.setFlight(flightTo);\nlet result: FlightPrintContent|undefined;\nsut.initializePrintDialog(4712);\nstore.select(s =&gt; s.print.content).subscribe(content =&gt; result = content);\ntick();\nexpect(result!.destination).toBe(&apos;77_long (ID: 77)&apos;);\n}));\n"},{"id":714,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-update-angular-cli.asciidoc","type":"docs","title":"Update Angular CLI","body":"18.15. Update Angular CLI\n"},{"id":715,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-update-angular-cli.asciidoc_angular-cli-common-issues","type":"docs","title":"Angular CLI common issues","body":"18.15.1. Angular CLI common issues\nThere are constant updates for the official Angular framework dependencies. These dependencies are directly related with the Angular CLI package. Since this package comes installed by default inside the devonfw distribution folder for Windows OS and the distribution is updated every few months it needs to be updated in order to avoid known issues.\n"},{"id":716,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-update-angular-cli.asciidoc_angular-cli-update-guide","type":"docs","title":"Angular CLI update guide","body":"18.15.2. Angular CLI update guide\nFor Linux users is as easy as updating the global package:\n$ npm unistall -g @angular/cli\n$ npm install -g @angular/cli\nFor Windows users the process is only a bit harder. Open the devonfw bundled console and do as follows:\n$ cd [devonfw_dist_folder]\n$ cd software/nodejs\n$ npm uninstall @angular/cli --no-save\n$ npm install @angular/cli --no-save\nAfter following these steps you should have the latest Angular CLI version installed in your system. In order to check it run in the distribution console:\nNote\nAt the time of this writing, the Angular CLI is at 1.7.4 version.\n&#x3BB; ng version\n_ _ ____ _ ___\n/ \\ _ __ __ _ _ _| | __ _ _ __ / ___| | |_ _|\n/ &#x25B3; \\ | &apos;_ \\ / _` | | | | |/ _` | &apos;__| | | | | | |\n/ ___ \\| | | | (_| | |_| | | (_| | | | |___| |___ | |\n/_/ \\_\\_| |_|\\__, |\\__,_|_|\\__,_|_| \\____|_____|___|\n|___/\nAngular CLI: 7.2.3\nNode: 10.13.0\nOS: win32 x64\nAngular:\n...\n"},{"id":717,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-upgrade-devon4ng.asciidoc","type":"docs","title":"Upgrade devon4ng Angular and Ionic/Angular applications","body":"18.16. Upgrade devon4ng Angular and Ionic/Angular applications\nAngular CLI provides a powerful tool to upgrade Angular based applications to the current stable release of the core framework.\nThis tool is ng update. It will not only upgrade dependencies and their related ones but also will perform some fixes in your code if available thanks to the provided schematics. It will check even if the update is not possible as there is another library or libraries that are not compatible with the versions of the upgraded dependencies. In this case it will keep your application untouched.\nNote\nThe repository must be in a clean state before executing a ng update. So, remember to commit your changes first.\n"},{"id":718,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-upgrade-devon4ng.asciidoc_basic-usage","type":"docs","title":"Basic usage","body":"18.16.1. Basic usage\nIn order to perform a basic upgrade we will execute:\n$ ng update @angular/cli @angular/core\nUpgrade to new Angular version\nThe process will be the same, but first we need to make sure that our devon4ng application is in the lates version of Angular 8, so the ng update command can perform the upgrade not only in the dependencies but also making code changes to reflect the new features and fixes.\nFirst, upgrade to latest Angular 9 version:\n$ ng update @angular/cli@9 @angular/core@9\nOptionally the flag -C can be added to previous command to make a commit automatically. This is also valid for the next steps.\nThen, upgrade Angular:\n$ ng update @angular/cli @angular/core\nIn case you use Angular Material:\n$ ng update @angular/material\nIf the application depends on third party libraries, the new tool ngcc can be run to make them compatible with the new Ivy compiler. In this case it is recommended to include a postinstall script in the package.json:\n{\n&quot;scripts&quot;: {\n&quot;postinstall&quot;: &quot;ngcc --properties es2015 browser module main --first-only --create-ivy-entry-points&quot;\n}\n}\nMore information at https://angular.io/guide/updating-to-version-9 and https://angular.io/guide/ivy.\nImportant use cases:\nTo update to the next beta or pre-release version, use the --next=true option.\nTo update from one major version to another, use the format ng update @angular/cli@^&lt;major_version&gt; @angular/core@^&lt;major_version&gt;.\nIn case your Angular application uses @angular/material include it in the first command:\n$ ng update @angular/cli @angular/core @angular/material\nIonic/Angular applications\nJust following the same procedure we can upgrade Angular applications, but we must take care of important specific Ionic dependencies:\n$ ng update @angular/cli @angular/core @ionic/angular @ionic/angular-toolkit [@ionic/...]\nOther dependencies\nEvery application will make use of different dependencies. Angular CLI ng upgrade will also take care of these ones. For example, if you need to upgrade @capacitor you will perform:\n$ ng update @capacitor/cli @capacitor/core [@capacitor/...]\nAnother example could be that you need to upgrade @ngx-translate packages. As always in this case you will execute:\n$ ng update @ngx-translate/core @ngx-translate/http-loader\nAngular Update Guide online tool\nIt is recommended to use the Angular Update Guide tool at https://update.angular.io/ that will provide the necessary steps to upgrade any Angular application depending on multiple criteria.\n"},{"id":719,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-working-with-angular-cli.asciidoc","type":"docs","title":"Working with Angular CLI","body":"18.17. Working with Angular CLI\nAngular CLI provides a facade for building, testing, linting, debugging and generating code.\nUnder the hood Angular CLI uses specific tools to achieve these tasks.\nThe user does no need to maintain them and can rely on Angular to keep them up to date and maybe switch to other tools which come up in the future.\nThe Angular CLI provides a wiki with common tasks you encounter when working on applications with the Angular CLI.\nThe Angular CLI Wiki can be found here.\nIn this guide we will go through the most important tasks.\nTo go into more details, please visit the Angular CLI wiki.\n"},{"id":720,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-working-with-angular-cli.asciidoc_installing-angular-cli","type":"docs","title":"Installing Angular CLI","body":"18.17.1. Installing Angular CLI\nAngular CLI should be added as global and local dependency.\nThe following commands add Angular CLI as global Dependency.\nyarn command\nyarn global add @angular/cli\nnpm command\nnpm install -g @angular/cli\nYou can check a successful installtion with ng --version.\nThis should print out the version installed.\nFigure 52. Printing Angular CLI Version\n"},{"id":721,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-working-with-angular-cli.asciidoc_running-a-live-development-server","type":"docs","title":"Running a live development server","body":"18.17.2. Running a live development server\nThe Angular CLI can be used to start a live development server.\nFirst your application will be compiled and then the server will be started.\nIf you change the code of a file, the server will reload the displayed page.\nRun your application with the following command:\nng serve -o\n"},{"id":722,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-working-with-angular-cli.asciidoc_running-unit-tests","type":"docs","title":"Running Unit Tests","body":"18.17.3. Running Unit Tests\nAll unit tests can be executed with the command:\nng test\nTo make a single run and create a code coverage file use the following command:\nng test -sr -cc\nTip\nYou can configure the output format for code coverage files to match your requirements in the file karma.conf.js which can be found on toplevel of your project folder.\nFor instance, this can be useful for exporting the results to a SonarQube.\n"},{"id":723,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-working-with-angular-cli.asciidoc_linting-the-code-quality","type":"docs","title":"Linting the code quality","body":"18.17.4. Linting the code quality\nYou can lint your files with the command\nng lint --type-check\nTip\nYou can adjust the linting rules in the file tslint.json which can be found on toplevel of your project folder.\n"},{"id":724,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-working-with-angular-cli.asciidoc_generating-code","type":"docs","title":"Generating Code","body":"18.17.5. Generating Code\nCreating a new Angular CLI project\nFor creating a new Angular CLI project the command ng new is used.\nThe following command creates a new application named my-app.\nng create my-app\nCreating a new feature module\nA new feature module can be created via ng generate module` command.\nThe following command generates a new feature module named todo.\nng generate module todo\nFigure 53. Generate a module with Angular CLI\nTip\nThe created feature module needs to be added to the AppModule by hand.\nOther option would be to define a lazy route in AppRoutingModule to make this a lazy loaded module.\nCreating a new component\nTo create components the command ng generate component can be used.\nThe following command will generate the component todo-details inside the components layer of todo module.\nIt will generate a class, a html file, a css file and a test file.\nAlso, it will register this component as declaration inside the nearest module - this ist TodoModule.\nng generate component todo/components/todo-details\nFigure 54. Generate a component with Angular CLI\nTip\nIf you want to export the component, you have to add the component to exports array of the module.\nThis would be the case if you generate a component inside shared module.\n"},{"id":725,"path":"../website/pages/docs/master-devon4ng.asciidoc_angular.html#guide-working-with-angular-cli.asciidoc_configuring-an-angular-cli-project","type":"docs","title":"Configuring an Angular CLI project","body":"18.17.6. Configuring an Angular CLI project\nInside an Angular CLI project the file .angular-cli.json can be used to configure the Angular CLI.\nThe following options are very important to understand.\nThe property defaults` can be used to change the default style extension.\nThe following settings will make the Angular CLI generate .less files, when a new component is generated.\n&quot;defaults&quot;: {\n&quot;styleExt&quot;: &quot;less&quot;,\n&quot;component&quot;: {}\n}\nThe property apps contains all applications maintained with Angular CLI.\nMost of the time you will have only one.\nassets configures all the static files, that the application needs - this can be images, fonts, json files, etc.\nWhen you add them to assets the Angular CLI will put these files to the build target and serve them while debugging.\nThe following will put all files in /i18n to the output folder /i18n\n&quot;assets&quot;: [\n{ &quot;glob&quot;: &quot;**/*.json&quot;, &quot;input&quot;: &quot;./i18n&quot;, &quot;output&quot;: &quot;./i18n&quot; }\n]\nstyles property contains all style files that will be globally available.\nThe Angular CLI will create a styles bundle that goes directly into index.html with it.\nThe following will make all styles in styles.less globally available.\n&quot;styles&quot;: [\n&quot;styles.less&quot;\n]\nenvironmentSource and environments are used to configure configuration with the Angular CLI.\nInside the code always the file specified in environmentSource will be referenced.\nYou can define different environments - eg. production, staging, etc. - which you list in enviroments.\nAt compile time the Angular CLI will override all values in environmentSource with the values from the matching environment target.\nThe following code will build the application for the environment staging.\nng build --environment=staging\n&#x2190;&#xA0;Previous:&#xA0;Guides&#xA0;| &#x2191;&#xA0;Up:&#xA0;devon4ng&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Ionic&#xA0;&#x2192;\n"},{"id":726,"path":"../website/pages/docs/master-devon4ng.asciidoc_architecture.html#master-devon4ng.asciidoc_architecture","type":"docs","title":"Architecture","body":"15. Architecture\n"},{"id":727,"path":"../website/pages/docs/master-devon4ng.asciidoc_architecture.html#architecture.asciidoc","type":"docs","title":"Architecture","body":"15.1. Architecture\nThe following principles and guidelines are based on Angular Styleguide - especially Angular modules (see Angular Docs).\nIt extends those where additional guidance is needed to define an architecture which is:\nmaintainable across applications and teams\neasy to understand, especially when coming from a classic Java/.Net perspective - so whenever possible the same principles apply both to the server and the client\npattern based to solve common problems\nbased on best of breed solutions coming from open source and Capgemini project experiences\ngives as much guidance as necessary and as little as possible\n"},{"id":728,"path":"../website/pages/docs/master-devon4ng.asciidoc_architecture.html#architecture.asciidoc_overview","type":"docs","title":"Overview","body":"15.1.1. Overview\nWhen using Angular the web client architecture is driven by the framework in a certain way Google and the Angular community think about web client architecture.\nAngular gives an opinion on how to look at architecture.\nIt is component based like devon4j but uses different terms which are common language in web application development.\nThe important term is module which is used instead of component. The primary reason is the naming collision with the Web Components standard (see Web Components).\nTo clarify this:\nA component describes an UI element containing HTML, CSS and JavaScript - structure, design and logic encapsulated inside a reusable container called component.\nA module describes an applications feature area. The application flight-app may have a module called booking.\nAn application developed using Angular consists of multiple modules.\nThere are feature modules and special modules described by the Angular Styleguide - core and shared.\nAngular or Angular Styleguide give no guidance on how to structure a module internally.\nThis is where this architecture comes in.\nLayers\nThe architecture describes two layers. The terminology is based on common language in web development.\nFigure 11. Layers\nComponents Layer encapsulates components which present the current application state.\nComponents are separated into Smart and Dumb Components.\nThe only logic present is view logic inside Smart Components.\nServices Layer is more or less what we call &apos;business logic layer&apos; on the server side.\nThe layer defines the applications state, the transitions between state and classic business logic.\nStores contain application state over time to which Smart Components subscribe to.\nAdapters are used to perform XHRs, WebSocket connections, etc.\nThe business model is described inside the module.\nUse case services perform business logic needed for use cases.\nA use case services interacts with the store and adapters.\nMethods of use case services are the API for Smart Components.\nThose methods are Actions in reactive terminology.\nModules\nAngular requires a module called app which is the main entrance to an application at runtime - this module gets bootstrapped.\nAngular Styleguide defines feature modules and two special modules - core and shared.\nFigure 12. Modules\nA feature module is basically a vertical cut through both layers.\nThe shared module consists of components shared across feature modules.\nThe core module holds services shared across modules.\nSo core module is a module only having a services layer\nand shared module is a module only having a components layer.\n"},{"id":729,"path":"../website/pages/docs/master-devon4ng.asciidoc_architecture.html#meta-architecture.asciidoc","type":"docs","title":"Meta Architecture","body":"15.2. Meta Architecture\n"},{"id":730,"path":"../website/pages/docs/master-devon4ng.asciidoc_architecture.html#meta-architecture.asciidoc_introduction","type":"docs","title":"Introduction","body":"15.2.1. Introduction\nPurpose of this document\nIn our business applications, the client easily gets underestimated. Sometimes the client is more complex to develop and design than the server. While the server architecture is nowadays easily to agree as common sense, for clients this is not as obvious and stable especially as it typically depends on the client framework used. Finding a concrete architecture applicable for all clients may therefore be difficult to accomplish.\nThis document tries to define on a high abstract level, a reference architecture which is supposed to be a mental image and frame for orientation regarding the evaluation and appliance of different client frameworks. As such it defines terms and concepts required to be provided for in any framework and thus gives a common ground of understanding for those acquainted with the reference architecture. This allows better comparison between the various frameworks out there, each having their own terms for essentially the same concepts. It also means that for each framework we need to explicitly map how it implements the concepts defined in this document.\nThe architecture proposed herein is neither new nor was it developed from scratch. Instead it is the gathered and consolidated knowledge and best practices of various projects (s. References).\nGoal of the Client Architecture\nThe goal of the client architecture is to support the non-functional requirements for the client, i.e. mostly maintainability, scalability, efficiency and portability. As such it provides a component-oriented architecture following the same principles listed already in the devonfw architecture overview. Furthermore it ensures a homogeneity regarding how different concrete UI technologies are being applied in the projects, solving the common requirements in the same way.\nArchitecture Views\nAs for the server we distinguish between the business and the technical architecture. Where the business architecture is different from project to project and relates to the concrete design of dialog components given concrete requirements, the technical architecture can be applied to multiple projects.\nThe focus of this document is to provide a technical reference architecture on the client on a very abstract level defining required layers and components. How the architecture is implemented has to be defined for each UI technology.\nThe technical infrastructure architecture is out of scope for this document and although it needs to be considered, the concepts of the reference architecture should work across multiple TI architecture, i.e. native or web clients.\n"},{"id":731,"path":"../website/pages/docs/master-devon4ng.asciidoc_architecture.html#meta-architecture.asciidoc_devonfw-reference-client-architecture","type":"docs","title":"devonfw Reference Client Architecture","body":"15.2.2. devonfw Reference Client Architecture\nThe following gives a complete overview of the proposed reference architecture. It will be built up incrementally in the following sections.\nFigure 1 Overview\nClient Architecture\nOn the highest level of abstraction we see the need to differentiate between dialog components and their container they are managed in, as well as the access to the application server being the backend for the client (e.g. an devon4j instance). This section gives a summary of these components and how they relate to each other. Detailed architectures for each component will be supplied in subsequent sections\nFigure 2 Overview of Client Architecture\nDialog Component\nA dialog component is a logical, self-contained part of the user interface. It accepts user input and actions and controls communication with the user. Dialog components use the services provided by the dialog container in order to execute the business logic. They are self-contained, i.e. they possess their own user interface together with the associated logic, data and states.\nDialog components can be composed of other dialog components forming a hierarchy\nDialog components can interact with each other. This includes communication of a parent to its children, but also between components independent of each other regarding the hierarchy.\nDialog Container\nDialog components need to be managed in their lifecycle and how they can be coupled to each other. The dialog container is responsible for this along with the following:\nBootstrapping the client application and environment\nConfiguration of the client\nInitialization of the application server access component\nDialog Component Management\nControlling the lifecycle\nControlling the dialog flow\nProviding means of interaction between the dialogs\nProviding application server access\nProviding services to the dialog components\n(e.g. printing, caching, data storage)\nShutdown of the application\nApplication Server Access\nDialogs will require a backend application server in order to execute their business logic. Typically in an devonfw application the service layer will provide interfaces for the functionality exposed to the client. These business oriented interfaces should also be present on the client backed by a proxy handling the concrete call of the server over the network. This component provides the set of interfaces as well as the proxy.\nDialog Container Architecture\nThe dialog container can be further structured into the following components with their respective tasks described in own sections:\nFigure 3 Dialog Container Architecture\nApplication\nThe application component represents the overall client in our architecture. It is responsible for bootstrapping all other components and connecting them with each other. As such it initializes the components below and provides an environment for them to work in.\nConfiguration Management\nThe configuration management manages the configuration of the client, so the client can be deployed in different environments. This includes configuration of the concrete application server to be called or any other environment-specific property.\nDialog Management\nThe Dialog Management component provides the means to define, create and destroy dialog components. It therefore offers basic lifecycle capabilities for a component. In addition it also allows composition of dialog components in a hierarchy. The lifecycle is then managed along the hierarchy, meaning when creating/destroying a parent dialog, this affects all child components, which are created/destroyed as well.\nService Registry\nApart from dialog components, a client application also consists of services offered to these. A service can thereby encompass among others:\nAccess to the application server\nAccess to the dialog container functions for managing dialogs or accessing the configuration\nDialog independent client functionality such as Printing, Caching, Logging, Encapsulated business logic such as tax calculation\nDialog component interaction\nThe service registry offers the possibility to define, register and lookup these services. Note that these services could be dependent on the dialog hierarchy, meaning different child instances could obtain different instances / implementations of a service via the service registry, depending on which service implementations are registered by the parents.\nServices should be defined as interfaces allowing for different implementations and thus loose coupling.\nDialog Component Architecture\nA dialog component has to support all or a subset of the following tasks:\n(T1)\tDisplaying the user interface incl. internationalization\n(T2)\tDisplaying business data incl. changes made to the data due to user interactions and localization of the data\n(T3)\tAccepting user input including possible conversion from e.g. entered Text to an Integer\n(T4)\tDisplaying the dialog state\n(T5)\tValidation of user input\n(T6)\tManaging the business data incl. business logic altering it due to user interactions\n(T7)\tExecution of user interactions\n(T8)\tManaging the state of the dialog (e.g. Edit vs. View)\n(T9)\tCalling the application server in the course of user interactions\nFollowing the principle of separation of concerns, we further structure a dialog component in an own architecture allowing us the distribute responsibility for these tasks along the defined components:\nFigure 4 Overview of dialog component architecture\nPresentation Layer\nThe presentation layer generates and displays the user interface, accepts user input and user actions and binds these to the dialog core layer (T1-5). The tasks of the presentation layer fall into two categories:\nProvision of the visual representation (View component)\nThe presentation layer generates and displays the user interface and accepts user input and user actions. The logical processing of the data, actions and states is performed in the dialog core layer. The data and user interface are displayed in localized and internationalized form.\nBinding of the visual representation to the dialog core layer\nThe presentation layer itself does not contain any dialog logic. The data or actions entered by the user are then processed in the dialog core layer. There are three aspects to the binding to the dialog core layer. We refer to &#x201C;data binding&#x201D;, &#x201C;state binding&#x201D; and &#x201C;action binding&#x201D;. Syntactical and (to a certain extent) semantic validations are performed during data binding (e.g. cross-field plausibility checks). Furthermore, the formatted, localized data in the presentation layer is converted into the presentation-independent, neutral data in the dialog core layer (parsing) and vice versa (formatting).\nDialog Core Layer\nThe dialog core layer contains the business logic, the control logic, and the logical state of the dialog. It therefore covers tasks T5-9:\nMaintenance of the logical dialog state and the logical data\nThe dialog core layer maintains the logical dialog state and the logical data in a form which is independent of the presentation. The states of the presentation (e.g. individual widgets) must not be maintained in the dialog core layer, e.g. the view state could lead to multiple presentation states disabling all editable widgets on the view.\nImplementation of the dialog and dialog control logic\nThe component parts in the dialog core layer implement the client specific business logic and the dialog control logic. This includes, for example, the manipulation of dialog data and dialog states as well as the opening and closing of dialogs.\nCommunication with the application server\nThe dialog core layer calls the interfaces of the application server via the application server access component services.\nThe dialog core layer should not depend on the presentation layer enforcing a strict layering and thus minimizing dependencies.\nInteractions between dialog components\nDialog components can interact in the following ways:\nEmbedding of dialog components\nAs already said dialog components can be hierarchically composed. This composition works by embedding on dialog component within the other. Apart from the lifecycle managed by the dialog container, the embedding needs to cope for the visual embedding of the presentation and core layer.\nEmbedding dialog presentation\nThe parent dialog needs to either integrate the embedded dialog in its layout or open it in an own model window.\nEmbedding dialog core\nThe parent dialog needs to be able to access the embedded instance of its children. This allows initializing and changing their data and states. On the other hand the children might require context information offered by the parent dialog by registering services in the hierarchical service registry.\nDialog flow\nApart from the embedding of dialog components representing a tight coupling, dialogs can interact with each other by passing the control of the UI, i.e. switching from one dialog to another.\nWhen interacting, dialog components should interact only between the same or lower layers, i.e. the dialog core should not access the presentation layer of another dialog component.\n"},{"id":732,"path":"../website/pages/docs/master-devon4ng.asciidoc_architecture.html#meta-architecture.asciidoc_appendix","type":"docs","title":"Appendix","body":"15.2.3. Appendix\nNotes about Quasar Client\nThe Quasar client architecture as the consolidated knowledge of our CSD projects is the major source for the above drafted architecture. However, the above is a much simplified and more agile version thereof:\nQuasar Client tried to abstract from the concrete UI library being used, so it could decouple the business from the technical logic of a dialog. The presentation layer should be the only one knowing the concrete UI framework used. This level of abstraction was dropped in this reference architecture, although it might of course still make sense in some projects. For fast-moving agile projects in the web however introducing such a level of abstraction takes effort with little gained benefits. With frameworks like Angular 2 we would even introduce one additional seemingly artificial and redundant layer, since it already separates the dialog core from its presentation.\nIn the past and in the days of Struts, JSF, etc. the concept of session handling was important for the client since part of the client was sitting on a server with a session relating it to its remote counterpart on the users PC. Quasar Client catered for this need, by very prominently differentiating between session and application in the root of the dialog component hierarchy. However, in the current days of SPA applications and the lowered importance of servers-side web clients, this prominent differentiation was dropped. When still needed the referenced documents will provide in more detail how to tailor the respective architecture to this end.\n"},{"id":733,"path":"../website/pages/docs/master-devon4ng.asciidoc_architecture.html#meta-architecture.asciidoc_references","type":"docs","title":"References","body":"15.2.4. References\nArchitecture Guidelines for Application Design:\nhttps://troom.capgemini.com/sites/vcc/engineering/Cross%20Cutting/ArchitectureGuide/Architecture_Guidelines_for_Application_Design_v2.0.docx\nQuasar Client Architekturen:\nhttps://troom.capgemini.com/sites/vcc/Shared%20Documents/CrossCuttingContent/TopicOrientedCCC/QuasarOverview/NCE%20Quasar%20Review%20Workshop%202009-11-17/Quasar%20Development/Quasar-Client-Architectures.doc\n&#x2190;&#xA0;Previous:&#xA0;Introduction&#xA0;| &#x2191;&#xA0;Up:&#xA0;devon4ng&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Layers&#xA0;&#x2192;\n"},{"id":734,"path":"../website/pages/docs/master-devon4ng.asciidoc_cookbook.html#master-devon4ng.asciidoc_cookbook","type":"docs","title":"Cookbook","body":"22. Cookbook\n"},{"id":735,"path":"../website/pages/docs/master-devon4ng.asciidoc_cookbook.html#cookbook-abstract-class-store.asciidoc","type":"docs","title":"Abstract Class Store","body":"22.1. Abstract Class Store\nThe following solution presents a base class for implementing stores which handle state and its transitions.\nWorking with the base class achieves:\ncommon API across all stores\nlogging (when activated in the constructor)\nstate transitions are asynchronous by design - sequential order problems are avoided\nListing 87. Usage Example\n@Injectable()\nexport class ModalStore extends Store&lt;ModalState&gt; {\nconstructor() {\nsuper({ isOpen: false }, !environment.production);\n}\ncloseDialog() {\nthis.dispatchAction(&apos;Close Dialog&apos;, (currentState) =&gt; ({...currentState, isOpen: false}));\n}\nopenDialog() {\nthis.dispatchAction(&apos;Open Dialog&apos;, (currentState) =&gt; ({...currentState, isOpen: true}));\n}\n}\nListing 88. Abstract Base Class Store\nimport { OnDestroy } from &apos;@angular/core&apos;;\nimport { BehaviorSubject } from &apos;rxjs/BehaviorSubject&apos;;\nimport { Observable } from &apos;rxjs/Observable&apos;;\nimport { intersection, difference } from &apos;lodash&apos;;\nimport { map, distinctUntilChanged, observeOn } from &apos;rxjs/operators&apos;;\nimport { Subject } from &apos;rxjs/Subject&apos;;\nimport { queue } from &apos;rxjs/scheduler/queue&apos;;\nimport { Subscription } from &apos;rxjs/Subscription&apos;;\ninterface Action&lt;T&gt; {\nname: string;\nactionFn: (state: T) =&gt; T;\n}\n/** Base class for implementing stores. */\nexport abstract class Store&lt;T&gt; implements OnDestroy {\nprivate actionSubscription: Subscription;\nprivate actionSource: Subject&lt;Action&lt;T&gt;&gt;;\nprivate stateSource: BehaviorSubject&lt;T&gt;;\nstate$: Observable&lt;T&gt;;\n/**\n* Initializes a store with initial state and logging.\n* @param initialState Initial state\n* @param logChanges When true state transitions are logged to the console.\n*/\nconstructor(initialState: T, public logChanges = false) {\nthis.stateSource = new BehaviorSubject&lt;T&gt;(initialState);\nthis.state$ = this.stateSource.asObservable();\nthis.actionSource = new Subject&lt;Action&lt;T&gt;&gt;();\nthis.actionSubscription = this.actionSource.pipe(observeOn(queue)).subscribe(action =&gt; {\nconst currentState = this.stateSource.getValue();\nconst nextState = action.actionFn(currentState);\nif (this.logChanges) {\nthis.log(action.name, currentState, nextState);\n}\nthis.stateSource.next(nextState);\n});\n}\n/**\n* Selects a property from the stores state.\n* Will do distinctUntilChanged() and map() with the given selector.\n* @param selector Selector function which selects the needed property from the state.\n* @returns Observable of return type from selector function.\n*/\nselect&lt;TX&gt;(selector: (state: T) =&gt; TX): Observable&lt;TX&gt; {\nreturn this.state$.pipe(\nmap(selector),\ndistinctUntilChanged()\n);\n}\nprotected dispatchAction(name: string, action: (state: T) =&gt; T) {\nthis.actionSource.next({ name, actionFn: action });\n}\nprivate log(actionName: string, before: T, after: T) {\nconst result: { [key: string]: { from: any, to: any} } = {};\nconst sameProbs = intersection(Object.keys(after), Object.keys(before));\nconst newProbs = difference(Object.keys(after), Object.keys(before));\nfor (const prop of newProbs) {\nresult[prop] = { from: undefined, to: (&lt;any&gt;after)[prop] };\n}\nfor (const prop of sameProbs) {\nif ((&lt;any&gt;before)[prop] !== (&lt;any&gt;after)[prop]) {\nresult[prop] = { from: (&lt;any&gt;before)[prop], to: (&lt;any&gt;after)[prop] };\n}\n}\nconsole.log(this.constructor.name, actionName, result);\n}\nngOnDestroy() {\nthis.actionSubscription.unsubscribe();\n}\n}\n"},{"id":736,"path":"../website/pages/docs/master-devon4ng.asciidoc_cookbook.html#guide-add-electron.asciidoc_add-electron-to-an-angular-application","type":"docs","title":"Add Electron to an Angular application","body":"22.1.1. Add Electron to an Angular application\nThis cookbook recipe explains how to integrate Electron in an Angular 10+ application. Electron is a framework for creating native applications with web technologies like JavaScript, HTML, and CSS. As an example, very well known applications as Visual Studio Code, Atom, Slack or Skype (and many more) are using Electron too.\nNote\nAt the moment of this writing Angular 11.2.0, Electron 11.2.3 and Electron-builder 22.9.1 were the versions available.\nHere are the steps to achieve this goal. Follow them in order.\nAdd Electron and other relevant dependencies\nThere are two different approaches to add the dependencies in the package.json file:\nWriting the dependencies directly in that file.\nInstalling using npm install or yarn add.\nImportant\nPlease remember if the project has a package-lock.json or yarn.lock file use npm or yarn respectively.\nIn order to add the dependencies directly in the package.json file, include the following lines in the devDependencies section:\n&quot;devDependencies&quot;: {\n...\n&quot;electron&quot;: &quot;^11.2.3&quot;,\n&quot;electron-builder&quot;: &quot;^22.9.1&quot;,\n...\n},\nAs indicated above, instead of this npm install can be used:\n$ npm install -D electron electron-builder\nOr with yarn:\n$ yarn add -D electron electron-builder\nCreate the necessary typescript configurations\nIn order to initiate electron in an angular app we need to modify the tsconfig.json file and create a tsconfig.serve.json and a tsconfig.base.json in the root folder.\ntsconfig.json\nThis file needs to be modified to create references to ./src/tsconfig.app.json and ./src/tsconfig.spec.json to support different configurations.\n{\n&quot;files&quot;: [],\n&quot;references&quot;: [\n{\n&quot;path&quot;: &quot;./src/tsconfig.app.json&quot;\n},\n{\n&quot;path&quot;: &quot;./src/tsconfig.spec.json&quot;\n}\n]\n}\ntsconfig.app.json\n{\n&quot;extends&quot;: &quot;../tsconfig.base.json&quot;,\n&quot;compilerOptions&quot;: {\n&quot;outDir&quot;: &quot;../app&quot;,\n&quot;module&quot;: &quot;es2015&quot;,\n&quot;baseUrl&quot;: &quot;&quot;,\n&quot;types&quot;: []\n},\n&quot;include&quot;: [\n&quot;**/*.ts&quot;,\n],\n&quot;exclude&quot;: [\n&quot;**/*.spec.ts&quot;\n],\n&quot;angularCompilerOptions&quot;: {\n&quot;fullTemplateTypeCheck&quot;: true,\n&quot;strictInjectionParameters&quot;: true,\n&quot;preserveWhitespaces&quot;: true\n}\n}\ntsconfig.spec.json\n{\n&quot;extends&quot;: &quot;../tsconfig.base.json&quot;,\n&quot;compilerOptions&quot;: {\n&quot;outDir&quot;: &quot;../spec&quot;,\n&quot;module&quot;: &quot;commonjs&quot;,\n&quot;types&quot;: [\n&quot;jasmine&quot;,\n&quot;node&quot;\n]\n},\n&quot;files&quot;: [\n&quot;test.ts&quot;,\n],\n&quot;include&quot;: [\n&quot;**/*.spec.ts&quot;,\n&quot;**/*.d.ts&quot;\n],\n&quot;exclude&quot;: [\n&quot;dist&quot;,\n&quot;release&quot;,\n&quot;node_modules&quot;\n]\n}\ntsconfig.base.json\nThis is shared betwen tsconfig.app.json and tsconfig.spec.json and it will be extended on each config file.\n{\n&quot;compileOnSave&quot;: false,\n&quot;compilerOptions&quot;: {\n&quot;outDir&quot;: &quot;./dist&quot;,\n&quot;sourceMap&quot;: true,\n&quot;declaration&quot;: false,\n&quot;moduleResolution&quot;: &quot;node&quot;,\n&quot;emitDecoratorMetadata&quot;: true,\n&quot;experimentalDecorators&quot;: true,\n&quot;target&quot;: &quot;es5&quot;,\n&quot;typeRoots&quot;: [\n&quot;node_modules/@types&quot;\n],\n&quot;lib&quot;: [\n&quot;es2017&quot;,\n&quot;es2016&quot;,\n&quot;es2015&quot;,\n&quot;dom&quot;\n]\n},\n&quot;files&quot;: [\n&quot;electron-main.ts&quot;\n&quot;src/polyfills.ts&quot;\n],\n&quot;include&quot;: [\n&quot;src/**/*.d.ts&quot;\n],\n&quot;exclude&quot;: [\n&quot;node_modules&quot;\n]\n}\ntsconfig.serve.json\nIn the root, tsconfig.serve.json needs to be created. This typescript config file is going to be used when we serve electron:\n{\n&quot;compilerOptions&quot;: {\n&quot;outDir&quot;: &quot;.&quot;,\n&quot;sourceMap&quot;: true,\n&quot;declaration&quot;: false,\n&quot;moduleResolution&quot;: &quot;node&quot;,\n&quot;emitDecoratorMetadata&quot;: true,\n&quot;experimentalDecorators&quot;: true,\n&quot;target&quot;: &quot;es5&quot;,\n&quot;typeRoots&quot;: [\n&quot;node_modules/@types&quot;\n],\n&quot;lib&quot;: [\n&quot;es2017&quot;,\n&quot;dom&quot;\n]\n},\n&quot;include&quot;: [\n&quot;electron-main.ts&quot;\n],\n&quot;exclude&quot;: [\n&quot;node_modules&quot;,\n&quot;**/*.spec.ts&quot;\n]\n}\nAdd Electron build configuration\nIn order to configure electron builds properly we need to create a new json on our application, let&#x2019;s call it electron-builder.json. For more information and fine tuning please refer to the Electron Builder official documentation.\nThe contents of the file will be something similar to the following:\n{\n&quot;productName&quot;: &quot;devon4ngElectron&quot;,\n&quot;directories&quot;:{\n&quot;output&quot;: &quot;./builder-release&quot;\n},\n&quot;win&quot;: {\n&quot;icon&quot;: &quot;dist/assets/icons&quot;,\n&quot;target&quot;: [\n&quot;portable&quot;\n]\n},\n&quot;mac&quot;: {\n&quot;icon&quot;: &quot;dist/assets/icons&quot;,\n&quot;target&quot;: [\n&quot;dmg&quot;\n]\n},\n&quot;linux&quot;: {\n&quot;icon&quot;: &quot;dist/assets/icons&quot;,\n&quot;target&quot;: [\n&quot;AppImage&quot;\n]\n}\n}\nTheres two important things in this files:\n&quot;output&quot;: this is where electron builder is going to build our application\n&quot;icon&quot;: in every OS possible theres an icon parameter, the route to the icon folder that will be created after building with angular needs to be used here. This will make it so the electron builder can find the icons and build.\nModify angular.json\nangular.json has to to be modified so the project is build inside /dist without an intermediate folder.\n{\n&quot;architect&quot;: {\n&quot;build&quot;: {\n&quot;outputPath&quot;: &quot;dist&quot;\n}\n}\n}\nCreate the electron window in electron-main.ts\nIn order to use electron, a file needs to be created at the root of the application (main.ts). This file will create a window with different settings checking if we are using --serve as an argument:\nimport { app, BrowserWindow } from &apos;electron&apos;;\nimport * as path from &apos;path&apos;;\nimport * as url from &apos;url&apos;;\nlet win: any;\nconst args: any = process.argv.slice(1);\nconst serve: any = args.some((val) =&gt; val === &apos;--serve&apos;);\nconst createWindow:any = ()=&gt;{\n// Create the browser window.\nwin = new BrowserWindow({\nfullscreen: true,\nwebPreferences: {\nnodeIntegration: true,\n}\n});\nif (serve) {\nrequire(&apos;electron-reload&apos;)(__dirname, {\nelectron: require(`${__dirname}/node_modules/electron`)\n});\nwin.loadURL(&apos;http://localhost:4200&apos;);\n} else {\nwin.loadURL(\nurl.format({\npathname: path.join(__dirname, &apos;dist/index.html&apos;),\nprotocol: &apos;file:&apos;,\nslashes: true\n})\n);\n}\nif (serve) {\nwin.webContents.openDevTools();\n}\n// Emitted when the window is closed.\nwin.on(&apos;closed&apos;, () =&gt; {\n// Dereference the window object, usually you would store window\n// in an array if your app supports multi windows, this is the time\n// when you should delete the corresponding element.\n// tslint:disable-next-line:no-null-keyword\nwin = null;\n});\n}\ntry {\n// This method will be called when Electron has finished\n// initialization and is ready to create browser windows.\n// Some APIs can only be used after this event occurs.\napp.on(&apos;ready&apos;, createWindow);\n// Quit when all windows are closed.\napp.on(&apos;window-all-closed&apos;, () =&gt; {\n// On OS X it is common for applications and their menu bar\n// to stay active until the user quits explicitly with Cmd + Q\nif (process.platform !== &apos;darwin&apos;) {\napp.quit();\n}\n});\napp.on(&apos;activate&apos;, () =&gt; {\n// On OS X it&apos;s common to re-create a window in the app when the\n// dock icon is clicked and there are no other windows open.\nif (win === null) {\ncreateWindow();\n}\n});\n} catch (e) {\n// Catch Error\n// throw e;\n}\nAdd the electron window and improve the package.json scripts\nInside package.json the electron window that will be transformed to electron-main.js when building needs to be added.\n{\n....\n&quot;main&quot;: &quot;electron-main.js&quot;,\n&quot;scripts&quot;: {...}\n....\n}\nThe scripts section in the package.json can be improved to avoid running too verbose commands. As a very complete example we can take a look to the My Thai Star&#x2019;s scripts section and copy the lines useful in your project. In any case, at least we recommend to add the following lines:\n&quot;scripts&quot;: {\n&quot;ng&quot;: &quot;ng&quot;,\n&quot;start&quot;: &quot;ng serve&quot;,\n&quot;build&quot;: &quot;ng build&quot;,\n&quot;test&quot;: &quot;ng test&quot;,\n&quot;lint&quot;: &quot;ng lint&quot;,\n&quot;e2e&quot;: &quot;ng e2e&quot;,\n&quot;electron:tsc&quot;: &quot;tsc -p tsconfig.serve.json&quot;,\n&quot;electron:run&quot;: &quot;npm run electron:tsc &amp;&amp; ng build --base-href ./ &amp;&amp; npx electron .&quot;,\n&quot;electron:serve&quot;: &quot;npm run electron:tsc &amp;&amp; npx electron . --serve&quot;,\n&quot;electron:pack&quot;: &quot;npm run electron:tsc &amp;&amp; electron-builder --dir --config electron-builder.json&quot;,\n&quot;electron:build&quot;: &quot;npm run electron:tsc &amp;&amp; electron-builder --config electron-builder.json build&quot;\n},\nThe electron: scripts do the following:\nelectron:tsc: Compiles electron TS files.\nelectron:run: Serves Angular app and runs electron.\nelectron:serve: Serves electron with an already running angular app (i.e. a ng serve command running on another terminal).\nelectron:pack: Packs electron app.\nelectron:build: Builds electron app.\n"},{"id":737,"path":"../website/pages/docs/master-devon4ng.asciidoc_cookbook.html#guide-angular-mock-service.asciidoc","type":"docs","title":"Angular Mock Service","body":"22.2. Angular Mock Service\nWe&#x2019;ve all been there: A new idea comes, let&#x2019;s quickly prototype it. But wait, there&#x2019;s no backend. What can we do?\nBelow you will find o solution that will get your started quick and easy. The idea is to write a simple mock service that helps us by feeding data into our components.\n"},{"id":738,"path":"../website/pages/docs/master-devon4ng.asciidoc_cookbook.html#guide-angular-mock-service.asciidoc_the-app-we-start-with","type":"docs","title":"The app we start with","body":"22.2.1. The app we start with\nLet&#x2019;s say you have a simple boilerplate code, with your favorite styling library hooked up and you&#x2019;re ready to go. The Angular Material sample is a good starting place.\n"},{"id":739,"path":"../website/pages/docs/master-devon4ng.asciidoc_cookbook.html#guide-angular-mock-service.asciidoc_the-components","type":"docs","title":"The Components","body":"22.2.2. The Components\nComponents - are the building blocks of our application. Their main role is to enable fragments of user interfaces. They will either display data (a list, a table, a chart, etc.), or &apos;collect&apos; user interaction (e.g: a form, a menu, etc.)\nComponents stay at the forefront of the application. They should also be reusable (as much as possible). Reusability is key for what we are trying to achieve - a stable, maintainable frontend where multiple people can contribute and collaborate.\nIn our project, we are at the beginning. That means we may have more ideas than plans. We are exploring possibilites. In order to code eficiently:\n1) We will not store mock data in the components.\n2) We will not fetch or save data directly in the components.\nLearn more about Angular Components\n"},{"id":740,"path":"../website/pages/docs/master-devon4ng.asciidoc_cookbook.html#guide-angular-mock-service.asciidoc_the-service","type":"docs","title":"The Service","body":"22.2.3. The Service\nSo, how do we get data in our app? How do we propagate the data to the components and how can we send user interaction from the components to the our data &quot;manager&quot; logic.\nThe answer to all these questions is an Angular Service (that we will just call a service from now on).\nA service is an injectable logic that can be consumed by all the components that need it. It can carry manipulation functions and ,in our case, fetch data from a provider.\nFigure 72. Angular Components &amp; Services architecture.\nInside the Angular App, an Injector gives access to each component to their required services. It&#x2019;s good coding practice to use a distinct service to each data type you want to manipulate. The type is described in a interface.\nStill, our ideas drive in diferent ways, so we have to stay flexible. We cannot use a database at the moment, but we want a way to represent data on screen, which can grow organically.\nLearn more about Angular Services\n"},{"id":741,"path":"../website/pages/docs/master-devon4ng.asciidoc_cookbook.html#guide-angular-mock-service.asciidoc_the-model","type":"docs","title":"The Model","body":"22.2.4. The Model\nFigure 73. Data box in relation to services and components.\nLet&#x2019;s consider a &apos;box of data&apos; represented in JSON. Phisicly this means a folder with some JSON/TS files in it. They are located in the app/mock folder. The example uses only one mock data file. The file is typed according to our data model.\nPro tip: separate your files based on purpose. In your source code, put the mock files in the mock folder, components in the components folder, services in the services folder and data models in the models folder.\nFigure 74. Project structure.\nAligned with the Angular way of development, we are implementing a model-view-controler pattern.\nThe model is represented by the interfaces we make. These interfaces describe the data structures we will use in our application. In this example, there is one data model, coresponding with the &apos;type&apos; of data that was mocked. In the models folder you will find the .ts script file that describes chemical elements. The corresponding mock file defines a set is chemical emlements objects, in accordance to our interface definition.\n"},{"id":742,"path":"../website/pages/docs/master-devon4ng.asciidoc_cookbook.html#guide-angular-mock-service.asciidoc_use-case","type":"docs","title":"Use case","body":"22.2.5. Use case\nEnough with the theory, let&#x2019;s see what we have here. The app presents 3 pages as follows:\nA leader bord with the top 3 elements\nA data table with all the elements\nA details page that reads a route paramenter and displays the details of the element.\nThere are a lot of business cases which have these requirements:\nA leader board can be understood as &quot;the most popular items in a set&quot;, &quot;the latest updated items&quot;, &quot;you favorite items&quot; etc.\nA data table with CRUD operations is very useful (in our case we only view details or delete an item, but they illustrate two important things: the details view shows how to navigate and consume a parametric route, the delete action shows how to invoke service operations over the loaded data - this means that the component is reusable and when the data comes with and API, only the service will need it&#x2019;s implementation changed)\nCheck out the Angular Mock Service sample from the samples folder and easily get started with fast data roundtrips between your mock data and your components.\n"},{"id":743,"path":"../website/pages/docs/master-devon4ng.asciidoc_cookbook.html#guide-cypress.asciidoc","type":"docs","title":"Testing e2e with Cypress","body":"22.3. Testing e2e with Cypress\nThis guide will cover the basics of e2e testing using Cypress.\nCypress is a framework &#x201C;all in one&#x201D; that provides the necessary libraries to write specific e2e tests, without the need of Selenium.\nWhy Cypress?\nUses javascript\nIt works directly with the browser so the compatibility with the frontend framework the project uses (in this case Angular) is not a problem.\nEasy cross browser testing\n"},{"id":744,"path":"../website/pages/docs/master-devon4ng.asciidoc_cookbook.html#guide-cypress.asciidoc_setup","type":"docs","title":"Setup","body":"22.3.1. Setup\nInstall\nFirst of all we need to install it, we can use npm install:\n$ npm install -D cypress\nOr we can install it with yarn:\n$ yarn add -D cypress\nWe need to run Cypress in order to get the folder tree downloaded, then create a tsconfig.json file inside cypress folder to add the typescript configuration.\n$ . /node_modules/.bin/cypress open\nListing 89. tsconfig.json\n{\n&quot;compilerOptions&quot;: {\n&quot;strict&quot;: true,\n&quot;baseUrl&quot;: &quot;../node_modules&quot;,\n&quot;target&quot;: &quot;es5&quot;,\n&quot;lib&quot;: [&quot;es5&quot;, &quot;dom&quot;],\n&quot;types&quot;: [&quot;cypress&quot;]\n},\n&quot;include&quot;: [\n&quot;**/*.ts&quot;\n]\n}\nBaseUrl\nLet&#x2019;s setup the base url so when we run the tests cypress will &quot;navegate&quot; to the right place, go to cypress.json on the root of the project.\nListing 90. cypress.json\n{\n&quot;baseUrl&quot;: &quot;http://localhost:4200&quot;\n}\n"},{"id":745,"path":"../website/pages/docs/master-devon4ng.asciidoc_cookbook.html#guide-cypress.asciidoc_files--structure","type":"docs","title":"Files / Structure","body":"22.3.2. Files / Structure\n/cypress\ntsconfig.json\n/fixtures\n- example.json\n/integration\n- button.spec.ts\n- test.spec.ts\n/examples\n/plugins\n- index.js\n/support\n- commands.js\n- index.js\ntsconfig.json for typescript configuration.\nfixtures to store our mock data or files (img, mp3&#x2026;&#x200B;) to use on our tests.\nintegration is where our tests go, by default it comes with an examples folder with tests samples.\nplugins is where the configuration files of the plugins go.\nsupport to add custom commands.\n"},{"id":746,"path":"../website/pages/docs/master-devon4ng.asciidoc_cookbook.html#guide-cypress.asciidoc_tests","type":"docs","title":"Tests","body":"22.3.3. Tests\nThe structure is the same than Mocha.\nFirst, we create a file, for example form.spec.ts, inside we define a context to group all our tests referred to the same subject.\nListing 91. form.spec.ts\ncontext(&apos;Button page&apos;, () =&gt; {\nbeforeEach(() =&gt; {\ncy.visit(&apos;/&apos;);\n});\nit(&apos;should have button&apos;,()=&gt;{\ncy.get(&apos;button&apos;).should(&apos;exist&apos;);\n});\nit(&apos;should contain PRESS&apos;,()=&gt;{\ncy.contains(&apos;button&apos;, &apos;PRESS&apos;);\n});\n});\nbeforeEach\nVisit &apos;/&apos; before every test.\nit\nInside we write the test.\nThe result:\nFor more info check Cypress documentation\nOn kitchensink\nyou can find an official cypress demo with all the comands being used.\n"},{"id":747,"path":"../website/pages/docs/master-devon4ng.asciidoc_cookbook.html#guide-cypress.asciidoc_fixtures","type":"docs","title":"Fixtures","body":"22.3.4. Fixtures\nWe use fixtures to mock data, it can be a json, an img, video&#x2026;&#x200B;\n{\n&quot;name&quot;: &quot;Dummy name&quot;,\n&quot;phone&quot;: 999 99 99 99,\n&quot;body&quot;: &quot;Mock data&quot;\n}\nYou can store multiple mocks on the same fixture file.\n{\n&quot;create&quot;:{&quot;name&quot;: &quot;e2etestBox&quot;},\n&quot;boxFruit&quot;:{\n&quot;uuid&quot;:&quot;3376339576e33dfb9145362426a33333&quot;,\n&quot;name&quot;:&quot;e2etestBox&quot;,\n&quot;visibility&quot;:true,\n&quot;items&quot;:[\n{&quot;name&quot;:&quot;apple&quot;,&quot;units&quot;:3},\n{&quot;name&quot;:&quot;kiwi&quot;,&quot;units&quot;:2},\n]\n},\n}\nTo access data we don&#x2019;t need to import any file, we just call cy.fixture(filename) inside the **.spec.ts. We can name it as we want.\ncy.fixture(&apos;box.json&apos;).as(&apos;fruitBox&apos;)\ncy.fixture(&apos;box.json&apos;) we get access to box.json\n.as(fruitBox) is used to create an alias (fruitBox) to the fixture.\nFor more info check Fixtures documentation\n"},{"id":748,"path":"../website/pages/docs/master-devon4ng.asciidoc_cookbook.html#guide-cypress.asciidoc_request--route","type":"docs","title":"Request / Route","body":"22.3.5. Request / Route\nWith cypress you can test your application with real data or with mocks.\nNot using mocks guarantees that your tests are real e2e test but makes them vulnerable to external issues.\nWhen you mock data you don&#x2019;t know exactly if the data and the structure received from the backend is correct because you are forcing a mock on the response, but you can avoid external issues, run test faster and have better control on the structure and status.\nTo get more information go to Testing Strategies\nRoute\nCypress can intercept a XHR request and interact with it.\ncy.server();\ncy.route(\n&apos;GET&apos;,\n&apos;/apiUrl/list&apos;,\n[{&quot;name&quot;:&quot;apple&quot;, &quot;units&quot;:3},{&quot;name&quot;:&quot;kiwi&quot;, &quot;units&quot;:2}]\n)\ncy.server(options) start a server to interact with the responses.\ncy.route(options) intercepts a XMLHttpRequests\nmethod GET\nurl /apiUrl/list&apos;\nresponse [{&quot;name&quot;:&quot;apple&quot;, &quot;units&quot;:3},{&quot;name&quot;:&quot;kiwi&quot;, &quot;units&quot;:2}]\nWaits\nEvery cypress action has a default await time to avoid asynchronous issues, but this time can be short for some particular actions like api calls, for those cases we can use cy.wait().\ncy.server();\ncy.route(&apos;/apiUrl/list&apos;).as(&apos;list&apos;);\ncy.visit(&apos;/boxList&apos;);\ncy.wait(&apos;@list&apos;);\nYou can find more information about cy.wait() here\nTo mock data with fixtures:\ncy.fixture(&apos;box&apos;)\n.then(({boxFruit}) =&gt; {\ncy.route(\n&apos;GET&apos;,\n&apos;/apiUrl/list&apos;,\nboxFruit\n).as(&apos;boxFruit&apos;);\ncy.get(&apos;#button&apos;).click();\ncy.wait(&apos;@journalsList&apos;);\ncy.get(&apos;#list&apos;).contains(&apos;apple&apos;);\n})\nWe get boxFruit data from the box fixture and then we mock the api call with it so now the response of the call is boxFruit object.\nWhen the button is clicked, it waits to recive the response of the call and then checks if the list contains one of the elements of the fruitBox.\nRequest\nMake a HTTP request.\ncy.server();\ncy.request(&apos;http://localhost:4200/&apos;)\n.its(&apos;body&apos;)\n.should(&apos;include&apos;, &apos;&lt;h1&gt;Welcome to Devon4ngAngularElementsTest!&lt;/h1&gt;&apos;);\nIf we have &apos;http://localhost:4200&apos; as baseUrl on cypress.json\ncy.server();\ncy.request(&apos;/&apos;)\n.its(&apos;body&apos;)\n.should(&apos;include&apos;, &apos;&lt;h1&gt;Welcome to Devon4ngAngularElementsTest!&lt;/h1&gt;&apos;);\n// Goes to http://localhost:4200/\nWe can add other options, like we can send the body of a form.\ncy.server();\ncy.request({\nmethod: &apos;POST&apos;,\nurl: &apos;/send&apos;,\nform: true,\nbody: {\nname: &apos;name task&apos;,\ndescription: &apos;description of the task&apos;\n}\n});\n"},{"id":749,"path":"../website/pages/docs/master-devon4ng.asciidoc_cookbook.html#guide-cypress.asciidoc_custom-comands","type":"docs","title":"Custom comands","body":"22.3.6. Custom comands\nIf you see yourself writing the same test more than once (login is a common one), you can create a custom command to make things faster.\nCypress.Commands.add(&apos;name&apos;, ()&#x21D2;{}) to create the test.\nListing 92. commands.ts\nCypress.Commands.add(&apos;checkPlaceholder&apos;, (name) =&gt; {\ncy.get(`[name=&apos;${name}&apos;]`).click();\ncy.get(&apos;mat-form-field.mat-focused&apos;).should(&apos;exist&apos;);\n});\nindex.ts\nTo use the commands we need to import the files on support/index.ts\nListing 93. index.ts\nimport &apos;./commands&apos;\nimport &apos;./file1&apos;\nimport &apos;./folder/file2&apos;\nindex.ts is where all our custom commands files unite so Cypress knows where to find them.\nAnd as we are using typescript we need to define a namespace, interface and define our function.\nindex.d.ts\ndeclare namespace Cypress {\ninterface Chainable&lt;Subject&gt; {\ncheckPlaceholder(name:string):Chainable&lt;void&gt;\n}\n}\nCheck typescript custom commands\n"},{"id":750,"path":"../website/pages/docs/master-devon4ng.asciidoc_cookbook.html#guide-cypress.asciidoc_cross-browser-testing","type":"docs","title":"Cross browser testing","body":"22.3.7. Cross browser testing\nBy default the browser used by Cypress is Chrome, it has compativility with it&#x2019;s family browsers (including Microsoft Edge) and has beta support for Mozilla Firefox.\nTo change the browser on the panel we can do it by selecting the desired one on the browsers tab before running the spec file.\nCypress will detect and display, except electron, only the browsers that you have already installed on your machine.\nOnce the browser is selected, you can run your tests.\nTo change the browser on the automatic test run, you can add a flag on the node command\ncypress run --browser edge\nOnly if we use the cypress run command.\nOr we can change the script file.\ncypress/script.js\nconst runTests= async ()=&gt;{\n...\nconst {totalFailed} = await cypress.run({browser:&apos;edge&apos;});\n...\n};\nCypress documentation\n"},{"id":751,"path":"../website/pages/docs/master-devon4ng.asciidoc_cookbook.html#guide-cypress.asciidoc_viewport","type":"docs","title":"Viewport","body":"22.3.8. Viewport\nCypress allow us to create tests depending on the viewport, so we can test responsiveness.\nThere are diferent ways to use it:\nInside a test case\nit(&apos;should change title when viewport is less than 320px&apos;, ()=&gt;{\ncy.get(&apos;.title-l&apos;).should(&apos;be.visible&apos;);\ncy.get(&apos;.title-s&apos;).should(&apos;not.be.visible&apos;);\ncy.viewport(320, 480);\ncy.get(&apos;.title-l&apos;).should(&apos;not.be.visible&apos;);\ncy.get(&apos;.title-s&apos;).should(&apos;be.visible&apos;);\n})\nPassing the configuration as an option\ndescribe(&apos;page display on medium size screen&apos;, {\nviewportHeight: 1000,\nviewportWidth: 400\n}, () =&gt; {\n...\n})\nOr we can set a default\ncypress.json\n...\n{\n&quot;viewportHeight&quot;: 1000\n&quot;viewportWidth&quot;: 400,\n}\n...\nViewport documentation\n"},{"id":752,"path":"../website/pages/docs/master-devon4ng.asciidoc_cookbook.html#guide-cypress.asciidoc_test-retries","type":"docs","title":"Test retries","body":"22.3.9. Test retries\nWe can get false negatives intermittently due external issues that can affect our tests, because of that we can add, in the configuration, a retries entry so cypres can run again a certain failed test the selected number of times to verify that the error is real.\nWe can set retries for run or open mode.\ncypress.json\n...\n&quot;retries&quot;: {\n&quot;runMode&quot;: 3,\n&quot;openMode&quot;: 3\n}\n...\nThe retries can be configured on the cypress.json or directly on a specific test.\nit(&apos;should get button&apos;, {\nretries: {\nrunMode: 2,\nopenMode: 2\n}\n}, () =&gt; {\n...\n})\nThis retries thoes not show on the test log.\nCheck more on retries documentation\n"},{"id":753,"path":"../website/pages/docs/master-devon4ng.asciidoc_cookbook.html#guide-cypress.asciidoc_reporter","type":"docs","title":"Reporter","body":"22.3.10. Reporter\nThe tests results appear on the terminal, but to have a more friendly view we can add a reporter.\nMochawesome\nIn this case we are going to use Mochawesome, initialy its a Mocha reporter but as Cypress uses Mocha it works the same.\nInstall\nnpm\nnpm install --save-dev mochawesome\nyarn\nyarn add -D mochawesome\nTo run the reporter:\ncypress run --reporter mochawesome\nMochawesome saves by default the generated files on ./mochawesome-report/ but we can add options to change this behabour.\nOptions can be passed to the reporter in two ways\nUsing a flag\ncypress run --reporter mochawesome --reporter-options reportDir=report\nOr on cypress.json\n{\n&quot;baseUrl&quot;: &quot;http://localhost:4200&quot;,\n&quot;reporter&quot;: &quot;mochawesome&quot;,\n&quot;reporterOptions&quot;: {\n&quot;overwrite&quot;: false,\n&quot;html&quot;: false,\n&quot;json&quot;: true,\n&quot;reportDir&quot;: &quot;cypress/report&quot;\n}\n}\nOverwrite:false to not overwrite every **:spec.ts test report, we want them to create a merged version later.\nreportDir to set a custom directory.\nhtml:false because we don&#x2019;t need it.\njson:true to save them on json.\nMochawesome only creates the html file of the last .spec.ts file that the tests run, that&#x2019;s why we don&#x2019;t generate html reports directly, in order to stack them all on the same final html we need to merge the reports.\nCheck the mochawesome documentation\nmochawesome-merge\nMochawesome-merge is a library that helps us to merge the different json.\nnpm\nnpm install --save-dev mochawesome-merge\nnpm install --save-dev mochawesome-report-generator\nyarn\nyarn add -D mochawesome-merge\nyarn add -D mochawesome-report-generator\nTo merge the files we execute this command:\nmochawesome-merge cypress/report/*.json &gt; cypress/reportFinal.json\nreportFinal.json is the result of this merge, whit that we hace the data of all the spec files in one json.\nWe can also automate the test, merge and convertion to html using a script.\nconst cypress = require(&apos;cypress&apos;);\nconst fse = require(&apos;fs-extra&apos;);\nconst { merge } = require(&apos;mochawesome-merge&apos;);\nconst generator = require(&apos;mochawesome-report-generator&apos;);\nconst runTests= async ()=&gt;{\nawait fse.remove(&apos;mochawesome-report&apos;);\nawait fse.remove(&apos;cypress/report&apos;);\nconst {totalFailed} = await cypress.run();\nconst reporterOptions = {\nfiles: [&quot;cypress/report/*.json&quot;]\n};\nawait generateReport(reporterOptions);\nif(totalFailed !== 0){\nprocess.exit(2);\n};\n};\nconst generateReport = (options)=&gt; {\nreturn merge(options).then((jsonReport)=&gt;{\ngenerator.create(jsonReport).then(()=&gt;{\nprocess.exit();\n});\n});\n};\nrunTests();\nfse.remove() to remove older reports data.\ncypress.run() to run the tests.\nmerge(options) we merge the jsons output from running the tests.\ngenerator.create(jsonReport) then we generate the html view of the report.\nCheck the mochawesome-merge documentation\nOn kitchensink\nyou can find an official cypress demo with all the comands being used.\n"},{"id":754,"path":"../website/pages/docs/master-devon4ng.asciidoc_cookbook.html#guide-eslint.asciidoc","type":"docs","title":"Angular ESLint support","body":"22.4. Angular ESLint support\nImportant\nESLint is supported in Angular 10.1.0 onwards.\n"},{"id":755,"path":"../website/pages/docs/master-devon4ng.asciidoc_cookbook.html#guide-eslint.asciidoc_what-about-tslint","type":"docs","title":"What about TSLint?","body":"22.4.1. What about TSLint?\nTSLint is a fantastic tool. It is a linter that was written specifically to work based on the TypeScript AST format. This has advantages and disadvantages, as with most decisions we are faced with in software engineering!\nOne advantage is there is no tooling required to reconcile differences between ESLint and TypeScript AST formats, but the major disadvantage is that the tool is therefore unable to reuse any of the previous work which has been done in the JavaScript ecosystem around linting, and it has to reimplement everything from scratch. Everything from rules to auto-fixing capabilities and more.\nHowever, the backers behind TSLint announced in 2019 that they would be deprecating TSLint in favor of supporting typescript-eslint in order to benefit the community. You can read more about that here: https://medium.com/palantir/tslint-in-2019-1a144c2317a9\nThe TypeScript Team themselves also announced their plans to move the TypeScript codebase from TSLint to typescript-eslint, and they have been big supporters of this project. More details at https://github.com/microsoft/TypeScript/issues/30553\nAngular ESLint support comes from the angular-eslint tooling package. Angular documentation also links to this repository as you can check in the ng lint section of the Angular CLI documentation.\n"},{"id":756,"path":"../website/pages/docs/master-devon4ng.asciidoc_cookbook.html#guide-eslint.asciidoc_quick-start-with-angular-and-eslint","type":"docs","title":"Quick start with Angular and ESLint","body":"22.4.2. Quick start with Angular and ESLint\nIn order to create a brand new Angular CLI workspace which uses ESLint instead of TSLint and Codelyzer, simply run the following commands:\n# Install the Angular CLI and @angular-eslint/schematics globally however you want (e.g. npm, yarn, volta etc)\n$ npm i -g @angular/cli @angular-devkit/core @angular-devkit/schematics @angular-eslint/schematics\n# Create a new Angular CLI workspace using the @angular-eslint/schematics collection (instead of the default)\n$ ng new --collection=@angular-eslint/schematics\n"},{"id":757,"path":"../website/pages/docs/master-devon4ng.asciidoc_cookbook.html#guide-eslint.asciidoc_migrating-an-angular-cli-project-from-codelyzer-and-tslint","type":"docs","title":"Migrating an Angular CLI project from Codelyzer and TSLint","body":"22.4.3. Migrating an Angular CLI project from Codelyzer and TSLint\n1 - Add relevant dependencies\nThe first step is to run the schematic to add @angular-eslint to your project:\n$ ng add @angular-eslint/schematics\nThis will handle installing the latest version of all the relevant packages for you and adding them to the devDependencies of your package.json.\n2 - Run the convert-tslint-to-eslint schematic on a project\nThe next thing to do is consider which &quot;project&quot; you want to migrate to use ESLint. If you have a single application in your workspace you will likely have just a single entry in the projects configuration object within your angular.json file. If you have a projects/` directory in your workspace, you will have multiple entries in your projects configuration and you will need to chose which one you want to migrate using the convert-tslint-to-eslint schematic.\nYou can run it like so:\n$ ng g @angular-eslint/schematics:convert-tslint-to-eslint {{YOUR_PROJECT_NAME_GOES_HERE}}\nFrom now on, ng lint will use ESLint!\n3 - Remove root TSLint configuration and use only ESLint\nOnce you are happy with your ESLint setup, you simply need to remove the root-level tslint.json and potentially uninstall TSLint and any TSLint-related plugins/dependencies if your Angular CLI workspace is now no longer using TSLint at all.\nMore info at https://github.com/angular-eslint/angular-eslint\n&#x2190;&#xA0;Previous:&#xA0;NgRx&#xA0;| &#x2191;&#xA0;Up:&#xA0;devon4ng&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;devon4net&#xA0;&#x2192;\n"},{"id":758,"path":"../website/pages/docs/master-devon4ng.asciidoc_guides.html#master-devon4ng.asciidoc_guides","type":"docs","title":"Guides","body":"17. Guides\n"},{"id":759,"path":"../website/pages/docs/master-devon4ng.asciidoc_guides.html#guide-package-managers.asciidoc","type":"docs","title":"Package Managers","body":"17.1. Package Managers\nThere are two major package managers currently used for JavaScript / TypeScript projects which leverage node.js as a build platform.\nnpm\nyarn\nOur recommendation is to use yarn but both package managers are fine.\nImportant\nWhen using npm it is important to use a version greater 5.0 as npm 3 has major drawbacks compared to yarn.\nThe following guide assumes that you are using npm &gt;= 5 or yarn.\nBefore you start reading further, please take a look at the docs:\nyarn getting started\nnpm getting started\nThe following guide will describe best practices for working with yarn / npm.\n"},{"id":760,"path":"../website/pages/docs/master-devon4ng.asciidoc_guides.html#guide-package-managers.asciidoc_semantic-versioning","type":"docs","title":"Semantic Versioning","body":"17.1.1. Semantic Versioning\nWhen working with package managers it is very important to understand the concept of semantic versioning.\nTable 45. Version example 1.2.3\nVersion\n1.\n2.\n3\nVersion name when incrementing\nMajor (2.0.0)\nMinor (1.3.0)\nPatch (1.2.4)\nHas breaking changes\nyes\nno\nno\nHas features\nyes\nyes\nno\nHas bugfixes\nyes\nyes\nyes\nThe table gives an overview of the most important parts of semantic versioning.\nIn the header version 1.2.3 is displayed.\nThe first row shows the name and the resulting version when incrementing a part of the version.\nThe next rows show specifics of the resulting version - e.g. a major version can have breaking changes, features and bugfixes.\nPackages from npm and yarn leverage semantic versioning and instead of selecting a fixed version one can specify a selector.\nThe most common selectors are:\n^1.2.3\nAt least 1.2.3 - 1.2.4 or 1.3.0 can be used, 2.0.0 can not be used\n~1.2.3\nAt lease 1.2.3 - 1.2.4 can be used, 2.0.0 and 1.3.0 can not be used\n&gt;=1.2.3\nAt least 1.2.3 - every version greater can also be used\nThis achieves a lower number of duplicates.\nTo give an example:\nIf package A needs version 1.3.0 of package C and package B needs version 1.4.0 of package C one would end up with 4 packages.\nIf package A needs version ^1.3.0 of package C and package B needs version 1.4.0 of package C one would end up with 3 packages.\nA would use the same version of C as B - 1.4.0.\n"},{"id":761,"path":"../website/pages/docs/master-devon4ng.asciidoc_guides.html#guide-package-managers.asciidoc_do-not-modify-package.json-and-lock-files-by-hand","type":"docs","title":"Do not modify package.json and lock files by hand","body":"17.1.2. Do not modify package.json and lock files by hand\nDependencies are always added using a yarn or npm command.\nAltering the package.json, package-json.lock or yarn.lock file by hand is not recommended.\nAlways use a yarn or npm command to add a new dependency.\nAdding the package express with yarn to dependencies.\nyarn add express\nAdding the package express with npm to dependencies.\nnpm install express\n"},{"id":762,"path":"../website/pages/docs/master-devon4ng.asciidoc_guides.html#guide-package-managers.asciidoc_what-does-the-lock-file-do","type":"docs","title":"What does the lock file do","body":"17.1.3. What does the lock file do\nThe purpose of files yarn.lock and package-json.lock is to freeze versions for a short time.\nThe following problem is solved:\nDeveloper A upgrades the dependency express to fixed version 4.16.3.\nexpress has sub-dependency accepts with version selector ~1.3.5\nHis local node_modules folder receives accepts in version 1.3.5\nOn his machine everything is working fine\nAfterward version 1.3.6 of accepts is published - it contains a major bug\nDeveloper B now clones the repo and loads the dependencies.\nHe receives version 1.3.6 of accepts and blames developer A for upgrading to a broken version.\nBoth yarn.lock and package-json.lock freeze all the dependencies.\nFor example in yarn lock you will find.\nListing 15. yarn.lock example (excerp)\naccepts@~1.3.5:\nversion &quot;1.3.5&quot;\nresolved &quot;[...URL to registry]&quot;\ndependencies:\nmime-types &quot;~2.1.18&quot;\nnegotiator &quot;0.6.1&quot;\nmime-db@~1.33.0:\nversion &quot;1.33.0&quot;\nresolved &quot;[...URL to registry]&quot;\nmime-types@~2.1.18:\nversion &quot;2.1.18&quot;\nresolved &quot;[...URL to registry]&quot;\ndependencies:\nmime-db &quot;~1.33.0&quot;\nnegotiator@0.6.1:\nversion &quot;0.6.1&quot;\nresolved &quot;[...URL to registry]&quot;\nThe described problem is solved by the example yarn.lock file.\naccepts is frozen at version ~1.3.5\nAll of its sub-dependencies are also frozen.\nIt needs mime-types at version ~2.1.18 which is frozen at 2.1.18.\nmime-types needs mime-db at ~1.33.0 which is frozen at 1.33.0\nEvery developer will receive the same versions of every dependency.\nImportant\nYou have to make sure all your developers are using the same npm/yarn version - this includes the CI build.\n"},{"id":763,"path":"../website/pages/docs/master-devon4ng.asciidoc_guides.html#guide-npm-yarn-workflow.asciidoc","type":"docs","title":"Package Managers Workflow","body":"17.2. Package Managers Workflow\n"},{"id":764,"path":"../website/pages/docs/master-devon4ng.asciidoc_guides.html#guide-npm-yarn-workflow.asciidoc_introduction","type":"docs","title":"Introduction","body":"17.2.1. Introduction\nThis document aims to provide you the necessary documentation and sources in order to help you understand the importance of dependencies between packages.\nProjects in node.js make use of modules, chunks of reusable code made by other people or teams. These small chunks of reusable code are called packages [1]. Packages are used to solve specific problems or tasks. These relations between your project and the external packages are called dependencies.\nFor example, imagine we are doing a small program that takes your birthday as an input and tells you how many days are left until your birthday. We search in the repository if someone has published a package to retrieve the actual date and manage date types, and maybe we could search for another package to show a calendar, because we want to optimize our time, and we wish the user to click a calendar button and choose the day in the calendar instead of typing it.\nAs you can see, packages are convenient. In some cases, they may be even needed, as they can manage aspects of your program you may not be proficient in, or provide an easier use of them.\nFor more comprehensive information visit npm definition\nPackage.json\nDependencies in your project are stored in a file called package.json. Every package.json must contain, at least, the name and version of your project.\nPackage.json is located in the root of your project.\nImportant\nIf package.json is not on your root directory refer to Problems you may encounter section\nIf you wish to learn more information about package.json, click on the following links:\nYarn Package.json\nnpm Package.json\nContent of package.json\nAs you noticed, package.json is a really important file in your project. It contains essential information about our project, therefore you need to understand what&#x2019;s inside.\nThe structure of package.json is divided in blocks, inside the first one you can find essential information of your project such as the name, version, license and optionally some Scripts.\n{\n&quot;name&quot;: &quot;exampleproject&quot;,\n&quot;version&quot;: &quot;0.0.0&quot;,\n&quot;license&quot;: &quot;MIT&quot;,\n&quot;scripts&quot;: {\n&quot;ng&quot;: &quot;ng&quot;,\n&quot;start&quot;: &quot;ng serve&quot;,\n&quot;build&quot;: &quot;ng build&quot;,\n&quot;test&quot;: &quot;ng test&quot;,\n&quot;lint&quot;: &quot;ng lint&quot;,\n&quot;e2e&quot;: &quot;ng e2e&quot;\n}\nThe next block is called dependencies and contains the packages that project needs in order to be developed, compiled and executed.\n&quot;private&quot;: true,\n&quot;dependencies&quot;: {\n&quot;@angular/animations&quot;: &quot;^4.2.4&quot;,\n&quot;@angular/common&quot;: &quot;^4.2.4&quot;,\n&quot;@angular/forms&quot;: &quot;^4.2.4&quot;,\n...\n&quot;zone.js&quot;: &quot;^0.8.14&quot;\n}\nAfter dependencies we find devDependencies, another kind of dependencies present in the development of the application but unnecessary for its execution. One example is typescript. Code is written in typescript, and then, transpiled to javascript. This means the application is not using typescript in execution and consequently not included in the deployment of our application.\n&quot;devDependencies&quot;: {\n&quot;@angular/cli&quot;: &quot;1.4.9&quot;,\n&quot;@angular/compiler-cli&quot;: &quot;^4.2.4&quot;,\n...\n&quot;@types/node&quot;: &quot;~6.0.60&quot;,\n&quot;typescript&quot;: &quot;~2.3.3&quot;\n}\nHaving a peer dependency means that your package needs a dependency that is the same exact dependency as the person installing your package\n&quot;peerDependencies&quot;: {\n&quot;package-123&quot;: &quot;^2.7.18&quot;\n}\nOptional dependencies are just that: optional. If they fail to install, Yarn will still say the install process was successful.\n&quot;optionalDependencies&quot;: {\n&quot;package-321&quot;: &quot;^2.7.18&quot;\n}\nFinally you can have bundled dependencies which are packages bundled together when publishing your package in a repository.\n{\n&quot;bundledDependencies&quot;: [\n&quot;package-4&quot;\n]\n}\nHere is the link to an in-depth explanation of dependency types&#x200B;.\nScripts\nScripts are a great way of automating tasks related to your package, such as simple build processes or development tools.\nFor example:\n{\n&quot;name&quot;: &quot;exampleproject&quot;,\n&quot;version&quot;: &quot;0.0.0&quot;,\n&quot;license&quot;: &quot;MIT&quot;,\n&quot;scripts&quot;: {\n&quot;build-project&quot;: &quot;node hello-world.js&quot;,\n}\nYou can run that script by running the command yarn (run) script or npm run script, check the example below:\n$ yarn (run) build-project # run is optional\n$ npm run build-project\nThere are special reserved words for scripts, like preinstall, which will execute the script automatically\nbefore the package you install are installed.\nChech different uses for scripts in the following links:\nYarn scripts documentation\nnpm scripts documentation\nOr you can go back to\nContent of package.json&#x200B;.\nManaging dependencies\nIn order to manage dependencies we recommend using package managers in your projects.\nA big reason is their usability. Adding or removing a package is really easy, and by doing so, packet manager update the package.json and copies (or removes) the package in the needed location, with a single comand.\nAnother reason, closely related to the first one, is reducing human error by automating the package management process.\nTwo of the package managers you can use in node.js projects are &quot;yarn&quot; and &quot;npm&quot;. While you can use both, we encourage you to use only one of them while working on projects. Using both may lead to different dependencies between members of the team.\nnpm\nWe&#x2019;ll start by installing npm following this small guide here.\nAs stated on the web, npm comes inside of node.js, and must be updated after installing node.js, in the same guide you used earlier are written the instructions to update npm.\nHow npm works\nIn order to explain how npms works, let&#x2019;s take a command as an example:\n$ npm install @angular/material @angular/cdk\nThis command tells npm to look for the packages @angular/material and @angular/cdk in the npm registry, download and decompress them in the folder node_modules along with their own dependencies. Additionally, npm will update package.json and create a new file called package-lock.json.\nAfter initializating and installing the first package there will be a new folder called node_modules in your project. This folder is where your packages are unzipped and stored, following a tree scheme.\nTake in consideration both npm and yarn need a package.json in the root of your project in order to work properly. If after creating your project don&#x2019;t have it, download again the package.json from the repository or you&#x2019;ll have to start again.\nBrief overview of commands\nIf we need to create a package.json from scratch, we can use the comand init. This command asks the user for basic information about the project and creates a brand new package.json.\n$ npm init\nInstall (or i) installs all modules listed as dependencies in package.json locally. You can also specify a package, and install that package. Install can also be used with the parameter -g, which tells npm to install the Global package.\n$ npm install\n$ npm i\n$ npm install Package\nNote\nEarlier versions of npm did not add dependencies to package.json unless it was used with the flag --save, so npm install package would be npm install --save package, you have one example below.\n$ npm install --save Package\nNpm needs flags in order to know what kind of dependency you want in your project, in npm you need to put the flag -D or --save-dev to install devdependencies, for more information consult the links at the end of this section.\n$ npm install -D package\n$ npm install --save-dev package\n&#x200B;\nThe next command uninstalls the module you specified in the command.\n$ npm uninstall Package\nls command shows us the dependencies like a nested tree, useful if you have few packages, not so useful when you need a lot of packages.\n$ npm ls\nnpm@@VERSION@ /path/to/npm\n&#x2514;&#x2500;&#x252C; init-package-json@0.0.4\n&#x2514;&#x2500;&#x2500; promzard@0.1.5\nexample tree\nWe recommend you to learn more about npm commands in the following link, navigating to the section cli commands.\nAbout Package-lock.json\nPackage-lock.json describes the dependency tree resulting of using package.json and npm.\nWhenever you update, add or remove a package, package-lock.json is deleted and redone with\nthe new dependencies.\n&quot;@angular/animations&quot;: {\n&quot;version&quot;: &quot;4.4.6&quot;,\n&quot;resolved&quot;: &quot;https://registry.npmjs.org/@angular/animations/-/animations-4.4.6.tgz&quot;,\n&quot;integrity&quot;: &quot;sha1-+mYYmaik44y3xYPHpcl85l1ZKjU=&quot;,\n&quot;requires&quot;: {\n&quot;tslib&quot;: &quot;1.8.0&quot;\n}\nThis lock file is checked everytime the command npm i (or npm install) is used without specifying a package,\nin the case it exists and it&#x2019;s valid, npm will install the exact tree that was generated, such that subsequent\ninstalls are able to generate identical dependency trees.\nWarning\nIt is not recommended to modify this file yourself. It&#x2019;s better to leave its management to npm.\nMore information is provided by the npm team at package-lock.json\nYarn\nYarn is an alternative to npm, if you wish to install yarn follow the guide getting started with yarn and download the correct version for your operative system. Node.js is also needed you can find it here.\nWorking with yarn\nYarn is used like npm, with small differences in syntax, for example npm install module is changed to yarn add module.\n$ yarn add @covalent\nThis command is going to download the required packages, modify package.json, put the package in the folder node_modules and makes a new yarn.lock with the new dependency.\nHowever, unlike npm, yarn maintains a cache with packages you download inside. You don&#x2019;t need to download every file every time you do a general installation. This means installations faster than npm.\nSimilarly to npm, yarn creates and maintains his own lock file, called yarn.lock. Yarn.lock gives enough information about the project for dependency tree to be reproduced.\nyarn commands\nHere we have a brief description of yarn&#x2019;s most used commands:\n$ yarn add Package\n$ yarn add --dev Package\nAdds a package locally to use in your package. Adding the flags --dev or -D will add them to devDependencies instead of the default dependencies, if you need more information check the links at the end of the section.\n$ yarn init\nInitializes the development of a package.\n$ yarn install\nInstalls all the dependencies defined in a package.json file, you can also write &quot;yarn&quot; to achieve the same effect.\n$ yarn remove Package\nYou use it when you wish to remove a package from your project.\n$ yarn global add Package\nInstalls the Global package.\nPlease, refer to the documentation to learn more about yarn commands and their attributes: yarn commands\nyarn.lock\nThis file has the same purpose as Package-lock.json, to guide the packet manager, in this case yarn,\nto install the dependency tree specified in yarn.lock.\nYarn.lock and package.json are\nessential files when collaborating in a project more co-workers and may be a\nsource of errors if programmers do not use the same manager.\nYarn.lock follows the same structure as package-lock.json, you can find an example of dependency below:\n&quot;@angular/animations@^4.2.4&quot;:\nversion &quot;4.4.6&quot;\nresolved &quot;https://registry.yarnpkg.com/@angular/animations/-/animations-4.4.6.tgz#fa661899a8a4e38cb7c583c7a5c97ce65d592a35&quot;\ndependencies:\ntslib &quot;^1.7.1&quot;\nWarning\nAs with package-lock.json, it&#x2019;s strongly not adviced to modify this file. Leave its management to yarn\nYou can learn more about yarn.lock here: yarn.lock\nGlobal package\nGlobal packages are packages installed in your operative system instead of your local project,\nglobal packages useful for developer tooling that is not part of any individual project but instead is used for local commands.\nA good example of global package is angular/cli, a command line interface for angular used in our projects. You can install\na global package in npm with &quot;npm install -g package&quot; and &quot;yarn global add package&quot; with yarn, you have a npm example below:\nListing 16. npm global package\nnpm install &#x2013;g @angular/cli\nGlobal npm\nGlobal yarn\nPackage version\nDependencies are critical to the success of a package. You must be extra careful about\nwhich version packages are using, one package in a different version may break your code.\nVersioning in npm and yarn, follows a semantic called semver, following the logic\nMAJOR.MINOR.PATCH, like for example, @angular/animations: 4.4.6.\nDifferent versions\nSometimes, packages are installed with a different version from the one initially installed.\nThis happens because package.json also contains the range of versions we allow yarn or npm to\ninstall or update to, example:\n&quot;@angular/animations&quot;: &quot;^4.2.4&quot;\nAnd here the installed one:\n&quot;@angular/animations&quot;: {\n&quot;version&quot;: &quot;4.4.6&quot;,\n&quot;resolved&quot;: &quot;https://registry.npmjs.org/@angular/animations/-/animations-4.4.6.tgz&quot;,\n&quot;integrity&quot;: &quot;sha1-+mYYmaik44y3xYPHpcl85l1ZKjU=&quot;,\n&quot;requires&quot;: {\n&quot;tslib&quot;: &quot;1.8.0&quot;\n}\nAs you can see, the version we initially added is 4.2.4, and the version finally installed after\na global installation of all packages, 4.4.6.\nInstalling packages without package-lock.json or yarn.lock using their respective packet managers, will always\nend with npm or yarn installing the latest version allowed by package.json.\n&quot;@angular/animations&quot;: &quot;^4.2.4&quot; contains not only the version we added, but also the range we allow npm and yarn\nto update. Here are some examples:\n&quot;@angular/animations&quot;: &quot;&lt;4.2.4&quot;\nThe version installed must be lower than 4.2.4 .\n&quot;@angular/animations&quot;: &quot;&gt;=4.2.4&quot;\nThe version installed must be greater than or equal to 4.2.4 .\n&quot;@angular/animations&quot;: &quot;=4.2.4&quot;\nthe version installed must be equal to 4.2.4 .\n&quot;@angular/animations&quot;: &quot;^4.2.4&quot;\nThe version installed cannot modify the first non zero digit, for example in this case\nit cannot surpass 5.0.0 or be lower than 4.2.4 .\nYou can learn more about this in Versions\nProblems you may encounter\nIf you can&#x2019;t find package.json, you may have deleted the one you had previously,\nwhich means you have to download the package.json from the repository.\nIn the case you are creating a new project you can create a new package.json. More information\nin the links below. Click on Package.json if you come from that section. \nCreating new package.json in yarn\nCreating new package.json in npm\nImportant\nUsing npm install or yarn without package.json in your projects will\nresult in compilation errors. As we mentioned earlier,\nPackage.json contains essential information about your project.\nIf you have package.json, but you don&#x2019;t have package-lock.json or yarn.lock the use of\ncommand &quot;npm install&quot; or &quot;yarn&quot; may result in a different dependency tree.\nIf you are trying to import a module and visual code studio is not able to find it,\nis usually caused by error adding the package to the project, try to add the module again with yarn or npm,\nand restart Visual Studio Code.\nBe careful with the semantic versioning inside your package.json of the packages,\nor you may find a new update on one of your dependencies breaking your code.\nTip\nIn the following link\nthere is a solution to a problematic update to one package.\nA list of common errors of npm can be found in: npm errors\nRecomendations\nUse yarn or npm in your project, reach an agreement with your team in order to choose one, this will avoid\nundesired situations like forgetting to upload an updated yarn.lock or package-lock.json.\nBe sure to have the latest version of your project when possible.\nTip\nPull your project every time it&#x2019;s updated. Erase your node_modules folder and reinstall all\ndependencies. This assures you to be working with the same dependencies your team has.\nAD Center recommends the use of yarn.\n"},{"id":765,"path":"../website/pages/docs/master-devon4ng.asciidoc_guides.html#guide-yarn-2-support.asciidoc","type":"docs","title":"Yarn 2","body":"17.3. Yarn 2\nYarn v2 is a very different software from the v1. The following list contains the main new features:\nConstraints\nOffline Cache\nPlug&#x2019;n&#x2019;Play\nPlugins\nProtocols\nRelease Workflow\nWorkspaces\nZero-Installs\nPlease, read them carefully to decide if your current project is suitable to use Yarn 2 as package manager.\nImportant\nSome features are still experimental, so please do not use them in production enviroments.\nMore info at https://yarnpkg.com/\n"},{"id":766,"path":"../website/pages/docs/master-devon4ng.asciidoc_guides.html#guide-yarn-2-support.asciidoc_global-install","type":"docs","title":"Global Install","body":"17.3.1. Global Install\nInstalling Yarn 2.x globally is discouraged as Yarn team is moving to a per-project install strategy. We advise you to keep Yarn 1.x (Classic) as your global binary by installing it via the instructions you can find here.\nOnce you&#x2019;ve followed the instructions (running yarn --version from your home directory should yield something like 1.22.0), go to the next section to see how to enable Yarn 2 on your project.\n"},{"id":767,"path":"../website/pages/docs/master-devon4ng.asciidoc_guides.html#guide-yarn-2-support.asciidoc_per-project-install","type":"docs","title":"Per-project install","body":"17.3.2. Per-project install\nFollow these instructions to update your current devon4ng project to Yarn 2:\nFollow the global install instructions.\nMove into your project folder:\ncd ~/path/to/project\nRun the following command:\nyarn policies set-version berry # below v1.22\nyarn set version berry # on v1.22+\nSince Angular CLI still is not fully supported with the new Yarn architecture as it is not compatible with PnP it is necessary to include the node-modules plugin adding the following line in the .yarnrc.yml file:\nnodeLinker: node-modules\nCommit the .yarn and .yarnrc.yml changes\nRun again yarn install.\nNote\nFor more advanced migration topics please refer to https://yarnpkg.com/advanced/migration\n"},{"id":768,"path":"../website/pages/docs/master-devon4ng.asciidoc_guides.html#guide-yarn-2-support.asciidoc_which-files-should-be-gitignored","type":"docs","title":"Which files should be gitignored?","body":"17.3.3. Which files should be gitignored?\nIf you&#x2019;re using Zero-Installs:\n.yarn/*\n!.yarn/cache\n!.yarn/releases\n!.yarn/plugins\nIf you&#x2019;re not using Zero-Installs:\n.yarn/*\n!.yarn/releases\n!.yarn/plugins\n.pnp.*\nMore details at https://yarnpkg.com/advanced/qa#details\n&#x2190;&#xA0;Previous:&#xA0;Layers&#xA0;| &#x2191;&#xA0;Up:&#xA0;devon4ng&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Angular&#xA0;&#x2192;\n"},{"id":769,"path":"../website/pages/docs/master-devon4ng.asciidoc_introduction.html#master-devon4ng.asciidoc_introduction","type":"docs","title":"Introduction","body":"14. Introduction\n"},{"id":770,"path":"../website/pages/docs/master-devon4ng.asciidoc_introduction.html#home.asciidoc","type":"docs","title":"devon4ng","body":"14.1. devon4ng\nThis guide describes an application architecture for web client development with Angular.\n"},{"id":771,"path":"../website/pages/docs/master-devon4ng.asciidoc_introduction.html#home.asciidoc_motivation","type":"docs","title":"Motivation","body":"14.1.1. Motivation\nFrontend development is a very difficult task since there are a lot of different frameworks, patterns and practices nowadays. For that reason, in devonfw we decided to make use of Angular since it is a full frontend framework that includes almost all the different patterns and features that any SPA may need and provides a well defined architecture to development, build and deploy.\nThe idea with devon4ng is to define an architecture which is a compromise between, on the one hand, leveraging the best practices and latest trends like reactive style development, on the other hand, providing a short onboarding time while still using an architecture that helps us scale and be productive at the same time.\nAt the same time devon4ng aims to help developers to solve common problems that appear in many projects and provide samples and blueprints to show how to apply this solutions in real situations.\n"},{"id":772,"path":"../website/pages/docs/master-devon4ng.asciidoc_introduction.html#home.asciidoc_contents","type":"docs","title":"Contents","body":"14.1.2. Contents\nArchitecture Overview\nThis section introduces in an easy way the main principles and guidelines based on Angular Styleguide.\nClient Meta Architecture\nThe goal of this topic is to support the non-functional requirements for the client, i.e. mostly maintainability, scalability, efficiency and portability. As such it provides a component-oriented architecture following the same principles listed already in the devonfw architecture overview.\nLayers\nThis section provides a condensed explanation about the different layers a good Angular application must provide.\nComponents Layer\nServices Layer\nGuides\nThis section introduces concepts to help developes with the tooling and package managers.\nPackage Managers\nPackage Managers Workflow\nYarn 2 Support\nAngular\nThis is the main section of the documentation, where the developer will find guidelines for accesibility, how to use the Angular toolchain, how to refactor components, create libraries and, in general, maintain Angular applications. But last and not least, developers will also find solutions to common problems many of the Angular projects may have.\nNote\nAll the different topics are demonstrated in the samples folder with a small application.\nAccessibility\nAngular Elements\nAngular Lazy Loading\nAngular Library\nAngular Material Theming\nAngular Progressive Web Apps\nApp Initializer\nComponent Decomposition\nConsuming REST services\nError Handler\nFile Structure\nInternationalization\nRouting\nTesting\nUpdate Angular CLI\nUpgrade devon4ng applications\nWorking with Angular CLI\nIonic\nAs part of the devon4ng stack, we include a small section to explain how to develop hybrid mobile Ionic/Angular applications and create PWAs with this UI library. As the pervious section, the contents are demonstrated in the samples folder.\nIonic Getting started\nIonic to Android\nIonic Progressive Web Apps\nLayouts\nAny SPA application must have a layout. So, the purpose of this section is to explain the Angular Material approach.\nAngular Material Layout\nNgRx\nState Management is a big topic in big frontend application. This section explains the fundamentals of the industry standard library NgRx, showing its main components.\nIntroduction\nState, Selection and Reducers\nSide effects with NgRx/Effects\nSimplifying CRUD with NgRx/Entity\nCookbook\nThe Cookbook section aims to provide solutions to cross-topic challenges that at this moment do not fit in the previous sections. As the Angular section, some of the topics are demonstrated with a sample located in the samples folder.\nAbstract Class Store\nAngular Electron\nMock Service\nCypress e2e testing\nAngular ESLint\ndevon4ng templates\nIn order to support CobiGen generation tool for Angular applications, devon4ng demos realization and provide more opinionated samples, the following templates are also included in devon4ng contents:\ndevon4ng-application-template: It is the Angular application template used by the CobiGen code generation tool.\ndevon4ng-ngrx-template: It is the Angular application template used by the CobiGen code generation tool that makes use of NgRx for state management.\ndevon4ng-ionic-application-template: It is the Ionic mobile application template used by the CobiGen code generation tool.\n&#x2191;&#xA0;Up:&#xA0;devon4ng&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Architecture&#xA0;&#x2192;\n"},{"id":773,"path":"../website/pages/docs/master-devon4ng.asciidoc_ionic.html#master-devon4ng.asciidoc_ionic","type":"docs","title":"Ionic","body":"19. Ionic\n"},{"id":774,"path":"../website/pages/docs/master-devon4ng.asciidoc_ionic.html#guide-ionic-getting-started.asciidoc","type":"docs","title":"Ionic 5 Getting started","body":"19.1. Ionic 5 Getting started\nIonic is a front-end focused framework which offers different tools for developing hybrid mobile applications. The web technologies used for this purpose are CSS, Sass, HTML5 and Typescript.\n"},{"id":775,"path":"../website/pages/docs/master-devon4ng.asciidoc_ionic.html#guide-ionic-getting-started.asciidoc_why-ionic","type":"docs","title":"Why Ionic?","body":"19.1.1. Why Ionic?\nIonic is used for developing hybrid applications, which means not having to rely on a specifyc IDE such as Android Studio or Xcode. Furthermore, development of native apps require learning different languages (Java/Kotlin for Android and Objective-C/Swift for Apple), with Ionic, a developer does not have to code the same functionality for multiple platforms, just use the adecuate libraries and components.\n"},{"id":776,"path":"../website/pages/docs/master-devon4ng.asciidoc_ionic.html#guide-ionic-getting-started.asciidoc_basic-environment-set-up","type":"docs","title":"Basic environment set up","body":"19.1.2. Basic environment set up\nInstall Ionic CLI\nAlthough the devonfw distribution comes with and already installed Ionic CLI, here are the steps to install it. The instalation of Ionic is easy, just one command has to be written:\n$ npm install -g @ionic/cli\nUpdate Ionic CLI\nIf there was a previous installation of the Ionic CLI, it will need to be uninstalled due to a change in package name.\n$ npm uninstall -g ionic\n$ npm install -g @ionic/cli\n"},{"id":777,"path":"../website/pages/docs/master-devon4ng.asciidoc_ionic.html#basic-proyect-set-up","type":"docs","title":"Basic proyect set up","body":"19.2. Basic proyect set up\nThe set up of an ionic application is pretty inmediate and can be done in one line:\nionic start &lt;name&gt; &lt;template&gt; --type=angular\nionic start: Command to create an app.\n&lt;name&gt;: Name of the application.\n&lt;template&gt;: Model of the application.\n--type=angular: With this flag, the app produced will be based on angular.\nTo create an empty project, the following command can be used:\nionic start MyApp blank --type=angular\nThe image above shows the directory structure generated.\nThere are more templates available that can be seen with the command\nionic start --list\nThe templates surrounded by red line are based on angular and comes with Ionic v5, while the others belong to earlier versions (before v4).\nNote\nMore info at https://ionicframework.com/docs. Remember to select Angular documentation, since Ionic supports React, Vue and Vanilla JS.\n"},{"id":778,"path":"../website/pages/docs/master-devon4ng.asciidoc_ionic.html#guide-ionic-from-code-to-android.asciidoc","type":"docs","title":"Ionic to android","body":"19.3. Ionic to android\nThis page is written to help developers to go from the source code of an ionic application to an android one, with this in mind, topics such as: environment, commands, modifications,&#x2026;&#x200B; are covered.\n"},{"id":779,"path":"../website/pages/docs/master-devon4ng.asciidoc_ionic.html#guide-ionic-from-code-to-android.asciidoc_assumptions","type":"docs","title":"Assumptions","body":"19.3.1. Assumptions\nThis document assumes that the reader has already:\nSource code of an Ionic application and wants to build it on an android device,\nA working installation of Node.js\nAn Ionic CLI installed and up-to-date.\nAndroid Studio and Android SDK.\n"},{"id":780,"path":"../website/pages/docs/master-devon4ng.asciidoc_ionic.html#guide-ionic-from-code-to-android.asciidoc_from-ionic-to-android-project","type":"docs","title":"From Ionic to Android project","body":"19.3.2. From Ionic to Android project\nWhen a native application is being dessigned, sometimes, functionalities that uses camera, geolocation, push notification, &#x2026;&#x200B; are requested. To resolve these requests, Capacitor can be used.\nIn general terms, Capacitor wraps apps made with Ionic (HTML, SCSS, Typescript) into WebViews that can be displayed in native applications (Android, IOS) and allows the developer to access native functionalities like the ones said before.\nInstalling capacitor is as easy as installing any node module, just a few commands have to be run in a console:\ncd name-of-ionic-4-app\nnpm install --save @capacitor/core @capacitor/cli\nThen, it is necessary to initialize capacitor with some information: app id, name of the app and the directory where your app is stored. To fill this information, run:\nnpx cap init\nModifications\nThroughout the development process, usually back-end and front-end are on a local computer, so it&#x2019;s a common practice to have diferent configuration files for each environment (commonly production and development). Ionic uses an angular.json file to store those configurations and some rules to be applied.\nIf a back-end is hosted on http://localhost:8081, and that direction is used in every environment, the application built for android will not work because computer and device do not have the same localhost. Fortunately, different configurations can be defined.\nAndroid Studio uses 10.0.0.2 as alias for 127.0.0.1 (computer&#x2019;s localhost) so adding http//10.0.0.2:8081 in a new environment file and modifying angular.json accordingly, will make possible connect front-end and back-end.\n&quot;build&quot;: {\n...\n&quot;configurations&quot;: {\n...\n&quot;android&quot;: {\n&quot;fileReplacements&quot;: [\n{\n&quot;replace&quot;: &quot;src/environments/environment.ts&quot;,\n&quot;with&quot;: &quot;src/environments/environment.android.ts&quot;\n}\n]\n},\n}\n}\nBuild\nOnce configured, it is necessary to build the Ionic app using this new configuration:\nionic build --configuration=android\nThe next commands copy the build application on a folder named android and open android studio.\nnpx cap add android\nnpx cap copy\nnpx cap open android\n"},{"id":781,"path":"../website/pages/docs/master-devon4ng.asciidoc_ionic.html#guide-ionic-from-code-to-android.asciidoc_from-android-project-to-emulated-device","type":"docs","title":"From Android project to emulated device","body":"19.3.3. From Android project to emulated device\nOnce Android Studio is opened, follow these steps:\nClick on &quot;Build&quot; &#x2192; Make project.\nClick on &quot;Build&quot; &#x2192; Make Module &apos;app&apos; (default name).\nClick on&quot; Build&quot; &#x2192; Build Bundle(s) / APK(s) &#x2192; Build APK(s).\nClick on run and choose a device.\nIf there are no devices available, a new one can be created:\nClick on &quot;Create new device&quot;\nSelect hardware and click &quot;Next&quot;. For example: Phone &#x2192; Nexus 5X.\nDownload a system image.\nClick on download.\nWait until the installation finished and then click &quot;Finish&quot;.\nClick &quot;Next&quot;.\nVerify configuration (default configuration should be enough) and click &quot;Next&quot;.\nCheck that the new device is created correctly.\n"},{"id":782,"path":"../website/pages/docs/master-devon4ng.asciidoc_ionic.html#guide-ionic-from-code-to-android.asciidoc_from-android-project-to-real-device","type":"docs","title":"From Android project to real device","body":"19.3.4. From Android project to real device\nTo test on a real android device, an easy aproach to comunicate a smartphone (front-end) and computer (back-end) is to configure a Wi-fi hotspot and connect the computer to it. A guide about this process can be found at https://support.google.com/nexus/answer/9059108?hl=en\nOnce connected, run ipconfig on a console if you are using windows or ifconfig on a linux machine to get the IP address of your machine&#x2019;s Wireless LAN adapter Wi-fi.\nThis obtained IP must be used instead of &quot;localhost&quot; or &quot;10.0.2.2&quot; at environment.android.ts.\nAfter this configuration, follow the build steps in &quot;From Ionic to Android project&quot; and the first three steps in &quot;From Android project to emulated device&quot;.\nSend APK to Android through USB\nTo send the built application to a device, you can connect computer and mobile through USB, but first, it is necessary to unlock developer options.\nOpen &quot;Settings&quot; and go to &quot;System&quot;.\nClick on &quot;About&quot;.\nClick &quot;Build number&quot; seven times to unlock developer options.\nGo to &quot;System&quot; again an then to &quot;Developer options&quot;\nCheck that the options are &quot;On&quot;.\nCheck that &quot;USB debugging&quot; is activated.\nAfter this, do the step four in &quot;From Android project to emulated device&quot; and choose the connected smartphone.\nSend APK to Android throught email\nWhen you build an APK, a dialog gives two options: locate or analyze. If the first one is chosen, Windows file explorer will be opened showing an APK that can be send using email. Download the APK on your phone and click it to install.\n"},{"id":783,"path":"../website/pages/docs/master-devon4ng.asciidoc_ionic.html#guide-ionic-from-code-to-android.asciidoc_result","type":"docs","title":"Result","body":"19.3.5. Result\nIf everything goes correctly, the Ionic application will be ready to be tested.\n"},{"id":784,"path":"../website/pages/docs/master-devon4ng.asciidoc_ionic.html#guide-ionic-pwa.asciidoc","type":"docs","title":"Ionic Progressive Web App","body":"19.4. Ionic Progressive Web App\nThis guide is a continuation of the guide Angular PWAs, therefore, valid concepts explained there are still valid in this page but focused on Ionic.\n"},{"id":785,"path":"../website/pages/docs/master-devon4ng.asciidoc_ionic.html#guide-ionic-pwa.asciidoc_assumptions","type":"docs","title":"Assumptions","body":"19.4.1. Assumptions\nThis guide assumes that you already have installed:\nNode.js\nnpm package manager\nAngular CLI\nIonic 5 CLI\nCapacitor\nAlso, it is a good idea to read the document about PWA using Angular.\n"},{"id":786,"path":"../website/pages/docs/master-devon4ng.asciidoc_ionic.html#guide-ionic-pwa.asciidoc_sample-application","type":"docs","title":"Sample Application","body":"19.4.2. Sample Application\nFigure 55. Basic ionic PWA.\nTo explain how to build progressive web apps (PWA) using Ionic, a basic application is going to be built. This app will be able to take photos even without network using PWA elements.\nStep 1: Create a new project\nThis step can be completed with one simple command: ionic start &lt;name&gt; &lt;template&gt;, where &lt;name&gt; is the name and &lt;template&gt; a model for the app. In this case, the app is going to be named basic-ion-pwa.\nStep 2: Structures and styles\nThe styles (scss) and structures (html) do not have anything specially relevant, just colors and ionic web components. The code can be found in devon4ng samples.\nStep 3: Add functionality\nAfter this step, the app will allow users take photos and display them in the main screen.\nFirst we have to import three important elements:\nDomSanitizer: Sanitizes values to be safe to use.\nSafeResourceUrl: Interface for values that are safe to use as URL.\nPlugins: Capacitor constant value used to access to the device&#x2019;s camera and toast dialogs.\nimport { DomSanitizer, SafeResourceUrl } from &apos;@angular/platform-browser&apos;;\nimport { Plugins, CameraResultType } from &apos;@capacitor/core&apos;;\nconst { Camera, Toast } = Plugins;\nThe process of taking a picture is enclosed in a takePicture method. takePicture calls the Camera&#x2019;s getPhoto function which returs an URL or an exception. If a photo is taken then the image displayed in the main page will be changed for the new picture, else, if the app is closed without changing it, a toast message will be displayed.\nexport class HomePage {\nimage: SafeResourceUrl;\n...\nasync takePicture() {\ntry {\nconst image = await Camera.getPhoto({\nquality: 90,\nallowEditing: true,\nresultType: CameraResultType.Uri,\n});\n// Change last picture shown\nthis.image = this.sanitizer.bypassSecurityTrustResourceUrl(image.webPath);\n} catch (e) {\nthis.show(&apos;Closing camera&apos;);\n}\n}\nasync show(message: string) {\nawait Toast.show({\ntext: message,\n});\n}\n}\nStep 4: PWA Elements\nWhen Ionic apps are not running natively, some resources like Camera do not work by default but can be enabled using PWA Elements. To use Capacitor&#x2019;s PWA elements run npm install @ionic/pwa-elements and modify src/main.ts as shown below.\n...\n// Import for PWA elements\nimport { defineCustomElements } from &apos;@ionic/pwa-elements/loader&apos;;\nif (environment.production) {\nenableProdMode();\n}\nplatformBrowserDynamic().bootstrapModule(AppModule)\n.catch(err =&gt; console.log(err));\n// Call the element loader after the platform has been bootstrapped\ndefineCustomElements(window);\nStep 5: Make it Progressive.\nTurining an Ionic 5 app into a PWA is pretty easy, the same module used to turn Angular apps into PWAs has to be added, to do so, run: ng add @angular/pwa. This command also creates an icons folder inside src/assets and contains angular icons for multiple resolutions. If you want use other images, be sure that they have the same resolution, the names can be different but the file manifest.json has to be changed accordingly.\nStep 6: Configure the app\nmanifest.json\nDefault configuration.\nngsw-config.json\nAt assetGroups &#x2192; resources add a urls field and a pattern to match PWA Elements scripts and other resources (images, styles, &#x2026;&#x200B;):\n&quot;urls&quot;: [&quot;https://unpkg.com/@ionic/pwa-elements@1.0.2/dist/**&quot;]\nStep 7: Check that your app is a PWA\nTo check if an app is a PWA lets compare its normal behaviour against itself but built for production. Run in the project&#x2019;s root folder the commands below:\nionic build --prod to build the app using production settings.\nnpm install http-server to install an npm module that can serve your built application. Documentation here. A good alternative is also npm install serve. It can be checked here.\nGo to the www folder running cd www.\nhttp-server -o or serve to serve your built app.\nNote\nIn order not to install anything not necessary npx can be used directly to serve the app. i.e run npx serve [folder] will automatically download and run this HTTP server without installing it in the project dependencies.\nFigure 56. Http server running on localhost:8081.\n&#xA0;\nIn another console instance run ionic serve to open the common app (not built).\nFigure 57. Ionic server running on localhost:8100.\n&#xA0;\nThe first difference can be found on Developer tools &#x2192; application, here it is seen that the PWA application (left) has a service worker and the common one does not.\nFigure 58. Application service worker comparison.\n&#xA0;\nIf the &quot;offline&quot; box is checked, it will force a disconnection from network. In situations where users do not have connectivity or have a slow, one the PWA can still be accesed and used.\nFigure 59. Offline application.\n&#xA0;\nFinally, plugins like Lighthouse can be used to test whether an application is progressive or not.\nFigure 60. Lighthouse report.\n&#x2190;&#xA0;Previous:&#xA0;Angular&#xA0;| &#x2191;&#xA0;Up:&#xA0;devon4ng&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Layouts&#xA0;&#x2192;\n"},{"id":787,"path":"../website/pages/docs/master-devon4ng.asciidoc_layers.html#master-devon4ng.asciidoc_layers","type":"docs","title":"Layers","body":"16. Layers\n"},{"id":788,"path":"../website/pages/docs/master-devon4ng.asciidoc_layers.html#components-layer.asciidoc","type":"docs","title":"Components Layer","body":"16.1. Components Layer\nThe components layer encapsulates all components presenting the current application view state, which means data to be shown to the user.\nThe term component refers to a component described by the standard Web Components.\nSo this layer has all Angular components, directives and pipes defined for an application.\nThe main challenges are:\nhow to structure the components layer (see File Structure Guide)\ndecompose components into maintainable chunks (see Component Decomposition Guide)\nhandle component interaction\nmanage calls to the services layer\napply a maintainable data and eventflow throughout the component tree\n"},{"id":789,"path":"../website/pages/docs/master-devon4ng.asciidoc_layers.html#components-layer.asciidoc_smart-and-dumb-components","type":"docs","title":"Smart and Dumb Components","body":"16.1.1. Smart and Dumb Components\nThe architecture applies the concept of Smart and Dumb Components (syn. Containers and Presenters).\nThe concept means that components are devided into Smart and Dumb Components.\nA Smart Component typically is a toplevel dialog inside the component tree.\na component, that can be routed to\na modal dialog\na component, which is placed inside AppComponent\nA Dumb Component can be used by one to many Smart Components.\nInside the component tree a Dumb Component is a child of a Smart Component.\nFigure 13. Component tree example\nAs shown the topmost component is always the AppComponent in Angular applications.\nThe component tree describes the hierarchy of components starting from AppComponent.\nThe figure shows Smart Components in blue and Dumb Components in green.\nAppComponent is a Smart Component by definition.\nInside the template of AppComponent placed components are static components inside the component tree.\nSo they are always displayed.\nIn the example OverviewComponent and DetailsComponent are rendered by Angular compiler depending on current URL the application displays.\nSo OverviewComponents subtree is displayed if the URL is /overview and DetailsComponents subtree is displayed if the URL is /details.\nTo clarify this distinction further the following table shows the main differences.\nTable 44. Smart vs Dumb Components\nSmart Components\nDumb Components\ncontain the current view state\nshow data via binding (@Input) and contain no view state\nhandle events emited by Dumb Components\npass events up the component tree to be handled by Smart Components (@Output)\ncall the services layer\nnever call the services layer\nuse services\ndo not use services\nconsists of n Dumb Components\nis independent of Smart Components\n"},{"id":790,"path":"../website/pages/docs/master-devon4ng.asciidoc_layers.html#components-layer.asciidoc_interaction-of-smart-and-dumb-components","type":"docs","title":"Interaction of Smart and Dumb Components","body":"16.1.2. Interaction of Smart and Dumb Components\nWith the usage of the Smart and Dumb Components pattern one of the most important part is component interaction.\nAngular comes with built in support for component interaction with @Input() and @Output() Decorators.\nThe following figure illustrates an unidirectional data flow.\nData always goes down the component tree - from a Smart Component down its children.\nEvents bubble up, to be handled by a Smart Component.\nFigure 14. Smart and Dumb Component Interaction\nAs shown a Dumb Components role is to define a signature by declaring Input and Output Bindings.\n@Input() defines what data is necessary for that component to work\n@Output() defines which events can be listened on by the parent component\nListing 11. Dumb Components define a signature\nexport class ValuePickerComponent {\n@Input() columns: string[];\n@Input() items: {}[];\n@Input() selected: {};\n@Input() filter: string;\n@Input() isChunked = false;\n@Input() showInput = true;\n@Input() showDropdownHeader = true;\n@Output() elementSelected = new EventEmitter&lt;{}&gt;();\n@Output() filterChanged = new EventEmitter&lt;string&gt;();\n@Output() loadNextChunk = new EventEmitter();\n@Output() escapeKeyPressed = new EventEmitter();\n}\nThe example shows the Dumb Component ValuePickerComponent.\nIt describes seven input bindings with isChunked, showHeader and showDropdownHeader being non mandatory as they have a default value.\nFour output bindings are present. Typically, a Dumb Component has very little code to no code inside the TypeScript class.\nListing 12. Smart Components use the Dumb Components signature inside the template\n&lt;div&gt;\n&lt;value-input\n...&gt;\n&lt;/value-input&gt;\n&lt;value-picker\n*ngIf=&quot;isValuePickerOpen&quot;\n[columns]=&quot;columns&quot;\n[items]=&quot;filteredItems&quot;\n[isChunked]=&quot;isChunked&quot;\n[filter]=&quot;filter&quot;\n[selected]=&quot;selectedItem&quot;\n[showDropdownHeader]=&quot;showDropdownHeader&quot;\n(loadNextChunk)=&quot;onLoadNextChunk()&quot;\n(elementSelected)=&quot;onElementSelected($event)&quot;\n(filterChanged)=&quot;onFilterChanged($event)&quot;\n(escapeKeyPressed)=&quot;onEscapePressedInsideChildTable()&quot;&gt;\n&lt;/value-picker&gt;\n&lt;/div&gt;\nInside the Smart Components template the events emitted by Dumb Components are handled.\nIt is a good practice to name the handlers with the prefix on* (e.g. onInputChanged()).\n"},{"id":791,"path":"../website/pages/docs/master-devon4ng.asciidoc_layers.html#services-layer.asciidoc","type":"docs","title":"Services Layer","body":"16.2. Services Layer\nThe services layer is more or less what we call &apos;business logic layer&apos; on the server side.\nIt is the layer where the business logic is placed.\nThe main challenges are:\nDefine application state and an API for the components layer to use it\nHandle application state transitions\nPerform backend interaction (XHR, WebSocket, etc.)\nHandle business logic in a maintainable way\nConfiguration management\nAll parts of the services layer are described in this chapter.\nAn example which puts the concepts together can be found at the end Interaction of Smart Components through the services layer.\n"},{"id":792,"path":"../website/pages/docs/master-devon4ng.asciidoc_layers.html#services-layer.asciidoc_boundaries","type":"docs","title":"Boundaries","body":"16.2.1. Boundaries\nThere are two APIs for the components layer to interact with the services layer:\nA store can be subscribed to for receiving state updates over time\nA use case service can be called to trigger an action\nTo illustrate the fact the follwing figure shows an abstract overview.\nFigure 15. Boundaries to components layer\n"},{"id":793,"path":"../website/pages/docs/master-devon4ng.asciidoc_layers.html#services-layer.asciidoc_store","type":"docs","title":"Store","body":"16.2.2. Store\nA store is a class which defines and handles application state with its transitions over time.\nInteraction with a store is always synchronous.\nA basic implementation using rxjs can look like this.\nTip\nA more profound implementation taken from a real-life project can be found here (Abstract Class Store).\nListing 13. Store defined using rxjs\n@Injectable()\nexport class ProductSearchStore {\nprivate stateSource = new BehaviorSubject&lt;ProductSearchState&gt;(defaultProductSearchState);\nstate$ = this.stateSource.asObservable();\nsetLoading(isLoading: boolean) {\nconst currentState = this.stateSource.getValue();\nthis.stateSource.next({\nisLoading: isLoading,\nproducts: currentState.products,\nsearchCriteria: currentState.searchCriteria\n});\n}\n}\nIn the example ProductSearchStore handles state of type ProductSearchState.\nThe public API is the property state$ which is an observable of type ProductSearchState.\nThe state can be changed with method calls.\nSo every desired change to the state needs to be modeled with an method.\nIn reactive terminology this would be an Action.\nThe store does not use any services.\nSubscribing to the state$ observable leads to the subscribers receiving every new state.\nThis is basically the Observer Pattern:\nThe store consumer registeres itself to the observable via state$.subscribe() method call.\nThe first parameter of subscribe() is a callback function to be called when the subject changes.\nThis way the consumer - the observer - is registered.\nWhen next() is called with a new state inside the store, all callback functions are called with the new value.\nSo every observer is notified of the state change.\nThis equals the Observer Pattern push type.\nA store is the API for Smart Components to receive state from the service layer.\nState transitions are handled automatically with Smart Components registering to the state$ observable.\n"},{"id":794,"path":"../website/pages/docs/master-devon4ng.asciidoc_layers.html#services-layer.asciidoc_use-case-service","type":"docs","title":"Use Case Service","body":"16.2.3. Use Case Service\nA use case service is a service which has methods to perform asynchronous state transitions.\nIn reactive terminology this would be an Action of Actions - a thunk (redux) or an effect (@ngrx).\nFigure 16. Use case services are the main API to trigger state transitions\nA use case services method - an action - interacts with adapters, business services and stores.\nSo use case services orchestrate whole use cases.\nFor an example see use case service example.\n"},{"id":795,"path":"../website/pages/docs/master-devon4ng.asciidoc_layers.html#services-layer.asciidoc_adapter","type":"docs","title":"Adapter","body":"16.2.4. Adapter\nAn adapter is used to communicate with the backend.\nThis could be a simple XHR request, a WebSocket connection, etc.\nAn adapter is simple in the way that it does not add anything other than the pure network call.\nSo there is no caching or logging performed here.\nThe following listing shows an example.\nFor further information on backend interaction see Consuming REST Services\nListing 14. Calling the backend via an adapter\n@Injectable()\nexport class ProducsAdapter {\nprivate baseUrl = environment.baseUrl;\nconstructor(private http: HttpClient) { }\ngetAll(): Observable&lt;Product[]&gt; {\nreturn this.http.get&lt;Product[]&gt;(this.baseUrl + &apos;/products&apos;);\n}\n}\n"},{"id":796,"path":"../website/pages/docs/master-devon4ng.asciidoc_layers.html#services-layer.asciidoc_interaction-of-smart-components-through-the-services-layer","type":"docs","title":"Interaction of Smart Components through the services layer","body":"16.2.5. Interaction of Smart Components through the services layer\nThe interaction of smart components is a classic problem which has to be solved in every UI technology.\nIt is basically how one dialog tells the other something has changed.\nAn example is adding an item to the shopping basket.\nWith this action there need to be multiple state updates.\nThe small logo showing how many items are currently inside the basket needs to be updated from 0 to 1\nThe price needs to be recalculated\nShipping costs need to be checked\nDiscounts need to be updated\nAds need to be updated with related products\netc.\nPattern\nTo handle this interaction in a scalable way we apply the following pattern.\nFigure 17. Smart Component interaction\nThe state of interest is encapsualted inside a store. All Smart Components interested in the state have to subscibe to the store&#x2019;s API served by the public observable. Thus, with every update to the store the subscribed components receive the new value. The components basically react to state changes. Altering a store can be done directly if the desired change is synchronous. Most actions are of asynchronous nature so the UseCaseService comes into play. Its actions are void methods, which implement a use case, i.e., adding a new item to the basket. It calls asynchronous actions and can perform multiple store updates over time.\nTo put this pattern into perspective the UseCaseService is a programmatic alternative to redux-thunk or @ngrx/effects. The main motivation here is to use the full power of TypeScript&#x2019;s --strictNullChecks and to let the learning curve not to become as steep as it would be when learning a new state management framework. This way actions are just void method calls.\nExample\nFigure 18. Smart Components interaction example\nThe example shows two Smart Components sharing the FlightSearchState by using the FlightSearchStore.\nThe use case shown is started by an event in the Smart Component FlightSearchComponent. The action loadFlight() is called. This could be submitting a search form.\nThe UseCaseService is FlightSearchService, which handles the use case Load Flights.\nUseCaseService example\nexport class FlightSearchService {\nconstructor(\nprivate flightSearchAdapter: FlightSearchAdapter,\nprivate store: FlightSearchStore\n) { }\nloadFlights(criteria: FlightSearchCriteria): void {\nthis.store.setLoadingFlights(true);\nthis.store.clearFlights();\nthis.flightSearchAdapter.getFlights(criteria.departureDate,\n{\nfrom: criteria.departureAirport,\nto: criteria.destinationAirport\n})\n.finally(() =&gt; this.store.setLoadingFlights(false))\n.subscribe((result: FlightTo[]) =&gt; this.store.setFlights(result, criteria));\n}\n}\nFirst the loading flag is set to true and the current flights are cleared. This leads the Smart Component showing a spinner indicating the loading action. Then the asynchronous XHR is triggert by calling the adapter. After completion the loading flag is set to false causing the loading indication no longer to be shown. If the XHR was successful, the data would be put into the store. If the XHR was not successful, this would be the place to handle a custom error. All general network issues should be handled in a dedicated class, i.e., an interceptor. So for example the basic handling of 404 errors is not done here.\n&#x2190;&#xA0;Previous:&#xA0;Architecture&#xA0;| &#x2191;&#xA0;Up:&#xA0;devon4ng&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Guides&#xA0;&#x2192;\n"},{"id":797,"path":"../website/pages/docs/master-devon4ng.asciidoc_layouts.html#master-devon4ng.asciidoc_layouts","type":"docs","title":"Layouts","body":"20. Layouts\n"},{"id":798,"path":"../website/pages/docs/master-devon4ng.asciidoc_layouts.html#guide-layout-with-angular-material.asciidoc","type":"docs","title":"Angular Material Layout","body":"20.1. Angular Material Layout\nThe purpose of this guide is to get a basic understanding of creating layouts using Angular Material in a devon4ng application. We will create an application with a header containing some menu links and a sidenav with some navigation links.\nFigure 61. This is what the finished application will look like\n"},{"id":799,"path":"../website/pages/docs/master-devon4ng.asciidoc_layouts.html#guide-layout-with-angular-material.asciidoc_lets-begin","type":"docs","title":"Let&#x2019;s begin","body":"20.1.1. Let&#x2019;s begin\nWe start with opening the console(running console.bat in the Devon distribution folder) and running the following command to start a project named devon4ng-mat-layout\nng new devon4ng-mat-layout\nSelect y when it asks whether it would like to add Angular routing and select SCSS when it asks for the stylesheet format.\nYou can also use the devonfw-ide CLI to create a new devon4ng application.\nOnce the creation process is complete, open your newly created application in Visual Studio Code. Try running the empty application by running the following command in the integrated terminal:\nng serve\nAngular will spin up a server and you can check your application by visiting http://localhost:4200/ in your browser.\nFigure 62. Blank application\n"},{"id":800,"path":"../website/pages/docs/master-devon4ng.asciidoc_layouts.html#guide-layout-with-angular-material.asciidoc_adding-angular-material-library-to-the-project","type":"docs","title":"Adding Angular Material library to the project","body":"20.1.2. Adding Angular Material library to the project\nNext we will add Angular Material to our application. In the integrated terminal, press Ctrl + C to terminate the running application and run the following command:\nnpm install --save @angular/material @angular/cdk @angular/animations\nYou can also use Yarn to install the dependencies if you prefer that:\nyarn add @angular/material @angular/cdk @angular/animations\nOnce the dependencies are installed, we need to import the BrowserAnimationsModule in our AppModule for animations support.\nListing 68. Importing BrowserAnimationsModule in AppModule\nimport {BrowserAnimationsModule} from &apos;@angular/platform-browser/animations&apos;;\n@NgModule({\n...\nimports: [BrowserAnimationsModule],\n...\n})\nexport class AppModule { }\nAngular Material provides a host of components for designing our application. All the components are well structured into NgModules. For each component from the Angular Material library that we want to use, we have to import the respective NgModule.\nListing 69. We will be using the following components in our application:\nimport { MatIconModule, MatButtonModule, MatMenuModule, MatListModule, MatToolbarModule, MatSidenavModule } from &apos;@angular/material&apos;;\n@NgModule({\n...\nimports: [\n...\nMatIconModule,\nMatButtonModule,\nMatMenuModule,\nMatListModule,\nMatToolbarModule,\nMatSidenavModule,\n...\n],\n...\n})\nexport class AppModule { }\nA better approach is to import and then export all the required components in a shared module. But for the sake of simplicity, we are importing all the required components in the AppModule itself.\nNext, we include a theme in our application. Angular Material comes with four inbuilt themes: indigo-pink, deeppurple-amber, pink-bluegrey and purple-green. It is also possible to create our own custom theme, but that is beyond the scope of this guide. Including a theme is required to apply all of the core and theme styles to your application.\nWe will include the indigo-pink theme in our application by importing the indigo-pink.css file in our src/styles.scss:\nListing 70. In src/styles.scss:\n@import &quot;~@angular/material/prebuilt-themes/indigo-pink.css&quot;;\nSome Angular Material components depend on HammerJs for gestures. So it is a good idea to install HammerJs as a dependency in our application. To do so, run the following command in the terminal:\nnpm install --save hammerjs\nThen import it in the src/main.ts file\nimport &apos;hammerjs&apos;;\nTo use Material Design Icons along with the mat-icon component, we will load the Material Icons library in our src/index.html file\nListing 71. In src/index.html:\n&lt;link href=&quot;https://fonts.googleapis.com/icon?family=Material+Icons&quot; rel=&quot;stylesheet&quot;&gt;\n"},{"id":801,"path":"../website/pages/docs/master-devon4ng.asciidoc_layouts.html#guide-layout-with-angular-material.asciidoc_development","type":"docs","title":"Development","body":"20.1.3. Development\nNow that we have all the Angular Material related dependencies set up in our project, we can start coding. Let&#x2019;s begin by adding a suitable margin and font to the body element of our single page application. We will add it in the src/styles.scss file to apply it globally:\nListing 72. In src/styles.scss:\nbody {\nmargin: 0;\nfont-family: &quot;Segoe UI&quot;, Roboto, sans-serif;\n}\nAt this point, if we run our application with ng serve, this is how it will look like:\nFigure 63. Application with Angular Material set up\nWe will clear the app.component.html file and setup a header with a menu button and some navigational links. We will use mat-toolbar, mat-button, mat-menu, mat-icon and mat-icon-button for this:\nListing 73. app.component.html:\n&lt;mat-toolbar color=&quot;primary&quot;&gt;\n&lt;button mat-icon-button aria-label=&quot;menu&quot;&gt;\n&lt;mat-icon&gt;menu&lt;/mat-icon&gt;\n&lt;/button&gt;\n&lt;button mat-button [matMenuTriggerFor]=&quot;submenu&quot;&gt;Menu 1&lt;/button&gt;\n&lt;button mat-button&gt;Menu 2&lt;/button&gt;\n&lt;button mat-button&gt;Menu 3&lt;/button&gt;\n&lt;mat-menu #submenu=&quot;matMenu&quot;&gt;\n&lt;button mat-menu-item&gt;Sub-menu 1&lt;/button&gt;\n&lt;button mat-menu-item [matMenuTriggerFor]=&quot;submenu2&quot;&gt;Sub-menu 2&lt;/button&gt;\n&lt;/mat-menu&gt;\n&lt;mat-menu #submenu2=&quot;matMenu&quot;&gt;\n&lt;button mat-menu-item&gt;Menu Item 1&lt;/button&gt;\n&lt;button mat-menu-item&gt;Menu Item 2&lt;/button&gt;\n&lt;button mat-menu-item&gt;Menu Item 3&lt;/button&gt;\n&lt;/mat-menu&gt;\n&lt;/mat-toolbar&gt;\nThe color attribute on the mat-toolbar element will give it the primary (indigo) color as defined by our theme. The color attribute works with most Angular Material components; the possible values are &apos;primary&apos;, &apos;accent&apos; and &apos;warn&apos;.\nThe mat-toolbar is a suitable component to represent a header. It serves as a placeholder for elements we want in our header.\nInside the mat-toolbar, we start with a button having mat-icon-button attribute, which itself contains a mat-icon element having the value menu. This will serve as a menu button which we can use to toggle the sidenav.\nWe follow it with some sample buttons having the mat-button attribute. Notice the first button has a property matMenuTriggerFor binded to a local reference submenu. As the property name suggests, the click of this button will display the mat-menu element with the specified local reference as a drop-down menu. The rest of the code is self explanatory.\nFigure 64. This is how our application looks with the first menu button (Menu 1) clicked.\nWe want to keep the sidenav toggling menu button on the left and move the rest to the right to make it look better. To do this we add a class to the menu icon button:\nListing 74. app.component.html:\n...\n&lt;button mat-icon-button aria-label=&quot;menu&quot; class=&quot;menu&quot;&gt;\n&lt;mat-icon&gt;menu&lt;/mat-icon&gt;\n&lt;/button&gt;\n...\nAnd in the app.component.scss file, we add the following style:\nListing 75. app.component.scss:\n.menu {\nmargin-right: auto;\n}\nThe mat-toolbar element already has it&#x2019;s display property set to flex. Setting the menu icon button&#x2019;s margin-right property to auto keeps itself on the left and pushes the other elements to the right.\nFigure 65. Final look of the header.\nNext, we will create a sidenav. But before that lets create a couple of components to navgate between, the links of which we will add to the sidenav.\nWe will use the ng generate component (or ng g c command for short) to create Home and Data components. We nest them in the pages sub-directory since they represent our pages.\nng g c pages/home\nng g c pages/data&apos;;\nLet us set up the routing such that when we visit http://localhost:4200/ root url we see the HomeComponent and when we visit http://localhost:4200/data url we see the DataComponent.\nWe had opted for routing while creating the application, so we have the routing module app-routing.module.ts setup for us. In this file, we have the empty routes array where we set up our routes.\nListing 76. app-routing.module.ts:\n...\nimport { HomeComponent } from &apos;./pages/home/home.component&apos;;\nimport { DataComponent } from &apos;./pages/data/data.component&apos;;\nconst routes: Routes = [\n{ path: &apos;&apos;, component: HomeComponent },\n{ path: &apos;data&apos;, component: DataComponent }\n];\n...\nWe need to provide a hook where the components will be loaded when their respective URLs are loaded. We do that by using the router-outlet directive in the app.component.html.\nListing 77. app.component.html:\n...\n&lt;/mat-toolbar&gt;\n&lt;router-outlet&gt;&lt;/router-outlet&gt;\nNow when we visit the defined URLs we see the appropriate components rendered on screen.\nLets change the contents of the components to have something better.\nListing 78. home.component.html:\n&lt;h2&gt;Home Page&lt;/h2&gt;\nListing 79. home.component.scss:\nh2 {\ntext-align: center;\nmargin-top: 50px;\n}\nListing 80. data.component.html:\n&lt;h2&gt;Data Page&lt;/h2&gt;\nListing 81. data.component.scss:\nh2 {\ntext-align: center;\nmargin-top: 50px;\n}\nThe pages look somewhat better now:\nFigure 66. Home page\nFigure 67. Data page\nLet us finally create the sidenav. To implement the sidenav we need to use 3 Angular Material components: mat-sidenav-container, mat-sidenav and mat-sidenav-content.\nThe mat-sidenav-container, as the name suggests, acts as a container for the sidenav and the associated content. So it is the parent element, and mat-sidenav and mat-sidenav-content are the children sibling elements. mat-sidenav represents the sidenav. We can put any content we want, though it is usually used to conatain a list of navigational links. The mat-sidenav-content element is for conataining our main page content. Since we need the sidenav application-wide, we will put it in the app.component.html.\nListing 82. app.component.html:\n...\n&lt;/mat-toolbar&gt;\n&lt;mat-sidenav-container&gt;\n&lt;mat-sidenav mode=&quot;over&quot; [disableClose]=&quot;false&quot; #sidenav&gt;\nSidenav\n&lt;/mat-sidenav&gt;\n&lt;mat-sidenav-content&gt;\n&lt;router-outlet&gt;&lt;/router-outlet&gt;\n&lt;/mat-sidenav-content&gt;\n&lt;/mat-sidenav-container&gt;\nThe mat-sidenav has a mode property, which accepts one of the 3 values: over, push and side. It decides the behavior of the sidenav. mat-sidenav also has a disableClose property which accents a boolean value. It toggles the behavior where we click on the backdrop or press the Esc key to close the sidenav. There are other properties which we can use to customize the appearance, behavior and position of the sidenav. You can find the properties documented online at https://material.angular.io/components/sidenav/api\nWe moved the router-outlet directive inside the mat-sidenav-content where it will render the routed component.\nBut if you check the running application in the browser, we don&#x2019;t see the sidenav yet. That is because it is closed. We want to have the sidenav opened/closed at the click of the menu icon button on the left side of the header we implemented earlier. Notice we have set a local reference #sidenav on the mat-sidenav element. We can access this element and call its toggle() function to toggle open or close the sidenav.\nListing 83. app.component.html:\n...\n&lt;button mat-icon-button aria-label=&quot;menu&quot; class=&quot;menu&quot; (click)=&quot;sidenav.toggle()&quot;&gt;\n&lt;mat-icon&gt;menu&lt;/mat-icon&gt;\n&lt;/button&gt;\n...\nFigure 68. Sidenav is implemented\nWe can now open the sidenav by clicking the menu icon button. But it does not look right. The sidenav is only as wide as its content. Also the page does not stretch the entire viewport due to lack of content.\nLet&#x2019;s add the following styles to make the page fill the viewport:\nListing 84. app.component.scss:\n...\nmat-sidenav-container {\nposition: absolute;\ntop: 64px;\nleft: 0;\nright: 0;\nbottom: 0;\n}\nThe sidenav&#x2019;s width will be corrected when we add the navigational links to it. That is the only thing remaining to be done. Lets implement it now:\nListing 85. app.component.html:\n...\n&lt;mat-sidenav [disableClose]=&quot;false&quot; mode=&quot;over&quot; #sidenav&gt;\n&lt;mat-nav-list&gt;\n&lt;a\nid=&quot;home&quot;\nmat-list-item\n[routerLink]=&quot;[&apos;./&apos;]&quot;\n(click)=&quot;sidenav.close()&quot;\nrouterLinkActive=&quot;active&quot;\n[routerLinkActiveOptions]=&quot;{exact: true}&quot;\n&gt;\n&lt;mat-icon matListAvatar&gt;home&lt;/mat-icon&gt;\n&lt;h3 matLine&gt;Home&lt;/h3&gt;\n&lt;p matLine&gt;sample home page&lt;/p&gt;\n&lt;/a&gt;\n&lt;a\nid=&quot;sampleData&quot;\nmat-list-item\n[routerLink]=&quot;[&apos;./data&apos;]&quot;\n(click)=&quot;sidenav.close()&quot;\nrouterLinkActive=&quot;active&quot;\n&gt;\n&lt;mat-icon matListAvatar&gt;grid_on&lt;/mat-icon&gt;\n&lt;h3 matLine&gt;Data&lt;/h3&gt;\n&lt;p matLine&gt;sample data page&lt;/p&gt;\n&lt;/a&gt;\n&lt;/mat-nav-list&gt;\n&lt;/mat-sidenav&gt;\n...\nWe use the mat-nav-list element to set a list of navigational links. We use the a tags with mat-list-item directive. We implement a click listener on each link to close the sidenav when it is clicked. The routerLink directive is used to provide the URLs to navigate to. The routerLinkActive directive is used to provide the class name which will be added to the link when it&#x2019;s URL is visited. Here we name the class`active`. To stye it, let&apos; modify the app.component.scss file:\nListing 86. app.component.scss:\n...\nmat-sidenav-container {\n...\na.active {\nbackground: #8e8d8d;\ncolor: #fff;\np {\ncolor: #4a4a4a;\n}\n}\n}\nNow we have a working application with a basic layout: a header with some menu and a sidenav with some navigational links.\nFigure 69. Finished application\n"},{"id":802,"path":"../website/pages/docs/master-devon4ng.asciidoc_layouts.html#guide-layout-with-angular-material.asciidoc_conclusion","type":"docs","title":"Conclusion","body":"20.1.4. Conclusion\nThe purpose of this guide was to provide a basic understanding of creating layouts with Angular Material. The Angular Material library has a huge collection of ready to use components which can be found at https://material.angular.io/components/categories\nIt has provided documentation and example usage for each of its components. Going through the documentation will give a better understanding of using Angular Material components in our devon4ng applications.\n&#x2190;&#xA0;Previous:&#xA0;Ionic&#xA0;| &#x2191;&#xA0;Up:&#xA0;devon4ng&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;NgRx&#xA0;&#x2192;\n"},{"id":803,"path":"../website/pages/docs/master-devon4ng.asciidoc_ngrx.html#master-devon4ng.asciidoc_ngrx","type":"docs","title":"NgRx","body":"21. NgRx\n"},{"id":804,"path":"../website/pages/docs/master-devon4ng.asciidoc_ngrx.html#guide-ngrx-getting-started.asciidoc","type":"docs","title":"Introduction to NgRx","body":"21.1. Introduction to NgRx\nNgRx is a state management framework for Angular based on the Redux pattern.\n"},{"id":805,"path":"../website/pages/docs/master-devon4ng.asciidoc_ngrx.html#guide-ngrx-getting-started.asciidoc_the-need-for-client-side-state-management","type":"docs","title":"The need for client side state management","body":"21.1.1. The need for client side state management\nYou may wonder why you should bother with state management. Usually data resides in a backend storage system, e.g. a database, and is retrieved by the client on a per-need basis. To add, update, or delete entities from this store, clients have to invoke API endpoints at the backend. Mimicking database-like transactions on the client side may seem redundant. However, there are many use cases for which a global client-side state is appropriate:\nthe client has some kind of global state which should survive the destruction of a component, but does not warrant server side persistence, for example: volume level of media, expansion status of menus\nsever side data should not be retrieved every time it is needed, either because multiple components consume it, or because it should be cached, e.g. the personal watchlist in an online streaming app\nthe app provides a rich experience with offline functionality, e.g. a native app built with Ionic\nSaving global states inside the services they originates from results in a data flow that is hard to follow and state becoming inconsistent due to unordered state mutations. Following the single source of truth principle, there should be a central location holding all your application&#x2019;s state, just like a server side database does. State managament libraries for Angular provide tools for storing, retrieving, and updating client-side state.\n"},{"id":806,"path":"../website/pages/docs/master-devon4ng.asciidoc_ngrx.html#guide-ngrx-getting-started.asciidoc_why-ngrx","type":"docs","title":"Why NgRx?","body":"21.1.2. Why NgRx?\nAs stated in the introduction, devon4ng does not stipulate a particular state library, or require using one at all. However, NgRx has proven to be a robust, mature solution for this task, with good tooling and 3rd-party library support. Albeit introducing a level of indirection that requires additional effort even for simple features, the redux concept enforces a clear separation of concerns leading to a cleaner architecture.\nNonetheless, you should always compare different approaches to state management and pick the best one suiting your use case. Here&#x2019;s a (non-exhaustive) list of competing state management libraries:\nPlain Rxjs using the simple store described in Abstract Class Store\nNgXS reduces some boilerplate of NgRx by leveraging the power of decorators and moving side effects to the store\nMobX follows a more imperative approach in contrast to the functional Redux pattern\nAkita also uses an imperative approach with direct setters in the store, but keeps the concept of immutable state transitions\n"},{"id":807,"path":"../website/pages/docs/master-devon4ng.asciidoc_ngrx.html#guide-ngrx-getting-started.asciidoc_setup","type":"docs","title":"Setup","body":"21.1.3. Setup\nTo get a quick start, use the provided template for devon4ng + NgRx.\nTo manually install the core store package together with a set of useful extensions:\nNPM:\nnpm install @ngrx/store @ngrx/effects @ngrx/entity @ngrx/store-devtools --save\nYarn:\nyarn add @ngrx/store @ngrx/effects @ngrx/entity @ngrx/store-devtools\nWe recommend to add the NgRx schematics to your project so you can create code artifacts from the command line:\nNPM:\nnpm install @ngrx/schematics --save-dev\nYarn:\nyarn add @ngrx/schematics --dev\nAfterwards, make NgRx your default schematics provider, so you don&#x2019;t have to type the qualified package name every time:\nng config cli.defaultCollection @ngrx/schematics\nIf you have custom settings for Angular schematics, you have to configure them as described here.\n"},{"id":808,"path":"../website/pages/docs/master-devon4ng.asciidoc_ngrx.html#guide-ngrx-getting-started.asciidoc_concept","type":"docs","title":"Concept","body":"21.1.4. Concept\nFigure 70. NgRx architecture overview\nFigure 1 gives an overview of the NgRx data flow. The single source of truth is managed as an immutable state object by the store. Components dispatch actions to trigger state changes. Actions are handed over to reducers, which take the current state and action data to compute the next state. Actions are also consumed byeffects, which perform side-effects such as retrieving data from the backend, and may dispatch new actions as a result. Components subscribe to state changes using selectors.\nContinue with Creating a Simple Store.\n"},{"id":809,"path":"../website/pages/docs/master-devon4ng.asciidoc_ngrx.html#guide-ngrx-simple-store.asciidoc","type":"docs","title":"State, Selection and Reducers","body":"21.2. State, Selection and Reducers\n"},{"id":810,"path":"../website/pages/docs/master-devon4ng.asciidoc_ngrx.html#guide-ngrx-simple-store.asciidoc_creating-a-simple-store","type":"docs","title":"Creating a Simple Store","body":"21.2.1. Creating a Simple Store\nIn the following pages we use the example of an online streaming service. We will model a particular feature, a watchlist that can be populated by the user with movies she or he wants to see in the future.\nInitializing NgRx\nIf you&#x2019;re starting fresh, you first have to initialize NgRx and create a root state. The fastest way to do this is using the schematic:\nng generate @ngrx/schematics:store State --root --module app.module.ts\nThis will automatically generate a root store and register it in the app module. Next we generate a feature module for the watchlist:\nng generate module watchlist\nand create a corresponding feature store:\nng generate store watchlist/Watchlist -m watchlist.module.ts\nThis generates a file watchlist/reducers/index.ts with the reducer function, and registers the store in the watchlist module declaration.\nWarning\nIf you&#x2019;re getting an error Schematic &quot;store&quot; not found in collection &quot;@schematics/angular&quot;, this means you forgot to register the NgRx schematics as default.\nNext, add the WatchlistModule to the AppModule imports so the feature store is registered when the application starts. We also added the store devtools which we will use later, resulting in the following file:\napp.module.ts\nimport { BrowserModule } from &apos;@angular/platform-browser&apos;;\nimport { NgModule } from &apos;@angular/core&apos;;\nimport { AppComponent } from &apos;./app.component&apos;;\nimport { EffectsModule } from &apos;@ngrx/effects&apos;;\nimport { AppEffects } from &apos;./app.effects&apos;;\nimport { StoreModule } from &apos;@ngrx/store&apos;;\nimport { reducers, metaReducers } from &apos;./reducers&apos;;\nimport { StoreDevtoolsModule } from &apos;@ngrx/store-devtools&apos;;\nimport { environment } from &apos;../environments/environment&apos;;\nimport { WatchlistModule } from &apos;./watchlist/watchlist.module&apos;;\n@NgModule({\ndeclarations: [\nAppComponent\n],\nimports: [\nBrowserModule,\nWatchlistModule,\nStoreModule.forRoot(reducers, { metaReducers }),\n// Instrumentation must be imported after importing StoreModule (config is optional)\nStoreDevtoolsModule.instrument({\nmaxAge: 25, // Retains last 25 states\nlogOnly: environment.production, // Restrict extension to log-only mode\n}),\n!environment.production ? StoreDevtoolsModule.instrument() : []\n],\nproviders: [],\nbootstrap: [AppComponent]\n})\nexport class AppModule { }\nCreate an entity model and initial state\nWe need a simple model for our list of movies. Create a file watchlist/models/movies.ts and insert the following code:\nexport interface Movie {\nid: number;\ntitle: string;\nreleaseYear: number;\nruntimeMinutes: number;\ngenre: Genre;\n}\nexport type Genre = &apos;action&apos; | &apos;fantasy&apos; | &apos;sci-fi&apos; | &apos;romantic&apos; | &apos;comedy&apos; | &apos;mystery&apos;;\nexport interface WatchlistItem {\nid: number;\nmovie: Movie;\nadded: Date;\nplaybackMinutes: number;\n}\nNote\nWe discourage putting several types into the same file and do this only for the sake of keeping this tutorial brief.\nLater we will learn how to retrieve data from the backend using effects. For now we will create an initial state for the user with a default movie.\nState is defined and transforms by a reducer function. Let&#x2019;s create a watchlist reducer:\ncd watchlist/reducers\nng g reducer WatchlistData --reducers index.ts\nOpen the generated file watchlist-data.reducer.ts. You see three exports: The State interface defines the shape of the state. There is only one instance of a feature state in the store at all times. The initialState constant is the state at application creation time. The reducer function will later be called by the store to produce the next state instance based on the current state and an action object.\nLet&#x2019;s put a movie into the user&#x2019;s watchlist:\nwatchlist-data.reducer.ts\nexport interface State {\nitems: WatchlistItem[];\n}\nexport const initialState: State = {\nitems: [\n{\nid: 42,\nmovie: {\nid: 1,\ntitle: &apos;Die Hard&apos;,\ngenre: &apos;action&apos;,\nreleaseYear: 1988,\nruntimeMinutes: 132\n},\nplaybackMinutes: 0,\nadded: new Date(),\n}\n]\n};\nSelect the current watchlist\nState slices can be retrieved from the store using selectors.\nCreate a watchlist component:\nng g c watchlist/Watchlist\nand add it to the exports of WatchlistModule. Also, replace app.component.html with\n&lt;app-watchlist&gt;&lt;/app-watchlist&gt;\nState observables are obtained using selectors. They are memoized by default, meaning that you don&#x2019;t have to worry about performance if you use complicated calculations when deriving state&#x2009;&#x2014;&#x2009;these are only performed once per state emission.\nAdd a selector to watchlist-data.reducer.ts:\nexport const getAllItems = (state: State) =&gt; state.items;\nNext, we have to re-export the selector for this substate in the feature reducer. Modify the watchlist/reducers/index.ts like this:\nwatchlist/reducers/index.ts\nimport {\nActionReducer,\nActionReducerMap,\ncreateFeatureSelector,\ncreateSelector,\nMetaReducer\n} from &apos;@ngrx/store&apos;;\nimport { environment } from &apos;src/environments/environment&apos;;\nimport * as fromWatchlistData from &apos;./watchlist-data.reducer&apos;;\nimport * as fromRoot from &apos;src/app/reducers/index&apos;;\nexport interface WatchlistState { (1)\nwatchlistData: fromWatchlistData.State;\n}\nexport interface State extends fromRoot.State { (2)\nwatchlist: WatchlistState;\n}\nexport const reducers: ActionReducerMap&lt;WatchlistState&gt; = { (3)\nwatchlistData: fromWatchlistData.reducer,\n};\nexport const metaReducers: MetaReducer&lt;WatchlistState&gt;[] = !environment.production ? [] : [];\nexport const getFeature = createFeatureSelector&lt;State, WatchlistState&gt;(&apos;watchlist&apos;); (4)\nexport const getWatchlistData = createSelector( (5)\ngetFeature,\nstate =&gt; state.watchlistData\n);\nexport const getAllItems = createSelector( (6)\ngetWatchlistData,\nfromWatchlistData.getAllItems\n);\nThe feature state, each member is managed by a different reducer\nFeature states are registered by the forFeature method. This interface provides a typesafe path from root to feature state.\nTie substates of a feature state to the corresponding reducers\nCreate a selector to access the &apos;watchlist&apos; feature state\nselect the watchlistData sub state\nre-export the selector\nNote how createSelector allows to chain selectors. This is a powerful tool that also allows for selecting from multiple states.\nYou can use selectors as pipeable operators:\nwatchlist.component.ts\nexport class WatchlistComponent {\nwatchlistItems$: Observable&lt;WatchlistItem[]&gt;;\nconstructor(\nprivate store: Store&lt;fromWatchlist.State&gt;\n) {\nthis.watchlistItems$ = this.store.pipe(select(fromWatchlist.getAllItems));\n}\n}\nwatchlist.component.html\n&lt;h1&gt;Watchlist&lt;/h1&gt;\n&lt;ul&gt;\n&lt;li *ngFor=&quot;let item of watchlistItems$ | async&quot;&gt;{{item.movie.title}} ({{item.movie.releaseYear}}): {{item.playbackMinutes}}/{{item.movie.runtimeMinutes}} min watched&lt;/li&gt;\n&lt;/ul&gt;\nDispatching an action to update watched minutes\nWe track the user&#x2019;s current progress at watching a movie as the playbackMinutes property. After closing a video, the watched minutes have to be updated. In NgRx, state is being updated by dispatching actions. An action is an option with a (globally unique) type discriminator and an optional payload.\nCreating the action\nCreate a file playback/actions/index.ts. In this example, we do not further separate the actions per sub state. Actions can be defined by using action creators:\nplayback/actions/index.ts\nimport { createAction, props, union } from &apos;@ngrx/store&apos;;\nexport const playbackFinished = createAction(&apos;[Playback] Playback finished&apos;, props&lt;{ movieId: number, stoppedAtMinute: number }&gt;());\nconst actions = union({\nplaybackFinished\n});\nexport type ActionsUnion = typeof actions;\nFirst we specify the type, followed by a call to the payload definition function. Next, we create a union of all possible actions for this file using union, which allows us a to access action payloads in the reducer in a typesafe way.\nTip\nAction types should follow the naming convention [Source] Event, e.g. [Recommended List] Hide Recommendation or [Auth API] Login Success. Think of actions rather as events than commands. You should never use the same action at two different places (you can still handle multiple actions the same way). This faciliates tracing the source of an action. For details see Good Action Hygiene with NgRx by Mike Ryan (video).\nDispatch\nWe skip the implementation of an actual video playback page and simulate wathcing a movie in 10 minute segments by adding a link in the template:\nwatchlist-component.html\n&lt;li *ngFor=&quot;let item of watchlistItems$ | async&quot;&gt;... &lt;button (click)=&quot;stoppedPlayback(item.movie.id, item.playbackMinutes + 10)&quot;&gt;Add 10 Minutes&lt;/button&gt;&lt;/li&gt;\nwatchlist-component.ts\nimport * as playbackActions from &apos;src/app/playback/actions&apos;;\n...\nstoppedPlayback(movieId: number, stoppedAtMinute: number) {\nthis.store.dispatch(playbackActions.playbackFinished({ movieId, stoppedAtMinute }));\n}\nState reduction\nNext, we handle the action inside the watchlistData reducer. Note that actions can be handled by multiple reducers and effects at the same time to update different states, for example if we&#x2019;d like to show a rating modal after playback has finished.\nwatchlist-data.reducer.ts\nexport function reducer(state = initialState, action: playbackActions.ActionsUnion): State {\nswitch (action.type) {\ncase playbackActions.playbackFinished.type:\nreturn {\n...state,\nitems: state.items.map(updatePlaybackMinutesMapper(action.movieId, action.stoppedAtMinute))\n};\ndefault:\nreturn state;\n}\n}\nexport function updatePlaybackMinutesMapper(movieId: number, stoppedAtMinute: number) {\nreturn (item: WatchlistItem) =&gt; {\nif (item.movie.id === movieId) {\nreturn {\n...item,\nplaybackMinutes: stoppedAtMinute\n};\n} else {\nreturn item;\n}\n};\n}\nNote how we changed the reducer&#x2019;s function signature to reference the actions union. The switch-case handles all incoming actions to produce the next state. The default case handles all actions a reducer is not interested in by returning the state unchanged. Then we find the watchlist item corresponding to the movie with the given id and update the playback minutes. Since state is immutable, we have to clone all objects down to the one we would like to change using the object spread operator (&#x2026;&#x200B;).\nCaution\nSelectors rely on object identity to decide whether the value has to be recalculated. Do not clone objects that are not on the path to the change you want to make. This is why updatePlaybackMinutesMapper returns the same item if the movie id does not match.\nAlternative state mapping with immer\nIt can be hard to think in immutable changes, especially if your team has a strong background in imperative programming. In this case, you may find the immer library convenient, which allows to produce immutable objects by manipulating a proxied draft. The same reducer can then be written as:\nwatchlist-data.reducer.ts with immer\nimport { produce } from &apos;immer&apos;;\n...\ncase playbackActions.playbackFinished.type:\nreturn produce(state, draft =&gt; {\nconst itemToUpdate = draft.items.find(item =&gt; item.movie.id === action.movieId);\nif (itemToUpdate) {\nitemToUpdate.playbackMinutes = action.stoppedAtMinute;\n}\n});\nImmer works out of the box with plain objects and arrays.\nRedux devtools\nIf the StoreDevToolsModule is instrumented as described above, you can use the browser extension Redux devtools to see all dispatched actions and the resulting state diff, as well as the current state, and even travel back in time by undoing actions.\nFigure 71. Redux devtools\nContinue with learning about effects\n"},{"id":811,"path":"../website/pages/docs/master-devon4ng.asciidoc_ngrx.html#guide-ngrx-effects.asciidoc","type":"docs","title":"Side effects with NgRx/Effects","body":"21.3. Side effects with NgRx/Effects\nReducers are pure functions, meaning they are side-effect free and deterministic. Many actions however have side effects like sending messages or displaying a toast notification. NgRx encapsulates these actions in effects.\nLet&#x2019;s build a recommended movies list so the user can add movies to their watchlist.\n"},{"id":812,"path":"../website/pages/docs/master-devon4ng.asciidoc_ngrx.html#guide-ngrx-effects.asciidoc_obtaining-the-recommendation-list-from-the-server","type":"docs","title":"Obtaining the recommendation list from the server","body":"21.3.1. Obtaining the recommendation list from the server\nCreate a module for recommendations and add stores and states as in the previous chapter. Add EffectsModule.forRoot([]) to the imports in AppModule below StoreModule.forRoot(). Add effects to the feature module:\nng generate effect recommendation/Recommendation -m recommendation/recommendation.module.ts\nWe need actions for loading the movie list, success and failure cases:\nrecommendation/actions/index.ts\nimport { createAction, props, union } from &apos;@ngrx/store&apos;;\nimport { Movie } from &apos;src/app/watchlist/models/movies&apos;;\nexport const loadRecommendedMovies = createAction(&apos;[Recommendation List] Load movies&apos;);\nexport const loadRecommendedMoviesSuccess = createAction(&apos;[Recommendation API] Load movies success&apos;, props&lt;{movies: Movie[]}&gt;());\nexport const loadRecommendedMoviesFailure = createAction(&apos;[Recommendation API] Load movies failure&apos;, props&lt;{error: any}&gt;());\nconst actions = union({\nloadRecommendedMovies,\nloadRecommendedMoviesSuccess,\nloadRecommendedMoviesFailure\n});\nexport type ActionsUnion = typeof actions;\nIn the reducer, we use a loading flag so the UI can show a loading spinner. The store is updated with arriving data.\nrecommendation/actions/index.ts\nexport interface State {\nitems: Movie[];\nloading: boolean;\n}\nexport const initialState: State = {\nitems: [],\nloading: false\n};\nexport function reducer(state = initialState, action: recommendationActions.ActionsUnion): State {\nswitch (action.type) {\ncase &apos;[Recommendation List] Load movies&apos;:\nreturn {\n...state,\nitems: [],\nloading: true\n};\ncase &apos;[Recommendation API] Load movies failure&apos;:\nreturn {\n...state,\nloading: false\n};\ncase &apos;[Recommendation API] Load movies success&apos;:\nreturn {\n...state,\nitems: action.movies,\nloading: false\n};\ndefault:\nreturn state;\n}\n}\nexport const getAll = (state: State) =&gt; state.items;\nexport const isLoading = (state: State) =&gt; state.loading;\nWe need an API service to talk to the server. For demonstration purposes, we simulate an answer delayed by one second:\nrecommendation/services/recommendation-api.service.ts\n@Injectable({\nprovidedIn: &apos;root&apos;\n})\nexport class RecommendationApiService {\nprivate readonly recommendedMovies: Movie[] = [\n{\nid: 2,\ntitle: &apos;The Hunger Games&apos;,\ngenre: &apos;sci-fi&apos;,\nreleaseYear: 2012,\nruntimeMinutes: 144\n},\n{\nid: 4,\ntitle: &apos;Avengers: Endgame&apos;,\ngenre: &apos;fantasy&apos;,\nreleaseYear: 2019,\nruntimeMinutes: 181\n}\n];\nloadRecommendedMovies(): Observable&lt;Movie[]&gt; {\nreturn of(this.recommendedMovies).pipe(delay(1000));\n}\n}\nHere are the effects:\nrecommendation/services/recommendation-api.service.ts\n@Injectable()\nexport class RecommendationEffects {\nconstructor(\nprivate actions$: Actions,\nprivate recommendationApi: RecommendationApiService,\n) { }\n@Effect()\nloadBooks$ = this.actions$.pipe(\nofType(recommendationActions.loadRecommendedMovies.type),\nswitchMap(() =&gt; this.recommendationApi.loadRecommendedMovies().pipe(\nmap(movies =&gt; recommendationActions.loadRecommendedMoviesSuccess({ movies })),\ncatchError(error =&gt; of(recommendationActions.loadRecommendedMoviesFailure({ error })))\n))\n);\n}\nEffects are always observables and return actions. In this example, we consume the actions observable provided by NgRx and listen only for the loadRecommendedMovies actions by using the ofType operator. Using switchMap, we map to a new observable, one that loads movies and maps the successful result to a new loadRecommendedMoviesSuccess action or a failure to loadRecommendedMoviesFailure. In a real application we would show a notification in the error case.\nNote\nIf an effect should not dispatch another action, return an empty observable.\nContinue reading how to simplify CRUD (Create Read Update Delete) operations using @ngrx/entity.\n"},{"id":813,"path":"../website/pages/docs/master-devon4ng.asciidoc_ngrx.html#guide-ngrx-entity.asciidoc","type":"docs","title":"Simplifying CRUD with NgRx/Entity","body":"21.4. Simplifying CRUD with NgRx/Entity\nMost of the time when manipulating entries in the store, we like to create, add, update, or delete entries (CRUD). NgRx/Entity provides convenience functions if each item of a collection has an id property. Luckily all our entities already have this property.\nLet&#x2019;s add functionality to add a movie to the watchlist. First, create the required action:\nrecommendation/actions/index.ts\nexport const addToWatchlist = createAction(&apos;[Recommendation List] Add to watchlist&apos;,\nprops&lt;{ watchlistItemId: number, movie: Movie, addedAt: Date }&gt;());\nNote\nYou may wonder why the Date object is not created inside the reducer instead, since it should always be the current time. However, remember that reducers should be deterministic state machines&#x2009;&#x2014;&#x2009;State A + Action B should always result in the same State C. This makes reducers easily testable.\nThen, rewrite the watchlistData reducer to make use of NgRx/Entity:\nrecommendation/actions/index.ts\nexport interface State extends EntityState&lt;WatchlistItem&gt; { (1)\n}\nexport const entityAdapter = createEntityAdapter&lt;WatchlistItem&gt;(); (2)\nexport const initialState: State = entityAdapter.getInitialState(); (3)\nconst entitySelectors = entityAdapter.getSelectors();\nexport function reducer(state = initialState, action: playbackActions.ActionsUnion | recommendationActions.ActionsUnion): State {\nswitch (action.type) {\ncase playbackActions.playbackFinished.type:\nconst itemToUpdate = entitySelectors\n.selectAll(state) (4)\n.find(item =&gt; item.movie.id === action.movieId);\nif (itemToUpdate) {\nreturn entityAdapter.updateOne({ (5)\nid: itemToUpdate.id,\nchanges: { playbackMinutes: action.stoppedAtMinute } (6)\n}, state);\n} else {\nreturn state;\n}\ncase recommendationActions.addToWatchlist.type:\nreturn entityAdapter.addOne({id: action.watchlistItemId, movie: action.movie, added: action.addedAt, playbackMinutes: 0}, state);\ndefault:\nreturn state;\n}\n}\nexport const getAllItems = entitySelectors.selectAll;\nNgRx/Entity requires state to extend EntityState. It provides a list of ids and a dictionary of id &#x21D2; entity entries\nThe entity adapter provides data manipulation operations and selectors\nThe state can be initialized with getInitialState(), which accepts an optional object to define any additional state beyond EntityState\nselectAll returns an array of all entities\nAll adapter operations consume the state object as the last argument and produce a new state\nUpdate methods accept a partial change definition; you don&#x2019;t have to clone the object\nThis concludes the tutorial on NgRx. If you want to learn about advanced topics such as selectors with arguments, testing, or router state, head over to the official NgRx documentation.\n&#x2190;&#xA0;Previous:&#xA0;Layouts&#xA0;| &#x2191;&#xA0;Up:&#xA0;devon4ng&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Cookbook&#xA0;&#x2192;\n"},{"id":814,"path":"../website/pages/docs/master-devon4node.asciidoc.html#master-devon4node.asciidoc","type":"docs","title":"VI. devon4node","body":"VI. devon4node\ndevonfw is a platform which provides solutions to building business applications which combine best-in-class frameworks and libraries as well as industry proven practices and code conventions. devonfw is 100% Open Source (Apache License version 2.0) since the beginning of 2018.\ndevon4node is the NodeJS stack of devonfw. It allows you to build business applications (backends) using NodeJS technology in standardized way based on established best-practices.\ndevon4node is based on NestJS. Nest (NestJS) is a framework for building efficient, scalable Node.js server-side applications. It uses progressive TypeScript and combines elements of OOP (Object Oriented Programming), FP (Functional Programming), and FRP (Functional Reactive Programming).\ndevon4node Architecture\nLayers\nGuides\ndevon4node applications\n&#x2190;&#xA0;Previous:&#xA0;Samples&#xA0;| &#x2191;&#xA0;Up:&#xA0;devonfw guide&#xA0;| Next:&#xA0;devon4node Architecture&#xA0;&#x2192;\n"},{"id":815,"path":"../website/pages/docs/master-devon4node.asciidoc_devon4node-applications.html#master-devon4node.asciidoc_devon4node-applications","type":"docs","title":"devon4node applications","body":"35. devon4node applications\n"},{"id":816,"path":"../website/pages/docs/master-devon4node.asciidoc_devon4node-applications.html#samples.asciidoc","type":"docs","title":"devon4node Samples","body":"35.1. devon4node Samples\nIn the folder /samples, you can find some devon4node examples that could be useful for you in order to understand better the framework.\nThe samples are:\nTodo\nEmployee\nComponents example\nAlso, we have another realistic example in the My Thai Star repository. This example is the implementation of My Thai Star backend, which is compatible with the frontend made with Angular. To do that, this node implementation exposes the same API as Java backend. Take care with this example, as we need to follow the Java API, some components do not follow the devon4node patterns and code conventions.\n"},{"id":817,"path":"../website/pages/docs/master-devon4node.asciidoc_devon4node-applications.html#samples.asciidoc_todo-example","type":"docs","title":"Todo example","body":"35.1.1. Todo example\nThis example is the backend part of an TO-DO application. It exposes and API where you can create, read, update and delete a TO-DO list.\nIn order to start the application, run the following commands in the todo folder:\n$ yarn\n$ yarn build\n$ yarn start\nNow, you can access to the application using the url http://localhost:3000/v1/todo/todos. If you want to now all endpoints exposed, you can see the swagger at: http://localhost:3000/v1/api.\nAlso, in this example we show you how to control the access to you application by implementing an authentication mechanism using JWT and rol based strategy. In order to access to the list of todos (http://localhost:3000/v1/todo/todos), first you need to call to POST http://localhost:3000/v1/auth/login and in the body you need to send the user information:\n{\n&quot;username&quot;: &quot;user&quot;,\n&quot;password&quot;: &quot;password&quot;\n}\nIt will return a JWT token for the user user. The rol of this user is USER, so you can only access to the methods GET, POST and DELETE of the endpoint http://localhost:3000/v1/todo/todos. If you login with the user admin/admin, you will be able to access to the methods UPDATE and PATCH.\n"},{"id":818,"path":"../website/pages/docs/master-devon4node.asciidoc_devon4node-applications.html#samples.asciidoc_employee-example","type":"docs","title":"Employee example","body":"35.1.2. Employee example\nThis is an example of employee management application. With the application you can create, read, update and delete employees.\nIn order to start the application, run the following commands in the todo folder:\n$ yarn\n$ yarn build\n$ yarn start\nNow, you can access to the application using the url http://localhost:8081/v1/employee/employees. If you want to now all endpoints exposed, you can see the swagger at: http://localhost:8081/v1/api.\nThis is a simple example without authentication. With this example you can learn how to work with database migrations. You can find them in the folder /src/migrations. The TypeORM is configured in order to execute the migrations every time that you start this application (&quot;migrationsRun&quot;: true at ormconfig.json). You can also execute the migration manually by typing the command devon4node db migration:run, or revert executing devon4node db migration:revert. Take into account that the database that this application is using is an in-memory sqlite, so every time that you stop the application all data is lost.\n"},{"id":819,"path":"../website/pages/docs/master-devon4node.asciidoc_devon4node-applications.html#samples.asciidoc_components-example","type":"docs","title":"Components example","body":"35.1.3. Components example\nThis example allow you to understand better the execution order of the components of a devon4node application (guards, pipes, interceptors, filters, middleware).\nIn order to start the application, run the following commands in the todo folder:\n$ yarn\n$ yarn build\n$ yarn start\nIn order to see the execution order, you can call to http://localhost:3000/v1. It will show you the execution order of all components except the filters. If you want to know the execution order while a filter is applied, call to the endpoint with the following queries: ?hello=error, ?hello=controller, ?hello=global.\n"},{"id":820,"path":"../website/pages/docs/master-devon4node.asciidoc_devon4node-applications.html#samples-step-by-step.asciidoc","type":"docs","title":"Create the employee sample step by step","body":"35.2. Create the employee sample step by step\n"},{"id":821,"path":"../website/pages/docs/master-devon4node.asciidoc_devon4node-applications.html#samples-step-by-step.asciidoc_application-requisites","type":"docs","title":"Application requisites","body":"35.2.1. Application requisites\nThe employee application needs:\nA configuration module\nA SQLite in memory database\nSecurity: CORS\nSwagger support\nAuthentication using JWT\nCRUD for manage employees. The employees will have the following properties:\nname\nsurname\nemail\n"},{"id":822,"path":"../website/pages/docs/master-devon4node.asciidoc_devon4node-applications.html#samples-step-by-step.asciidoc_create-the-application","type":"docs","title":"Create the application","body":"35.2.2. Create the application\nInstall Nest CLI\nExecute the command yarn global add @nestjs/cli\nInstall devon4node schematics\nExecute the command yarn global add @devon4node/schematics\nCreate the new application\nExecute the command nest g -c @devon4node/schematics application employee\nThen, we need to add some components, go inside the project folder and execute the following commands:\nGo inside project folder: cd employee.\nConfig module: nest g -c @devon4node/schematics config-module.\nTypeorm database, choose sqlite DB when asked nest g -c @devon4node/schematics typeorm.\nAdd security: nest g -c @devon4node/schematics security.\nSwagger module: nest g -c @devon4node/schematics swagger.\nAuth-jwt authentication: nest g -c @devon4node/schematics auth-jwt.\nAdd an application module: nest g -c @devon4node/schematics module employee.\nAdd CRUD component: nest g -c @devon4node/schematics crud employee/employee.\nWith this, you will generate the following files:\n/employee/.prettierrc\n/employee/nest-cli.json\n/employee/package.json\n/employee/README.md\n/employee/tsconfig.build.json\n/employee/tsconfig.json\n/employee/tslint.json\n/employee/src/main.ts\n/employee/test/app.e2e-spec.ts\n/employee/test/jest-e2e.json\n/employee/src/app/app.controller.spec.ts\n/employee/src/app/app.controller.ts\n/employee/src/app/app.module.ts\n/employee/src/app/app.service.ts\n/employee/src/app/core/core.module.ts\n/employee/src/app/shared/logger/winston.logger.ts\n/employee/src/app/core/configuration/configuration.module.ts\n/employee/src/app/core/configuration/model/index.ts\n/employee/src/app/core/configuration/model/types.ts\n/employee/src/app/core/configuration/services/configuration.service.spec.ts\n/employee/src/app/core/configuration/services/configuration.service.ts\n/employee/src/app/core/configuration/services/index.ts\n/employee/src/config/default.ts\n/employee/src/config/develop.ts\n/employee/src/config/production.ts\n/employee/src/config/test.ts\n/employee/src/config/uat.ts\n/employee/docker-compose.yml\n/employee/ormconfig.json\n/employee/src/app/shared/model/entities/base-entity.entity.ts\n/employee/src/app/core/auth/auth.module.ts\n/employee/src/app/core/auth/controllers/auth.controller.spec.ts\n/employee/src/app/core/auth/controllers/auth.controller.ts\n/employee/src/app/core/auth/controllers/index.ts\n/employee/src/app/core/auth/decorators/index.ts\n/employee/src/app/core/auth/decorators/roles.decorator.spec.ts\n/employee/src/app/core/auth/decorators/roles.decorator.ts\n/employee/src/app/core/auth/guards/index.ts\n/employee/src/app/core/auth/guards/roles.guard.spec.ts\n/employee/src/app/core/auth/guards/roles.guard.ts\n/employee/src/app/core/auth/model/index.ts\n/employee/src/app/core/auth/model/roles.enum.ts\n/employee/src/app/core/auth/model/user-request.interface.ts\n/employee/src/app/core/auth/services/auth.service.spec.ts\n/employee/src/app/core/auth/services/auth.service.ts\n/employee/src/app/core/auth/services/index.ts\n/employee/src/app/core/auth/strategies/index.ts\n/employee/src/app/core/auth/strategies/jwt.strategy.spec.ts\n/employee/src/app/core/auth/strategies/jwt.strategy.ts\n/employee/src/app/core/user/user.module.ts\n/employee/src/app/core/user/model/index.ts\n/employee/src/app/core/user/model/dto/user-payload.dto.ts\n/employee/src/app/core/user/model/entities/user.entity.ts\n/employee/src/app/core/user/services/index.ts\n/employee/src/app/core/user/services/user.service.spec.ts\n/employee/src/app/core/user/services/user.service.ts\n/employee/test/auth/auth.service.mock.ts\n/employee/test/user/user.repository.mock.ts\n/employee/src/app/employee/employee.module.ts\n/employee/src/app/employee/model/entities/employee.entity.ts\n/employee/src/app/employee/model/index.ts\n/employee/src/app/employee/controllers/employee.crud.controller.ts\n/employee/src/app/employee/services/employee.crud.service.ts\n/employee/src/app/employee/services/index.ts\n/employee/src/app/employee/controllers/index.ts\nOpen the VSCode\nExecute the commands:\nyarn install\ncode .\nFill in the entity: src/app/employee/model/entities/employee.entity.ts\nAdd the columns\n@Entity()\nexport class Employee extends BaseEntity {\n@Column(&apos;varchar&apos;, { length: 255, nullable: true })\nname?: string;\n@Column(&apos;varchar&apos;, { length: 255, nullable: true })\nsurname?: string;\n@Column(&apos;varchar&apos;, { length: 255, nullable: true })\nemail?: string;\n}\nAdd the validations\n@Entity()\nexport class Employee extends BaseEntity {\n@IsDefined({ groups: [CrudValidationGroups.CREATE] })\n@IsOptional({ groups: [CrudValidationGroups.UPDATE] })\n@MaxLength(255)\n@Column(&apos;varchar&apos;, { length: 255, nullable: true })\nname?: string;\n@IsDefined({ groups: [CrudValidationGroups.CREATE] })\n@IsOptional({ groups: [CrudValidationGroups.UPDATE] })\n@MaxLength(255)\n@Column(&apos;varchar&apos;, { length: 255, nullable: true })\nsurname?: string;\n@IsDefined({ groups: [CrudValidationGroups.CREATE] })\n@IsOptional({ groups: [CrudValidationGroups.UPDATE] })\n@MaxLength(255)\n@IsEmail()\n@Column(&apos;varchar&apos;, { length: 255, nullable: true })\nemail?: string;\n}\nAdd the transformations\nIn this specific case, we will not transform any property, but you can see an example in the src/app/shared/model/entities/base-entity.entity.ts file.\nexport abstract class BaseEntity {\n@PrimaryGeneratedColumn(&apos;increment&apos;)\nid!: number;\n@VersionColumn({ default: 1 })\n@Exclude({ toPlainOnly: true })\nversion!: number;\n@CreateDateColumn()\n@Exclude({ toPlainOnly: true })\ncreatedAt!: string;\n@UpdateDateColumn()\n@Exclude({ toPlainOnly: true })\nupdatedAt!: string;\n}\nAdd swagger metadata\n@Entity()\nexport class Employee extends BaseEntity {\n@ApiPropertyOptional()\n@IsDefined({ groups: [CrudValidationGroups.CREATE] })\n@IsOptional({ groups: [CrudValidationGroups.UPDATE] })\n@MaxLength(255)\n@Column(&apos;varchar&apos;, { length: 255, nullable: true })\nname?: string;\n@ApiPropertyOptional()\n@IsDefined({ groups: [CrudValidationGroups.CREATE] })\n@IsOptional({ groups: [CrudValidationGroups.UPDATE] })\n@MaxLength(255)\n@Column(&apos;varchar&apos;, { length: 255, nullable: true })\nsurname?: string;\n@ApiPropertyOptional()\n@IsDefined({ groups: [CrudValidationGroups.CREATE] })\n@IsOptional({ groups: [CrudValidationGroups.UPDATE] })\n@MaxLength(255)\n@IsEmail()\n@Column(&apos;varchar&apos;, { length: 255, nullable: true })\nemail?: string;\n}\nAdd swagger metadata to src/app/employee/controllers/employee.crud.controller.ts\n@ApiTags(&apos;employee&apos;)\nGenerate database migrations\nBuild the application: yarn build\nIn order to create migration scripts with typeorm, you need to install ts-node: yarn global add ts-node\nGenerate the tables creation migration: yarn run typeorm migration:generate -n CreateTables\nThe optput will be something similar to:\nexport class CreateTables1572480273012 implements MigrationInterface {\nname = &apos;CreateTables1572480273012&apos;;\npublic async up(queryRunner: QueryRunner): Promise&lt;any&gt; {\nawait queryRunner.query(\n`CREATE TABLE &quot;user&quot; (&quot;id&quot; integer PRIMARY KEY AUTOINCREMENT NOT NULL, &quot;version&quot; integer NOT NULL DEFAULT (1), &quot;createdAt&quot; datetime NOT NULL DEFAULT (datetime(&apos;now&apos;)), &quot;updatedAt&quot; datetime NOT NULL DEFAULT (datetime(&apos;now&apos;)), &quot;username&quot; varchar(255) NOT NULL, &quot;password&quot; varchar(255) NOT NULL, &quot;role&quot; integer NOT NULL DEFAULT (0))`,\nundefined,\n);\nawait queryRunner.query(\n`CREATE TABLE &quot;employee&quot; (&quot;id&quot; integer PRIMARY KEY AUTOINCREMENT NOT NULL, &quot;version&quot; integer NOT NULL DEFAULT (1), &quot;createdAt&quot; datetime NOT NULL DEFAULT (datetime(&apos;now&apos;)), &quot;updatedAt&quot; datetime NOT NULL DEFAULT (datetime(&apos;now&apos;)), &quot;name&quot; varchar(255), &quot;surname&quot; varchar(255), &quot;email&quot; varchar(255))`,\nundefined,\n);\n}\npublic async down(queryRunner: QueryRunner): Promise&lt;any&gt; {\nawait queryRunner.query(`DROP TABLE &quot;employee&quot;`, undefined);\nawait queryRunner.query(`DROP TABLE &quot;user&quot;`, undefined);\n}\n}\nThe number in the name is a timestamp, so may change in your application.\nCreate a migration to insert data:`yarn run typeorm migration:generate -n InsertData`\nand fill in with the following code:\nexport class InsertData1572480830290 implements MigrationInterface {\npublic async up(queryRunner: QueryRunner): Promise&lt;any&gt; {\nawait queryRunner.query(\n`INSERT INTO EMPLOYEE(id, name, surname, email) VALUES(1, &apos;Santiago&apos;, &apos;Fowler&apos;, &apos;Santiago.Fowler@example.com&apos;);`,\n);\nawait queryRunner.query(\n`INSERT INTO EMPLOYEE(id, name, surname, email) VALUES(2, &apos;Clinton&apos;, &apos;Thornton&apos;, &apos;Clinton.Thornton@example.com&apos;);`,\n);\nawait queryRunner.query(\n`INSERT INTO EMPLOYEE(id, name, surname, email) VALUES(3, &apos;Lisa&apos;, &apos;Rodriquez&apos;, &apos;Lisa.Rodriquez@example.com&apos;);`,\n);\nawait queryRunner.query(\n`INSERT INTO EMPLOYEE(id, name, surname, email) VALUES(4, &apos;Calvin&apos;, &apos;Becker&apos;, &apos;Calvin.Becker@example.com&apos;);`,\n);\nawait queryRunner.query(`INSERT INTO USER(id, username, password, role) VALUES(?, ?, ?, ?);`, [\n1,\n&apos;user&apos;,\nawait hash(&apos;password&apos;, await genSalt(12)),\nroles.USER,\n]);\nawait queryRunner.query(`INSERT INTO USER(id, username, password, role) VALUES(?, ?, ?, ?);`, [\n2,\n&apos;admin&apos;,\nawait hash(&apos;admin&apos;, await genSalt(12)),\nroles.ADMIN,\n]);\n}\npublic async down(queryRunner: QueryRunner): Promise&lt;any&gt; {\nawait queryRunner.query(`DELETE FROM EMPLOYEE`);\nawait queryRunner.query(`DELETE FROM USER`);\n}\n}\nStart the application: yarn start:dev\nCheck the swagger endpoint: http://localhost:3000/v1/api\nMake petitions to the employee CRUD: http://localhost:3000/v1/employee/employees\nWrite the tests\nAs we do not create any method, only add some properties to the entity, all application must be tested by the autogenerated code. As we add some modules, you need to uncomment some lines in the src/app/core/configuration/services/configuration.service.spec.ts:\ndescribe(&apos;ConfigurationService&apos;, () =&gt; {\nconst configService: ConfigurationService = new ConfigurationService();\nit(&apos;should return the values of test config file&apos;, () =&gt; {\nexpect(configService.isDev).toStrictEqual(def.isDev);\nexpect(configService.host).toStrictEqual(def.host);\nexpect(configService.port).toStrictEqual(def.port);\nexpect(configService.clientUrl).toStrictEqual(def.clientUrl);\nexpect(configService.globalPrefix).toStrictEqual(def.globalPrefix);\n// Remove comments if you add those modules\nexpect(configService.database).toStrictEqual(def.database);\nexpect(configService.swaggerConfig).toStrictEqual(def.swaggerConfig);\nexpect(configService.jwtConfig).toStrictEqual(def.jwtConfig);\n// expect(configService.mailerConfig).toStrictEqual(def.mailerConfig);\n});\nit(&apos;should take the value of environment varible if defined&apos;, () =&gt; {\nprocess.env.isDev = &apos;true&apos;;\nprocess.env.host = &apos;notlocalhost&apos;;\nprocess.env.port = &apos;123456&apos;;\nprocess.env.clientUrl = &apos;http://theclienturl.net&apos;;\nprocess.env.globalPrefix = &apos;v2&apos;;\nprocess.env.swaggerConfig = JSON.stringify({\nswaggerTitle: &apos;Test Application&apos;,\n});\nprocess.env.database = JSON.stringify({\ntype: &apos;oracle&apos;,\ncli: { entitiesDir: &apos;src/notentitiesdir&apos; },\n});\nprocess.env.jwtConfig = JSON.stringify({ secret: &apos;NOTSECRET&apos; });\n// process.env.mailerConfig = JSON.stringify({ mailOptions: { host: &apos;notlocalhost&apos; }});\nexpect(configService.isDev).toBe(true);\nexpect(configService.host).toBe(&apos;notlocalhost&apos;);\nexpect(configService.port).toBe(123456);\nexpect(configService.clientUrl).toBe(&apos;http://theclienturl.net&apos;);\nexpect(configService.globalPrefix).toBe(&apos;v2&apos;);\nconst database: any = { ...def.database, type: &apos;oracle&apos; };\ndatabase.cli.entitiesDir = &apos;src/notentitiesdir&apos;;\nexpect(configService.database).toStrictEqual(database);\nexpect(configService.swaggerConfig).toStrictEqual({\n...def.swaggerConfig,\nswaggerTitle: &apos;Test Application&apos;,\n});\nexpect(configService.jwtConfig).toStrictEqual({\n...def.jwtConfig,\nsecret: &apos;NOTSECRET&apos;,\n});\n// const mail: any = { ...def.mailerConfig };\n// mail.mailOptions.host = &apos;notlocalhost&apos;;\n// expect(configService.mailerConfig).toStrictEqual(mail);\nprocess.env.isDev = undefined;\nprocess.env.host = undefined;\nprocess.env.port = undefined;\nprocess.env.clientUrl = undefined;\nprocess.env.globalPrefix = undefined;\nprocess.env.database = undefined;\nprocess.env.swaggerConfig = undefined;\nprocess.env.jwtConfig = undefined;\n// process.env.mailerConfig = undefined;\n});\n});\nAnd the output should be:\n&#x2190;&#xA0;Previous:&#xA0;Guides&#xA0;| &#x2191;&#xA0;Up:&#xA0;devon4node&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Choosing your Database&#xA0;&#x2192;\n"},{"id":823,"path":"../website/pages/docs/master-devon4node.asciidoc_guides.html#master-devon4node.asciidoc_guides","type":"docs","title":"Guides","body":"34. Guides\n"},{"id":824,"path":"../website/pages/docs/master-devon4node.asciidoc_guides.html#guides-key-principles.asciidoc","type":"docs","title":"Key Principles","body":"34.1. Key Principles\ndevon4node is built following some basic principles like:\nSOLID\nPatterns\nOpen\nBut key principles that best define devon4node (and are inherited from NestJS) are:\nSimplicity (aka KISS)\nReusability\nProductivity\n"},{"id":825,"path":"../website/pages/docs/master-devon4node.asciidoc_guides.html#guides-key-principles.asciidoc_simplicity","type":"docs","title":"Simplicity","body":"34.1.1. Simplicity\nIn devon4node we tried to do everything as simple as possible. Following this principle we will be able to do easy to maintain applications.\nFor example, in order to expose all CRUD operations for an entity, you only need to create a controller like:\n@Crud({\nmodel: {\ntype: Employee,\n},\n})\n@CrudType(Employee)\n@Controller(&apos;employee/employees&apos;)\nexport class EmployeeCrudController {\nconstructor(public service: EmployeeCrudService) {}\n}\nYou can find this code in the employee example. Only with this code your exposing the full CRUD operations for the employee entity. As you can see, it&#x2019;s an empty class with some decorators and the EmployeeCrudService injected as dependency. Simple, isn&#x2019;t it? The EmployeeCrudService is also simple:\n@Injectable()\nexport class EmployeeCrudService extends TypeOrmCrudService&lt;Employee&gt; {\nconstructor(@InjectRepository(Employee) repo: Repository&lt;Employee&gt;) {\nsuper(repo);\n}\n}\nAnother empty class which extends from TypeOrmCrudService&lt;Employee&gt; and injects the Employee Repository as dependency. Nothing else.\nWith these examples you can get an idea of how simple it can be to code a devon4node application .\n"},{"id":826,"path":"../website/pages/docs/master-devon4node.asciidoc_guides.html#guides-key-principles.asciidoc_reusability","type":"docs","title":"Reusability","body":"34.1.2. Reusability\nNestJS (and devon4node) applications are designed in a modular way. This allows you to isolate some functionality in a module, and then reuse it in every application that you need. This is the same behaviour that Angular has. You can see it in the NestJS modules like TypeORM, Swagger and others. Also, in devon4node we have the Mailer module.\nIn your applications, you only need to import those modules and then you will be able to use the functionality that they implement. Example\n@Module({\nimports: [ AuthModule, ConfigurationModule ],\n})\nexport class SomeModule {}\n"},{"id":827,"path":"../website/pages/docs/master-devon4node.asciidoc_guides.html#guides-key-principles.asciidoc_productivity","type":"docs","title":"Productivity","body":"34.1.3. Productivity\ndevon4node is designed to create secure enterprise applications. But also, it allow you to do it in a fast way. To increase the productivity devon4node, devon4node provide schematics in order to generate some boilerplate code.\nFor example, to create a module you need to create a new file for a module (or copy it) and write the code, then you need to import it in the AppModule. This is a easy example, but you can introduce some errors: forget to import it in the AppModule, introduce errors with the copy/paste and so on. By using the command nest g module --name &lt;module-name&gt; it will do everything for you. Just a simple command. In this specific case probably you do not see any advantage, but there are other complex cases where you can generate more complex code with nest and devon4node schematics command.\nSee code generation in order to know how to increase your productivity creating devon4node applications.\n"},{"id":828,"path":"../website/pages/docs/master-devon4node.asciidoc_guides.html#guides-code-generation.asciidoc","type":"docs","title":"Code Generation","body":"34.2. Code Generation\nAs we mention in the page key principles, one of our key principles is Productivity. In order to provide that productivity, we have some tools to generate code. These tools will help you generate the common parts of the application so that you can focus only on the specific functionality.\nThose tools are:\ndevon4node schematics through Nest CLI\nCobiGen\n"},{"id":829,"path":"../website/pages/docs/master-devon4node.asciidoc_guides.html#guides-code-generation.asciidoc_nest-cli-and-devon4node-schematics","type":"docs","title":"Nest CLI and Devon4node schematics","body":"34.2.1. Nest CLI and Devon4node schematics\nWe are going to use the Nest CLI to generate code of our application, you can know more about NodeJs CLI in the official documentation.\nInstall devon4node schematics\nFirst of all, you need to install Nest CLI\nExecute the command yarn global add @nestjs/cli.\nYou can also use npm: npm install -g @nestjs/cli\nAnd then Devon4node schematics globally with the following command:\nyarn global add @devon4node/schematics or npm install -g @devon4node/schematics\nNote\nIf you get an error trying execute any devon4node schematic related to collection not found, try to reinstall devon4node/schematics on the project folder or be sure that schematics folder is inside @devon4node in node_modules.\nyarn add @devon4node/schematics\nGenerate new devon4node application\nTo start creating a devon4node application, execute the command:\nnest g -c @devon4node/schematics application [application-name]\nIf you do not put a name, the command line will ask you for one.\nGenerate code for Typeorm\nInitialize typeorm into your current project in a correct way.\nnest g -c @devon4node/schematics typeorm\nThen, you will be asked about which DB you want to use.\nGenerate CRUD\nGenerate CRUD methods for a entity. Requires TypeORM installed in the project.\nIt will add the @nestjsx/crud module as a project dependency. Then, generates an entity, a CRUD controller and a CRUD service. It also register the entity, controller and service in the module.\nExecute nest g -c @devon4node/schematics crud and then you will need to write a name for the crud.\nGenerate Typeorm entity\nAdd a TypeOrm entity to your project. Requires TypeORM installed in the project.\nExecute nest g -c @devon4node/schematics entity and you will be asked for an entity name.\nAdd config-module\nAdd the config module to the project.\nIt will add the @devon4node/common module as a project dependency. Then, it will generate the configuration module into your project and add it in the core module. Also, it generates the config files for the most common environments.\nThe command to execute will be nest g -c @devon4node/schematics config-module\nAdd mailer module\nAdd @devon4node/mailer module to project.\nIt will add the @devon4node/mailer module as a project dependency. Also, it will add it to the core module and it will generate some email template examples.\nWrite the command nest g -c @devon4node/schematics mailer\nAdd swagger module\nAdd swagger module to project.\nIt will add the @nestjs/swagger module as a project dependency. Also, it will update the main.ts file in order to expose the endpoint for swagger. The default endpoint is: /v1/api\nExecute the command nest g -c @devon4node/schematics swagger\nAdd auth-jwt module\nAdd the auth JWT module to the project.\nIt will add to your project the auth-jwt and user module. Also, it will import those modules into the core module.\nExecute nest g -c @devon4node/schematics auth-jwt\nAdd security\nAdd cors and helmet to your project.\nIt will add helmet package as project dependency and update the main.ts file in order to enable the cors and helmet in your application.\nExecute nest g -c @devon4node/schematics security\nGenerate database migrations\nGenerate database migrations\nIn order to create migration scripts with typeorm, you need to install ts-node: yarn global add ts-node or npm i -g ts-node\nGenerate the tables creation migration: yarn run typeorm migration:generate -n CreateTables\nIt will connect to the database, read all entities and then it will generate a migration file with all sql queries need to transform the current status of the database to the status defined by the entities. If the database is empty, it will generate all sql queries need to create all tables defined in the entities. You can find a example in the todo example\nAs typeorm is the tool used for DB. You can check official documentation for more information.\nSee typeorm CLI documentation.\n"},{"id":830,"path":"../website/pages/docs/master-devon4node.asciidoc_guides.html#guides-code-generation.asciidoc_cobigen","type":"docs","title":"CobiGen","body":"34.2.2. CobiGen\nCurrently, we do not have templates to generate devon4node code (we have planned to do that in the future). Instead, we have templates that read the code of a devon4node application and generate a devon4ng application. Visit the CobiGen page for more information.\n"},{"id":831,"path":"../website/pages/docs/master-devon4node.asciidoc_guides.html#guides-coding-conventions.asciidoc","type":"docs","title":"Coding Conventions","body":"34.3. Coding Conventions\ndevon4node defines some coding conventions in order to improve the readability, reduce the merge conflicts and be able to develop applications in an industrialized way.\nIn order to ensure that you are following the devon4node coding conventions, you can use the following tools:\nESLint: ESLint ESLint is a tool for identifying and reporting on patterns found in ECMAScript/JavaScript code, with the goal of making code more consistent and avoiding bugs. We recommend to use the ESLint VSCode extension (included in the devonfw Platform Extension Pack) in order to be able to see the linting errors while you are developing.\nPrettier: Prettier is a code formatter. We recommend to use the Prettier VSCode extension (included in the devonfw Platform Extension Pack) and enable the editor.formatOnSave option.\ndevon4node application schematic: this tool will generate code follwing the devon4node coding conventions. Also, when you generate a new project using the devon4node application schematic, it generates the configuration files for TSLint and Prettier that satisfy the devon4node coding conventions.\nWhen you combine all tools, you can be sure that you follow the devon4node coding conventions.\n"},{"id":832,"path":"../website/pages/docs/master-devon4node.asciidoc_guides.html#guides-coding-conventions.asciidoc_detailed-devon4node-coding-conventions","type":"docs","title":"Detailed devon4node Coding Conventions","body":"34.3.1. Detailed devon4node Coding Conventions\nHere we will detail some of most important devon4node coding conventions. To be sure that you follows all devon4node coding conventions use the tools described before.\nIndentation\nAll devon4node code files must be indented using spaces. The indentation with must be 2 spaces.\nWhite space\nIn order to improve the readability of your code, you must introduce whitespaces. Example:\nif(condition){\nmust be\nif (condition) {\nNaming conventions\nFile naming\nThe file name must follow the pattern: (name in kebap case).(kind of component).(extension)\nThe test file name must follow the pattern: (name in kebap case).(kind of component).spec.(extension)\nExample:\nauth-jwt.service.ts\nauth-jwt.service.spec.ts\nInterface naming\nThe interface names must be in pascal case, and must start with I. There is some controversy in starting the interface names with an I, but we decided to do it because is most of cases you will have an interface and a class with the same name, so, to differentiate them, we decided to start the interfaces with I. Other devonfw stacks solves it by adding the suffix Impl in the class implementations.\nExample:\ninterface ICoffee {}\nClass naming\nThe class names must be in pascal case.\nExample:\nclass Coffee {}\nVariable naming\nAll variable names must be in camel case.\nconst coffeeList: Coffe[];\nDeclarations\nFor all variable declarations we must use const or let. var is forbidden. We preffer to use const when possible.\nProgramming practices\nTrailing comma\nAll statements must end with a trailing comma. Example:\n{\none: &apos;one&apos;,\ntwo: &apos;two&apos; // bad\n}\n{\none: &apos;one&apos;,\ntwo: &apos;two&apos;, // good\n}\nArrow functions\nAll anonymous functions must be definned with the arrow function notation. In most of cases it&#x2019;s not a problem, but sometimes, when you do not want to bind this when you define the function, you can use the other function definition. In this special cases you must disable the linter for those sentence.\nComments\nComments must start with a whitespace. Example:\n//This is a bad comment\n// This is OK\nQuotemarks\nFor string definitions, we must use single quotes.\nif statements\nIn all if statements you always must use brackets. Example:\n// Bad if statement\nif (condition)\nreturn true;\n// Good if statement\nif (condition) {\nreturn true;\n}\n"},{"id":833,"path":"../website/pages/docs/master-devon4node.asciidoc_guides.html#guides-coding-conventions.asciidoc_pre-commit-hooks","type":"docs","title":"Pre-commit hooks","body":"34.3.2. Pre-commit hooks\nIn order to ensure that your new code follows the coding conventions, devon4node uses by default husky. Husky is a tool that allows you to configure git hooks easly in your project. When you make a git commit in your devon4node project, it will execute two actions:\nPrettify the staged files\nExecute the linter in the staged files\nIf any action fails, you won&#x2019;t be able to commit your new changes.\nNote\nIf you want to skip the git hooks, you can do a commit passing the --no-verify flag.\n"},{"id":834,"path":"../website/pages/docs/master-devon4node.asciidoc_guides.html#guides-dependency-injection.asciidoc","type":"docs","title":"Dependency Injection","body":"34.4. Dependency Injection\nThe dependency injection is a well-known common design pattern applied by frameworks in all languages, like Spring in Java, Angular and others. The intention of this page is not to explain how dependency injection works, but instead how it is addressed by NestJS.\nNestJS resolve the dependency injection in their modules. When you define a provider in a module, it can be injected in all components of the module. By default, those providers are only available in the module where it is defined. The only way to export a module provider to other modules which import it is adding those provider to the export array. You can also reexport modules.\n"},{"id":835,"path":"../website/pages/docs/master-devon4node.asciidoc_guides.html#guides-dependency-injection.asciidoc_inject-dependencies-in-nestjs","type":"docs","title":"Inject dependencies in NestJS","body":"34.4.1. Inject dependencies in NestJS\nIn oder to inject a dependency in a NestJS component, you need to declare it in the component constructor. Example:\nexport class CoffeeController {\nconstructor(public readonly conffeeService: CoffeeService) {}\n}\nNestJS can resolve all dependencies that are defined in the module as provider, and also the dependencies exported by the modules imported. Example:\n@Module({\ncontrollers: [CoffeeController],\nproviders: [CoffeeService],\n})\nexport class CoffeeModule {}\nInject dependencies in the constructor is the is the preferred choice, but, sometimes it is not possible. For example, when you are extending another class and want to keep the constructor definition. In this specific cases we can inject dependencies in the class properties. Example:\nexport class CoffeeController {\n@Inject(CoffeeService)\nprivate readonly conffeeService: CoffeeService;\n}\n"},{"id":836,"path":"../website/pages/docs/master-devon4node.asciidoc_guides.html#guides-dependency-injection.asciidoc_dependency-graph","type":"docs","title":"Dependency Graph","body":"34.4.2. Dependency Graph\nIn the previous image, the Module A can inject dependencies exported by Module B, Module E and Module F. If module B reexport Module C and Module D, they are also accesibles by Module A.\nIf there is a conflict with the injection token, it resolves the provider with less distance with the module. For example: if the modules C and F exports a UserService provider, the Module A will resolve the UserService exported by the Module F, because the distance from Module A to Module F is 1, and the distance from Module A to Module C is 2.\nWhen you define a module as global, the dependency injection system is the same. The only difference is now all modules as a link to the global module. For example, if we make the Module C as global the dependency graph will be:\n"},{"id":837,"path":"../website/pages/docs/master-devon4node.asciidoc_guides.html#guides-dependency-injection.asciidoc_custom-providers","type":"docs","title":"Custom providers","body":"34.4.3. Custom providers\nWhen you want to change the provider name, you can use a NestJS feature called custom providers. For example, if you want to define a provider called MockUserService with the provider token UserService you can define it like:\n@Module({\nproviders: [{\nprovide: UserService,\nuseValue: MockUserService,\n}],\n})\nWith this, when you inject want to inject UserService as dependency, the MockUserService will be injected.\nCustom provider token can be also a string:\n@Module({\nproviders: [{\nprovide: &apos;USER_SERVICE&apos;,\nuseValue: MockUserService,\n}],\n})\nbut now, when you want to inject it as dependency you need to use the @Inject decorator.\nconstructor(@Inject(&apos;USER_SERVICE&apos;) userService: any) {}\n"},{"id":838,"path":"../website/pages/docs/master-devon4node.asciidoc_guides.html#guides-configuration-module.asciidoc","type":"docs","title":"Configuration Module","body":"34.5. Configuration Module\ndevon4node provides a way to generate a configuration module inside your appication. To generate it you only need to execute the command nest g -c @devon4node/schematics config-module. This command will generate inside your application:\nConfiguration module inside the core module.\nconfig folder where all environment configuration are stored.\ndefault configuration: configuration for your local development environment.\ndevelop environment configuration for the develop environment.\nuat environment configuration for the uat environment.\nproduction environment configuration for the production environment.\nproduction environment configuration for the production environment.\ntest environment configuration used by test.\nNote\nsome code generators will add some properties to this module, so, be sure that the config module is the first module that you generate in your application.\n"},{"id":839,"path":"../website/pages/docs/master-devon4node.asciidoc_guides.html#guides-configuration-module.asciidoc_use-the-configuration-service","type":"docs","title":"Use the configuration service","body":"34.5.1. Use the configuration service\nTo use the configuration service, you only need to inject it as dependency. As configuration module is defined in the core module, it will be available everywhere in your application. Example:\nexport class MyProvider {\nconstructor(public readonly configService: ConfigurationService) {}\nmyMethod() {\nreturn this.confiService.isDev;\n}\n}\n"},{"id":840,"path":"../website/pages/docs/master-devon4node.asciidoc_guides.html#guides-configuration-module.asciidoc_choose-an-environment-file","type":"docs","title":"Choose an environment file","body":"34.5.2. Choose an environment file\nBy default, when you use the configuration service it will take the properties defined in the default.ts file. If you want to change the configuration file, you only need to set the NODE_ENV environment property with the name of the desired environment. Examples: in windows execute set NODE_ENV=develop before executing the application, in linux execute NODE_ENV=develop before executing the application or NODE_ENV=develop yarn start.\n"},{"id":841,"path":"../website/pages/docs/master-devon4node.asciidoc_guides.html#guides-configuration-module.asciidoc_override-configuration-properties","type":"docs","title":"Override configuration properties","body":"34.5.3. Override configuration properties\nSometimes, you want to keep some configuration property secure, and you do not want to publish it to the repository, or you want to reuse some configuration file but you need to change some properties. For those scenarios, you can override configuration properties by defining a environment variable with the same name. For example, if you want to override the property host, you can do: set host=&quot;newhost&quot;. It also works with objects. For example, if you want to change the value of secret in the property jwtConfig for this example, you can set a environment variable like this: set jwtConfig=&quot;{&quot;secret&quot;: &quot;newsecret&quot;}&quot;. As you can see, this environment variable has a JSON value. It will take object and merge the jwtConfig property with the properties defined inside the environment variable. It other properties maintain their value. The behaviour is the same for the nested objects.\n"},{"id":842,"path":"../website/pages/docs/master-devon4node.asciidoc_guides.html#guides-configuration-module.asciidoc_add-a-configuration-property","type":"docs","title":"Add a configuration property","body":"34.5.4. Add a configuration property\nIn order to add a new property to the configuration module, you need to follow some steps:\nAdd the property to IConfig interface in src/app/core/configuration/types.ts file. With this, we can ensure that the ConfigurationService and the environment files has those property at compiling time.\nAdd the new property getter to ConfigurationService. You must use the get method of ConfigurationService to ensure that the property will be loaded from the desired config file. You can also add extra logic if needed.\nAdd the property to all config files inside the src/config folder.\nExample:\nWe want to add the property devonfwUrl to our ConfigurationService, so:\nWe add the following code in IConfig interface:\ndevonfwUrl: string;\nThen, we add the getter in the ConfigurationService:\nget devonfwUrl(): string {\nreturn this.get(&apos;devonfwUrl&apos;)!;\n}\nFinally, we add the definition in all config files:\ndevonfwUrl: &apos;https://devonfw.com&apos;,\n"},{"id":843,"path":"../website/pages/docs/master-devon4node.asciidoc_guides.html#guides-auth-jwt.asciidoc","type":"docs","title":"Auth JWT module","body":"34.6. Auth JWT module\ndevon4node provides a way to generate a default authentication module using JWT (JSON Web Token). It uses the @nestjs/passport library descrbe here.\nTo generate the devon4node auth-jwt module you only need to execute the command: nest generate -c @devon4node/schematics auth-jwt. We generate this module inside the applications instead of distributing a npm package because this module is prone to be modified depending on the requirements. It alse generate a basic user module.\nIn this page we will explain the default implementation provided by devon4node. For more information about authentication, JWT, passport and other you can see:\nJWT\nNestJS authentication\nPassport\nPassport JWT\n"},{"id":844,"path":"../website/pages/docs/master-devon4node.asciidoc_guides.html#guides-auth-jwt.asciidoc_auth-jwt-endpoints","type":"docs","title":"Auth JWT endpoints","body":"34.6.1. Auth JWT endpoints\nIn order to execute authentication operations, the auth-jwt module exposes the following endpoints:\nPOST /auth/login: receive an username and a password and return the token in the header if the combination of username and password is correct.\nPOST /auth/register: register a new user.\nGET /auth/currentuser: return the user data if he is authenticated.\n"},{"id":845,"path":"../website/pages/docs/master-devon4node.asciidoc_guides.html#guides-auth-jwt.asciidoc_protect-endpoints-with-auth-jwt","type":"docs","title":"Protect endpoints with auth-jwt","body":"34.6.2. Protect endpoints with auth-jwt\nIn order to protect your endpoints with auth-jwt module you only need to add the AuthGuard() in the UseGuards decorator. Example:\n@Get(&apos;currentuser&apos;)\n@UseGuards(AuthGuard())\ncurrentUser(@Request() req: UserRequest) {\nreturn req.user;\n}\nNow, all request to currentuser are protected by the AuthGuard.\n"},{"id":846,"path":"../website/pages/docs/master-devon4node.asciidoc_guides.html#guides-auth-jwt.asciidoc_role-based-access-control","type":"docs","title":"Role based Access Control","body":"34.6.3. Role based Access Control\nThe auth-jwt module provides also a way to control the access to some endpoints by using roles. For example, if you want to grant access to a endpoint only to admins, you only need to add the Roles decorator to those endpoints with the roles allowed. Example:\n@Get(&apos;currentuser&apos;)\n@UseGuards(AuthGuard())\n@Roles(roles.ADMIN)\ncurrentUser(@Request() req: UserRequest) {\nreturn req.user;\n}\n"},{"id":847,"path":"../website/pages/docs/master-devon4node.asciidoc_guides.html#guides-swagger.asciidoc","type":"docs","title":"Swagger","body":"34.7. Swagger\nWe can use swagger (OpenAPI) in order to describe the endpoints that our application exposes.\nNestJS provides a module which will read the code of our application and will expose one endpoint where we can see the swagger.\nAdd swagger to a devon4node application is simple, you only need to execute the command nest g -c @devon4node/schematics swagger and it will do everything for you. The next time that you start your application, you will be able to see the swagger at /v1/api endpoint.\nThe swagger module can read your code in order to create the swagger definition, but sometimes you need to help him by decorating your handlers.\nFor more information about decorators and other behaviours about swagger module, you can see the NestJS swagger documentation page\nNote\nthe OpenAPI specification that this module supports is v2.0. The OpenAPI v3.0 is not available yet by using this module.\n"},{"id":848,"path":"../website/pages/docs/master-devon4node.asciidoc_guides.html#guides-typeorm.asciidoc","type":"docs","title":"TypeORM","body":"34.8. TypeORM\nTypeORM is the default ORM provided by devon4node. It supports MySQL, MariaDB, Postgres, CockroachDB, SQLite, Microsoft SQL Server, Oracle, sql.js relational dabases and also supports MongoDB NoSQL database.\nAdd TypeORM support to a devon4node application is very easy: you only need to execute the command nest g -c @devon4node/schematics typeorm and it will add all required dependencies to the project and also imports the @nestjs/typeorm module.\nFor more information about TypeORM and the integration with NestJS you can visit TypeORM webpage, TypeORM GitHub repository and NestJS TypeORM documentation page\n"},{"id":849,"path":"../website/pages/docs/master-devon4node.asciidoc_guides.html#guides-typeorm.asciidoc_configuration","type":"docs","title":"Configuration","body":"34.8.1. Configuration\nWhen you have the configuration module, the typeorm generator will add one property in order to be able to configure the database depending on the environment. Example:\ndatabase: {\ntype: &apos;sqlite&apos;,\ndatabase: &apos;:memory:&apos;,\nsynchronize: false,\nmigrationsRun: true,\nlogging: true,\nentities: [&apos;dist/**/*.entity.js&apos;],\nmigrations: [&apos;dist/migration/**/*.js&apos;],\nsubscribers: [&apos;dist/subscriber/**/*.js&apos;],\ncli: {\nentitiesDir: &apos;src/entity&apos;,\nmigrationsDir: &apos;src/migration&apos;,\nsubscribersDir: &apos;src/subscriber&apos;,\n},\n},\nThis object is a TypeORM ConnectionOptions. For fore information about it visit the TypeORM Connection Options page.\nThere is also a special case: the default configuration. As the devon4node CLI need the database configuration when you use the devon4node db command, we also provide the ormconfig.json file. In this file you must put the configuration for you local environment. In order to do not have duplicated the configuration for local environment, in the default config file the database property is setted like:\ndatabase: require(&apos;../../ormconfig.json&apos;),\nSo, you only need to maintain the ormconfig.json file for the local environment.\n"},{"id":850,"path":"../website/pages/docs/master-devon4node.asciidoc_guides.html#guides-typeorm.asciidoc_entity","type":"docs","title":"Entity","body":"34.8.2. Entity\nEntity is a class that maps to a database table. The devon4node schematics has a generator to create new entities. You only need to execute the command nest g -c @devon4node/schematics entity &lt;entity-name&gt; and it generate the entity.\nIn the entity, you must define all columns, relations, primary keys of your database table. By default, devon4node provides a class named BaseEntity. All entities created with the devon4node schematics will extends the BaseEntity. This entity provides you some common columns:\nid: the primary key of you table\nversion: the version of the entry (used for auditing purposes)\ncreatedAt: creation date of the entry (used for auditing purposes)\nupdatedAt: last update date of the entry (used for auditing purposes)\nFor more information about Entities, please visit the TypeORM entities page\n"},{"id":851,"path":"../website/pages/docs/master-devon4node.asciidoc_guides.html#guides-typeorm.asciidoc_repository","type":"docs","title":"Repository","body":"34.8.3. Repository\nWith repositories, you can manage (insert, update, delete, load, etc.) a concrete entity. Using this pattern, we have separated the data (Entities) from the methods to manage it (Repositories).\nTo use a repository you only need to:\nImport it in the module as follows:\n@Module({\nimports: [TypeOrmModule.forFeature([Employee])],\n})\nNote\nif you generate the entities with the devon4node schematic, this step is not neccesary, devon4node schematic will do it for you.\nInject the repository as dependency in your service:\nconstructor(@InjectRepository(Employee) employeeRepository: Repository&lt;Employee&gt;) {}\nYou can see more details in the NestJS database and NestJS TypeORM documentation pages.\n"},{"id":852,"path":"../website/pages/docs/master-devon4node.asciidoc_guides.html#guides-serializer.asciidoc","type":"docs","title":"Serializer","body":"34.9. Serializer\nSerialization is the process of translating data structures or object state into a format that can be transmitted across network and reconstructed later.\nNestJS by default serialize all data to JSON (JSON.stringify). Sometimes this is not enough. In some situations you need to exclude some property (e.g password). Instead doing it manually, devon4node provides an interceptor (ClassSerializerInterceptor) that will do it for you. You only need to return a class instance as always and the interceptor will transform those class to the expected data.\nThe ClassSerializerInterceptor takes the class-transformer decorators in order to know how to transform the class and then send the result to the client.\nSome of class-transformer decorators are:\nExpose\nExclude\nType\nTransform\nAnd methods to transform data:\nplainToClass\nplainToClassFromExist\nclassToPlain\nclassToClass\nserialize\ndeserialize\ndeserializeArray\nSee the class-transformer page for more information.\nSee NestJS serialization page for more information about ClassSerializerInterceptor.\n"},{"id":853,"path":"../website/pages/docs/master-devon4node.asciidoc_guides.html#guides-validation.asciidoc","type":"docs","title":"Validation","body":"34.10. Validation\nTo be sure that your application will works well, you must validate any input data. devon4node by default provides a ValidationPipe. This ValidationPipe is the responsible of validate the request input and, if the input do not pass the validation process, it returns a 400 Bad Request error.\n"},{"id":854,"path":"../website/pages/docs/master-devon4node.asciidoc_guides.html#guides-validation.asciidoc_defining-validators","type":"docs","title":"Defining Validators","body":"34.10.1. Defining Validators\nThe ValidationPipe needs to know how to validate the input. For that purpose we use the class-validator package. This package allows you to define the validation of a class by using decorators.\nFor example:\nexport class Coffee {\n@IsDefined()\n@IsString()\n@MaxLength(255)\nname: string;\n@IsDefined()\n@IsString()\n@MaxLength(25)\ntype: string;\n@IsDefined()\n@IsNumber()\nquantity: number;\n}\nAs you can see in the previous example, we used some decorators in order to define the validators for every property of the Coffee class. You can find all decorators in the class-validator github repository.\nNow, when you want to receive a Coffee as input in some endpoint, it will execute the validations before executing the handler function.\nNote\nIn order to be able to use the class-validator package, you must use classes instead of interfaces. As you know interfaces disappear at compiling time, and class-validator need to know the metadata of the properties in order to be able to validate.\nNote\nThe ValidationPipe only works if you put a specific type in the handler definition. For example, if you define a handler like getCoffee(@Body() coffee: any): Coffee {} the ValidationPipe will not do anything. You must specify the type of the input: getCoffee(@Body() coffee: Coffee): Coffee {}\n"},{"id":855,"path":"../website/pages/docs/master-devon4node.asciidoc_guides.html#guides-logger.asciidoc","type":"docs","title":"Logger","body":"34.11. Logger\nWhen you create a new devon4node application, it already has a logger: src/app/shared/logger/winston.logger.ts. This logger provide the methods log, error and warn. All of those methods will write a log message, but with a different log level.\nThe winston logger has two transports: one to log everything inside the file logs/general.log and the other to log only the error logs inside the file logs/error.log. In addition, it uses the default NestJS logger in order to show the logs in the console.\nAs you can see it is a simple example about how to use logger in a devon4node application. It will be update to a complex one in the next versions.\n"},{"id":856,"path":"../website/pages/docs/master-devon4node.asciidoc_guides.html#guides-logger.asciidoc_how-to-use-logger","type":"docs","title":"How to use logger","body":"34.11.1. How to use logger\nIn order to use the logger you only need to inject the logger as a dependency:\nconstructor(logger: WinstonLogger){}\nand then use it\nasync getAll() {\nthis.service.getAll();\nthis.logger.log(&apos;Returning all data&apos;);\n}\n"},{"id":857,"path":"../website/pages/docs/master-devon4node.asciidoc_guides.html#guides-mailer.asciidoc","type":"docs","title":"Mailer Module","body":"34.12. Mailer Module\nThis module enables you to send emails in devon4node. It also provides a template engine using Handlebars.\nIt is a NestJS module that inject into your application a MailerService, which is the responsible to send the emails using the nodemailer library.\n"},{"id":858,"path":"../website/pages/docs/master-devon4node.asciidoc_guides.html#guides-mailer.asciidoc_installing","type":"docs","title":"Installing","body":"34.12.1. Installing\nExecute the following command in a devon4node project:\nyarn add @devon4node/mailer\n"},{"id":859,"path":"../website/pages/docs/master-devon4node.asciidoc_guides.html#guides-mailer.asciidoc_configuring","type":"docs","title":"Configuring","body":"34.12.2. Configuring\nTo configure the mailer module, you only need to import it in your application into another module. Example:\n@Module({\n...\nimports: [\nMailerModule.forRoot(),\n],\n...\n})\nYour must pass the configuration using the forRoot or forRootAsync methods.\nforRoot()\nThe forRoot method receives an MailerModuleOptions object as parameter. It configures the MailerModule using the input MailerModuleOptions object.\nThe structure of MailerModuleOptions is:\n{\nhbsOptions?: {\ntemplatesDir: string;\nextension?: string;\npartialsDir?: string;\nhelpers?: IHelperFunction[];\ncompilerOptions?: ICompileOptions;\n},\nmailOptions?: nodemailerSmtpTransportOptions;\nemailFrom: string;\n}\nHere, you need to specify the Handlebars compile options, the nodemailer transport options and the email address which will send the emails.\nThen, you need to call to forRoot function in the module imports. Example:\n@Module({\n...\nimports: [\nMailerModule.forRoot({\nmailOptions: {\nhost: &apos;localhost&apos;,\nport: 1025,\nsecure: false,\ntls: {\nrejectUnauthorized: false,\n},\n},\nemailFrom: &apos;noreply@capgemini.com&apos;,\nhbsOptions: {\ntemplatesDir: join(__dirname, &apos;../..&apos;, &apos;templates/views&apos;),\npartialsDir: join(__dirname, &apos;../..&apos;, &apos;templates/partials&apos;),\nhelpers: [{\nname: &apos;fullname&apos;,\nfunc: person =&gt; `${person.name} ${person.surname}`,s\n}],\n},\n}),\n...\n})\nforRootAsync()\nThe method forRootAsync enables you to get the mailer configuration in a asynchronous way. It is useful when you need to get the configuration using, for example, a service (e.g. ConfigurationService).\nExample:\n@Module({\n...\nimports: [\nMailerModule.forRootAsync({\nimports: [ConfigurationModule],\nuseFactory: (config: ConfigurationService) =&gt; {\nreturn config.mailerConfig;\n},\ninject: [ConfigurationService],\n}),\n...\n})\nIn this example, we use the ConfigurationService in order to get the MailerModuleOptions (the same as forRoot)\n"},{"id":860,"path":"../website/pages/docs/master-devon4node.asciidoc_guides.html#guides-mailer.asciidoc_usage","type":"docs","title":"Usage","body":"34.12.3. Usage\nIn order to use, you only need to inject using the dependency injection the MailerService.\nExample:\n@Injectable()\nexport class CatsService {\nconstructor(private readonly mailer: MailerService) {}\n}\nThen, you only need to use the methods provided by the MailerService in your service. Take into account that you can inject it in every place that support NestJS dependency injection.\nMailerService methods\nsendPlainMail\nThe method sendPlainMail receive a string sends a email.\nThe method signatures are:\nsendPlainMail(emailOptions: SendMailOptions): Promise&lt;SentMessageInfo&gt;;\nsendPlainMail(to: string, subject: string, mail: string): Promise&lt;SentMessageInfo&gt;;\nExamples:\nthis.mailer.sendPlainMail({\nto: &apos;example@example.com&apos;,\nsubject: &apos;This is a subject&apos;,\nhtml: &apos;&lt;h1&gt;Hello world&lt;/h1&gt;&apos;\n});\nthis.mailer.sendPlainMail(&apos;example@example.com&apos;, &apos;This is a subject&apos;, &apos;&lt;h1&gt;Hello world&lt;/h1&gt;&apos;);\nsendTemplateMail\nThe method sendTemplateMail sends a email based on a Handlebars template. The templates are registered using the templatesDir option or using the addTemplate method.\nThe template name is the name of the template (without extension) or the first parameter of the method addTemplate.\nThe method signatures are:\nsendTemplateMail(emailOptions: SendMailOptions, templateName: string, emailData: any, hbsOptions?: RuntimeOptions): Promise&lt;SentMessageInfo&gt;;\nsendTemplateMail(to: string, subject: string, templateName: string, emailData: any, hbsOptions?: RuntimeOptions): Promise&lt;SentMessageInfo&gt;;\nExamples:\nthis.mailer.sendTemplateMail({\nto: &apos;example@example.com&apos;,\nsubject: &apos;This is a subject&apos;,\nhtml: &apos;&lt;h1&gt;Hello world&lt;/h1&gt;&apos;\n}, &apos;template1&apos;, { person: {name: &apos;Dario&apos;, surname: &apos;Rodriguez&apos;}});\nthis.mailer.sendTemplateMail(&apos;example@example.com&apos;, &apos;This is a subject&apos;, &apos;template1&apos;, { person: {name: &apos;Dario&apos;, surname: &apos;Rodriguez&apos;}});\naddTemplate\nAdds a new template to the MailerService.\nMethod signature:\naddTemplate(name: string, template: string, options?: CompileOptions): void;\nExample:\nthis.mailer.addTemplate(&apos;newTemplate&apos;, &apos;&lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt;{{&gt;partial1}}&lt;/body&gt;&lt;/html&gt;&apos;)\nregisterPartial\nRegister a new partial in Handlebars.\nMethod signature:\nregisterPartial(name: string, partial: Handlebars.Template&lt;any&gt;): void;\nExample:\nthis.mailer.registerPartial(&apos;partial&apos;, &apos;&lt;h1&gt;Hello World&lt;/h1&gt;&apos;)\nregisterHelper\nRegister a new helper in Handlebars.\nMethod signature:\nregisterHelper(name: string, helper: Handlebars.HelperDelegate): void;\nExample:\nthis.mailer.registerHelper(&apos;fullname&apos;, person =&gt; `${person.name} ${person.surname}`)\n"},{"id":861,"path":"../website/pages/docs/master-devon4node.asciidoc_guides.html#guides-mailer.asciidoc_handlebars-templates","type":"docs","title":"Handlebars templates","body":"34.12.4. Handlebars templates\nAs mentioned above, this module allow you to use Handlebars as template engine, but it is optional. If you do not need the Handlebars, you just need to keep the hbsOptions undefined.\nIn order to get the templates form the file system, you can specify the template folder, the partials folder and the helpers.\nAt the moment of module initialization, it will read the content of the template folder, and will register every file with the name (without extension) and the content as Handlebars template. It will do the same for the partials.\nYou can specify the extension of template files using the extension parameter. The default value is .handlebars\n"},{"id":862,"path":"../website/pages/docs/master-devon4node.asciidoc_guides.html#guides-mailer.asciidoc_local-development","type":"docs","title":"Local development","body":"34.12.5. Local development\nIf you want to work with this module but you don&#x2019;t have a SMTP server, you can use the streamTransport. Example:\n{\nmailOptions: {\nstreamTransport: true,\nnewline: &apos;windows&apos;,\n},\nemailFrom: ...\nhbsOptions: ...\n}\nThen, you need to get the sendPlainMail or sendTemplateMail result, and print the email to the standard output (STDOUT). Example:\nconst mail = await this.mailer.sendTemplateMail(...);\nmail.message.pipe(process.stdout);\n"},{"id":863,"path":"../website/pages/docs/master-devon4node.asciidoc_guides.html#guides-eslint-sonarqube-config.asciidoc","type":"docs","title":"Importing your ESLint reports into SonarQube","body":"34.13. Importing your ESLint reports into SonarQube\nThis guide covers the import of ESLint reports into SonarQube instances in CI environments, as this is the recommended way of using ESLint and SonarQube for devon4node projects. The prerequisites for this process are a CI environment, preferably a Production Line instance, and the ESLint CLI, which is already included when generating a new devon4node project.\nConfiguring the ESLint analysis\nYou can configure the ESLint analysis parameters in the .eslintrc.js file inside the top-level directory of your project. If you created your node project using the devon4node application schematic, this file will already exist. If you want to make further adjustments to it, have a look at the ESLint documentation.\nThe ESLint analysis script lint is already configured in the scripts part of your package.json. Simply add -f json &gt; report.json, so that the output of the analysis is saved in a .json file. Additional information to customization options for the ESLint CLI can be found here.\nTo run the analysis, execute the script with npm run lint inside the base directory of your project.\nConfiguring SonarQube\nIf you haven&#x2019;t already generated your CICD-related files, follow the tutorial on the devon4node schematic of our CICDGEN project, as you will need a Jenkinsfile configured in your project to proceed.\nInside the script for the SonarQube code analysis in your Jenkinsfile, add the parameter -Dsonar.eslint.reportPaths=report.json. Now, whenever a SonarQube analysis is triggered by your CI environment, the generated report will be loaded into your SonarQube instance.\nTo avoid duplicated issues, you can associate an empty TypeScript quality profile with your project in its server configurations.\n&#x2190;&#xA0;Previous:&#xA0;Layers&#xA0;| &#x2191;&#xA0;Up:&#xA0;devon4node&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;devon4node applications&#xA0;&#x2192;\n"},{"id":864,"path":"../website/pages/docs/master-devon4node.asciidoc_layers.html#master-devon4node.asciidoc_layers","type":"docs","title":"Layers","body":"33. Layers\n"},{"id":865,"path":"../website/pages/docs/master-devon4node.asciidoc_layers.html#layer-controller.asciidoc","type":"docs","title":"Controller Layer","body":"33.1. Controller Layer\nThe controller layer is responsible for handling the requests/responses to the client. This layer knows everything about the endpoints exposed, the expected input (and also validate it), the response schema, the HTTP codes for the response and the HTTP errors that every endpoint can send.\n"},{"id":866,"path":"../website/pages/docs/master-devon4node.asciidoc_layers.html#layer-controller.asciidoc_how-to-implement-the-controller-layer","type":"docs","title":"How to implement the controller layer","body":"33.1.1. How to implement the controller layer\nThis layer is implemented by the NestJS controllers. Let&#x2019;s see how it works with an example:\n@Controller(&apos;coffee/coffees&apos;)\nexport class CoffeeController {\nconstructor(private readonly coffeeService: CoffeeService) {}\n@Post(&apos;search&apos;)\n@HttpCode(200)\nasync searchCoffees(@Body() search: CoffeeSearch): Promise&lt;Array&lt;Coffee&gt;&gt; {\ntry {\nreturn await this.coffeeService.searchCoffees(search);\n} catch (error) {\nthrow new BadRequestException(error.message, error);\n}\n}\n}\nAs you can see in the example, to create a controller you only need to decorate a class with the Controller decorator. This example is handling all request to coffee/coffees.\nAlso, you have defined one handler. This handler is listening to POST request for the route coffee/coffees/search. In addition, this handler is waiting for a CoffeeSearch object and returns an array of Coffee. In order to keep it simple, that&#x2019;s all that you need in order to define one route.\nOne important thing that can be observed in this example is that there is no business logic. It delegates to the service layer and return the response to the client. At this point, transformations from the value that you receive from the service layer to the desired return type are also allowed.\nBy default, every POST handler return an HTTP 204 response with the returned value as body, but you can change it in a easy way by using decorators. As you can see in the example, the handler will return a HTTP 200 response (@HttpCode(200)).\nFinally, if the service layer throws an error, this handler will catch it and return a HTTP 400 Bad Request response. The controller layer is the only one that knows about the answers to the client, therefore it is the only one that knows which error codes should be sent.\n"},{"id":867,"path":"../website/pages/docs/master-devon4node.asciidoc_layers.html#layer-controller.asciidoc_validation","type":"docs","title":"Validation","body":"33.1.2. Validation\nIn order to do not propagate errors in the incoming payload, we need to validate all data in the controller layer. See the validation guide for more information.\n"},{"id":868,"path":"../website/pages/docs/master-devon4node.asciidoc_layers.html#layer-controller.asciidoc_error-handling","type":"docs","title":"Error handling","body":"33.1.3. Error handling\nIn the previous example, we catch all errors using the try/catch statement. This is not the usual implementation. In order to catch properly the errors you must use the exception filters. Example:\n@Controller(&apos;coffee/coffees&apos;)\nexport class CoffeeController {\nconstructor(private readonly coffeeService: CoffeeService) {}\n@Post(&apos;search&apos;)\n@HttpCode(200)\n@UseFilters(CaffeExceptionFilter)\nasync searchCoffees(@Body() search: CoffeeSearch): Promise&lt;Array&lt;Coffee&gt;&gt; {\nreturn await this.coffeeService.searchCoffees(search);\n}\n}\n"},{"id":869,"path":"../website/pages/docs/master-devon4node.asciidoc_layers.html#layer-service.asciidoc","type":"docs","title":"Service Layer","body":"33.2. Service Layer\nThe logic layer is the heart of the application and contains the main business logic. It knows everything about the business logic, but it does not know about the response to the client and the HTTP errors. That&#x2019;s why this layer is separated from the controller layer.\n"},{"id":870,"path":"../website/pages/docs/master-devon4node.asciidoc_layers.html#layer-service.asciidoc_how-to-implement-the-service-layer","type":"docs","title":"How to implement the service layer","body":"33.2.1. How to implement the service layer\nThis layer is implemented by services, a specific kind of providers. Let&#x2019;s see one example:\n@Injectable()\nexport class CoffeeService {\nconstructor(private readonly coffeeService: CoffeeService) {}\nasync searchCoffees(@InjectRepository(Coffee) coffeeRepository: Repository&lt;Coffee&gt;): Promise&lt;Array&lt;Coffee&gt;&gt; {\nconst coffees = this.coffeeRepository.find();\nreturn doSomeBusinessLogic(coffees);\n}\n}\nThis is the CoffeeService that we inject in the example of controller layer. As you can see, a service is a regular class with the Injectable decorator. Also, it inject as dependency the data access layer (in this specific case, the Repository&lt;Coffee&gt;).\nThe services expose methods in order to transform the input from the controllers by applying some business logic. They can also request data from the data access layer. And that&#x2019;s all.\n"},{"id":871,"path":"../website/pages/docs/master-devon4node.asciidoc_layers.html#layer-dataaccess.asciidoc","type":"docs","title":"Data Access Layer","body":"33.3. Data Access Layer\nThe data access layer is responsible for all outgoing connections to access and process data. This is mainly about accessing data from a persistent data-store but also about invoking external services.\nThis layer is implemented using providers. Those providers could be: services, repositories and others. Although services can be used for this layer, they should not be confused with the service layer. Services in this layer are responsible for data access, while services in the service layer are responsible for business logic.\n"},{"id":872,"path":"../website/pages/docs/master-devon4node.asciidoc_layers.html#layer-dataaccess.asciidoc_database","type":"docs","title":"Database","body":"33.3.1. Database\nWe strongly recommend TypeORM for database management in devon4node applications. Although services can be used for this layer, they should not be confused with the service layer. Services in this layer are responsible for data access, while services in the service layer are responsible for business logic. TypeORM supports the most commonly used relational databases, link Oracle, MySQL, MariaDB, PostgreSQL, SQLite, MSSQL and others. Also, it supports no-relational databases like MongoDB.\nTypeORM supports Active Record and Repository patterns. We recommend to use the Repository pattern. This pattern allows you to separate the data objects from the methods to manipulate the database.\n"},{"id":873,"path":"../website/pages/docs/master-devon4node.asciidoc_layers.html#layer-dataaccess.asciidoc_external-apis","type":"docs","title":"External APIs","body":"33.3.2. External APIs\nIn order to manage the data in a external API, you need to create a service for that purpose. In order to manage the connections with the external API, we strongly recommend the NestJS HTTP module\n&#x2190;&#xA0;Previous:&#xA0;devon4node Architecture&#xA0;| &#x2191;&#xA0;Up:&#xA0;devon4node&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Guides&#xA0;&#x2192;\n"},{"id":874,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc.html#master-devonfw-shop-floor.asciidoc","type":"docs","title":"VIII. devonfw shop floor","body":"VIII. devonfw shop floor\nWhat is devonfw shop floor?\nHow to use it\nProvisioning environments\nConfiguration and services integration\nCreate project\nDeployment environments\nMonitoring\nAnnexes\n&#x2190;&#xA0;Previous:&#xA0;GigaSpaces XAP (Smart Cache)&#xA0;| &#x2191;&#xA0;Up:&#xA0;devonfw guide&#xA0;| Next:&#xA0;What is devonfw shop floor?&#xA0;&#x2192;\n"},{"id":875,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_annexes.html#master-devonfw-shop-floor.asciidoc_annexes","type":"docs","title":"Annexes","body":"60. Annexes\n"},{"id":876,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_annexes.html#master-devonfw-shop-floor.asciidoc_bitbucket","type":"docs","title":"BitBucket","body":"60.1. BitBucket\n[Under construction]\nThe purpose of the present document is to provide the basic steps carried out to setup a BitBucket server in OpenShift.\nIntroduction\nBitBucket is the Atlassian tool that extends the Git functionality, by adding integration with JIRA, Confluence, or Trello, as well as incorporates extra features for security or management of user accounts (See BitBucket).\nBitBucket server is the Atlassian tool that runs the BitBucket services (See BitBucket server).\nThe followed approach has been not using command line, but OpenShift Web Console, by deploying the Docker image atlassian/bitbucket-server (available in Docker Hub) in the existing project Deployment.\nThe procedure below exposed consists basically in three main steps:\nDeploy the BitBucket server image (from OpenShift web console)\nAdd a route for the external traffic (from OpenShift web console)\nConfigure the BitBucket server (from BitBucket server web console)\nPrerequisites\nOpenShift up &amp; running\nAtlassian account (with personal account key). Not required for OpenShift, but for the initial BitBucket server configuration.\nProcedure\n]\n=== Step 0: Log into our OpenShift Web console\nStep 1: Get into Development project\nStep 2.1: Deploy a new image to the project\nStep 2.2: Introduce the image name (available in Docker Hub) and search\nImage name: atlassian/bitbucket-server\nStep 2.3: Leave by the moment the default config. since it is enough for the basic setup. Press Create\nStep 2.4: Copy the oc commands in case it is required to work via command line, and Go to overview\nStep 2.5: Wait until OpenShift deploys and starts up the image. All the info will be available.\nPlease notice that there are no pre-configured routes, hence the application is not accessible from outside the cluster.\nStep 3: Create a route in order for the application to be accessible from outside the cluster (external traffic). Press Create\nPlease notice that there are different fields that can be specified (hostname, port). If required, the value of those fields can be modified later.\nLeave by the moment the default config. as it is enough for the basic setup.\nThe route for external traffic is now available.\nNow the BitBucker server container is up &amp; running in our cluster.\nThe below steps correspond to the basic configuration of our BitBucket server.\nStep 4.1: Click on the link of the external traffic route. This will open our BitBucket server setup wizard\nStep 4.2: Leave by the moment the Internal database since it is enough for the basic setup (and it can be modified later), and click Next\nStep 4.3: Select the evaluation license, and click I have an account\nStep 4.4: Select the option Bitbucker (Server)\nStep 4.5: Introduce your organization (Capgemini), and click Generate License\nStep 4.6: Confirm that you want to install the license on the BitBucket server\nThe license key will be automatically generated. Click Next\nStep 4.7: Introduce the details of the Administration account.\nSince our BitBucket server is not going to be integrated with JIRA, click on Go to Bitbucket. The integration with JIRA can be configured later.\nStep 4.8: Log in with the admin account that has been just created\nDONE !!\n[Under construction]\nThe purpose of the present document is to provide the basic steps carried out to improve the configuration of BitBucket server in OpenShift.\nThe improved configuration consists on:\nPersistent Volume Claims\nHealth Checks (pending to be completed)\nPersistent Volume Claims.\nPlease notice that the BitBucket server container does not use persistent volume claims by default, which means that the data (e.g.: BitBucket server config.) will be lost from one deployment to another.\nIt is very important to create a persistent volume claim in order to prevent the mentioned loss of data.\nStep 1: Add storage\nStep 2: Select the appropriate storage, or create it from scratch if necessary\nStep 3: Introduce the required information\nPath as it is specified in the BitBucket server Docker image (/var/atlassian/application-data/bitbucket)\nVolume name with a unique name to clearly identify the volume\nThe change will be inmediately applied\n"},{"id":877,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_annexes.html#master-devonfw-shop-floor.asciidoc_selenium-basic-grid","type":"docs","title":"Selenium Basic Grid","body":"60.2. Selenium Basic Grid\n"},{"id":878,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_annexes.html#dsf-openshift-services-selenium-basic-grid.asciidoc","type":"docs","title":"Basic Selenium Grid setup in OpenShift","body":"60.2.1. Basic Selenium Grid setup in OpenShift\n[Under construction]\nThe purpose of the present document is to provide the basic steps carried out to setup a Selenium Grid (Hub + Nodes) in OpenShift.\nIntroduction\nSelenium is a tool to automate web browser across many platforms. It allows the automation of the testing in many different browsers, operating systems, programing laguages, or testing frameworks. (for further information pelase see Selenium)\nSelenium Grid is the platform provided by Selenium in order to perform the execution of tests in parallel and in a distributed way.\nIt basically consists on a Selenium Server (also known as hub or simply server) which redirects the requests it receives to the appropriate node (Firefox node, Chrome node, &#x2026;&#x200B;) depending on how the Selenium WebDriver is configured or implemented (See Selenium Doc.)\nAdditional documentacion:\nhttps://www.tutorialspoint.com/selenium/selenium_grids.htm\nhttp://www.softwaretestinghelp.com/selenium-ide-download-and-installation-selenium-tutorial-2\nhttps://examples.javacodegeeks.com/enterprise-java/selenium/selenium-standalone-server-example\nhttps://tripleqa.com/2016/09/26/hello-world-selenium\nhttp://queirozf.com/entries/selenium-hello-world-style-tutorial\nPrerequisites\nOpenShift up &amp; running\nProcedure\nThe present procedure is divided into two different main parts:\n* First part: Selenium Hub (server) installation\n* Second part: Selenium node installation (Firefox &amp; Chrome)\n* Create persistent volumes for the hub and the node(s)\nSelenium Hub installation\nThe followed approach consists on deploying new image from the OpenShift WenConsole.\nThe image as well as its documentation and details can be found at Selenium Hub Docker Image\nStep 1: Deploy Image\nStep 2: Image Name\nAs it is specified in the documentation (selenium/hub)\n(Please notice that, as it is described in the additional documentation of the above links, the server will run by default on 4444 port)\nStep 3: Introduce the appropriate resource name\n(selenium-hub in this case)\n(No additional config. is required by the moment)\nOnce the image is deployed, you will be able to check &amp; review the config. of the container. Please notice by, by default, no route is created for external traffic, hence the application (the selenium server or hub) is not reachable from outside the cluster\nStep 4: Create a route for external traffic\nStep 5: Change the default config. if necessary\nDONE !!\nThe Selenium Server is now accesible from outside the cluster. Click on the link of the route and you will be able to see the server home page.\nconsole/view config to see the default server config.\nPlease notice that the server is not detecting any node up &amp; running, since we have not yet installed none of them.\nSelenium Node Firefox installation\n(Same steps apply for Selenium Node Chrome with the selenium/node-chrome Docker image)\nThe key point of the nodes installation is to specify the host name and port of the hub. If this step is not correctly done, the container will be setup but the application will not run.\nThe followed approach consists on deploying new image from the OpenShift WenConsole.\nThe image as well as its documentation and details can be found at Selenium Hub Docker Image (firefox node in this case)\nStep 1: Deploy Image\nIntroduce the appropriate Docker Image name as it is specified in the documentation (selenium/node-firefox)\nStep 2: Introduce the appropriate resource name\n(selenium-node-firefox in this case)\nStep 3: Introduce, as environment variables, the host name and port of the selenium hub previously created\nEnv. var. for selenium hub host name\nName: HUB_PORT_4444_TCP_ADDR\nValue: The Selenium hub host name. It&#x2019;s recommended to use the service name of the internal OpenShift service.\nEnv. var. for host selenium hub host port\nName: HUB_PORT_4444_TCP_PORT\nValue: 4444 (by default), or the appropriate one if it was changed during the installation.\nDONE !!\nIf the creation of the container was correct, we will be able to see our new selenium-node-firefox application up &amp; running, as well as we will be able to see that the firefox node has correctly detected the selenium hub (in the log of the POD)\nIf we go back to the configuration of the SeleniumHub through the WebConsole, we also will be able to see the our new firefox node\nPersistent Volumes\nLast part of the installation of the Selenium Grid consists on creating persistent volumes for both, the hub container and the node container.\nPersistent Volumes can be easely created folling the the BitBucket Extra server configuration\n"},{"id":879,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_annexes.html#master-devonfw-shop-floor.asciidoc_mirabaud-experience","type":"docs","title":"Mirabaud Experience","body":"60.3. Mirabaud Experience\n"},{"id":880,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_annexes.html#dsf-mirabaud-cicd-environment-setup.asciidoc","type":"docs","title":"Mirabaud CICD Environment Setup","body":"60.3.1. Mirabaud CICD Environment Setup\nInitial requirements:\nOS: RHEL 6.5\nRemote setup in CI machine (located in the Netherlands)\n- Jenkins\n- Nexus\n- GitLab\n- Mattermost\n- Atlassian Crucible\n- SonarQube\n1. Install Docker and Docker Compose in RHEL 6.5\nDocker\nDue to that OS version, the only way to have Docker running in the CI machine is by installing it from the EPEL repository (Extra Packages for Enterprise Linux).\nAdd EPEL\n# rpm -iUvh http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm\nInstall docker.io from that repository\n# yum -y install docker-io\nStart Docker daemon\n# service docker start\nCheck the installation\n# docker -v\nDocker version 1.7.1, build 786b29d/1.7.1\nDocker Compose\nDownload and install it via curl. It will use this site.\n# curl -L https://github.com/docker/compose/releases/download/1.5.0/docker-compose-`uname -s`-`uname -m` &gt; /usr/local/bin/docker-compose\n# chmod +x /usr/local/bin/docker-compose\nAdd it to your sudo path:\nFind out where it is:\n# echo $PATH\nCopy the docker-compose file from /usr/local/bin/ to your sudo PATH.\n# docker-compose -v\ndocker-compose version 1.5.2, build 7240ff3\n2. Directories structure\nSeveral directories had been added to organize some files related to docker (like docker-compose.yml) and docker volumes for each service. Here&#x2019;s how it looks:\n/home\n/[username]\n/jenkins\n/volumes\n/jenkins_home\n/sonarqube\n/volumes\n/conf\n/data\n/extensions\n/lib\n/bundled-plugins\n/nexus\n/volumes\n/nexus-data\n/crucible\n/volumes\n/\n/gitlab\ndocker-compose.yml\n/volumes\n/etc\n/gitlab\n/var\n/log\n/opt\n/mattermost\ndocker-compose.yml\n/volumes\n/db\n/var\n/lib\n/postgresql\n/data\n/app\n/mattermost\n/config\n/data\n/logs\n/web\n/cert\n3. CICD Services with Docker\nSome naming conventions had been followed as naming containers as mirabaud_[service].\nSeveral folders have been created to store each service&#x2019;s volumes, docker-compose.yml(s), extra configuration settings and so on:\nJenkins\nCommand\n# docker run -d -p 8080:8080 -p 50000:50000 --name=mirabaud_jenkins \\\n-v /home/[username]/jenkins/volumes/jenkins_home:/var/jenkins_home \\\njenkins\nGenerate keystore\nkeytool -importkeystore -srckeystore server.p12 -srcstoretype pkcs12 -srcalias 1 -destkeystore newserver.jks -deststoretype jks -destalias server\nStart jekins with SSL (TODO: make a docker-compose.yml for this):\nsudo docker run -d --name mirabaud_jenkins -v /jenkins:/var/jenkins_home -p 8080:8443 jenkins --httpPort=-1 --httpsPort=8443 --httpsKeyStore=/var/jenkins_home/certs/keystore.jks --httpsKeyStorePassword=Mirabaud2017\nVolumes\nvolumes/jenkins_home:/var/jenkins_home\nSonarQube\nCommand\n# docker run -d -p 9000:9000 -p 9092:9092 --name=mirabaud_sonarqube \\\n-v /home/[username]/sonarqube/volumes/conf:/opt/sonarqube/conf \\\n-v /home/[username]/sonarqube/volumes/data:/opt/sonarqube/data \\\n-v /home/[username]/sonarqube/volumes/extensions:/opt/sonarqube/extensions \\\n-v /home/[username]/sonarqube/volumes/lib/bundled-plugins:/opt/sonarqube//lib/bundled-plugins \\\nsonarqube\nVolumes\nvolumes/conf:/opt/sonarqube/conf\nvolumes/data:/opt/sonarqube/data\nvolumes/extensions:/opt/sonarqube/extensions\nvolumes/lib/bundled-plugins:/opt/sonarqube/lib/bundled-plugins\nNexus\nCommand\n# docker run -d -p 8081:8081 --name=mirabaud_nexus\\\n-v /home/[username]/nexus/nexus-data:/sonatype-work\nsonatype/nexus\nVolumes\nvolumes/nexus-data/:/sonatype-work\nAtlassian Crucible\nCommand\n# docker run -d -p 8084:8080 --name=mirabaud_crucible \\\n-v /home/[username]/crucible/volumes/data:/atlassian/data/crucible\nmswinarski/atlassian-crucible:latest\nVolumes\nvolumes/data:/atlassian/data/crucible\n4. CICD Services with Docker Compose\nBoth Services had been deploying by using the # docker-compose up -d command from their root directories (/gitlab and /mattermost). The syntax of the two docker-compose.yml files is the one corresponding with the 1st version (due to the docker-compose v1.5).\nGitLab\ndocker-compose.yml\nmirabaud:\nimage: &apos;gitlab/gitlab-ce:latest&apos;\nrestart: always\nports:\n- &apos;8888:80&apos;\nvolumes:\n- &apos;/home/[username]/gitlab/volumes/etc/gilab:/etc/gitlab&apos;\n- &apos;/home/[username]/gitlab/volumes/var/log:/var/log/gitlab&apos;\n- &apos;/home/[username]/gitlab/volumes/var/opt:/var/opt/gitlab&apos;\nCommand (docker)\ndocker run -d -p 8888:80 --name=mirabaud_gitlab \\\n-v /home/[username]/gitlab/volumes/etc/gitlab/:/etc/gitlab \\\n-v /home/[username]/gitlab/volumes/var/log:/var/log/gitlab \\\n-v /home/[username]/gitlab/volumes/var/opt:/var/opt/gitlab \\\ngitlab/gitlab-ce\nVolumes\nvolumes/etc/gitlab:/etc/gitlab\nvolumes/var/opt:/var/log/gitlab\nvolumes/var/log:/var/log/gitlab\nMattermost\ndocker-compose.yml:\ndb:\nimage: mattermost/mattermost-prod-db\nrestart: unless-stopped\nvolumes:\n- ./volumes/db/var/lib/postgresql/data:/var/lib/postgresql/data\n- /etc/localtime:/etc/localtime:ro\nenvironment:\n- POSTGRES_USER=mmuser\n- POSTGRES_PASSWORD=mmuser_password\n- POSTGRES_DB=mattermost\napp:\nimage: mattermost/mattermost-prod-app\nlinks:\n- db:db\nrestart: unless-stopped\nvolumes:\n- ./volumes/app/mattermost/config:/mattermost/config:rw\n- ./volumes/app/mattermost/data:/mattermost/data:rw\n- ./volumes/app/mattermost/logs:/mattermost/logs:rw\n- /etc/localtime:/etc/localtime:ro\nenvironment:\n- MM_USERNAME=mmuser\n- MM_PASSWORD=mmuser_password\n- MM_DBNAME=mattermost\nweb:\nimage: mattermost/mattermost-prod-web\nports:\n- &quot;8088:80&quot;\n- &quot;8089:443&quot;\nlinks:\n- app:app\nrestart: unless-stopped\nvolumes:\n- ./volumes/web/cert:/cert:ro\n- /etc/localtime:/etc/localtime:ro\nSSL Certificate\nHow to generate the certificates:\nGet the crt and key from CA or generate a new one self-signed. Then:\n// 1. create the p12 keystore\n# openssl pkcs12 -export -in cert.crt -inkey mycert.key -out certkeystore.p12\n// 2. export the pem certificate with password\n# openssl pkcs12 -in certkeystore.p12 -out cert.pem\n// 3. export the pem certificate without password\n# openssl rsa -in cert.pem -out key-no-password.pem\nSSL:\nCopy the cert and the key without password at:\n./volumes/web/cert/cert.pem\nand\n./volumes/web/cert/key-no-password.pem\nRestart the server and the SSL should be enabled at port 8089 using HTTPS.\nVolumes\n-- db --\nvolumes/db/var/lib/postgresql/data:/var/lib/postgresql/data\n/etc/localtime:/etc/localtime:ro # absolute path\n-- app --\nvolumes/app/mattermost/config:/mattermost/config:rw\nvolumes/app/mattermost/data:/mattermost/data:rw\nvolumes/app/mattermost/logs:/mattermost/logs:rw\n/etc/localtime:/etc/localtime:ro # absolute path\n-- web --\nvolumes/web/cert:/cert:ro\n/etc/localtime:/etc/localtime:ro # absolute path\n5. Service Integration\nAll integrations had been done following CICD Services Integration guides:\nJenkins - Nexus integration\nJenkins - GitLab integration\nJenkins - SonarQube integration\nNote\nThese guides may be obsolete. You can find here the official configuration guides,\n"},{"id":881,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_annexes.html#dsf-mirabaud-jenkins-gitLab-integration.asciidoc","type":"docs","title":"Jenkins - GitLab integration","body":"60.3.2. Jenkins - GitLab integration\nThe first step to have a Continuous Integration system for your development is to make sure that all your changes to your team&#x2019;s remote repository are evaluated by the time they are pushed. That usually implies the usage of so-called webhooks. You&#x2019;ll find a fancy explanation about what Webhooks are in here.\nTo resume what we&#x2019;re doing here, we are going to prepare our Jenkins and our GitLab so when a developer pushes some changes to the GitLab repository, a pipeline in Jenkins gets triggered. Just like that, in an automatic way.\n1. Jenkins GitLab plugin\nAs it usually happens, some Jenkins plug-in(s) must be installed. In this case, let&#x2019;s install those related with GitLab:\n2. GitLab API Token\nTo communicate with GitLab from Jenkins, we will need to create an authentication token from your GitLab user settings. A good practice for this would be to create it from a machine user. Something like (i.e.) devonfw-ci/******.\nSimply by adding a name to it and a date for it expire is enough:\nAs GitLab said, you should make sure you don&#x2019;t lose your token. Otherwise you would need to create a new one.\nThis will allow Jenkins to connect with right permissions to our GitLab server.\n3. Create &quot;GitLab API&quot; Token credentials\nThose credentials will use that token already generated in GitLab to connect once we declare the GitLab server in the Global Jenkins configuration. Obviously, those credentials must be GitLab API token-like.\nThen, we add the generated token in the API token field:\nLook in your Global credentials if they had been correctly created:\n4. Create GitLab connection in Jenkins\nSpecify a GitLab connection in your Jenkins&#x2019;s Manage Jenkins &gt; Configure System configuration. This will tell Jenkins where is our GitLab server, a user to access it from and so on.\nYou&#x2019;ll need to give it a name, for example, related with what this GitLab is dedicated for (specific clients, internal projects&#x2026;&#x200B;). Then, the Gitlab host URL is just where your GitLab server is. If you have it locally, that field should look similar to:\nConnection name: my-local-gitlab\nGitlab host URL: http://localhost:${PORT_NUMBER}\nFinally, we select our recently GitLab API token as credentials.\n5. Jenkins Pipeline changes\n5.1 Choose GitLab connection in Pipeline&#x2019;s General configuration\nFirst, our pipeline should allow us to add a GitLab connection to connect to (the already created one).\nIn the case of the local example, could be like this:\nGitLab connection: my-local-gitlab\nGitLab Repository Name: myusername/webhook-test (for example)\n5.2 Create a Build Trigger\nYou should already see your GitLab project&#x2019;s URL (as you stated in the General settings of the Pipeline).\nWrite .*build.* in the comment for triggering a build\nSpecify or filter the branch of your repo you want use as target. That means, whenever a git action is done to that branch (for example, master), this Pipeline is going to be built.\nGenerate a Secret token (to be added in the yet-to-be-created GitLab webhook).\n6. GitLab Webhook\nGo to you GitLab project&#x2019;s Settings &gt; Integration section.\nAdd the path to your Jenkins Pipeline. Make sure you add project instead of job in the path.\nPaste the generated Secret token of your Jenkins pipeline\nSelect your git action that will trigger the build.\n7. Results\nAfter all those steps you should have a result similar to this in your Pipeline:\nEnjoy the Continuous Integration! :)\n"},{"id":882,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_annexes.html#dsf-mirabaud-jenkins-nexus-integration.asciidoc","type":"docs","title":"Jenkins - Nexus integration","body":"60.3.3. Jenkins - Nexus integration\nNexus is used to both host dependencies for devonfw projects to download (common Maven ones, custom ones such as ojdb and even devonfw so-far-IP modules). Moreover, it will host our projects&apos; build artifacts (.jar, .war, &#x2026;&#x200B;) and expose them for us to download, wget and so on. A team should have a bidirectional relation with its Nexus repository.\n1. Jenkins credentials to access Nexus\nBy default, when Nexus is installed, it contains 3 user credentials for different purposes. The admin ones look like this: admin/admin123. There are also other 2: deployment/deployment123 and TODO.\n// ADD USER TABLE IMAGE FROM NEXUS\nIn this case, let&#x2019;s use the ones with the greater permissions: admin/admin123.\nGo to Credentials &gt; System (left sidebar of Jenkins) then to Global credentials (unrestricted) on the page table and on the left sidebar again click on Add Credentials.\nThis should be shown in your Jenkins:\nFill the form like this:\nAnd click in OK to create them. Check if the whole thing went as expected:\n2. Jenkins Maven Settings\nThose settings are also configured (or maybe not-yet-configured) in our devonfw distributions in:\n/${devonfw-dist-path}\n/software\n/maven\n/conf\nsettings.xml\nGo to Manage Jenkins &gt; Managed files and select Add a new Config in the left sidebar.\nThe ID field will get automatically filled with a unique value if you don&#x2019;t set it up. No problems about that. Click on Submit and let&#x2019;s create some Servers Credentials:\nThose Server Credentials will allow Jenkins to access to the different repositories/servers that are going to be declared afterwards.\nLet&#x2019;s create 4 server credentials.\nmy.nexus: Will serve as general profile for Maven.\nmynexus.releases: When a mvn deploy process is executed, this will tell Maven where to push releases to.\nmynexus.snapshots: The same as before, but with snapshots instead.\nmynexus.central: Just in case we want to install an specific dependency that is not by default in the Maven Central repository (such as ojdbc), Maven will point to it instead.\nA more or less complete Jenkins Maven settings would look look like this:\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;\n&lt;settings xmlns=&quot;http://maven.apache.org/SETTINGS/1.0.0&quot;\nxmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;\nxsi:schemaLocation=&quot;http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd&quot;&gt;\n&lt;mirrors&gt;\n&lt;mirror&gt;\n&lt;id&gt;mynexus.central&lt;/id&gt;\n&lt;mirrorOf&gt;central&lt;/mirrorOf&gt;\n&lt;name&gt;central&lt;/name&gt;\n&lt;url&gt;http://${URL-TO-YOUR-NEXUS-REPOS}/central&lt;/url&gt;\n&lt;/mirror&gt;\n&lt;/mirrors&gt;\n&lt;profiles&gt;\n&lt;profile&gt;\n&lt;id&gt;my.nexus&lt;/id&gt;\n&lt;!-- 3 REPOS ARE DECLARED --&gt;\n&lt;repositories&gt;\n&lt;repository&gt;\n&lt;id&gt;mynexus.releases&lt;/id&gt;\n&lt;name&gt;mynexus Releases&lt;/name&gt;\n&lt;url&gt;http://${URL-TO-YOUR-NEXUS-REPOS}/releases&lt;/url&gt;\n&lt;releases&gt;\n&lt;enabled&gt;true&lt;/enabled&gt;\n&lt;updatePolicy&gt;always&lt;/updatePolicy&gt;\n&lt;/releases&gt;\n&lt;snapshots&gt;\n&lt;enabled&gt;false&lt;/enabled&gt;\n&lt;updatePolicy&gt;always&lt;/updatePolicy&gt;\n&lt;/snapshots&gt;\n&lt;/repository&gt;\n&lt;repository&gt;\n&lt;id&gt;mynexus.snapshots&lt;/id&gt;\n&lt;name&gt;mynexus Snapshots&lt;/name&gt;\n&lt;url&gt;http://${URL-TO-YOUR-NEXUS-REPOS}/snapshots&lt;/url&gt;\n&lt;releases&gt;\n&lt;enabled&gt;false&lt;/enabled&gt;\n&lt;updatePolicy&gt;always&lt;/updatePolicy&gt;\n&lt;/releases&gt;\n&lt;snapshots&gt;\n&lt;enabled&gt;true&lt;/enabled&gt;\n&lt;updatePolicy&gt;always&lt;/updatePolicy&gt;\n&lt;/snapshots&gt;\n&lt;/repository&gt;\n&lt;/repositories&gt;\n&lt;pluginRepositories&gt;\n&lt;pluginRepository&gt;\n&lt;id&gt;public&lt;/id&gt;\n&lt;name&gt;Public Repositories&lt;/name&gt;\n&lt;url&gt;http://${URL-TO-YOUR-NEXUS}/nexus/content/groups/public/&lt;/url&gt;\n&lt;releases&gt;\n&lt;enabled&gt;true&lt;/enabled&gt;\n&lt;updatePolicy&gt;always&lt;/updatePolicy&gt;\n&lt;/releases&gt;\n&lt;snapshots&gt;\n&lt;enabled&gt;true&lt;/enabled&gt;\n&lt;updatePolicy&gt;always&lt;/updatePolicy&gt;\n&lt;/snapshots&gt;\n&lt;/pluginRepository&gt;\n&lt;/pluginRepositories&gt;\n&lt;/profile&gt;\n&lt;/profiles&gt;\n&lt;!-- HERE IS WHERE WE TELL MAVEN TO CHOOSE THE my.nexus PROFILE --&gt;\n&lt;activeProfiles&gt;\n&lt;activeProfile&gt;my.nexus&lt;/activeProfile&gt;\n&lt;/activeProfiles&gt;\n&lt;/settings&gt;\n3. Use it in Jenkins Pipelines\n"},{"id":883,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_annexes.html#dsf-mirabaud-jenkins-sonarqube-integration.asciidoc","type":"docs","title":"Jenkins - SonarQube integration","body":"60.3.4. Jenkins - SonarQube integration\nFirst thing is installing both tools by, for example, Docker or Docker Compose. Then, we have to think about how they should collaborate to create a more efficient Continuous Integration process.\nOnce our project&#x2019;s pipeline is triggered (it could also be triggered in a fancy way, such as when a merge to the develop branch is done).\n1. Jenkins SonarQube plugin\nTypically in those integration cases, Jenkins plug-in installations become a must. Let&#x2019;s look for some available SonarQube plug-in(s) for Jenkins:\n2. SonarQube token\nOnce installed let&#x2019;s create a token in SonarQube so that Jenkins can communicate with it to trigger their Jobs. Once we install SonarQube in our CI/CD machine (ideally a remote machine) let&#x2019;s login with admin/admin credentials:\nAfterwards, SonarQube itself asks you to create this token we talked about (the name is up to you):\nThen a token is generated:\nYou click in &quot;continue&quot; and the token&#x2019;s generation is completed:\n3. Jenkins SonarQube Server setup\nNow we need to tell Jenkins where is SonarQube and how to communicate with it. In Manage Jenkins &gt; Configure Settings. We add a name for the server (up to you), where it is located (URL), version and the Server authentication token created in point 2.\n4. Jenkins SonarQube Scanner\nInstall a SonarQube Scanner as a Global tool in Jenkins to be used in the project&#x2019;s pipeline.\n5. Pipeline code\nLast step is to add the SonarQube process in our project&#x2019;s Jenkins pipeline. The following code will trigger a SonarQube process that will evaluate our code&#x2019;s quality looking for bugs, duplications, and so on.\nstage &apos;SonarQube Analysis&apos;\ndef scannerHome = tool &apos;SonarQube scanner&apos;;\nsh &quot;${scannerHome}/bin/sonar-scanner \\\n-Dsonar.host.url=http://url-to-your-sq-server:9000/ \\\n-Dsonar.login=[SONAR_USER] -Dsonar.password=[SONAR_PASS] \\\n-Dsonar.projectKey=[PROJECT_KEY] \\\n-Dsonar.projectName=[PROJECT_NAME] -Dsonar.projectVersion=[PROJECT_VERSION] \\\n-Dsonar.sources=. -Dsonar.java.binaries=. \\\n-Dsonar.java.source=1.8 -Dsonar.language=java&quot;\n6. Results\nAfter all this, you should end up having something like this in Jenkins:\nAnd in SonarQube:\n7. Changes in a devonfw project to execute SonarQube tests with Coverage\nThe plugin used to have Coverage reports in the SonarQube for devonfw projects is Jacoco. There are some changes in the project&#x2019;s parent pom.xml that are mandatory to use it.\nInside of the &lt;properties&gt; tag:\n&lt;properties&gt;\n(...)\n&lt;sonar.jacoco.version&gt;3.8&lt;/sonar.jacoco.version&gt;\n&lt;sonar.java.coveragePlugin&gt;jacoco&lt;/sonar.java.coveragePlugin&gt;\n&lt;sonar.core.codeCoveragePlugin&gt;jacoco&lt;/sonar.core.codeCoveragePlugin&gt;\n&lt;sonar.dynamicAnalysis&gt;reuseReports&lt;/sonar.dynamicAnalysis&gt;\n&lt;sonar.language&gt;java&lt;/sonar.language&gt;\n&lt;sonar.java.source&gt;1.7&lt;/sonar.java.source&gt;\n&lt;sonar.junit.reportPaths&gt;target/surefire-reports&lt;/sonar.junit.reportPaths&gt;\n&lt;sonar.jacoco.reportPaths&gt;target/jacoco.exec&lt;/sonar.jacoco.reportPaths&gt;\n&lt;sonar.sourceEncoding&gt;UTF-8&lt;/sonar.sourceEncoding&gt;\n&lt;sonar.exclusions&gt;\n**/generated-sources/**/*,\n**io/oasp/mirabaud/general/**/*,\n**/*Dao.java,\n**/*Entity.java,\n**/*Cto.java,\n**/*Eto.java,\n**/*SearchCriteriaTo.java,\n**/*management.java,\n**/*SpringBootApp.java,\n**/*SpringBootBatchApp.java,\n**/*.xml,\n**/*.jsp\n&lt;/sonar.exclusions&gt;\n&lt;sonar.coverage.exclusions&gt;\n**io/oasp/mirabaud/general/**/*,\n**/*Dao.java,\n**/*Entity.java,\n**/*Cto.java,\n**/*Eto.java,\n**/*SearchCriteriaTo.java,\n**/*management.java,\n**/*SpringBootApp.java,\n**/*SpringBootBatchApp.java,\n**/*.xml,\n**/*.jsp\n&lt;/sonar.coverage.exclusions&gt;\n&lt;sonar.host.url&gt;http://${YOUR_SONAR_SERVER_URL}/&lt;/sonar.host.url&gt;\n&lt;jacoco.version&gt;0.7.9&lt;/jacoco.version&gt;\n&lt;war.plugin.version&gt;3.2.0&lt;/war.plugin.version&gt;\n&lt;assembly.plugin.version&gt;3.1.0&lt;/assembly.plugin.version&gt;\n&lt;/properties&gt;\nOf course, those sonar amd sonar.coverage can/must be changed to fit with other projects.\nNow add the Jacoco Listener as a dependency:\n&lt;dependencies&gt;\n&lt;dependency&gt;\n&lt;groupId&gt;org.sonarsource.java&lt;/groupId&gt;\n&lt;artifactId&gt;sonar-jacoco-listeners&lt;/artifactId&gt;\n&lt;scope&gt;test&lt;/scope&gt;\n&lt;/dependency&gt;\n&lt;/dependencies&gt;\nPlugin Management declarations:\n&lt;pluginManagement&gt;\n&lt;plugins&gt;\n&lt;plugin&gt;\n&lt;groupId&gt;org.sonarsource.scanner.maven&lt;/groupId&gt;\n&lt;artifactId&gt;sonar-maven-plugin&lt;/artifactId&gt;\n&lt;version&gt;3.2&lt;/version&gt;\n&lt;/plugin&gt;\n&lt;plugin&gt;\n&lt;groupId&gt;org.jacoco&lt;/groupId&gt;\n&lt;artifactId&gt;jacoco-maven-plugin&lt;/artifactId&gt;\n&lt;version&gt;${jacoco.version}&lt;/version&gt;\n&lt;/plugin&gt;\n&lt;/plugins&gt;\n&lt;pluginManagement&gt;\nPlugins:\n&lt;plugins&gt;\n(...)\n&lt;plugin&gt;\n&lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\n&lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt;\n&lt;version&gt;2.20.1&lt;/version&gt;\n&lt;configuration&gt;\n&lt;argLine&gt;-XX:-UseSplitVerifier -Xmx2048m ${surefireArgLine}&lt;/argLine&gt;\n&lt;testFailureIgnore&gt;false&lt;/testFailureIgnore&gt;\n&lt;useFile&gt;false&lt;/useFile&gt;\n&lt;reportsDirectory&gt;${project.basedir}/${sonar.junit.reportPaths}&lt;/reportsDirectory&gt;\n&lt;argLine&gt;${jacoco.agent.argLine}&lt;/argLine&gt;\n&lt;excludedGroups&gt;${oasp.test.excluded.groups}&lt;/excludedGroups&gt;\n&lt;alwaysGenerateSurefireReport&gt;true&lt;/alwaysGenerateSurefireReport&gt;\n&lt;aggregate&gt;true&lt;/aggregate&gt;\n&lt;properties&gt;\n&lt;property&gt;\n&lt;name&gt;listener&lt;/name&gt;\n&lt;value&gt;org.sonar.java.jacoco.JUnitListener&lt;/value&gt;\n&lt;/property&gt;\n&lt;/properties&gt;\n&lt;/configuration&gt;\n&lt;/plugin&gt;\n&lt;plugin&gt;\n&lt;groupId&gt;org.jacoco&lt;/groupId&gt;\n&lt;artifactId&gt;jacoco-maven-plugin&lt;/artifactId&gt;\n&lt;configuration&gt;\n&lt;argLine&gt;-Xmx128m&lt;/argLine&gt;\n&lt;append&gt;true&lt;/append&gt;\n&lt;propertyName&gt;jacoco.agent.argLine&lt;/propertyName&gt;\n&lt;destFile&gt;${sonar.jacoco.reportPath}&lt;/destFile&gt;\n&lt;excludes&gt;\n&lt;exclude&gt;**/generated-sources/**/*,&lt;/exclude&gt;\n&lt;exclude&gt;**io/oasp/${PROJECT_NAME}/general/**/*&lt;/exclude&gt;\n&lt;exclude&gt;**/*Dao.java&lt;/exclude&gt;\n&lt;exclude&gt;**/*Entity.java&lt;/exclude&gt;\n&lt;exclude&gt;**/*Cto.java&lt;/exclude&gt;\n&lt;exclude&gt;**/*Eto.java&lt;/exclude&gt;\n&lt;exclude&gt;**/*SearchCriteriaTo.java&lt;/exclude&gt;\n&lt;exclude&gt;**/*management.java&lt;/exclude&gt;\n&lt;exclude&gt;**/*SpringBootApp.java&lt;/exclude&gt;\n&lt;exclude&gt;**/*SpringBootBatchApp.java&lt;/exclude&gt;\n&lt;exclude&gt;**/*.class&lt;/exclude&gt;\n&lt;/excludes&gt;\n&lt;/configuration&gt;\n&lt;executions&gt;\n&lt;execution&gt;\n&lt;id&gt;prepare-agent&lt;/id&gt;\n&lt;phase&gt;initialize&lt;/phase&gt;\n&lt;goals&gt;\n&lt;goal&gt;prepare-agent&lt;/goal&gt;\n&lt;/goals&gt;\n&lt;configuration&gt;\n&lt;destFile&gt;${sonar.jacoco.reportPath}&lt;/destFile&gt;\n&lt;append&gt;true&lt;/append&gt;\n&lt;/configuration&gt;\n&lt;/execution&gt;\n&lt;execution&gt;\n&lt;id&gt;report-aggregate&lt;/id&gt;\n&lt;phase&gt;verify&lt;/phase&gt;\n&lt;goals&gt;\n&lt;goal&gt;report-aggregate&lt;/goal&gt;\n&lt;/goals&gt;\n&lt;/execution&gt;\n&lt;execution&gt;\n&lt;id&gt;jacoco-site&lt;/id&gt;\n&lt;phase&gt;verify&lt;/phase&gt;\n&lt;goals&gt;\n&lt;goal&gt;report&lt;/goal&gt;\n&lt;/goals&gt;\n&lt;/execution&gt;\n&lt;/executions&gt;\n&lt;/plugin&gt;\n&lt;/plugins&gt;\nJenkins SonarQube execution\nIf the previous configuration is already setup, once Jenkins execute the sonar maven plugin, it will automatically execute coverage as well.\nThis is an example of a block of code from a devonfw project&#x2019;s Jenkinsfile:\nwithMaven(globalMavenSettingsConfig: &apos;YOUR_GLOBAL_MAVEN_SETTINGS&apos;, jdk: &apos;OpenJDK 1.8&apos;, maven: &apos;Maven_3.3.9&apos;) {\nsh &quot;mvn sonar:sonar -Dsonar.login=[USERNAME] -Dsonar.password=[PASSWORD]&quot;\n}\n"},{"id":884,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_annexes.html#master-devonfw-shop-floor.asciidoc_azure-devops","type":"docs","title":"Azure DevOps","body":"60.4. Azure DevOps\n"},{"id":885,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_annexes.html#dsf-azure-install-sonar-with-docker-in-a-virtual-machine.asciidoc_connect-to-a-virtual-machinevm-in-azure","type":"docs","title":"Connect to a Virtual Machine(VM) in Azure","body":"60.4.1. Connect to a Virtual Machine(VM) in Azure\nPre-requisites\nHave a VM created and a private key in order to connect to it\nEstablish a connection\n1- Open the client of your choice(putty,cmder,bash)\n2- Ensure you have read-only access to the private key.\nchmod 400 azureuser.pem\n3- Run this command to connect to your VM\nssh -i &lt;private key path&gt; azureuser@51.103.78.61\nnote: To get the IP go to your azure portal, click on your VM, click on Networking and you will find the IP needed to establish the connection\nYou are connected:\n"},{"id":886,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_annexes.html#dsf-azure-install-sonar-with-docker-in-a-virtual-machine.asciidoc_install-sonar-using-docker-and-docker-compose","type":"docs","title":"Install Sonar using Docker and Docker-compose","body":"60.4.2. Install Sonar using Docker and Docker-compose\nAs an example we will use the practical case of Bad Weather, a project where we were asked to install Sonar inside a VM in Azure portal\nWe had 2 possible scenarios, we went for the case A since no other service will be installed in this VM\nSteps\n1- Install docker and docker compose in the VM\nsudo dnf config-manager --add-repo=https://download.docker.com/linux/centos/docker-ce.repo\nsudo dnf list docker-ce\nsudo dnf install docker-ce --nobest -y\nsudo systemctl start docker\nsudo systemctl enable docker\ndocker --version\nsudo dnf install curl -y\nsudo curl -L &quot;https://github.com/docker/compose/releases/download/1.25.0/docker-compose-$(uname -s)-$(uname -m)&quot; -o /usr/local/bin/docker-compose\nsudo chmod +x /usr/local/bin/docker-compose\nsudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose\ndocker-compose --version\n2- Deploy SonarQube and Postgress\n2.1- Set necesary parameters for sonarqube\nsudo sysctl -w vm.max_map_count=262144\nsudo sysctl -w fs.file-max=65536\nsudo ulimit -n 65536\nsudo ulimit -u 4096\n2.2- Use docker-compose with the next definition to deploy it:\nvim /home/sonar/docker-compose.yaml\nversion: &quot;3&quot;\nservices:\nsonarqube:\nimage: &quot;sonarqube:7.9-community&quot;\nnetworks:\n- sonar\nenvironment:\n- sonar.jdbc.username=user\n- sonar.jdbc.password=pass\n- sonar.jdbc.url=jdbc:postgresql://sonarqube-db:5432/sonar\nports:\n- &quot;80:9000&quot;\ndepends_on:\n- &quot;sonarqube-db&quot;\nvolumes:\n- &quot;$PWD/volumes/sonarqube/conf:/opt/sonarqube/conf&quot;\n- &quot;$PWD/volumes/sonarqube/data:/opt/sonarqube/data&quot;\n- &quot;$PWD/volumes/sonarqube/extensions:/opt/sonarqube/extensions&quot;\n- &quot;$PWD/volumes/sonarqube/logs:/opt/sonarqube/logs&quot;\nulimits:\nnofile:\nsoft: 65536\nhard: 65536\nsonarqube-db:\nimage: &quot;postgres:12-alpine&quot;\nnetworks:\n- sonar\nvolumes:\n- &quot;$PWD/volumes/sonarqube-db/data:/var/lib/postgresql/data&quot;\nenvironment:\n- POSTGRES_USER=youruser\n- POSTGRES_PASSWORD=yourpass\n- POSTGRES_DB=sonar\n- PGDATA=/var/lib/postgresql/data\nnetworks:\nsonar:\ndriver: bridge\n3- Update the start configuration to set automatically the correct values and run the docker-compose\nvim /usr/local/sbin/start.sh\nsysctl -w vm.max_map_count=262144\nsysctl -w fs.file-max=65536\nulimit -n 65536\nulimit -u 4096\ncd /home/sonar &amp;&amp; docker-compose up -d\n4- Add this to execute the docker-compose file every time the machine turns on\ncrontab -e\n@reboot /usr/local/sbin/start.sh\nvim /etc/sysctl.conf\nvm.max_map_count=262144\nfs.file-max=65536\nYour Sonar is Up and running in your VM\n"},{"id":887,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_annexes.html#create-an-azure-pipeline-from-scratch","type":"docs","title":"Create an Azure pipeline from scratch","body":"60.4.3. Create an Azure pipeline from scratch\nThe following steps will allow you to create a basic pipeline in Azure Devops from scratch\nIn order to deploy in Azure, we&#x2019;ve created an automatic pipeline in Azure Devops that will be executed automaticaly when developers make a push to the Azure repositories, the pipeline will compile the code, build the application and ensure with automatic tests that the build is not going to break the application, to ensure a good quality code the code will be analyzed by sonar as well as your code coverage and last but not least, your application will be deployed using Azure App Services.\n"},{"id":888,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_annexes.html#dsf-azure-pipelines.asciidoc_steps","type":"docs","title":"Steps","body":"60.4.4. Steps\n1- Sign in to your Azure DevOps organization and navigate to your project.\n2- Go to Pipelines, and then select New Pipeline.\n3- Choose the location of your source code(Github, Bitbucket,Azure repos..etc), in this case we have our code in Azure Repos Git.\nA list of your repositories will be shown here:\n4- When the list of repositories appears, select your repository.\nDepending on your project type(Java, .NET, Python or JavaScript) the following configuration will change, in this case our project is a .NET, for more type of projects please follow the official documentation.\n5- When the Configure tab appears, select ASP.NET Core(or the one according to your project)\n6- A .yaml file in your ./ location will be generated with all the required steps to run your pipeline.\nThe name of this .yaml file is &apos;azure-pipelines.yaml&apos; wich is the default name that will be used in your pipeline settings.\nNote:If you change the name or the location, you will need to specify in the pipeline settings the new name or location:\nThe pipeline is created with the minimum required steps to run it which are the following:\nTRIGGERS\nTriggers that will activate the pipeline execution\ntrigger:\n- master\n- develop\nVARIABLES\nVariables that will be used in the next steps\nvariables:\nsolution: &apos;**/*.sln&apos;\nbuildPlatform: &apos;Any CPU&apos;\nbuildConfiguration: &apos;Release&apos;\nTOOLS AND LIBRARIES\nFor .NET:\n-NuGet Tool Installer task:\n- task: NuGetToolInstaller@1\nUse this task to find, download, and cache a specified version of NuGet and add it to the PATH.\n-The NuGet command to run:\n- task: NuGetCommand@2\ninputs:\nrestoreSolution: &apos;$(solution)&apos;\nThe NuGet command to run.\nFor more info use the official documentation.\nBUILD\n-Visual Studio Build task:\n- task: VSBuild@1\ninputs:\nsolution: &apos;$(solution)&apos;\nmsbuildArgs: &apos;/p:DeployOnBuild=true /p:WebPublishMethod=Package /p:PackageAsSingleFile=true /p:SkipInvalidConfigurations=true /p:DesktopBuildPackageLocation=&quot;$(build.artifactStagingDirectory)\\WebApp.zip&quot; /p:DeployIisAppPath=&quot;Default Web Site&quot;&apos;\nplatform: &apos;$(buildPlatform)&apos;\nconfiguration: &apos;$(buildConfiguration)&apos;\nUse this task to build with MSBuild and set the Visual Studio version property.\nFor more info use the official documentation\nTEST\n-Visual Studio Test task:\n- task: DotNetCoreCLI@2\ninputs:\ncommand: &apos;test&apos;\narguments: &apos;/p:CollectCoverage=true /p:CoverletOutputFormat=opencover /p:CoverletOutput=$(Agent.TempDirectory)/&apos;\nprojects: &apos;$(solution)&apos;\npublishTestResults: true\ncontinueOnError: false\ndisplayName: &apos;Dot Net Core CLI Test&apos;\nUse this task to run unit and functional tests (Selenium, Appium, Coded UI test, and more) using the Visual Studio Test Runner.\nFor more info use the official documentation\nThis steps are the ones generated when your pipeline is created, we can create the ones we need using the Azure Devops wizard in an easy way.\nIn our case, apart from build and test, we also need to deploy\nDEPLOY\nApp Services\nWhile deploying with App Services, 2 steps are required:\nStep 1: Publish\nUse this task in a pipeline to publish artifacts for the Azure Pipeline\n- task: PublishPipelineArtifact@0\ninputs:\nartifactName: &apos;Bad_Weather_Backend&apos;\ntargetPath: &apos;$(Build.ArtifactStagingDirectory)&apos;\nTo know more about the use of predefined variables in azure take a look at the documentation\nStep 2: Deployment\nUse this task to deploy to a range of App Services on Azure\n- task: AzureRmWebAppDeployment@4\ninputs:\nConnectionType: &apos;AzureRM&apos;\nazureSubscription: &apos;bad-weather-poc-rs-bw-dev&apos;\nappType: &apos;webApp&apos;\nWebAppName: &apos;bwbackendbe&apos;\npackageForLinux: &apos;$(build.artifactStagingDirectory)\\WebApp.zip&apos;\nThis task has 2 prerequisites:\n1-App Service instance:\nThe task is used to deploy a Web App project or Azure Function project to an existing Azure App Service instance, which must exist before the task runs.\n2-Azure Subscription:\nIn order to deploy to Azure, an Azure subscription must be linked to the pipeline.\nTo know more about the input arguments for this task, make use of the offcial documentation\n"},{"id":889,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_annexes.html#dsf-azure-connection-strings.asciidoc_connection-strings","type":"docs","title":"CONNECTION STRINGS","body":"60.4.5. CONNECTION STRINGS\nOnce your database is created, you will need to connect that DB to your backend application, this can be made using connection strings.\nCREATE THE CONNECTION STRING\nGo to the Azure portal,select the App Service that you want to connect with the DB, to be able to establish this connection, both your DB and your App Service must be under the same resource group.\nP.E\nAs we can see here, both the app service and the DB exist under the same resource group &apos;BW-dev&apos;\nSelect your app service and go to &apos;settings &gt; Configuration&apos;, scroll down looking for &apos;Connection strings&apos; and click on &quot;New connection string&quot;\nPut the name you want(we&#x2019;ve put the name &apos;Context&apos;, this name will be used later in your appSettings.json) and select the DB type, and for fill the value box go to &apos;Home&gt;SQL databases&apos;, click on the target DB and click on &apos;Show database connection strings&apos;, copy the value that appears there and paste it in the value box.\nPaste the connection string in the &apos;value&apos; box and click OK\nYour connection string has been created.\nUSE THE CONNECTION STRING\nGo to your project, open the file AppSettings.json and add the connection string\n&quot;ConnectionStrings&quot;: {\n&quot;Context&quot;: &quot;Source=(localdb)\\\\MSSQLLocalDB;Initial Catalog=my-db;Integrated Security=True;&quot;\n}\nContext is the name that we choose for the connection string that we&#x2019;ve created before and that value is only for local purposes.\nWhen the application is deployed,the value for context will be replaced for the value of the connection string that we&#x2019;ve created in the earlier steps, using this we avoid to put the user and the password into the code and we use them as secrets that will be replaced in the deployment.\n"},{"id":890,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_annexes.html#dsf-azure-sonarqube-integration.asciidoc_integrate-the-sonarqube-plugin-in-an-azure-devops-pipeline","type":"docs","title":"Integrate the SonarQube plugin in an Azure DevOps pipeline","body":"60.4.6. Integrate the SonarQube plugin in an Azure DevOps pipeline\nThe purpose of this readme is that you can configure your Azure Devops pipeline in order to be able to run a code analysis, analyse the code coverage and publish the results through the Sonar plugin.\n"},{"id":891,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_annexes.html#dsf-azure-sonarqube-integration.asciidoc_how-to-do-it","type":"docs","title":"How to do it","body":"60.4.7. How to do it\nStep 1: Create a service connection\nThe first thing to do is to declare your SonarQube server as a service endpoint in your Azure DevOps project settings.\nGo to project settings &#x2192; pipelines &#x2192; service connections and create and choose &apos;SonarQube&apos;.\nCreate service connection\nSpecify the server url and the connection name of your SonarQube server and the token Auth\nGo to your SonarQube server and log in as admin,\nonce inside, go to administration &#x2192; Security &#x2192; Users &#x2192; Administrator &#x2192; Tokens&#x2192; And generate the token.\nCopy the generated token(once created it will never appear again so don&#x2019;t lose it) and paste it and click on save .\nThe service connection has been created.\nOnce this step is done your service creation will appear now in the service connections side bar.\nFor more info regarding the Authentication part please read the official documentation\nStep 2: Add the required tasks in the azure pipeline\nIn order to integrate the SonarQube in the pipeline, 3 steps or tasks are required(Depending on the different solutions like .NET, Java, C..etc some of this tasks can be optional), this tasks are:\nPrepare Analysis configuration\nRun Code Analysis\nPublish Quality Gate result\nWe can use the wizard to create this in an easy way, search &quot;SonarQube&quot; and let&#x2019;s configure the tasks one by one.\nPrepare Analysis configuration:\nFill the required fields and click on add\nThe prepare task will be now shown in the pipeline code:\nFollow the official documentation if you have doubts while filling the fields:\nOnce the prepare is done, continue with the code analysis.\nRun Code Analysis\nSelect this from the task assistant and just like happened with the first task, the code will appear in your pipeline.\nNow, let&#x2019;s publish the result of the analysis.\nPublish quality gate result\nSame as we did before, select in the display the publish extension and add it\nStep 3: Run the pipeline\nWith this, all the required steps to integrate SonarQube in your Azure DevOps pipeline are done, the last thing you need to do is run your pipeline and your code will be analyzed and the results published.\n"},{"id":892,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_annexes.html#install-and-use-custom-sonar-plugin-in-azure-devops","type":"docs","title":"Install and use custom sonar plugin in Azure Devops","body":"60.4.8. Install and use custom sonar plugin in Azure Devops\nBy default, the sonar plugin is not capable to be used in every branch you want to, to do this you need to purchase a license or customize the current plugin in order to satisfy our needs.\nHow to costumize the plugin is not the purpose of this documentation, this documentation is for the intallment and use of it.\nIf you want to install a custom plugin, sign into your Azure Devops organization and once you are in, click on the marketplace icon:\nSelect *browse marketplace&gt;publish extension\nChoose the extension you want to install and clik on the options\nImportant:\nYou need to choose the organization for which you are going to use the extension and share it, if not, you won&#x2019;t be able to install it.\nOnce you&#x2019;ve done this click on View extension and &apos;Get it free&apos;, the extension will be downloaded and you will be able to use it in the next screen\nIf there are no organizations you can seee the possible causes here.\nAnother cause might be that you forgot to share the extension.\nNote: If the install button does not appear, it&#x2019;s possible that you don&#x2019;t have permissions to install it so you will need to talk with the owner of the org.\nAnother posibility is that you can request an installation.\nOnce installed, in the pipeline wizard it will appear and you will be able to select it.\nWe can see in the image the default plugin and the customized one.\n"},{"id":893,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_annexes.html#master-devonfw-shop-floor.asciidoc_okd-openshift-origin","type":"docs","title":"OKD (OpenShift Origin)","body":"60.5. OKD (OpenShift Origin)\n"},{"id":894,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_annexes.html#dsf-okd.asciidoc","type":"docs","title":"What is OKD","body":"60.6. OKD (OpenShift Origin)\n60.6.1. What is OKD\nOKD is a distribution of Kubernetes optimized for continuous application development and multi-tenant deployment. OKD is the upstream Kubernetes distribution embedded in Red Hat OpenShift.\nOKD embeds Kubernetes and extends it with security and other integrated concepts. OKD is also referred to as Origin in github and in the documentation.\nOKD provides a complete open source container application platform. If you are looking for enterprise-level support, or information on partner certification, Red Hat also offers Red Hat OpenShift Container Platform.\n"},{"id":895,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_annexes.html#dsf-okd.asciidoc_continue-reading...","type":"docs","title":"Continue reading&#x2026;&#x200B;","body":"Continue reading&#x2026;&#x200B;\nHow to install Openshift Origin\nInitial setup\ns2i\ntemplates\nCustomize Openshift\nCustomize icons\nCustomize catalog\n"},{"id":896,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_annexes.html#dsf-okd.asciidoc","type":"docs","title":"How to use Oc Cluster Wrapper","body":"60.6.2. OKD (OpenShift Origin)\nWhat is OKD\nOKD is a distribution of Kubernetes optimized for continuous application development and multi-tenant deployment. OKD is the upstream Kubernetes distribution embedded in Red Hat OpenShift.\nOKD embeds Kubernetes and extends it with security and other integrated concepts. OKD is also referred to as Origin in github and in the documentation.\nOKD provides a complete open source container application platform. If you are looking for enterprise-level support, or information on partner certification, Red Hat also offers Red Hat OpenShift Container Platform.\nContinue reading&#x2026;&#x200B;\nHow to install Openshift Origin\nInitial setup\ns2i\ntemplates\nCustomize Openshift\nCustomize icons\nCustomize catalog\n60.6.3. Install OKD (Openshift Origin)\nPre-requisites\nInstall docker\nhttps://docs.docker.com/engine/installation/linux/docker-ce/debian/#set-up-the-repository\n$ sudo groupadd docker\n$ sudo usermod -aG docker $USER\nDownload Openshift Origin Client\nDownload Openshift Origin Client from here\nWhen the download it&#x2019;s complete, only extract it on the directory that you want, for example /home/administrador/oc\nAdd oc to path\n$ export PATH=$PATH:/home/administrador/oc\nInstall Openshift Cluster\nAdd the insecure registry\nCreate file /etc/docker/daemon.json with the next content:\n{\n&quot;insecure-registries&quot; : [ &quot;172.30.0.0/16&quot; ]\n}\nDownload docker images for openshift\n$ oc cluster up\nInstall Oc Cluster Wrapper\nTo manage easier the cluster persistent, we are going to use oc cluster wrapper.\ncd /home/administrador/oc\nwget https://raw.githubusercontent.com/openshift-evangelists/oc-cluster-wrapper/master/oc-cluster\noc-cluster up devonfw-shop-floor --public-hostname X.X.X.X\nConfigure iptables\nWe must create iptables rules to allow traffic from other machines.\n- The next commands it&apos;s to let all traffic, don&apos;t do it on a real server.\n- $ iptables -F\n- $ iptables -X\n- $ iptables -t nat -F\n- $ iptables -t nat -X\n- $ iptables -t mangle -F\n- $ iptables -t mangle -X\n- $ iptables -P INPUT ACCEPT\n- $ iptables -P OUTPUT ACCEPT\n- $ iptables -P FORWARD ACCEPT\n60.6.4. How to use Oc Cluster Wrapper\nWith oc cluster wrapper we could have different clusters with different context.\nCluster up\n$ oc-cluster up devonfw-shop-floor --public-hostname X.X.X.X\nCluster down\n$ oc-cluster down\nUse non-persistent cluster\noc cluster up --image openshift/origin --public-hostname X.X.X.X --routing-suffix apps.X.X.X.X.nip.io\n"},{"id":897,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_annexes.html#dsf-okd-initial-setup.asciidoc","type":"docs","title":"devonfw Openshift Origin Initial Setup","body":"60.6.5. devonfw Openshift Origin Initial Setup\nThese are scripts to customize an Openshift cluster to be a devonfw Openshift.\nHow to use\nPrerequisite: Customize Openshift\ndevonfw Openshift Origin use custom icons, and we need to add it to openshift. More information:\nCustomize Openshift\nScript initial-setup\nDownload this script and execute it.\nMore information about what this script does here.\nKnown issues\nFailed to push image\nIf you receive an error like this:\nerror: build error: Failed to push image: After retrying 6 times, Push image still failed due to error: Get http://172.30.1.1:5000/v2/: dial tcp 172.30.1.1:5000: getsockopt: connection refused\nIt&#x2019;s because the registry isn&#x2019;t working, go to openshift console and enter into the default project https://x.x.x.x:8443/console/project/default/overview and you must see two resources, docker-registry and router they must be running. If they don&#x2019;t work, try to deploy them and look at the logs what is happen.\n"},{"id":898,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_annexes.html#dsf-okd-s2i.asciidoc","type":"docs","title":"s2i devonfw","body":"60.6.6. s2i devonfw\nThis are the s2i source and templates to build an s2i images. It provides OpenShift builder images for components of the devonfw (at this moment only for angular and java).\nThis work is totally based on the implementation of Michael Kuehl from RedHat for Oasp s2i.\nAll this information is used as a part of the initial setup for openshift.\nPrevious setup\nIn order to build all of this, it will be necessary, first, to have a running OpenShift cluster. How to install it here.\nUsage\nBefore using the builder images, add them to the OpenShift cluster.\nDeploy the Source-2-Image builder images\nFirst, create a dedicated devonfw project as admin.\n$ oc new-project devonfw --display-name=&apos;devonfw&apos; --description=&apos;devonfw Application Standard Platform&apos;\nNow add the builder image configuration and start their build.\noc create -f https://raw.githubusercontent.com/devonfw/devonfw-shop-floor/master/dsf4openshift/openshift-devonfw-deployment/s2i/java/s2i-devonfw-java-imagestream.json --namespace=devonfw\noc create -f https://raw.githubusercontent.com/devonfw/devonfw-shop-floor/master/dsf4openshift/openshift-devonfw-deployment/s2i/angular/s2i-devonfw-angular-imagestream.json --namespace=devonfw\noc start-build s2i-devonfw-java --namespace=devonfw\noc start-build s2i-devonfw-angular --namespace=devonfw\nMake sure other projects can access the builder images:\noc policy add-role-to-group system:image-puller system:authenticated --namespace=devonfw\nThat&#x2019;s all!\nDeploy devonfw templates\nNow, it&#x2019;s time to create devonfw templates to use this s2i and add it to the browse catalog. More information here.\nBuild All\nUse this script to automatically install and build all image streams. The script also creates templates devonfw-angular and devonfw-java inside the project &apos;openshift&apos; to be used by everyone.\nOpen a bash shell as Administrator\nExecute shell file:\n$ /PATH/TO/BUILD/FILE/initial-setup.sh\nMore information about what this script does here.\nLinks &amp; References\nThis is a list of useful articles, etc, that I found while creating the templates.\nTemplate Icons\nRed Hat Cool Store Microservice Demo\nOpenshift Web Console Customization\n"},{"id":899,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_annexes.html#dsf-okd-templates.asciidoc","type":"docs","title":"devonfw templates","body":"60.6.7. devonfw templates\nThis are the devonfw templates to build devonfw apps for Openshift using the s2i images. They are based on the work of Mickuehl in Oasp templates/mythaistar for deploy My Thai Star.\nInside the example-mythaistar we have an example to deploy My Thai Star application using devonfw templates.\nAll this information is used as a part of the initial setup for openshift.\nHow to use\nPrevious requirements\nDeploy the Source-2-Image builder images\nRemember that this templates need a build image from s2i-devonfw-angular and s2i-devonfw-java. More information:\nDeploy the Source-2-Image builder images.\nCustomize Openshift\nRemember that this templates also have custom icons, and to use it, we must modify the master-config.yml inside openshift. More information:\nCustomize Openshift.\nDeploy devonfw templates\nNow, it&#x2019;s time to create devonfw templates to use this s2i and add it to the browse catalog.\nTo let all user to use these templates in all openshift projects, we should create it in an openshift namespace. To do that, we must log in as an admin.\noc create -f https://raw.githubusercontent.com/devonfw/devonfw-shop-floor/master/dsf4openshift/openshift-devonfw-deployment/templates/devonfw-java-template.json --namespace=openshift\noc create -f https://raw.githubusercontent.com/devonfw/devonfw-shop-floor/master/dsf4openshift/openshift-devonfw-deployment/templates/devonfw-angular-template.json --namespace=openshift\nWhen it finishes, remember to logout as an admin and enter with our normal user.\n$ oc login\nHow to use devonfw templates in openshift\nTo use these templates with openshift, we can override any parameter values defined in the file by adding the --param-file=paramfile option.\nThis file must be a list of &lt;name&gt;=&lt;value&gt; pairs. A parameter reference may appear in any text field inside the template items.\nThe parameters that we must override are the following\n$ cat paramfile\nAPPLICATION_NAME=app-Name\nAPPLICATION_GROUP_NAME=group-Name\nGIT_URI=Git uri\nGIT_REF=master\nCONTEXT_DIR=/context\nThe following parameters are optional\n$ cat paramfile\nAPPLICATION_HOSTNAME=Custom hostname for service routes. Leave blank for default hostname, e.g.: &lt;application-name&gt;.&lt;project&gt;.&lt;default-domain-suffix&gt;,\n# Only for angular\nREST_ENDPOINT_URL=The URL of the backend&apos;s REST API endpoint. This can be declared after,\nREST_ENDPOINT_PATTERN=The pattern URL of the backend&apos;s REST API endpoint that must be modify by the REST_ENDPOINT_URL variable,\nFor example, to deploy My Thai Star Java\n$ cat paramfile\nAPPLICATION_NAME=&quot;mythaistar-java&quot;\nAPPLICATION_GROUP_NAME=&quot;My-Thai-Star&quot;\nGIT_URI=&quot;https://github.com/oasp/my-thai-star.git&quot;\nGIT_REF=&quot;develop&quot;\nCONTEXT_DIR=&quot;/java/mtsj&quot;\n$ oc new-app --template=devonfw-java --namespace=mythaistar --param-file=paramfile\n"},{"id":900,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_annexes.html#dsf-okd-customize.asciidoc","type":"docs","title":"Customize Openshift Origin for devonfw","body":"60.6.8. Customize Openshift Origin for devonfw\nThis is a guide to customize Openshift cluster.\nImages Styles\nThe icons for templates must measure the same as below or the images don&#x2019;t show right:\nOpenshift logo: 230px x 40px.\nTemplate logo: 50px x 50px.\nCategory logo: 110px x 36px.\nHow to use\nTo use it, we need to enter in openshift as an admin and use the next command:\n$ oc login\n$ oc edit configmap/webconsole-config -n openshift-web-console\nAfter this, we can see in our shell the webconsole-config.yaml, we only need to navigate until extensions and add the url for our own css in the stylesheetURLs and javascript in the scriptURLs section.\nIMPORTANT: Scripts and stylesheets must be served with the correct content type or they will not be run by the browser. Scripts must be served with Content-Type: application/javascript and stylesheets with Content-Type: text/css.\nIn git repositories, the content type of raw is text/plain. You can use rawgit to convert a raw from a git repository to the correct content type.\nExample:\nwebconsole-config.yaml: |\n[...]\nextensions:\nscriptURLs:\n- https://cdn.rawgit.com/devonfw/devonfw-shop-floor/master/dsf4openshift/openshift-cluster-setup/initial-setup/customizeOpenshift/scripts/catalog-categories.js\nstylesheetURLs:\n- https://cdn.rawgit.com/devonfw/devonfw-shop-floor/master/dsf4openshift/openshift-cluster-setup/initial-setup/customizeOpenshift/stylesheet/icons.css\n[...]\nMore information\nCustomize icons for Openshift.\nCustomize catalog for Openshift.\nOpenshift docs about customization.\nOld versions\nCustomize Openshift for version 3.7.\nHow to add Custom Icons inside openshift\nThis is a guide to add custom icons into an Openshift cluster.\nHere we can find an icons.css example to use the devonfw icons.\nImages Styles\nThe icons for templates must measure the same as below or the images don&#x2019;t show right:\nOpenshift logo: 230px x 40px.\nTemplate logo: 50px x 50px.\nCategory logo: 110px x 36px.\nCreate a css\nCustom logo for openshift cluster\nFor this example, we are going to call the css icons.css but you can call as you wish.\nOpenshift cluster draw their icon by the id header-logo, then we only need to add to our icons.css the next Style Attribute ID\n#header-logo {\nbackground-image: url(&quot;https://raw.githubusercontent.com/devonfw/devonfw-shop-floor/master/dsf4openshift/openshift-cluster-setup/initial-setup/customizeOpenshift/images/devonfw-openshift.png);\nwidth: 230px;\nheight: 40px;\n}\nCustom icons for templates\nTo use a custom icon to a template openshift use a class name. Then, we need to insert inside our icons.css the next Style Class\n.devonfw-logo {\nbackground-image: url(&quot;https://raw.githubusercontent.com/devonfw/devonfw-shop-floor/master/dsf4openshift/openshift-cluster-setup/initial-setup/customizeOpenshift/images/devonfw.png&quot;);\nwidth: 50px;\nheight: 50px;\n}\nTo show that custom icon on a template, we only need to write the name of our class in the tag &quot;iconClass&quot; of our template.\n{\n...\n&quot;items&quot;: [\n{\n...\n&quot;metadata&quot;: {\n...\n&quot;annotations&quot;: {\n...\n&quot;iconClass&quot;: &quot;devonfw-logo&quot;,\n...\n}\n},\n...\n}\n]\n}\nUse our own css inside openshift\nTo do that, we need to enter in openshift as an admin and use the next command:\n$ oc login\n$ oc edit configmap/webconsole-config -n openshift-web-console\nAfter this, we can see in our shell the webconsole-config.yaml, we only need to navigate until extensions and add the url for our own css in the stylesheetURLs section.\nIMPORTANT: Scripts and stylesheets must be served with the correct content type or they will not be run by the browser. stylesheets must be served with Content-Type: text/css.\nIn git repositories, the content type of raw is text/plain. You can use rawgit to convert a raw from a git repository to the correct content type.\nExample:\nwebconsole-config.yaml: |\n[...]\nextensions:\nstylesheetURLs:\n- https://cdn.rawgit.com/devonfw/devonfw-shop-floor/master/dsf4openshift/openshift-cluster-setup/initial-setup/customizeOpenshift/stylesheet/icons.css\n[...]\nHow to add custom catalog categories inside openshift\nThis is a guide to add custom Catalog Categories into an Openshift cluster.\nHere we can find a catalog-categories.js example to use the devonfw catalog categories.\nCreate a scrip to add custom langauges and custom catalog categories\nCustom language\nFor this example, we are going add a new language into the languages category. To do that we must create a script and we named as catalog-categories.js\n// Find the Languages category.\nvar category = _.find(window.OPENSHIFT_CONSTANTS.SERVICE_CATALOG_CATEGORIES,\n{ id: &apos;languages&apos; });\n// Add Go as a new subcategory under Languages.\ncategory.subCategories.splice(2,0,{ // Insert at the third spot.\n// Required. Must be unique.\nid: &quot;devonfw-languages&quot;,\n// Required.\nlabel: &quot;devonfw&quot;,\n// Optional. If specified, defines a unique icon for this item.\nicon: &quot;devonfw-logo-language&quot;,\n// Required. Items matching any tag will appear in this subcategory.\ntags: [\n&quot;devonfw&quot;,\n&quot;devonfw-angular&quot;,\n&quot;devonfw-java&quot;\n]\n});\nCustom category\nFor this example, we are going add a new category into the category tab. To do that we must create a script and we named as catalog-categories.js\n// Add a Featured category as the first category tab.\nwindow.OPENSHIFT_CONSTANTS.SERVICE_CATALOG_CATEGORIES.unshift({\n// Required. Must be unique.\nid: &quot;devonfw-featured&quot;,\n// Required\nlabel: &quot;devonfw&quot;,\nsubCategories: [\n{\n// Required. Must be unique.\nid: &quot;devonfw-languages&quot;,\n// Required.\nlabel: &quot;devonfw&quot;,\n// Optional. If specified, defines a unique icon for this item.\nicon: &quot;devonfw-logo-language&quot;,\n// Required. Items matching any tag will appear in this subcategory.\ntags: [\n&quot;devonfw&quot;,\n&quot;devonfw-angular&quot;,\n&quot;devonfw-java&quot;\n]\n}\n]\n});\nUse our own javascript inside openshift\nTo do that, we need to enter in openshift as an admin and use the next command:\n$ oc login\n$ oc edit configmap/webconsole-config -n openshift-web-console\nAfter this, we can see in our shell the webconsole-config.yaml, we only need to navigate until extensions and add the url for our own javascript in the scriptURLs section.\nIMPORTANT: Scripts and stylesheets must be served with the correct content type or they will not be run by the browser. Scripts must be served with Content-Type: application/javascript.\nIn git repositories, the content type of raw is text/plain. You can use rawgit to convert a raw from a git repository to the correct content type.\nExample:\nwebconsole-config.yaml: |\n[...]\nextensions:\nscriptURLs:\n- https://cdn.rawgit.com/devonfw/devonfw-shop-floor/master/dsf4openshift/openshift-cluster-setup/initial-setup/customizeOpenshift/scripts/catalog-categories.js\n[...]\nCustomize Openshift Origin v3.7 for devonfw\nThis is a guide to customize Openshift cluster. For more information read the next:\nOpenshift docs customization for the version 3.7.\nImages Styles\nThe icons for templates must measure the same as below or the images don&#x2019;t show right:\nOpenshift logo: 230px x 40px.\nTemplate logo: 50px x 50px.\nCategory logo: 110px x 36px.\nQuick Use\nThis is a quick example to add custom icons and categories inside openshift.\nTo modify the icons inside openshift, we must to modify our master-config.yaml of our openshift cluster. This file is inside the openshift container and to obtain a copy of it, we must to know what&#x2019;s our openshift container name.\nObtain the master-config.yaml of our openshift cluster\nObtain the name of our openshift container\nTo obtain it, we can know it executing the next:\n$ docker container ls\nCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES\n83a4e3acda5b openshift/origin:v3.7.0 &quot;/usr/bin/openshift &#x2026;&quot; 6 days ago Up 6 days origin\nHere we can see that the name of the container is origin. Normaly the container it&#x2019;s called as origin.\nCopy the master-config.yaml of our openshift container to our directory\nThis file is inside the openshift container in the next directory: /var/lib/origin/openshift.local.config/master/master-config.yaml and we can copy it with the next command:\n$ docker cp origin:/var/lib/origin/openshift.local.config/master/master-config.yaml ./\nNow we have a file with the configuration of our openshift cluster.\nCopy all customize files inside the openshift container\nTo use our customization of devonfw Openshift, we need to copy our files inside the openshift container.\nTo do this we need to copy the images, scripts and stylesheets from here inside openshift\ncontainer, for example, we could put it all inside a folder called openshift.local.devonfw. On the step one we obtain the name of this container, for this example we assume that it&#x2019;s called origin. Then our images are located inside openshift container and we can see an access it in /var/lib/origin/openshift.local.devonfw/images.\n$ docker cp ./openshift.local.devonfw origin:/var/lib/origin/\nEdit and copy the master-config.yaml to use our customize files\nThe master-config.yaml have a sections to charge our custom files. All these sections are inside the assetConfig and their names are the next:\nThe custom stylessheets are into extensionStylesheets.\nThe custom scripts are into extensionScripts.\nThe custom images are into extensions.\nTo use all our custom elements only need to add the directory routes of each element in their appropriate section of the master-config.yaml\n...\nassetConfig:\n...\nextensionScripts:\n- /var/lib/origin/openshift.local.devonfw/scripts/catalog-categories.js\nextensionStylesheets:\n- /var/lib/origin/openshift.local.devonfw/stylesheet/icons.css\nextensions:\n- name: images\nsourceDirectory: /var/lib/origin/openshift.local.devonfw/images\n...\n...\nNow we only need to copy that master-config.yaml inside openshift, and restart it to load the new configuration. To do that execute the next:\n$ docker cp ./master-config.yaml origin:/var/lib/origin/openshift.local.config/master/master-config.yaml\nTo re-start openshift do oc cluster down and start again your persistent openshift cluster.\nMore information\nCustomize icons for Openshift.\nCustomize catalog for Openshift.\nOpenshift docs about customization.\n"},{"id":901,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_annexes.html#master-devonfw-shop-floor.asciidoc_istio-guide","type":"docs","title":"ISTIO Guide","body":"60.7. ISTIO Guide\n"},{"id":902,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_annexes.html#dsf-istio-guide.asciidoc","type":"docs","title":"ISTIO Service Mesh Implementation Guide","body":"60.7.1. ISTIO Service Mesh Implementation Guide\nIntroduction\nA service mesh separating applications from network functions like resilience, fault tolerance, etc,.\nA service mesh addresses the below functions without changing the application code.\nTest the new versions of services without impacting the users.\nScale the services.\nFind the services with the help of service registry.\nTest against failures.\nSecure service-to-service communication.\nRoute traffic to a specific way.\nCircuit breaking and fault injection.\nMonitor the services and collect matrices.\nTracing.\nISTIO service mesh is an open environment for Connecting, Securing, Monitoring services across the environments.\nISTIO Architecture\nISTIO is split into data plane and control plane. Refer ISTIO Architecture\nData Plane\nThe data plane is a set of intelligent proxies (Envoy) deployed as sidecars that mediate and control all network communication among microservices.\nControl Plane\nThe control plane is managing and configuring proxies to route traffic and enforcing policies.\nPilot manages all the proxies and responsible for routing\nMixer collects telemetry and policy check\nCitadel does Certificate management (TLS certs to Envoys)\nISTIO installation\nDownload ISTIO from releases\nistioctl install --set profile=demo\nHere used demo profile, there are other profiles for production.\nVerify installation:\nkubectl get all -n istio-system\nInject sidecar container automatically by issuing the below command.\nkubectl label namespace default istio-injection=enabled\nVerify:\nkubectl get namespace -L istio-injection\nFor more installation guides, refer ISTIO Installation\nTraffic Management\nISITO&#x2019;s traffic management model relies on the Envoy proxies which deployed as sidecars to services.\nBelow are the traffic management API resources\nVirtual Services\nDestination Rules\nGateways\nService Entries\nSidecars\nA virtual service, higher level abstraction of Kubernetes Service, lets you configure how requests are routed to a service within an Istio service mesh. Your mesh may have multiple virtual services or none. Virtual service consists of routing rules that are evaluated in order.\nDark Launch\nThe following virtual service routes requests to different versions of a service depending on whether the request comes from a testuser. If the testuser calls then version v1 will be used, and for others version v2.\nBlue/Green deployment\nIn blue/green deployment two versions of the application running. Both versions are live on different domain names, in this example it is mtsj.com and test.mtsj.com.\nDefine 2 virtual services for mtsj v1 and v2 versions.\nDefine DestinationRule and configure the subsets for v1 and v2.\nWhen end user browses mtsj.com, the gateway call goes to subset v1 of the virtual service and redirects to destination version v1, and for test.mtsj.com to version v2.\nCanary Deployment (Traffic Splitting)\nIn canary deployment old and new versions of the application alive. ISTIO can be configured, how much percentage of traffic can go to each version.\nHere, the traffic is divided 75% to the version V1, and 25% to the version V2, as we gain confidence the percentage can be increased the latest version and gradually the traffic to the old version can be reduced and removed.\nYou may refer ISTIO Traffic Management for more details.\nMyThaiStar Implementation\nIn this example dish will have two versions and the traffic will be routed alternately using the ISTIO configuration.\nFind all configuration files in istio/trafficmanagement/canary directory under mythaistarmicroservices example.\nMyThaiStar defines below\nService\nService Account\nDeployment\nThe above configurations are defined in a single yaml file for all the different services like angular, dish, image etc.\ndish-v2: Dish Version 2 can be kept separately in different yaml file.\nmts-gateway defines the ingress gateway which routes the outbound request to each service.\ndestination-rule-all defines the subsets here for later traffic routing\ndish-50-50: traffic routing for different versions of dishmanagement.\nNetwork Resilience\nTimeout\nIstio lets you adjust the timeouts using virtual services. The default timeout is 15 seconds.\nRetry\nA retry setting specifies the maximum number of times an Envoy proxy attempts to connect to a service if the initial call fails.\nRetries can also be configured on Gateway Error, Connection failure, Connection Refused or any 5xx error from the application.\nretryOn: gateway-error,connect-failure,refused-stream,5xx\nCircuit Breakers\nBy defining the destination rule, set limits for calls to individual hosts within a service, such as the number of concurrent connections or how many times calls to this host have failed once the limit reached.\nOutlier Detection is an ISTIO Resiliency strategy to detect unusual host behaviour and evict the unhealthy hosts from the set of load balanced healthy hosts inside a cluster.\nIf a request is sent to a service instance and it fails (returns a 50X error code), then ISTIO ejects the instance from the load balanced pool for a specified duration.\nFault Injection\nTwo types of faults can be generated using ISTIO. This is useful for the testing.\nDelays: timing failures.\nAborts: crash failures.\nBelow example is a crash failure Virtual Service. The below example configured to receive http status 500 error for the testuser. The application works fine for all other users.\nThe below virtual service configured to wait 10s for all requests.\nSecurity\nISTIO provides security solution has the below functions.\nTraffic encryption\nMutual TLS and fine-grained access policies.\nAuditing tools\nAuthentication\nISTIO provides two types of authentication.\nPeer authentication, secures service to service authentication\nRequest authentication is end user authentication to verify credential attached to the request.\nMutual TLS Authentication\nBy default, the TLS protocol only proves the identity of the server to the client. Mutual TLS authentication ensures that traffic has been traffic is secure and trusted in both the directions between the client and server.\nAll traffic between services with proxies uses mutual TLS by default.\nPeer Authentication\nPeer authentication has Permissive, Strict and Disabled mode. With permissive mode, a service accepts both plain text and mutual TLS traffic. Permissive mode is good at the time of onboarding and should switch to Strict later.\nThe authentication policy can be applied to mesh-wide, namespace wide or workload specific using the selector field.\nHere the policy applied to the workload bookings.\nCheck the default mesh policy:\nkubectl describe meshpolicy default\nRequest authentication\nRequest authentication policies specify the values needed to validate JWT tokens.\nAuthentication\nApplies to\nUses\nIdentity\nPeer authentication\nService to service\nmTLS\nsource.principal\nRequest authentication\nEnd User authentication\nJWT\nrequest.auth.principal\nAuthorization\nApply an authorization policy to the workload/namespace/mesh to enforce the access control. Supports ALLOW and DENY actions.\nDeny All\nBelow example authorization policy without any rules denies access to all workloads in admin namespace.\nExample below allowing the GET methods from order service.\nExample below denies the request to the /registered path for requests without request principals.\nYou may refer ISTIO Security for more details.\nObservability\nISTIO generates\nMetrics - for monitor latency, traffic, errors and saturation.\nDistributed Traces to identify call flows and service dependencies\nAccess Logs enables audit service behaviour to the individual service level.\nGrafana dashboard\nGrafana and Prometheus are preconfigured addons on ISTIO. To enable, choose the configuration profile which has Prometheus and Grafana enabled. Eg: Demo profile\nVerify Prometheus and Grafana running in the cluster.\nkubectl get pods -n istio-system\nKiali dashboard\nThe Kiali dashboard helps you understand the structure of your service mesh by displaying the topology. The demo profile enables Kiali dashboard also.\nAccess the Kiali dashboard. The default user name is admin and default password is admin.\nistioctl dashboard kiali\nYou may refer ISTIO Observability\nMinikube Troubleshooting Tips\nThis documentation provides the troubleshooting tips while working with minikube in a local machine.\nAlways start minikube with a minimum of 4GB of memory or more if available. Using command minikube start --memory=4096\nIf minikube is not starting or throwing any error even after multiple attempts. Try the below tips:\nDelete the minikube in your local machine using minikube delete and do a fresh minikube start.\nIn any case, if minikube is not starting even after the above step, go to .minikube folder under the users directory and delete it manually. Now try starting minikube.\nSet docker environment in minikube using minikube docker-env. Now all the docker commands that are run will be on the docker inside minikube. So building your application after executing the above command will have the application docker images available to minikube.\nTo exit minikube docker environment use minikube docker-env -u\nIn any case, if you face any error related to docker image such as Failed to pull image, or image not found errors we will have to manually push the application docker image to minikube docker cache using the below commands.\nFor better results - stop minikube using minikube stop command.\nExecute the command minikube cache add imageName/tagName.\nNow start the minikube. To verify if the docker image has been added to minikube docker execute minikube ssh docker images.\nTo remove any docker image from minikube docker stop any containers running that docker image and then execute minikube cache delete imageName/tagName.\nTo reload any docker image to minikube docker environment, execute minikube cache reload.\nIn any case, if the docker images are not getting removed from minikube docker environment then navigate to .minikube/cache/images and then delete the particular image.\nExecute the below command to make the Grafana available.\nkubectl -n istio-system port-forward $(kubectl -n istio-system get pod -l app=grafana -o jsonpath=&apos;\\{.items[0].metadata.name}&apos;) 3000:3000 &amp;\nUse the below URLs to view the dashboard in local machine.\nhttp://localhost:3000/dashboard/db/istio-mesh-dashboard\n&#x2190;&#xA0;Previous:&#xA0;Monitoring&#xA0;| &#x2191;&#xA0;Up:&#xA0;devonfw shop floor&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;cicdgen&#xA0;&#x2192;\n"},{"id":903,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_configuration-and-services-integration.html#master-devonfw-shop-floor.asciidoc_configuration-and-services-integration","type":"docs","title":"Configuration and services integration","body":"56. Configuration and services integration\n"},{"id":904,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_configuration-and-services-integration.html#dsf-configure-nexus.asciidoc","type":"docs","title":"Nexus Configuration","body":"56.1. Nexus Configuration\nIn this document you will see how you can configure Nexus repository and how to integrate it with jenkins.\n"},{"id":905,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_configuration-and-services-integration.html#dsf-configure-nexus.asciidoc_login-in-nexus","type":"docs","title":"Login in Nexus","body":"56.1.1. Login in Nexus\nThe first time you enter in Nexus you need to log in with the user &apos;admin&apos; and the password that is inside the path: /volumes/nexus/nexus-data\nThen you can change that password and create a new one.\n"},{"id":906,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_configuration-and-services-integration.html#dsf-configure-nexus.asciidoc_prerequisites","type":"docs","title":"Prerequisites","body":"56.1.2. Prerequisites\nRepositories\nYou need to have one repository for snapshots, another for releases and another one for release-candidates. Normally you use maven2 (hosted) repositories and if you are going to use a docker registry, you need docker (hosted) too.\nTo create a repository in Nexus go to the administration clicking on the gear icon at top menu bar. Then on the left menu click on Repositories and press the Create repository button.\nNow you must choose the type of the repository and configure it. This is an example for Snapshot:\n"},{"id":907,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_configuration-and-services-integration.html#dsf-configure-nexus.asciidoc_create-user-to-uploaddownload-content","type":"docs","title":"Create user to upload/download content","body":"56.1.3. Create user to upload/download content\nOnce you have the repositories, you need a user to upload/download content. To do it go to the administration clicking on the gear icon at top menu bar. Then on the left menu click on Users and press the Create local user button.\nNow you need to fill a form like this:\n"},{"id":908,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_configuration-and-services-integration.html#dsf-configure-nexus.asciidoc_jenkins-integration","type":"docs","title":"Jenkins integration","body":"56.1.4. Jenkins integration\nTo use Nexus in our pipelines you need to configure Jenkins.\nCustomize jenkins\nThe first time you enter jenkins, you are asked fot the pluggins to be installed.\nWe select install suggested plugins and later we can add the plugins that we need depending on the project necessities.\nThen we need to create our first admin user, we can do it like this:\nThe next step is the jenkins URL:\nYour jenkins setup is ready!\nAdd nexus user credentials\nFirst of all you need to add the user created in the step before to Jenkins. To do it (on the left menu) click on Credentials, then on System. Now you could access to Global credentials (unrestricted).\nEnter on it and you could see a button on the left to Add credentials. Click on it and fill a form like this:\nAdd the nexus user to maven global settings\nIn order to do this, you will need the Config File Provider plugin so we need to download it.Go to Jenkins&#x2192;Manage jenkins&#x2192;Manage plugins and &quot;available&quot; tab and search for it:\nClick on &quot;Download now and install after restart&quot;.\nNow you need to go to Manage Jenkins clicking on left menu and enter in Managed files.\nClick on Add a new config/Global Maven settings.xml, change the id for a new one more readable:\nThen click on &quot;Submit&quot;\nEdit the Global Maven settings.xml to add your nexus repositories credentials(the ones you created before) as you could see in the next image:\nAnd you are done.\n"},{"id":909,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_configuration-and-services-integration.html#dsf-configure-sonarqube.asciidoc","type":"docs","title":"SonarQube Configuration","body":"56.2. SonarQube Configuration\nTo use SonarQube you need to use a token to connect, and to know the results of the analysis you need a webhook. Also, you need to install and configure SonarQube in Jenkins.\n"},{"id":910,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_configuration-and-services-integration.html#dsf-configure-sonarqube.asciidoc_generate-user-token","type":"docs","title":"Generate user token","body":"56.2.1. Generate user token\nTo generate the user token, go to your account clicking in the left icon on the top menu bar.\nNote\nIf you don&#x2019;t have any account, you can use the admin/admin user/pass\nGo to security tab and generate the token.\n"},{"id":911,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_configuration-and-services-integration.html#dsf-configure-sonarqube.asciidoc_webhook","type":"docs","title":"Webhook","body":"56.2.2. Webhook\nWhen you execute our SonarQube scanner in our pipeline job, you need to ask SonarQube if the quality gate has been passed. To do it you need to create a webhook.\nGo to administration clicking the option on the top bar menu and select the tab for Configuration.\nThen search in the left menu to go to webhook section and create your webhook.\nAn example for Production Line:\n"},{"id":912,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_configuration-and-services-integration.html#dsf-configure-sonarqube.asciidoc_jenkins-integration","type":"docs","title":"Jenkins integration","body":"56.2.3. Jenkins integration\nTo use SonarQube in our pipelines you need to configure Jenkins to integrate SonarQube.\nSonarQube Scanner\nFirst, you need to configure the scanner. Go to Manage Jenkins clicking on left menu and enter in Global Tool Configuration.\nGo to SonarQube Scanner section and add a new SonarQube scanner like this.\nSonarQube Server\nNow you need to configure where is our SonarQube server using the user token that you create before. Go to Manage Jenkins clicking on left menu and enter in Configure System.\nFor example, in Production Line the server is the next:\nNote\nRemember, the token was created at the beginning of this SonarQube configuration.\n"},{"id":913,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_configuration-and-services-integration.html#dsf-configure-sonarqube.asciidoc_sonarqube-configuration","type":"docs","title":"SonarQube configuration","body":"56.2.4. SonarQube configuration\nNow is time to configure your sonar in order to measure the quality of your code. To do it, please follow the official documentation about our plugins and Quality Gates and Profiles here.\nHow to ignore files\nUsually the developers need to ignore some files from Sonar analysis. To do that, they must add the next line as a parameter of the sonar execution to their Jenkinsfile in the SonarQube code analysis step.\n-Dsonar.exclusions=&apos;**/*.spec.ts, **/*.model.ts, **/*mock.ts&apos;\n&#x2190;&#xA0;Previous:&#xA0;Provisioning environments&#xA0;| &#x2191;&#xA0;Up:&#xA0;devonfw shop floor&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Create project&#xA0;&#x2192;\n"},{"id":914,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_create-project.html#master-devonfw-shop-floor.asciidoc_create-project","type":"docs","title":"Create project","body":"57. Create project\n"},{"id":915,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_create-project.html#master-devonfw-shop-floor.asciidoc_create-and-integrate-git-repository","type":"docs","title":"Create and integrate git repository","body":"57.1. Create and integrate git repository\n"},{"id":916,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_create-project.html#dsf-configure-gitlab.asciidoc","type":"docs","title":"GitLab Configuration","body":"57.1.1. GitLab Configuration\nCreate new repository\nTo create a new project in GitLab, go to your dashboard and click the green New project button or use the plus icon in the navigation bar.\nThis opens the New project page. Choose your group and fill the name of your project, the description and the visibility level in the next form:\nNote\nmore information about how to create projects in GitLab in the official documentation\nService integration\nTo learn how to configure the integration between GitLab and Jenkins see the next example\n"},{"id":917,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_create-project.html#master-devonfw-shop-floor.asciidoc_start-new-devonfw-project","type":"docs","title":"start new devonfw project","body":"57.2. start new devonfw project\nIt is time to create your devonfw project:\n"},{"id":918,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_create-project.html#dsf-create-new-devonfw-project.asciidoc","type":"docs","title":"How to create new devonfw project","body":"57.2.1. How to create new devonfw project\nHere you can find the official guides to start new devonfw projects:\nvisit our devon4ng guide.\nvisit our devon4j guide.\n"},{"id":919,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_create-project.html#master-devonfw-shop-floor.asciidoc_cicd-configuration","type":"docs","title":"cicd configuration","body":"57.3. cicd configuration\n"},{"id":920,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_create-project.html#master-devonfw-shop-floor.asciidoc_manual-configuration","type":"docs","title":"Manual configuration","body":"57.3.1. Manual configuration\nJenkinsfile\nIntroduction\nHere you are going to learn how you should configure the jenkinsfile of your project to apply CI/CD operations and enables automated application deployment.\nHere you can find examples of the Jenkinsfile generated by cicdgen:\ndevon4j\ndevon4ng\ndevon4node\nNext you could find an explanation about what is done in these Jenkinsfiles.\nEnvironment values\nAt the top of the pipeline you should add the environment variables. in this tutorial you need the next variables:\n// sonarQube\n// Name of the sonarQube tool\nsonarTool = &apos;SonarQube&apos;\n// Name of the sonarQube environment\nsonarEnv = &quot;SonarQube&quot;\n// Nexus\n// Artifact groupId\ngroupId = &apos;&lt;%= groupid %&gt;&apos;\n// Nexus repository ID\nrepositoryId = &apos;pl-nexus&apos;\n// Nexus internal URL\nrepositoryUrl = &apos;http://nexus3-core:8081/nexus3/repository/&apos;\n// Maven global settings configuration ID\nglobalSettingsId = &apos;MavenSettings&apos;\n// Maven tool id\nmavenInstallation = &apos;Maven3&apos;\n// Docker registry\ndockerRegistry = &apos;docker-registry-&lt;%= plurl %&gt;&apos;\ndockerRegistryCredentials = &apos;nexus-docker&apos;\ndockerTool = &apos;docker-global&apos;\n// OpenShift\nopenshiftUrl = &apos;&lt;%= ocurl %&gt;&apos;\nopenShiftCredentials = &apos;openshift&apos;\nopenShiftNamespace = &apos;&lt;%= ocn %&gt;&apos;\nStages\nThe pipeline consists of stages, and at the beginning of each stage it is declared for which branches the step will be executed.\nNow it is time to create the stages.\nSetup Jenkins tools\nThe first stage is one of the most dangerous, because in it on one hand the tools are added to the pipeline and to the path and on other hand the values are tagged depending on the branch that is being executed. If you are going to create a ci/cd for a new branch or you are going to modify something, be very careful with everything that this first step declares.\nThis is an example of this stage:\nscript {\ntool yarn\ntool Chrome-stable\ntool dockerTool\nif (env.BRANCH_NAME.startsWith(&apos;release&apos;)) {\ndockerTag = &quot;release&quot;\nrepositoryName = &apos;maven-releases&apos;\ndockerEnvironment = &quot;_uat&quot;\nopenShiftNamespace += &quot;-uat&quot;\nsonarProjectKey = &apos;-release&apos;\n}\nif (env.BRANCH_NAME == &apos;develop&apos;) {\ndockerTag = &quot;latest&quot;\nrepositoryName = &apos;maven-snapshots&apos;\ndockerEnvironment = &quot;_dev&quot;\nopenShiftNamespace += &quot;-dev&quot;\nsonarProjectKey = &apos;-develop&apos;\n}\nif (env.BRANCH_NAME == &apos;master&apos;) {\ndockerTag = &quot;production&quot;\nrepositoryName = &apos;maven-releases&apos;\ndockerEnvironment = &apos;_prod&apos;\nopenShiftNamespace += &quot;-prod&quot;\nsonarProjectKey = &apos;&apos;\n}\nsh &quot;yarn&quot;\n}\nCode lint analysis\nThe next stage is to analyze the code making a lint analysis. To do it your project should have a tslint file with the configuration (tslint.json).\nanalyzing the code in your pipeline is as simple as executing the following command:\nsh &quot;&quot;&quot;yarn lint&quot;&quot;&quot;\nNote\nYour project need to have an script with tslint configuration (tslint.json).\nExecute tests\nTo test you application first of all your application should have created the tests and you should use one of the next two options:\nExecute test with maven (It should be used by devon4j).\nwithMaven(globalMavenSettingsConfig: globalSettingsId, maven: mavenInstallation) {\nsh &quot;mvn clean test&quot;\n}\nExecute test with yarn (It should be used by devon4ng or devon4node).\nsh &quot;&quot;&quot;yarn test:ci&quot;&quot;&quot;\nNote\nRemember that your project should have the tests created and in case of do it with yarn or npm, you package.json should have the script declared. This is an example &quot;test:ci&quot;: &quot;ng test --browsers ChromeHeadless --watch=false&quot;.\nSonarQube Analisys\nIt is time to see if your application complies the requirements of the sonar analysis.\nTo do it you could use one of the next two options:\nExecute Sonar with sonarTool (It should be used by devon4ng or devon4node).\nscript {\ndef scannerHome = tool sonarTool\ndef props = readJSON file: &apos;package.json&apos;\nwithSonarQubeEnv(sonarEnv) {\nsh &quot;&quot;&quot;\n${scannerHome}/bin/sonar-scanner \\\n-Dsonar.projectKey=${props.name}${sonarProjectKey} \\\n-Dsonar.projectName=${props.name}${sonarProjectKey} \\\n-Dsonar.projectVersion=${props.version} \\\n-Dsonar.sources=${srcDir} \\\n-Dsonar.typescript.lcov.reportPaths=coverage/lcov.info\n&quot;&quot;&quot;\n}\ntimeout(time: 1, unit: &apos;HOURS&apos;) {\ndef qg = waitForQualityGate()\nif (qg.status != &apos;OK&apos;) {\nerror &quot;Pipeline aborted due to quality gate failure: ${qg.status}&quot;\n}\n}\n}\nExecute Sonar with maven (It should be used by devon4j).\nscript {\nwithMaven(globalMavenSettingsConfig: globalSettingsId, maven: mavenInstallation) {\nwithSonarQubeEnv(sonarEnv) {\n// Change the project name (in order to simulate branches with the free version)\nsh &quot;cp pom.xml pom.xml.bak&quot;\nsh &quot;cp api/pom.xml api/pom.xml.bak&quot;\nsh &quot;cp core/pom.xml core/pom.xml.bak&quot;\nsh &quot;cp server/pom.xml server/pom.xml.bak&quot;\ndef pom = readMavenPom file: &apos;./pom.xml&apos;;\npom.artifactId = &quot;${pom.artifactId}${sonarProjectKey}&quot;\nwriteMavenPom model: pom, file: &apos;pom.xml&apos;\ndef apiPom = readMavenPom file: &apos;api/pom.xml&apos;\napiPom.parent.artifactId = pom.artifactId\napiPom.artifactId = &quot;${pom.artifactId}-api&quot;\nwriteMavenPom model: apiPom, file: &apos;api/pom.xml&apos;\ndef corePom = readMavenPom file: &apos;core/pom.xml&apos;\ncorePom.parent.artifactId = pom.artifactId\ncorePom.artifactId = &quot;${pom.artifactId}-core&quot;\nwriteMavenPom model: corePom, file: &apos;core/pom.xml&apos;\ndef serverPom = readMavenPom file: &apos;server/pom.xml&apos;\nserverPom.parent.artifactId = pom.artifactId\nserverPom.artifactId = &quot;${pom.artifactId}-server&quot;\nwriteMavenPom model: serverPom, file: &apos;server/pom.xml&apos;\nsh &quot;mvn sonar:sonar&quot;\nsh &quot;mv pom.xml.bak pom.xml&quot;\nsh &quot;mv api/pom.xml.bak api/pom.xml&quot;\nsh &quot;mv core/pom.xml.bak core/pom.xml&quot;\nsh &quot;mv server/pom.xml.bak server/pom.xml&quot;\n}\n}\ntimeout(time: 1, unit: &apos;HOURS&apos;) {\ndef qg = waitForQualityGate()\nif (qg.status != &apos;OK&apos;) {\nerror &quot;Pipeline aborted due to quality gate failure: ${qg.status}&quot;\n}\n}\n}\nBuild\nIf SonarQube is passed, you could build your application. To do it, if you are using devon4ng or devon4node you only need to add the next command:\nsh &quot;&quot;&quot;yarn build&quot;&quot;&quot;\nNote\nIf you are using devon4j this and the next step Store in Nexus are making together using mvn deploy.\nStore in Nexus\nOne time the application has been built the code of the application you could find the artifacts stored in the dist folder. You should push these artifacts to store them in Nexus.\nYou can do it following one of the next options:\nUse maven deploy config of your project (It should be used by devon4j).\nwithMaven(globalMavenSettingsConfig: globalSettingsId, maven: mavenInstallation) {\nsh &quot;mvn deploy -Dmaven.test.skip=true&quot;\n}\nConfigure maven deploy in your pipeline (It should be used by devon4ng and devon4node).\nscript {\ndef props = readJSON file: &apos;package.json&apos;\nzip dir: &apos;dist/&apos;, zipFile: &quot;&quot;&quot;${props.name}.zip&quot;&quot;&quot;\nversion = props.version\nif (!version.endsWith(&quot;-SNAPSHOT&quot;) &amp;&amp; env.BRANCH_NAME == &apos;develop&apos;) {\nversion = &quot;${version}-SNAPSHOT&quot;\nversion = version.replace(&quot;-RC&quot;, &quot;&quot;)\n}\nif (!version.endsWith(&quot;-RC&quot;) &amp;&amp; env.BRANCH_NAME.startsWith(&apos;release&apos;)) {\nversion = &quot;${version}-RC&quot;\nversion = version.replace(&quot;-SNAPSHOT&quot;, &quot;&quot;)\n}\nif (env.BRANCH_NAME == &apos;master&apos; &amp;&amp; (version.endsWith(&quot;-RC&quot;) || version.endsWith(&quot;-SNAPSHOT&quot;))){\nversion = version.replace(&quot;-RC&quot;, &quot;&quot;)\nversion = version.replace(&quot;-SNAPSHOT&quot;, &quot;&quot;)\n}\nwithMaven(globalMavenSettingsConfig: globalSettingsId, maven: mavenInstallation) {\nsh &quot;&quot;&quot;\nmvn deploy:deploy-file \\\n-DgroupId=${groupId} \\\n-DartifactId=${props.name} \\\n-Dversion=${version} \\\n-Dpackaging=zip \\\n-Dfile=${props.name}.zip \\\n-DrepositoryId=${repositoryId} \\\n-Durl=${repositoryUrl}${repositoryName}\n&quot;&quot;&quot;\n}\n}\nCreate docker image\nNow we need to use this artifacts to create a Docker image. To create the docker image you need an external server to do it. You could do it using one of the next:\nCreate docker image using OpenShift cluster\nTo create the docker image with this option you need to configure your OpenShift. You could read how to configure it here.\nprops = readJSON file: &apos;package.json&apos;\nwithCredentials([usernamePassword(credentialsId: &quot;${openShiftCredentials}&quot;, passwordVariable: &apos;pass&apos;, usernameVariable: &apos;user&apos;)]) {\nsh &quot;oc login -u ${user} -p ${pass} ${openshiftUrl} --insecure-skip-tls-verify&quot;\ntry {\nsh &quot;oc start-build ${props.name} --namespace=${openShiftNamespace} --from-dir=dist --wait&quot;\nsh &quot;oc import-image ${props.name} --namespace=${openShiftNamespace} --from=${dockerRegistry}/${props.name}:${dockerTag} --confirm&quot;\n} catch (e) {\nsh &quot;&quot;&quot;\noc logs \\$(oc get builds -l build=${props.name} --namespace=${openShiftNamespace} --sort-by=.metadata.creationTimestamp -o name | tail -n 1) --namespace=${namespace}\nthrow e\n&quot;&quot;&quot;\n}\n}\nNote\nif your project is a maven project you should read the pom.xml file instead of the package.json, you could do it with the next command def pom = readMavenPom file: &apos;pom.xml&apos;. Due to the fact that there are different variable names between those two files, remember to modify ${props.name} for ${pom.artifactId} in the code.\nCreate docker image using docker server\nTo create the docker image with this option you need to install docker and configure where is the docker host in your jenkins.\ndocker.withRegistry(&quot;&quot;&quot;${dockerRegistryProtocol}${dockerRegistry}&quot;&quot;&quot;, dockerRegistryCredentials) {\ndef props = readJSON file: &apos;package.json&apos;\ndef customImage = docker.build(&quot;${props.name}:${props.version}&quot;, &quot;-f ${dockerFileName} .&quot;)\ncustomImage.push()\ncustomImage.push(dockerTag);\n}\nhere\nNote\nif your project is a maven project you should read the pom.xml file instead of the package.json, you could do it with the next command def pom = readMavenPom file: &apos;pom.xml&apos;. Due to the fact that there are different variable names between those two files, remember to modify ${props.name} for ${pom.artifactId} and ${props.version} for ${pom.version} in the code.\nDeploy docker image\nOnce you have the docker image in the registry we only need to import it into your deployment environment. We can do it executing one of the next commands:\nDeploy docker image in OpenShift cluster\nTo deploy the docker image with this option you need to configure your OpenShift. You could read how to configure it here.\nscript {\nprops = readJSON file: &apos;package.json&apos;\nwithCredentials([usernamePassword(credentialsId: &quot;${openShiftCredentials}&quot;, passwordVariable: &apos;pass&apos;, usernameVariable: &apos;user&apos;)]) {\nsh &quot;oc login -u ${user} -p ${pass} ${openshiftUrl} --insecure-skip-tls-verify&quot;\ntry {\nsh &quot;oc import-image ${props.name} --namespace=${openShiftNamespace} --from=${dockerRegistry}/${props.name}:${dockerTag} --confirm&quot;\n} catch (e) {\nsh &quot;&quot;&quot;\noc logs \\$(oc get builds -l build=${props.name} --namespace=${openShiftNamespace} --sort-by=.metadata.creationTimestamp -o name | tail -n 1) --namespace=${openShiftNamespace}\nthrow e\n&quot;&quot;&quot;\n}\n}\n}\nNote\nif your project is a maven project you should read the pom.xml file instead of the package.json, you could do it with the next command def pom = readMavenPom file: &apos;pom.xml&apos;. Due to the fact that there are different variable names between those two files, remember to modify ${props.name} for ${pom.artifactId} in the code.\nDeploy docker image using docker server\nTo deploy the docker image with this option you need to install docker and configure your docker server and also integrate it with Jenkins.\nscript {\ndocker.withRegistry(&quot;&quot;&quot;${dockerRegistryProtocol}${dockerRegistry}&quot;&quot;&quot;, dockerRegistryCredentials) {\ndef props = readJSON file: &apos;package.json&apos;\ndocker.image(&quot;${props.name}:${props.version}&quot;).pull()\ndef containerId = sh returnStdout: true, script: &quot;&quot;&quot;docker ps -aqf &quot;name=${containerName}${dockerEnvironment}&quot; &quot;&quot;&quot;\nif (containerId?.trim()) {\nsh &quot;docker rm -f ${containerId.trim()}&quot;\n}\nprintln &quot;&quot;&quot;docker run -d --name ${containerName}${dockerEnvironment} --network=${networkName} ${dockerRegistry}/${props.name}:${props.version}&quot;&quot;&quot;\nsh &quot;&quot;&quot;docker run -d --name ${containerName}${dockerEnvironment} --network=${networkName} ${dockerRegistry}/${props.name}:${props.version}&quot;&quot;&quot;\n}\n}\nNote\nif your project is a maven project you should read the pom.xml file instead of the package.json, you could do it with the next command def pom = readMavenPom file: &apos;pom.xml&apos;. Due to the fact that there are different variable names between those two files, remember to modify ${props.name} for ${pom.artifactId} and ${props.version} for ${pom.version} in the code.\nCheck status\nNow is time to check if your pods are running ok.\nTo check if your pods are ok in OpenShift you should add the next code to your pipeline:\nscript {\nprops = readJSON file: &apos;package.json&apos;\nsleep 30\nwithCredentials([usernamePassword(credentialsId: &quot;${openShiftCredentials}&quot;, passwordVariable: &apos;pass&apos;, usernameVariable: &apos;user&apos;)]) {\nsh &quot;oc login -u ${user} -p ${pass} ${openshiftUrl} --insecure-skip-tls-verify&quot;\nsh &quot;oc project ${openShiftNamespace}&quot;\ndef oldRetry = -1;\ndef oldState = &quot;&quot;;\nsh &quot;oc get pods -l app=${props.name} &gt; out&quot;\ndef status = sh (\nscript: &quot;sed &apos;s/[\\t ][\\t ]*/ /g&apos; &lt; out | sed &apos;2q;d&apos; | cut -d&apos; &apos; -f3&quot;,\nreturnStdout: true\n).trim()\ndef retry = sh (\nscript: &quot;sed &apos;s/[\\t ][\\t ]*/ /g&apos; &lt; out | sed &apos;2q;d&apos; | cut -d&apos; &apos; -f4&quot;,\nreturnStdout: true\n).trim().toInteger();\nwhile (retry &lt; 5 &amp;&amp; (oldRetry != retry || oldState != status)) {\nsleep 30\noldRetry = retry\noldState = status\nsh &quot;&quot;&quot;oc get pods -l app=${props.name} &gt; out&quot;&quot;&quot;\nstatus = sh (\nscript: &quot;sed &apos;s/[\\t ][\\t ]*/ /g&apos; &lt; out | sed &apos;2q;d&apos; | cut -d&apos; &apos; -f3&quot;,\nreturnStdout: true\n).trim()\nretry = sh (\nscript: &quot;sed &apos;s/[\\t ][\\t ]*/ /g&apos; &lt; out | sed &apos;2q;d&apos; | cut -d&apos; &apos; -f4&quot;,\nreturnStdout: true\n).trim().toInteger();\n}\nif(status != &quot;Running&quot;){\ntry {\nsh &quot;&quot;&quot;oc logs \\$(oc get pods -l app=${props.name} --sort-by=.metadata.creationTimestamp -o name | tail -n 1)&quot;&quot;&quot;\n} catch (e) {\nsh &quot;echo error reading logs&quot;\n}\nerror(&quot;The pod is not running, cause: &quot; + status)\n}\n}\n}\nPost operations\nWhen all its finish, remember to clean your workspace.\npost {\ncleanup {\ncleanWs()\n}\n}\nNote\nYou could also delete your dir adding the next command deleteDir().\nDockerfile\nYou have examples of dockerfiles in cicdgen repository.\ninside these folders you could find all the files that you need to use those dockerfiles. Two dockerfiles are provaided, Dockerfile and Dockerfile.ci, the first one is to compile the code and create the docker image used normally in local, and Dockerfile.ci is to use in Jenkins or similar, after building the application.\nvisit our devon4ng Dockerfiles.\nvisit our devon4j Dockerfiles.\nvisit our devon4node Dockerfiles.\nNote\nDockerfile.ci should be copied to de artifacts and renamed as Dockerfile to work. In the case or devon4ng and devon4node this is the dist folder, in case of devon4ng is on server/target folder.\n"},{"id":921,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_create-project.html#master-devonfw-shop-floor.asciidoc_automatic-configuration","type":"docs","title":"Automatic configuration","body":"57.3.2. Automatic configuration\ncicdgen\nIf you are using production line for provisioning you could use cicdgen to configure automatically almost everything explained in the manual configuration. To do it see the cicdgen documentation.\n&#x2190;&#xA0;Previous:&#xA0;Configuration and services integration&#xA0;| &#x2191;&#xA0;Up:&#xA0;devonfw shop floor&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Deployment environments&#xA0;&#x2192;\n"},{"id":922,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_deployment-environments.html#master-devonfw-shop-floor.asciidoc_deployment-environments","type":"docs","title":"Deployment environments","body":"58. Deployment environments\n"},{"id":923,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_deployment-environments.html#master-devonfw-shop-floor.asciidoc_openshift","type":"docs","title":"OpenShift","body":"58.1. OpenShift\n"},{"id":924,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_deployment-environments.html#dsf-deployment-dsf4openshift.asciidoc","type":"docs","title":"dsf4openshift deployment environment","body":"58.1.1. dsf4openshift deployment environment\nIn this section you will see how you can create a new environment instance in OpenShift and the things that you must add to the Jenkinsfiles of your repository to deploy a branch in this new environment. To conclude you are going to see how to add config files for environment in the source code of the applications.\nConfigure your OpenShift to deploy your devonfw projects\nPrerequisites\nOpenShift Cluster\nTo have your deployment environment with OpenShift you need to have an OpenShift Cluster.\nManual configuration\nHere you can find all that you need to know to configure OpenShift manually.\nAutomatic configuration\nHere you can find all that you need to know to configure OpenShift automatically.\nService integration with jenkins\nPrerequisites\nTo integrate it, you need to have installed the plugin OpenShift Client. To install it go to Manage Jenkins clicking on left menu and enter in Manage Plugins. Go to Available tab and search it using the filter textbox in the top right corner and install it.\nConfiguration\nSecond, you need to configure the OC Client. Go to Manage Jenkins clicking on left menu and enter in Global Tool Configuration.\nGo to OpenShift Client Tools section and add a new one like this.\nUpgrade your Jenkinsfile\nNow it is time to add/upgrade the next stages in to your Jenkinsfile:\nAdd create docker image stage.\nAdd deploy docker image stage.\nAdd check status stage.\nUpgrade Setup Jenkins tools stage.\nNote\nRemember to upgrade your parameters to difference which environment is used per branch.\n"},{"id":925,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_deployment-environments.html#dsf-deployment-dsf4openshift-manual-configuration.asciidoc","type":"docs","title":"OpenShift deployment environment manual configuration","body":"58.1.2. OpenShift deployment environment manual configuration\nIn this section you will see how you can create a new environment instance in your OpenShift cluster to deploy devonfw projects using docker images.\nPrerequisites\ndevonfw project\nYo need to have a devonfw project in a git repository or a docker image uploaded to a docker registry.\nComunication between components\nOpenshift must have access to docker registry.\nDownload OpenShift Client Tools\nFirst of all you need to download the OpenShift client, you can find it here.\nRemember that what you need to download oc Client Tools and not OKD Server.\nNote\nThis tutorial has been made with the version 3.10.0 of the client, it is recommended to use the most current client, but if it does not work, it is possible that the instructions have become obsolete or that the OpenShift used needs another older/newer version of the client. To download a specific version of the client you can find here the older versions and the version 3.10.0.\nAdd oc client to path\nOnce you have downloaded the client you have to add it to the PATH environment variable.\nLog into OpenShift with admin account\nYou can log using a terminal and executing the next instructions:\noc login $OpenShiftUrl\nNote\nYou need a valid user to log in.\nSelect the project where you are going to create the environment\noc project $projectName\nAdd all the secrets that you need\nFor example, to create a secret for a nexus repository you should execute the next commands:\noc create secret docker-registry $nameForSecret --docker-server=${dockerRegistry} --docker-username=${user} --docker-password=${pass} --docker-email=no-reply@email.com\nConfigure OpenShift\nConfigure builds to create docker image using OpenShift\nIf you need to create docker images of your projects you could use OpenShift to do it (Off course only if you have enough rights).\nTo do it, follow the next steps.\nCreate new builds configs\nThe first thing you need to do for create a new environment is prepare the buildconfigs for the front and for the middleware and rise default memory limits for the middleware. You can do it using a terminal and executing the next instructions:\nThese are a summary about the parameters used in our commands:\n${dockerRegistry}: The url of the docker repository.\n${props.name}: The name of the project (for example could be find on package.json)\n${dockerTag}: The tag of the image\nNote\nFrom now on you will refer to the name that you are going to give to the environment as $enviroment. Remember to modify it for the correct value in all instructions.\ndevon4ng build config\nYou need to create nginx build config with docker.\noc new-build --strategy docker --binary --docker-image nginx:alpine-perl --name=${props.name}-$environment --to=${dockerRegistry}/${props.name}:${dockerTag} --to-docker=true\nNote\nYou need nginx:alpine-perl to read the environment config file in openshift, if you are not going to use it, you could use nginx:latest instead.\ndevon4node build config\noc new-build --strategy docker --binary --docker-image node:lts --name=${props.name}-$environment --to=${dockerRegistry}/${props.name}:${dockerTag} --to-docker=true\ndevon4j build config\noc new-build --strategy docker --binary --docker-image openjdk:&lt;version&gt; --name=${props.name}-$environment --to=${dockerRegistry}/${props.name}:${dockerTag} --to-docker=true\nNote\nYou need to specify the &lt;version&gt; of java used for your project. Also you can use the -alpine image. This image is based on the popular Alpine Linux project. Alpine Linux is much smaller than most distribution base images (~5MB), and thus leads to much slimmer images in general. More information on docker hub.\nHow to use the build\nIn this step is where you will build a docker image from a compiled application.\nPrerequisite\nTo build the source in OpenShift, first of all you need to compile your source and obtain the artifacts &quot;dist folder&quot; or download it from a repository. Normally the artifacts have been built on Jenkins and have been stored in Nexus.\nTo download it, you can access to your registry, select the last version and download the &quot;.tar&quot;. The next image shows an example of where is the link to download it, marked in yellow:\nBuild in OpenShift\nWhen you have the artifacts, you can send them to your openshift and build them using your buildconfig that you created on the previous step. This is going to create a new docker image and push it to your registry.\nIf your docker registry need credentials you should use a secret. You could add it to your buildconfig using the next command:\noc set build-secret --push bc/${props.name}-$environment ${nameForSecret}\nNow you can use your build config and push the docker image to your registry. To do it you need to use a terminal and execute the following:\noc start-build ${props.name}-$environment --from-dir=${artifactsPath} --follow\nNote\n${artifactsPath} is the path where you have the artifacts of the prerequisite (On jenkins is the dist folder generated by the build).\nNote\nMaybe you need to raise your memory or CPU limits.\nConfigure new environment\nNow it is time to configure the environment.\nPrerequisite\nYou need a docker image of your application. You could create it using OpenShift as you see in the last step.\nCreate new app on OpenShift\nTo create new app you need to use the next command.\noc new-app --docker-image=${artifactsPath} --name=${props.name}-$environment --source-secret=${nameForSecret}\nNote\nYou could add environment variables using -e $name=$value\nNote\nIf you do not need to use a secret remove the end part of the command --source-secret=${nameForSecret}\nCreate routes\nFinally, you need add a route to access the service.\nAdd http route\nIf you want to create an http route execute the following command in a terminal:\noc expose svc/${props.name}-$environment\nAdd https route\nIf you want to create an https route you can do it executing the following command:\noc create route edge --service=${props.name}-$environment\nIf you want to change the default route path you can use the command --hostname=$url. For example:\noc expose svc/${props.name}-$environment --hostname=$url\noc create route edge --service=${props.name}-$environment --hostname=$url\nImport new images from registry\nWhen you have new images in the registry you must import them to OpenShift. You could do it executing the next commands:\noc import-image ${props.name}-$environment --from=${dockerRegistry}/${props.name}:${dockerTag} --confirm\nNote\nMaybe you need to raise your memory or CPU limits. It is explained below.\nRaise/decrease memory or CPU limits\nIf you need to raise (or decrease) the memory or CPU limits that you need you could do it for your deployments and builders configurations following the next steps.\nFor deployments\nYou could do it in OpenShift using the user interface. To do it you should enter in OpenShift and go to deployments.\nAt the right top, you could see a drop down actions, click on it and you could edit the resource limits of the container.\nMaybe you should modify the resource limits of the pod too. To do it you should click on drop down actions and go to edit YAML. Then you could see something like the next image.\nIn the image, you could see that appear resources two times. One at the bottom of the image, this are the container resources that you modified on the previous paragraph and another one at the top of the image. The resources of the top are for the pod, you should give to it at least the same of the sum for all containers that the pod use.\nAlso you could do it using command line interface and executing the next command:\nTo modify pod limits\noc patch dc/boat-frontend-test --patch &apos;{&quot;spec&quot;:{&quot;strategy&quot;:{&quot;resources&quot;:{&quot;limits&quot;:{&quot;cpu&quot;: &quot;100m&quot;, &quot;memory&quot;: &quot;100Mi&quot;}, &quot;requests&quot;:{&quot;cpu&quot;: &quot;100m&quot;, &quot;memory&quot;: &quot;100Mi&quot;}}}}}&apos;\nTo modify container limits\nWhen this guide was written Openshift have a bug and you cannot do it from command line interface.\nNote\nIf that command did not work and you received an error like this error: unable to parse &quot;&apos;{spec:&#x2026;&#x200B;&quot;: yaml: found unexpected end of stream, try to use the patch using &quot;&quot; instead of &apos;&apos;. It looks like this: --patch &quot;{\\&quot;spec\\&quot;:&#x2026;&#x200B;\\&quot;}}}}&quot;\nFor builders\nYou could do it using command line interface and executing the next command:\noc patch bc/${props.name}${APP_NAME_SUFFIX} --patch &apos;{&quot;spec&quot;:{&quot;resources&quot;:{&quot;limits&quot;:{&quot;cpu&quot;: &quot;125m&quot;, &quot;memory&quot;: &quot;400Mi&quot;},&quot;requests&quot;:{&quot;cpu&quot;: &quot;125m&quot;, &quot;memory&quot;: &quot;400Mi&quot;}}}}&apos;\nNote\nIf that command did not work and you received an error like this error: unable to parse &quot;&apos;{spec:&#x2026;&#x200B;&quot;: yaml: found unexpected end of stream, try to use the patch using &quot;&quot; instead of &apos;&apos;. It looks like this: --patch &quot;{\\&quot;spec\\&quot;:&#x2026;&#x200B;\\&quot;}}}}&quot;\n"},{"id":926,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_deployment-environments.html#dsf-deployment-dsf4openshift-automatic-configuration.asciidoc","type":"docs","title":"OpenShift deployment environment automatic configuration","body":"58.1.3. OpenShift deployment environment automatic configuration\nIn this section you will see how you can create a new environment instance in your OpenShift cluster to deploy devonfw projects using docker images.\nPrerequisites\nAdd OpenShift Client to Jenkins\nTo integrate it, you need to have installed the plugin OpenShift Client. To install it go to Manage Jenkins clicking on left menu and enter in Manage Plugins. Go to Available tab and search it using the filter textbox in the top right corner and install it.\nConfiguration OpenShift Client in Jenkins\nSecond, you need to configure the OC Client. Go to Manage Jenkins clicking on left menu and enter in Global Tool Configuration.\nGo to OpenShift Client Tools section and add a new one like this.\ndevonfw project\nYou need to have a devonfw project in a git repository or a docker image uploaded to a docker registry.\nComunication between components\nJenkins must have access to git, docker registry and OpenShift.\nOpenshift must have access to docker registry.\nJenkinsfiles to Configure OpenShift\nYou can find one Jenkinsfile per devonfw technology in devonfw shop floor repository to configure automatically your OpenShift cluster.\nHow to use it\nTo use it you need to follow the next steps\nCreate a new pipeline\nYou need to create a new pipeline in your repository and point it to Jenkinsfile in devonfw shop floor repository.\nNote: In the script path section you should use the Jenkinsfile of the technology that you need.\nBuild with parameters\nThe first time that you execute the pipeline is going to fail because Jenkins does not know that this pipeline needs parameters to execute. The better that you can do is stop it manually when Declarative: Checkout SCM is over.\nThen you could see a button to Build with Parameters, click on it and fill the next form, these are the parameters:\nDocker registry credentials for OpenShift\nCREATE_SECRET: This option allows you to add the credentials of your docker registry in your OpenShift and stored it as a secret called docker-registry + registry_secret_name_suffix value.\nRemember that you only need one secret to connect with your registry per namespace, if you are going to add more than one application in the same namespace that use the same registry, use the same name suffix and please do not create more than one secret in the same namespace. The namespace is the OpenShift project when you are going to deploy your application.\nYou can see your secrets stored in OpenShift going to OpenShift and click on the left menu:\nNote\nIf the secret exists, you should uncheck the checkbox and fill the name suffix to use it.\nREGISTRY_SECRET_NAME_SUFFIX: This is the suffix of the name for your docker registry credentials stored in OpenShift as a secret. The name is going to be docker-registry + this suffix, if you use more than one docker-registry in the same namespace you need to add a suffix. For example you could add the name of your project, then to have the name as docker-registry-myprojectname you should use -myprojectname value.\nBuild your docker image using OpenShift and store it in your docker registry\nCREATE_DOCKER_BUILDER: This option allows you to create a build configuration in your OpenShift to create the docker images of your project and store them in your docker registry. If you are going to create the builder, your application is needed, you need to specify where is your git repository and which is the branch and credentials to use it.\nThe following parameters of this section are only necessary if a builder is to be created.\nGIT_REPOSITORY: This is the url of your git repository.\nNote\nIf you are using production line, remember to use the internal rout of your repository, to use it you must change the base url of your production line for the internal route http://gitlab-core:80/gitlab. For example, if your production line repository is for example https://shared-services.pl.s2-eu.capgemini.com/gitlab/boat/boat-frontend.git use http://gitlab-core:80/gitlab/boat/boat-frontend.git)\nGIT_BRANCH: This is the branch that we are going to use for creating the first docker image. The next time that you are going to use the builder you could use another branches.\nGIT_CREDENTIALS: This is the credentials id stored in your jenkins to download the code from your git repository.\nBUILD_SCRIPT: In case of use devon4ng or devon4node you could specify which is the build script used to build and create the first docker image with this builder.\nJAVA_VERSION In case of use devon4j this is the java version used for your docker image.\nDocker registry information\nDOCKER_REGISTRY: This is the url of your docker registry.\nNote\nIf you are using production line, the url of your registry is docker-registry- + your production line url. For example, if your production line is shared-services.pl.s2-eu.capgemini.com your docker registry is docker-registry-shared-services.pl.s2-eu.capgemini.com.\nIf you cannot access to your docker registry, please open an incident in i4u.\nDOCKER_REGISTRY_CREDENTIALS: This is the credentials id stored in your jenkins to download or upload docker images in your docker registry.\nDOCKER_TAG: This is the tag that is going to be used for the builder to push the docker image and for the deployment config to pull and deploy it.\nOpenShift cluster information\nOPENSHIFT_URL: This is the url of your OpenShift cluster.\nOPENSHIFT_CREDENTIALS: This is the credentials id stored in your jenkins to use OpenShift.\nOPENSHIFT_NAMESPACE: This is the name of the project in your OpenShift where you are going to use. The name of the project in OpenShift is called namespace.\nTake care because although you see at the top of your OpenShift interface the name of the project that you are using, this name is the display-name and not the value that you need. To obtain the correct value you must check your OpenShift url like you see in the next image:\nAPP_NAME_SUFFIX: The name of all things created in your OpenShift project are going to be called as the configuration of your application says. Normaly, our projects use a suffix that depends on the environment. You can see the values in the next list:\nFor develop branch we use -dev\nFor release branch we use -uat\nFor master branch we use -prod\nHOSTNAME: If you do not specify nothing, OpenShift is going to autogenerate a valid url for your application. You could modify the value by default but be sure that you configure everything to server your application in the route that you specify.\nSECURED_PROTOCOL: If true, the protocol for the route will be https otherwise will be http.\nJenkins tools\nAll those parameters are the name of the tools in your Jenkinsfile.\nTo obtain it you need enter in your Jenkins and go to Manage Jenkins clicking on left menu and enter in Global Tool Configuration or in Managed files.\nOPENSHIFT_TOOL: Is located in Global tool configuration.\nNODEJS_TOOL: Is located in Global tool configuration.\nYARN_TOOL: Is located in Global tool configuration, inside the custom tools.\nGLOBAL_SETTINGS_ID Is located in Managed files. You need to click on edit button and take the id.\nMAVEN_INSTALLATION Is located in Global tool configuration.\n&#x2190;&#xA0;Previous:&#xA0;Create project&#xA0;| &#x2191;&#xA0;Up:&#xA0;devonfw shop floor&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Monitoring&#xA0;&#x2192;\n"},{"id":927,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_monitoring.html#master-devonfw-shop-floor.asciidoc_monitoring","type":"docs","title":"Monitoring","body":"59. Monitoring\n"},{"id":928,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_monitoring.html#dsf-configure-jenkins-build-monitor-view.asciidoc","type":"docs","title":"Build monitor view","body":"59.1. Build monitor view\nThis tool you will be able to see in real time what is the state of your Jenkins pipelines.\n"},{"id":929,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_monitoring.html#dsf-configure-jenkins-build-monitor-view.asciidoc_prerequisites","type":"docs","title":"Prerequisites","body":"59.1.1. Prerequisites\nAdd build monitor view plugin\nTo integrate it, you need to have installed the build monitor view. To install it go to Manage Jenkins clicking on left menu and enter in Manage Plugins. Go to Available tab and search it using the filter textbox in the top right corner and install it.\n"},{"id":930,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_monitoring.html#dsf-configure-jenkins-build-monitor-view.asciidoc_how-to-use-it","type":"docs","title":"How to use it","body":"59.1.2. How to use it\nWhen you have build monitor view installed, you could add a new view clicking on the + tab in the top bar.\nNow you need to fill which is the name that you are goint to give to your view and select Build Monitor View option.\nThen you can see the configuration.\nIn Job Filters section you can specify which resources are going to be showed and whether subfolders should be included in the search.\nIn Build Monitor - View Settings you could specify which is the name at the top of the view and what is the ordering criterion.\nIn Build Monitor - Widget Settings you could specify if you want to show the committers and which is the field to display if it fails.\nAnd this is the output:\nYou could limit the colums and the text scale clicking on the gear button at the right top corner.\n&#x2190;&#xA0;Previous:&#xA0;Deployment environments&#xA0;| &#x2191;&#xA0;Up:&#xA0;devonfw shop floor&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Annexes&#xA0;&#x2192;\n"},{"id":931,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_provisioning-environments.html#master-devonfw-shop-floor.asciidoc_provisioning-environments","type":"docs","title":"Provisioning environments","body":"55. Provisioning environments\n"},{"id":932,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_provisioning-environments.html#dsf-provisioning-production-line.asciidoc","type":"docs","title":"Production Line provisioning environment","body":"55.1. Production Line provisioning environment\nThe Production Line Project is a set of server-side collaboration tools for Capgemini engagements. It has been developed for supporting project engagements with individual tools like issue tracking, continuous integration, continuous deployment, documentation, binary storage and much more!\nFor additional information use the official documentation.\n"},{"id":933,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_provisioning-environments.html#dsf-provisioning-production-line.asciidoc_how-to-obtain-your-production-line","type":"docs","title":"How to obtain your Production Line","body":"55.1.1. How to obtain your Production Line\nYou can order your Production Line environment instance following the official guide. Remember that you need to order at least the next tools:\n* Jenkins\n* GitLab\n* SonarQube\n* Nexus\nBack.\n"},{"id":934,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_provisioning-environments.html#dsf-provisioning-dsf4docker.asciidoc","type":"docs","title":"dsf4docker provisioning environment","body":"55.2. dsf4docker provisioning environment\n"},{"id":935,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_provisioning-environments.html#dsf-provisioning-dsf4docker.asciidoc_architecture-overview","type":"docs","title":"Architecture overview","body":"55.2.1. Architecture overview\n"},{"id":936,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_provisioning-environments.html#dsf-provisioning-dsf4docker.asciidoc_prerequisite","type":"docs","title":"Prerequisite","body":"55.2.2. Prerequisite\nTo use dsf4docker provisioning environment you need a remote server and you must clone or download devonfw shop floor.\n"},{"id":937,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_provisioning-environments.html#dsf-provisioning-dsf4docker.asciidoc_how-to-use-it","type":"docs","title":"How to use it","body":"55.2.3. How to use it\nNavigate to ./devonfw-shop-floor/dsf4docker/environment and here you can find one scripts to install it, and another one to uninstall it.\nInstall devonfw shop floor 4 Docker\nThere is an installation script to do so, so the complete installation should be completed by running it. Make sure this script has execution permissions in the Docker Host:\nchmod +x dsf4docker-install.sh\nsudo ./dsf4docker-install.sh\nThis script, besides the container &quot;installation&quot; itself, will also adapt the docker-compose.yml file to your host (using sed to replace the IP_ADDRESS word of the file for your real Docker Host&#x2019;s IP address).\nUninstall devonfw shop floor 4 Docker\nAs well as for the installation, if we want to remove everything concerning devonfw shop floor 4 Docker from our Docker Host, we&#x2019;ll run this script:\nchmod +x dsf4docker-uninstall.sh\nsudo ./dsf4docker-uninstall.sh\n"},{"id":938,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_provisioning-environments.html#dsf-provisioning-dsf4docker.asciidoc_troubleshooting","type":"docs","title":"Troubleshooting","body":"55.2.4. Troubleshooting\nWhen trying to execute the install or uninstall .sh there may be some problems related to the windows/linux format file, so if you see this error log while executing the script:\n./dsf4docker-install.sh: line 16: $&apos;\\r&apos;: command not found\nYou need to do a file conversion with this command:\ndos2unix dsf4docker-install.sh\nor\ndos2unix dsf4docker-uninstall.sh\n"},{"id":939,"path":"../website/pages/docs/master-devonfw-shop-floor.asciidoc_provisioning-environments.html#dsf-provisioning-dsf4docker.asciidoc_a-little-history","type":"docs","title":"A little history","body":"55.2.5. A little history\nThe Docker part of the shop floor is created based on the experience of the environment setup of the project Mirabaud Advisory, and intended to be updated to latest versions. Mirabaud Advisory is a web service developed with devonfw (Java) that, alongside its own implementation, it needed an environment both for the team to follow CICD rules through their 1-week-long sprints and for the client (Mirabaud) to check the already done work.\nThere is a practical experience about the Mirabaud Case.\nBack.\n&#x2190;&#xA0;Previous:&#xA0;How to use it&#xA0;| &#x2191;&#xA0;Up:&#xA0;devonfw shop floor&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Configuration and services integration&#xA0;&#x2192;\n"},{"id":940,"path":"../website/pages/docs/master-mrchecker.asciidoc.html#master-mrchecker.asciidoc","type":"docs","title":"XII. MrChecker - devonfw testing tool","body":"XII. MrChecker - devonfw testing tool\nWho Is MrChecker\nTest Framework Modules\nMrChecker download\nTutorials\nMigration from JUnit4 to JUnit5\nFAQ\n&#x2190;&#xA0;Previous:&#xA0;Template Development&#xA0;| &#x2191;&#xA0;Up:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Who Is MrChecker&#xA0;&#x2192;\n"},{"id":941,"path":"../website/pages/docs/master-mrchecker.asciidoc_faq.html#master-mrchecker.asciidoc_faq","type":"docs","title":"FAQ","body":"82. FAQ\nHere you can find the most frequently asked questions regarding working with MrChecker and installation problems.\n"},{"id":942,"path":"../website/pages/docs/master-mrchecker.asciidoc_faq.html#master-mrchecker.asciidoc_common-problems","type":"docs","title":"Common problems","body":"82.1. Common problems\n"},{"id":943,"path":"../website/pages/docs/master-mrchecker.asciidoc_faq.html#I-cannot-find.asciidoc","type":"docs","title":"I can&#x2019;t find the boilerplate module. Has it been removed?","body":"82.1.1. I can&#x2019;t find the boilerplate module. Has it been removed?\nThe boilerplate module has been removed from the GitHub project on purpose.\nThere were problems with naming and communication, not everybody was aware of the meaning of the word boilerplate.\nThe name of the folder has been changed to template. It can be found in the GitHub project.\n"},{"id":944,"path":"../website/pages/docs/master-mrchecker.asciidoc_faq.html#It-is-possible.asciidoc","type":"docs","title":"Is it possible to use Docker with MrChecker?","body":"82.1.2. Is it possible to use Docker with MrChecker?\nMrChecker works seamlessly with Docker.\nA direct example of how to use it can be found in following JenkinsFile https://github.com/devonfw/devonfw-testing/blob/develop/mrchecker-app-under-test/pipelines/CI/Jenkinsfile_node.groovy\nNote that the structure of the folders can be changed. If that happens - search in repo for /pipeline/CI/Jenkinsfile_node.groovy\n"},{"id":945,"path":"../website/pages/docs/master-mrchecker.asciidoc_faq.html#Tests-are-not-stable.asciidoc","type":"docs","title":"Tests are not stable","body":"82.1.3. Tests are not stable\nSelenium tests perform actions much faster than a normal user would. Because pages can contain dynamically changing content, some web elements can still not be loaded when Selenium driver tries to access them.\ngetDriver().waitForPageLoaded() method checks ready state in the browser, that&#x2019;s why stability problems may happen in advanced frontend projects.\nTo improve test stability you can:\nadd waiting methods before dynamically loading elements e.g. getDriver().waitForElement(By selector)\nadd timeout parameter in method getDriver().findElementDynamic(By selector, int timeOut)\nchange global waiting timeout value using method getDriver().manage().timeouts().implicitlyWait(long time, TimeUnit unit)\nFurthermore, if the page displays visible loading bars or spinners, create FluentWait method to wait until they disappear.\nNotice that by increasing timeouts you may improve stability but too long waiting time makes tests run slower.\nLearn more from tutorials:\nExample 10: Dynamically loaded Elements\nExample 11: Exit intent\nExample 12: File download test\n"},{"id":946,"path":"../website/pages/docs/master-mrchecker.asciidoc_faq.html#master-mrchecker.asciidoc_how-to","type":"docs","title":"How to","body":"82.2. How to\n"},{"id":947,"path":"../website/pages/docs/master-mrchecker.asciidoc_faq.html#Change-timeouts.asciidoc","type":"docs","title":"How to: Change timeouts?","body":"82.2.1. How to: Change timeouts?\nIf you would like to change timeouts - you don&#x2019;t have to change them globally.\nIt is possible to add waiting time parameter to searching methods, such as:\ngetDriver().findElementDynamic(By selector, int timeOut)\ntimeout - in seconds\nIt is recommended to use methods that significantly level up the repetitiveness of the code:\ngetDriver().waitForElement(By selector);\ngetDriver().waitForElementVisible(By selector);\ngetDriver().waitForPageLoaded();\ngetDriver().waitUntilElementIsClickable(By selector);\nOr Fluent Wait methods with changed timeout and interval:\nFluentWait&lt;WebDriver&gt; wait = new FluentWait&lt;WebDriver&gt;(getDriver())\n.withTimeout(long duration, TimeUnit unit)\n.pollingEvery(long duration, TimeUnit unit);\nwait.until((WebDriver wd) -&gt; expectedCondition.isTrue());\ngetWebDriverWait().withTimeout(millis, TimeUnit.MILLISECONDS)\n.withTimeout(long duration, TimeUnit unit)\n.pollingEvery(long duration, TimeUnit unit)\n.until((WebDriver wd) -&gt; expectedCondition.isTrue());\nThese methods allow You to change WebDriver timeouts values such as:\ngetDriver().manage().timeouts().pageLoadTimeout(long time, TimeUnit unit)\nthe amount of time to wait for a page to load before throwing an exception. This is the default timeout for method getDriver().waitForPageLoaded()\ngetDriver().manage().timeouts().setScriptTimeout(long time, TimeUnit unit)\nthe amount of time to wait for execution of script to finish before throwing an exception\ngetDriver().manage().timeouts().implicitlyWait(long time, TimeUnit unit)\nthe amount of time the driver should wait when searching for an element if it is not immediately present. After that time, it throws an exception. This the default timeout for methods such as getDriver().findElementDynamic(By selector) or getDriver().waitForElement(By selector)\nChanging timeouts can improve test stability but can also make test run time longer.\n"},{"id":948,"path":"../website/pages/docs/master-mrchecker.asciidoc_faq.html#Start-a-browser.asciidoc","type":"docs","title":"How to: Start a browser in Incognito/Private mode?","body":"82.2.2. How to: Start a browser in Incognito/Private mode?\nIn MrChecker there is a fpossibility of changing browser options during runtime execution.\nTo run the browser in incognito mode:\nIn Eclipse - open Run Configurations window:\nSelect a test which you want to run and switch to arguments tab:\nAdd VM argument:\nfor the incognito mode in chrome:\nRead more about browsers&apos; options: https://github.com/devonfw/devonfw-testing/wiki/Run-with-different-browser-options\n"},{"id":949,"path":"../website/pages/docs/master-mrchecker.asciidoc_faq.html#master-mrchecker.asciidoc_installation-problems","type":"docs","title":"Installation problems","body":"82.3. Installation problems\n"},{"id":950,"path":"../website/pages/docs/master-mrchecker.asciidoc_faq.html#Chromedriver-version.asciidoc","type":"docs","title":"Chromedriver version is not compatible with Chrome browser","body":"82.3.1. Chromedriver version is not compatible with Chrome browser\nProblem:\nDuring the tests your web browser window opens and immediately closes, all your tests are broken.\nFollowing error message is visible in the test description:\nsession not created: This version of ChromeDriver only supports Chrome version 76\nBuild info: version: &apos;&lt;build_version&gt;&apos;, revision: &apos;&lt;build_revision&gt;&apos;, time: &apos;&lt;time&gt;&apos;\nSystem info: host: &apos;&lt;your_computer_name&gt;&apos;, ip: &apos;&lt;your_ip_address&gt;&apos;, os.name: &apos;&lt;your_os_name&gt;&apos;, os.arch: &apos;&lt;your_os_architecture&gt;&apos;, os.version: &apos;&lt;your_os_version&gt;&apos;, java.version: &apos;&lt;java_version_installed&gt;&apos;\nDriver info: driver.version: NewChromeDriver\nSolution:\nMake a change in the following files:\nMrChecker_Test_Framework\\workspace\\devonfw-testing\\src\\resources\\settings.properties\nFor project template-app-under-test: MrChecker_Test_Framework\\workspace\\devonfw-testing\\template\\src\\resources\\settings.properties\nFor project example-app-under-test: MrChecker_Test_Framework\\workspace\\devonfw-testing\\example\\src\\resources\\settings.properties\nChange the value of selenium.driverAutoUpdate field form true to false\nReplace the following file with a version compatible with your browser:\nMrChecker_Test_Framework\\workspace\\devonfw-testing\\example\\lib\\webdrivers\\chrome\\chromedriver.exe .\n"},{"id":951,"path":"../website/pages/docs/master-mrchecker.asciidoc_faq.html#My-browser-opens-up.asciidoc","type":"docs","title":"My browser opens up in German by default","body":"82.3.2. My browser opens up in German by default\nProblem:\nI would like my browser to use the English language, but the default language for the browser is German. How can I change the settings?\nSolution:\nThere is a Properties file installed together with MrCheker installation. It is possible to set the language in which a browser could be opened for testing purposes in Properties &gt; Selenium configuration,.\n&#x2190;&#xA0;Previous:&#xA0;Migration from JUnit4 to JUnit5&#xA0;| &#x2191;&#xA0;Up:&#xA0;MrChecker - devonfw testing tool&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;MyThaiStar&#xA0;&#x2192;\n"},{"id":952,"path":"../website/pages/docs/master-mrchecker.asciidoc_migration-from-junit4-to-junit5.html#master-mrchecker.asciidoc_migration-from-junit4-to-junit5","type":"docs","title":"Migration from JUnit4 to JUnit5","body":"81. Migration from JUnit4 to JUnit5\n"},{"id":953,"path":"../website/pages/docs/master-mrchecker.asciidoc_migration-from-junit4-to-junit5.html#master-mrchecker.asciidoc_migration-guide","type":"docs","title":"Migration guide","body":"81.1. Migration guide\n"},{"id":954,"path":"../website/pages/docs/master-mrchecker.asciidoc_migration-from-junit4-to-junit5.html#Migration-guide.asciidoc","type":"docs","title":"Junit4 to Junit5 migration guide","body":"81.1.1. Junit4 to Junit5 migration guide\nmrchecker-core-module version 5.6.2.1 features the upgrade of Junit4 to Junit5. Consequently, the Junit4 features are now obsolete and current test projects require migration\nin order to use the latest revision of MrChecker. This site provides guidance on the migration.\nReferences:\nJunit5 User Guide - https://junit.org/junit5/docs/current/user-guide/#overview\nPOM\nThe project pom.xml file needs to be adjusted in the first place. An exemplary POM file for download can be found here: https://github.com/devonfw/mrchecker/blob/develop/template/pom.xml\nTest Annotations\nJunit5 redefines annotations defining a test flow. The annotations need to be adjusted as per the following table.\nRule, ClassRule, TestRule and TestMethod\nJunit4 @Rule and @ClassRule annoations as well as TestRule and TestMethod interfaces have been replaced\nwith the Junit5 extension mechanism (https://junit.org/junit5/docs/current/user-guide/#extensions).\nDuring the migration to Junit5, all the instances of the mentioned types need to be rewritten according to the Junit5 User Guide.\nThe extension mechanism is far more flexible than the Junit4 functionality based on rules.\nNote: as per Junit5 API spec: ExpectedExceptionSupport,&#xA0;ExternalResourceSupport,&#xA0;VerifierSupport\nprovide native support of the correspoinding Junit4 rules.\nExtension registration example:\nTestRule (TestWatcher and ExternalResource) to Extension (TestWatcher and AfterAllCallback) example:\nPage, BasePageAutoRegistration and PageFactory classes\nPage class is a new MrChecker class. It was introduced to provide common implemenation for its subpages in specific MrChecker modules.\nIn order to receive test lifecycle notifications, particular Pages need to be registered by calling addToTestExecutionObserver() method.\nTo facilitate this process, PageFactory class was designed and it&#x2019;s usage is a recommended way of creating Page objects for tests.\nAlthough in MrChecker based on Junit4, the registration process was done in a specific BasePage constructor, it&#x2019;s been considered error prone and reimplemented.\nFurthermore, to reduce migration cost BasePageAutoRegistration classes are available in MrChceker modules. They use the old way of registration.\nGiven that three ways of migration are possible.\nMigration with PageFactory class example (RECOMMENDED):\nMigration with calling addToTestExecutionObserver() method example:\nMigration with BasePageAutoRegistration class example:\nTest suites\nTest suite migration example:\nRunning tests from Maven:\nConcurrency\nJunit5 provides native thread count and parallel execution control in contrast to Junit4 where it was controlled by Maven Surefire plugin.\nTo enable concurrent test execution, junit-platform.properties file needs to placed in the test/resources directory of a project.\nExemplary file contents:\nA ready-to-use file can be found here.\nMrChecker supports only concurrent test class execution.\n@ResourceLock can be used to synchronize between classes if needed:\nCucumber\nIf Cucumber is used in a project, it is neccessary to change a hook class.\nAn exemplary hook source file for download can be found here.\nData driven tests\nJunit5 implements new approach to data driven tests by various data resolution mechanisms.\nAn example of method source parameters migration version one:\nAn example of method source parameters migration version two:\nAn example of method source in another class parameters migration:\nProviding parameters directly in annotations has no analogy in Junit5 and needs to be replaced with e.g. method source:\nAn example of csv parameters source with no header line migration:\nAn example of csv parameters source with the header line migration:\nAn example of csv parameters source with object mapping migration step1:\nAn example of csv parameters source with object mapping migration step 2:\nsetUp() and tearDown()\nBaseTest.setUp() and BaseTest.tearDown() methods are now not abstract and need no implementation in subclasses. @Override when a custom implemenatation is needed.\n&#x2190;&#xA0;Previous:&#xA0;Tutorials&#xA0;| &#x2191;&#xA0;Up:&#xA0;MrChecker - devonfw testing tool&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;FAQ&#xA0;&#x2192;\n"},{"id":955,"path":"../website/pages/docs/master-mrchecker.asciidoc_mrchecker-download.html#master-mrchecker.asciidoc_mrchecker-download","type":"docs","title":"MrChecker download","body":"79. MrChecker download\n"},{"id":956,"path":"../website/pages/docs/master-mrchecker.asciidoc_mrchecker-download.html#master-mrchecker.asciidoc_windows","type":"docs","title":"Windows","body":"79.1. Windows\n"},{"id":957,"path":"../website/pages/docs/master-mrchecker.asciidoc_mrchecker-download.html#Easy-out-of-the-box.asciidoc","type":"docs","title":"Easy out of the Box","body":"79.1.1. Easy out of the Box\nClick on the link Ready to use MrChecker_Test_Environment for Junit4 or Ready to use MrChecker_Test_Environment for Junit5 and download the package\nUnzip the downloaded MrChecker Test Framework into the folder C:\\ on your PC - recommended tool: 7z All the necessary components, such as Eclipse, Java and Maven will be pre-installed for you. There is no need for any additional installations.\nNote: Please double check the place into which you have unzipped MrChecker_Test_Framework\nGo to folder C:\\MrChecker_Test_Framework\\ , into which Mr.Checker has been unzipped\nIn order to run the program, double click on start-eclipse-with-java.bat\n(note that start-eclipse.bat won&#x2019;t detect Java)\nUpdate project structure (ALT + F5)\n"},{"id":958,"path":"../website/pages/docs/master-mrchecker.asciidoc_mrchecker-download.html#Out-of-the-box-installation.asciidoc","type":"docs","title":"Out of the box installation","body":"79.1.2. Out of the box installation\nStart from Easy out of the box installation\nOpen Eclipse\nManually Delete folders that appear in Eclipse\nClick inside Eclipse with a right mouse button and open Import\nSelect Maven &#x2192; existing Maven project\nSelect Mr Checker &#x2192; workspace &#x2192; devonfw-testing and click OK\nAll test folders should be imported into Eclipse and ready to use.\n"},{"id":959,"path":"../website/pages/docs/master-mrchecker.asciidoc_mrchecker-download.html#Advanced-installation.asciidoc","type":"docs","title":"Advanced installation","body":"79.1.3. Advanced installation\nJava installation\nThere is one important pre-requisite for Mr Checker installation - Java has to be installed on the computer and an environmental variable has to be set in order to obtain optimal functioning of the framework.\nInstall Java 1.8 JDK 64bit\nDownload and install Java download link\n(To download JDK 8 from Oracle you have to have an account. It is recommended to get a JDK build based on OpenJDK from AdoptOpenJDK)\nWindows Local Environment - How to set:\nVariable name: JAVA_HOME | Variable value: C:\\Where_You&#x2019;ve_Installed_Java\nVariable name: PATH | Variable value: %JAVA_HOME%/bin;%JAVA_HOME%\\lib\nNext, verify it in the command line:\n&gt; java --version\nOther components installation\nInstall each component separately, or update the existing ones on your PC.\nMaven 3.5\nDownload Maven\nUnzip Maven in following location C:\\maven\nSet Windows Local Environment\nVariable name: M2_HOME | Variable value: C:\\maven\\apache-maven-3.5.0\nVariable name: PATH | Variable value: %M2_HOME%\\bin\nVerify it in the command line:\n&gt; mvn --version\nEclipse IDE\nDownload an unzip Eclipse\nDownload MrCheckerTestFramework source code\nImport:\nProjects from folders\nOpen already created projects:\nUpdate project structure - ALT + F5\n"},{"id":960,"path":"../website/pages/docs/master-mrchecker.asciidoc_mrchecker-download.html#master-mrchecker.asciidoc_mac","type":"docs","title":"Mac","body":"79.2. Mac\n"},{"id":961,"path":"../website/pages/docs/master-mrchecker.asciidoc_mrchecker-download.html#Mac.asciidoc","type":"docs","title":"MrChecker macOS installation","body":"79.2.1. MrChecker macOS installation\nOn this page, you can find all the details regarding MrChecker installation on your Mac.\nJava installation\nThere is one important pre-requisite for Mr Checker installation - Java has to be installed on the computer and an environmental variable has to be set in order to obtain optimal functioning of the framework.\nInstall Java 1.8 JDK 64bit\nDownload and install Java download link\n(To download JDK 8 from Oracle you have to have an account. It is recommended to get a JDK build based on OpenJDK from AdoptOpenJDK)\nNext, verify thx in the command line:\n&gt; java --version\nOther components installation\nInstall each component separately, or update the existing ones on your Mac.\nMaven 3.5\nDownload Maven\nUnzip Maven in the following location /maven\nAdd Maven to PATH\n&gt; $ export PATH=$PATH:/maven/apache-maven-3.5.0/bin/\nVerify in terminal:\n&gt; $ mvn -version\nEclipse IDE\nDownload and unzip Eclipse\nDownload MrCheckerTestFramework source code\nImport:\nSelect Projects from folders:\nOpen already created projects:\nUpdate project structure - ALT + F5\n&#x2190;&#xA0;Previous:&#xA0;Test Framework Modules&#xA0;| &#x2191;&#xA0;Up:&#xA0;MrChecker - devonfw testing tool&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Tutorials&#xA0;&#x2192;\n"},{"id":962,"path":"../website/pages/docs/master-mrchecker.asciidoc_test-framework-modules.html#master-mrchecker.asciidoc_test-framework-modules","type":"docs","title":"Test Framework Modules","body":"78. Test Framework Modules\nIn this section, it is possible to find all the information regarding the main modules of MrChecker:\n"},{"id":963,"path":"../website/pages/docs/master-mrchecker.asciidoc_test-framework-modules.html#master-mrchecker.asciidoc_core-test-module","type":"docs","title":"Core Test Module","body":"78.1. Core Test Module\n"},{"id":964,"path":"../website/pages/docs/master-mrchecker.asciidoc_test-framework-modules.html#Core-Test-Module.asciidoc","type":"docs","title":"Core Test Module","body":"78.1.1. Core Test Module\nWhat is Core Test Module\nCore Test Module Functions\nTest reports with logs and/or screenshots\nTest groups/tags\nData driven approach\nTest case parallel execution\nBDD - Gherkin - Cucumber approach\nRun on independent Operating Systems\nExternalize test environment (DEV, QA, SIT, PROD)\nEncrypting sensitive data\nHow to start?\nRead: Framework Test Class\n"},{"id":965,"path":"../website/pages/docs/master-mrchecker.asciidoc_test-framework-modules.html#Core-Test-Module-Test-reports-with-logs-and-or-screenshots.asciidoc","type":"docs","title":"Allure Logger &#x2192; BFLogger","body":"78.1.2. Allure Logger &#x2192; BFLogger\nIn Allure E2E Test Framework you have ability to use and log any additional information crucial for:\ntest steps\ntest exection\npage object actions, and many more.\nWhere to find saved logs\nEvery logged information is saved in a separate test file, as a result of parallel tests execution.\nThe places they are saved:\nIn test folder C:\\Allure_Test_Framework\\allure-app-under-test\\logs\nIn every Allure Test report, logs are always embedded as an attachment, according to test run.\nHow to use logger:\nStart typing\nBFLogger\nThen type . (dot)\nType of logger:\nBFLogger.logInfo(&quot;Your text&quot;) - used for test steps\nBFLogger.logDebug(&quot;Your text&quot;) - used for non official information, either during test build process or in Page Object files\nBFLogger.logError(&quot;Your text&quot;) - used to emphasize critical information\nConsole output:\n"},{"id":966,"path":"../website/pages/docs/master-mrchecker.asciidoc_test-framework-modules.html#Core-Test-Module-Test-reports-with-logs-and-or-screenshots.asciidoc","type":"docs","title":"Allure Reports","body":"78.1.3. Allure Reports\nAllure is a tool designed for test reports.\nGenerate report - command line\nYou can generate a report using one of the following commands:\nSince mrchecker-core-module version 5.6.2.1:\nmvn test allure:serve -Dgroups=TestsTag1\nPrior to mrchecker-core-module version 5.6.2.1:\nmvn test allure:serve -Dtest=TS_Tag1\nA report will be generated into temp folder. Web server with results will start. You can additionally configure the server timeout. The default value is &quot;3600&quot; (one hour).\nSystem property allure.serve.timeout.\nSince mrchecker-core-module version 5.6.2.1:\nmvn test allure:report -Dgroups=TestsTag1\nPrior to mrchecker-core-module version 5.6.2.1:\nmvn test allure:report -Dtest=TS_Tag1\nA report will be generated t&#x43E; directory: target/site/allure-maven/index.html\nNOTE: Please open index.html file under Firefox. Chrome has some limitations to presenting dynamic content. If you want to open a report with a Chromium based Web Browser, you need to launch it first with --allow-file-access-from-files argument.\nGenerate report - Eclipse\nA report is created here allure-app-under-test\\target\\site\\allure-report\\index.html\nNOTE: Please open index.html file under Firefox. Chrome has some limitations to presenting dynamic content. If you want to open a report with a Chromium based Web Browser, you need to launch it first with --allow-file-access-from-files argument.\nGenerate report - Jenkins\nIn our case, we&#x2019;ll use the Allure Jenkins plugin. When integrating Allure in a Jenkins job configuration, we&#x2019;ll have direct access to the build&#x2019;s test report.\nThere are several ways to access the Allure Test Reports:\nUsing the &quot;Allure Report&quot; button on the left navigation bar or center of the general job overview\nUsing the &quot;Allure Report&quot; button on the left navigation bar or center of a specific build overview\nAfterwards you&#x2019;ll be greeted with either the general Allure Dashboard (showing the newest build) or the Allure Dashboard for a specific (older) build.\nAllure dashboard\nThe Dashboard provides a graphical overview on how many test cases were successful, failed or broken.\nPassed means, that the test case was executed successfully.\nBroken means, that there were mistakes, usually inside of the test method or test class. As tests are being treated as code, broken code has to be expected, resulting in occasionally broken test results.\nFailed means that an assertion failed.\nDefects\nThe defects tab lists out all the defects that occurred, and also descriptions thereof. Clicking on a list item displays the test case which resulted in an error. Clicking on a test case allows the user to have a look at the test case steps, as well as Log files or Screenshots of the failure.\nGraph\nThe graph page includes a pie chart of all tests, showing their result status (failed, passed, etc.). Another graph allows insight into the time elapsed during the tests. This is a very useful information to find and eliminate possible bottlenecks in test implementations.\n"},{"id":967,"path":"../website/pages/docs/master-mrchecker.asciidoc_test-framework-modules.html#Core-Test-Module-test-groups-tags.asciidoc","type":"docs","title":"Why join Test Cases in groups - Test Suites","body":"78.1.4. Why join Test Cases in groups - Test Suites\nRegresion Suite:\nRegression testing is a type of software testing which verifies that software which was previously developed and tested still performs the same way after it was changed or interfaced with another software.\nSmoke\nBusiness vital functionalities\nFull scope of test cases\nFunctional Suite:\nSmoke\nBusiness function A\nBusiness function B\nSingle Responsibility Unit:\nSingle page\nSpecific test case\n"},{"id":968,"path":"../website/pages/docs/master-mrchecker.asciidoc_test-framework-modules.html#Core-Test-Module-test-groups-tags.asciidoc","type":"docs","title":"How to build a Test Suite based on tags","body":"78.1.5. How to build a Test Suite based on tags\nStructure of the Test Suite\nSince mrchecker-core-module version 5.6.2.1:\nWhere:\n@RunWith(JUnitPlatform.class) - use Junit5 runner\n@IncludeTags({&quot;TestsTag1&quot;}) - search all test files with the tag &quot;TestsTag1&quot;\n@ExcludeTags({&quot;TagToExclude&quot;}) - exclude test files with the tag &quot;TagToExclude&quot;\n@SelectPackages(&quot;com.capgemini.mrchecker.core.groupTestCases.testCases&quot;) - search only test files in &quot;com.capgemini.mrchecker.core.groupTestCases.testCases&quot; package\npublic class TS_Tag1 - the name of the Test Suite is &quot;TS_Tag1&quot;\nMost commonly used filters to build a Test Suite are ones using:\n@IncludeTags({ })\n@ExcludeTags({ })\nExample:\n@IncludeTags({ &quot;TestsTag1&quot; }) , @ExcludeTags({ }) &#x2192; will execute all test cases with the tag TestsTag1\n@IncludeTags({ &quot;TestsTag1&quot; }) , @ExcludeTags({ &quot;SlowTest&quot; }) &#x2192; will execute all test cases with tag &quot;TestsTag1&quot; although it will exclude from this list the test cases with the tag &quot;SlowTest&quot;\n@IncludeTags({ }) , @ExcludeTags({ &quot;SlowTest&quot; }) &#x2192; It will exclude test cases with the tag &quot;SlowTest&quot;\nPrior to mrchecker-core-module version 5.6.2.1:\nWhere:\n@RunWith(WildcardPatternSuiteBF.class) - search for test files under /src/test/java\n@IncludeCategories({ TestsTag1.class }) - search for all test files with the tag &quot;TestsTag1.class&quot;\n@ExcludeCategories({ }) - exclude test files. In this example, there is no exclusion\n@SuiteClasses({ &quot;**/*Test.class&quot; }) - search only test files, where the file name ends with &quot;&lt;anyChar/s&gt;Test.class&quot;\npublic class TS_Tag1 - the name of the Test Suite is &quot;TS_Tag1&quot;\nMost commonly used filters to build Test Suite are ones using:\n@IncludeCategories({ })\n@ExcludeCategories({ })\nExample:\n@IncludeCategories({ TestsTag1.class }) , @ExcludeCategories({ }) &#x2192; will execute all test cases with the tag TestsTag1.class\n@IncludeCategories({ TestsTag1.class }) , @ExcludeCategories({ SlowTest.class }) &#x2192; will execute all test cases with the tag &quot;TestsTag1.class&quot; although it will exclude from this list the test cases with the tag &quot;SlowTest.class&quot;\n@IncludeCategories({ }) , @ExcludeCategories({ SlowTest.class }) &#x2192; will execute all test cases from /src/test/java, although it will exclude from this list the test cases with the tag &quot;SlowTest.class&quot;\nStructure of Test Case\nSince mrchecker-core-module version 5.6.2.1:\nWhere:\n@TestsTag1, @TestsSmoke, @TestsSelenium - list of tags assigned to this test case - &quot;TestsTag1, TestsSmoke, TestSelenium&quot; annotations\npublic class FristTest_tag1_Test - the name of the test case is &quot;FristTest_tag1_Test&quot;\nPrior to mrchecker-core-module version 5.6.2.1:\nWhere:\n@Category({ TestsTag1.class, TestsSmoke.class, TestSelenium.class }) - list of tags / categories assigned to this test case - &quot;TestsTag1.class, TestsSmoke.class, TestSelenium.class&quot;\npublic class FristTest_tag1_Test - the name of the test case is &quot;FristTest_tag1_Test&quot;\nStructure of Tags / Categories\nSince mrchecker-core-module version 5.6.2.1:\nTag name: TestsTag1 annotation\nTag name: TestsSmoke annotation\nTag name: TestSelenium annotation\nPrior to mrchecker-core-module version 5.6.2.1:\nTag name: TestsTag1.class\nTag name: TestsSmoke.class\nTag name: TestSelenium.class\n"},{"id":969,"path":"../website/pages/docs/master-mrchecker.asciidoc_test-framework-modules.html#Core-Test-Module-test-groups-tags.asciidoc","type":"docs","title":"How to run Test Suite","body":"78.1.6. How to run Test Suite\nTo run a Test Suite you perform the same steps as you do to run a test case\nCommand line\nSince mrchecker-core-module version 5.6.2.1:\nJUnit5 disallows running suite classes from maven. Use -Dgroups=Tag1,Tag2 and -DexcludeGroups=Tag4,Tag5 to create test suites in maven.\nmvn test site -Dgroups=TestsTag1\nPrior to mrchecker-core-module version 5.6.2.1:\nmvn test site -Dtest=TS_Tag1\nEclipse\n"},{"id":970,"path":"../website/pages/docs/master-mrchecker.asciidoc_test-framework-modules.html#Core-Test-Module-Data-driven-approach.asciidoc","type":"docs","title":"Data driven approach","body":"78.1.7. Data driven approach\nData driven approach - External data driven\nExternal data driven - Data as external file injected in test case\nTest case - Categorize functionality and severity\nYou can find more information about data driven here and here\nThere are a few ways to define parameters for tests.\n"},{"id":971,"path":"../website/pages/docs/master-mrchecker.asciidoc_test-framework-modules.html#Core-Test-Module-Data-driven-approach.asciidoc","type":"docs","title":"Internal Data driven approach","body":"78.1.8. Internal Data driven approach\nData as part of test case\nThe different means to pass in parameters are shown below.\nSince mrchecker-core-module version 5.6.2.1\nStatic methods are used to provide the parameters.\nA method in the test class:\n@ParameterizedTest\n@MethodSource(&quot;argumentsStream&quot;)\nOR\n@ParameterizedTest\n@MethodSource(&quot;arrayStream&quot;)\nIn the first case the arguments are directly mapped to the test method parameters. In the second case the array is passed as the argument.\nA method in a different class:\n@ParameterizedTest\n@MethodSource(&quot;com.capgemini.mrchecker.core.datadriven.MyContainsTestProvider#provideContainsTrueParameters&quot;)\nPrior to mrchecker-core-module version 5.6.2.1\nParameters that are passed into tests using the @Parameters annotation must be _Object[]_s\nIn the annotation:\n@Parameters({&quot;1, 2, 3&quot;, &quot;3, 4, 7&quot;, &quot;5, 6, 11&quot;, &quot;7, 8, 15&quot;})\nThe parameters must be primitive objects such as integers, strings, or booleans. Each set of parameters is contained within a single string and will be parsed to their correct values as defined by the test method&#x2019;s signature.\nIn a method named in the annotation:\n@Parameters(method = &quot;addParameters&quot;)\nA separate method can be defined and referred to for parameters. This method must return an Object[] and can contain normal objects.\nIn a class:\n@Parameters(source = MyContainsTestProvider.class)\nA separate class can be used to define parameters for the test. This test must contain at least one static method that returns an Object[], and its name must be prefixed with provide. The class could also contain multiple methods that provide parameters to the test, as long as they also meet the required criteria.\n"},{"id":972,"path":"../website/pages/docs/master-mrchecker.asciidoc_test-framework-modules.html#Core-Test-Module-Data-driven-approach.asciidoc","type":"docs","title":"External Data Driven","body":"78.1.9. External Data Driven\nData as external file injected in test case\nSince mrchecker-core-module version 5.6.2.1\nTests use the annotation @CsvFileSource to inject CSVs file.\n@CsvFileSource(resources = &quot;/datadriven/test.csv&quot;, numLinesToSkip = 1)\nA CSV can also be used to contain the parameters for the tests. It is pretty simple to set up, as it&#x2019;s just a comma-separated list.\nClassic CSV\nand CSV file structure\nCSV with headers\nand CSV file structure\nCSV with specific column mapper\nand Mapper implementation\nPrior to mrchecker-core-module version 5.6.2.1\nTests use the annotation @FileParameters to inject CSVs file.\n@FileParameters(&quot;src/test/resources/datadriven/test.csv&quot;)\nA CSV can also be used to contain the parameters for the tests. It is pretty simple to set up, as it&#x2019;s just a comma-separated list.\nClassic CSV\nand CSV file structure\nCSV with headers\nand CSV file structure\nCSV with specific column mapper\nand Mapper implementation\n"},{"id":973,"path":"../website/pages/docs/master-mrchecker.asciidoc_test-framework-modules.html#Core-Test-Module-Test-case-parallel-execution.asciidoc","type":"docs","title":"What is &quot;Parallel test execution&quot; ?","body":"78.1.10. What is &quot;Parallel test execution&quot; ?\nParallel test execution means many &quot;Test Classes&quot; can run simultaneously.\n&quot;Test Class&quot;, as this is a Junit Test class, it can have one or more test cases - &quot;Test case methods&quot;\n"},{"id":974,"path":"../website/pages/docs/master-mrchecker.asciidoc_test-framework-modules.html#Core-Test-Module-Test-case-parallel-execution.asciidoc","type":"docs","title":"How many parallel test classes can run simultaneously?","body":"78.1.11. How many parallel test classes can run simultaneously?\nSince mrchecker-core-module version 5.6.2.1\nJUnit5 supports parallelism natively. The feature is configured using a property file located at src\\test\\resources\\junit-platform.properties.\nAs per default configuration, concurrent test execution is set to run test classes in parallel using the thread count equal to a number of your CPUs.\nVisit JUnit5 site to learn more about parallel test execution.\nPrior to mrchecker-core-module version 5.6.2.1\nBy default, number of parallel test classes is set to 8.\nIt can be updated as you please, on demand, by command line:\nmvn test site -Dtest=TS_Tag1 -Dthread.count=16\n-Dthread.count=16 - increase number of parallel Test Class execution to 16.\nOverview\nCucumber / Selenium\nBusiness and IT don&#x2019;t always understand each other. Very often misunderstandings between business and IT result in the costly failure of IT projects. With this in mind, Cucumber was developed as a tool to support human collaboration between business and IT.\nCucumber uses executable specifications to encourage a close collaboration. This helps teams to keep the business goal in mind at all times. With Cucumber you can merge specification and test documentation into one cohesive whole, allowing your team to maintain one single source of truth. Because these executable specifications are automatically tested by Cucumber, your single source of truth is always up-to-date.\nCucumber supports testers when designing test cases. To automate these test cases, several languages can be used. Cucumber also works well with Browser Automation tools such as Selenium Webdriver.\nSelenium\nSelenium automates browsers and is used for automating web applications for testing purposes. Selenium offers testers and developers full access to the properties of objects and the underlying tests, via a scripting environment and integrated debugging options.\nSelenium consists of many parts. If you want to create robust, browser-based regression automation suites and tests, Selenium Webdriver is most appropriate. With Selenium Webdriver you can also scale and distribute scripts across many environments.\nStrengths\nSupports BDD\nThose familiar with Behavior Driven Development (BDD) recognize Cucumber as an excellent open source tool that supports this practice.\nAll in one place\nWith Cucumber / Selenium you can automate at the UI level. Automation at the unit or API level can also be implemented using Cucumber. This means all tests, regardless of the level at which they are implemented, can be implemented in one tool.\nMaintainable test scripts\nMany teams seem to prefer UI level automation, despite huge cost of maintaining UI level tests compared to the cost of maintaining API or unit tests. To lessen the maintenance of UI testing, when designing UI level functional tests, you can try describing the test and the automation at three levels: business rule, UI workflow, technical implementation.\nWhen using Cucumber combined with Selenium, you can implement these three levels for better maintenance.\nEarly start\nExecutable specifications can and should be written before the functionality is implemented. By starting early, teams get most return on investment from their test automation.\nSupported by a large community\nCucumber and Selenium are both open source tools with a large community, online resources and mailing lists.\nHow to run cucumber tests in Mr.Checker\nCommand line / Jenkins\nRun cucumber tests and generate Allure report. Please use this for Jenkins execution. Report is saved under ./target/site.\nmvn clean -P cucumber test site\nRun and generate report\nmvn clean -P cucumber test site allure:report\nRun cucumber tests, generate Allure report and start standalone report server\nmvn clean -P cucumber test site allure:serve\nEclipse IDE\nTooling\nCucumber\nCucumber supports over a dozen different software platforms. Every Cucumber implementation provides the same overall functionality, but they also have their own installation procedure and platform-specific functionality. See https://cucumber.io/docs for all Cucumber implementations and framework implementations.\nAlso, IDEs such as Intellij offer several plugins for Cucumber support.\nSelenium\nSelenium has the support of some of the largest browser vendors who have taken (or are taking) steps to make Selenium a native part of their browser. It is also the core technology in countless other browser automation tools, APIs and frameworks.\nAutomation process\nWrite a feature file\nTest automation in Cucumber starts with writing a feature file. A feature normally consists of several (test)scenarios and each scenario consists of several steps.\nFeature: Refund item\nScenario: Jeff returns a faulty microwave\nGiven Jeff has bought a microwave for $100\nAnd he has a receipt\nWhen he returns the microwave\nThen Jeff should be refunded $100\nAbove example shows a feature &#x201C;Refund item&#x201D; with one scenario &#x201C;Jeff returns a faulty microwave&#x201D;. The scenario consists of four steps each starting with a key word (Given, And, When, Then).\nImplementing the steps\nNext the steps are implemented. Assuming we use Java to implement the steps, the Java code will look something like this.\npublic class MyStepdefs \\{\n@Given(&quot;Jeff has bought a microwave for $(\\d+)&quot;)\npublic void Jeff_has_bought_a_microwave_for(int amount) \\{\n// implementation can be plain java\n// or selenium\ndriver.findElement(By.name(&quot;test&quot;)).sendKeys(&quot;This is an example\\n&quot;);\ndriver.findElement(By.name(&quot;button&quot;)).click();// etc\n}\n}\nCucumber uses an annotation (highlighted) to match the step from the feature file with the function implementing the step in the Java class. The name of the class and the function can be as the developer sees fit. Selenium code can be used within the function to automate interaction with the browser.\nRunning scenarios\nThere are several ways to run scenarios with Cucumber, for example the JUnit runner, a command line runner and several third party runners.\nReporting test results\nCucumber can report results in several different formats, using formatter plugins\nFeatures\nFeature files using Gherkin\nCucumber executes your feature files. As shown in the example below, feature files in Gherkin are easy to read so they can be shared between IT and business. Data tables can be used to execute a scenario with different inputs.\nOrganizing tests\nFeature files are placed in a directory structure and together form a feature tree.\nTags can be used to group features based on all kinds of categories. Cucumber can include or exclude tests with certain tags when running the tests.\nReporting test results\nCucumber can report results in several formats, using formatter plugins.\nNot supported option by Shared Services: The output from Cucumber can be used to present test results in Jenkins or Hudson depending of the preference of the project.\nHOW IS Cucumber / Selenium USED AT Capgemini?\nTool deployment\nCucumber and Selenium are chosen as one of Capgemini&#x2019;s test automation industrial tools. We support the Java implementation of Cucumber and Selenium Webdriver. We can help with creating Cucumber, Selenium projects in Eclipse and IntelliJ.\nApplication in ATaaS (Automated Testing as a Service)\nIn the context of industrialisation, Capgemini has developed a range of services to assist and support the projects in process and tools implementation.\nIn this context a team of experts assists projects using test automation.\nThe main services provided by the center of expertise are:\nAdvise on the feasibility of automation.\nSupport with installation.\nCoaching teams in the use of BDD.\n"},{"id":975,"path":"../website/pages/docs/master-mrchecker.asciidoc_test-framework-modules.html#Core-Test-Module-Run-on-independent-Operating-Systems.asciidoc","type":"docs","title":"Run on independent Operation Systems","body":"78.1.12. Run on independent Operation Systems\nAs E2E Allure test framework is build on top of:\nJava 1.8\nMaven 3.3\nThis guarantees portability to all operating systems.\nE2E Allure test framework can run on OS:\nWindows,\nLinux and\nMac.\nTest creation and maintenance in E2E Allure test framework can be done with any type of IDE:\nEclipse,\nIntelliJ,\nWebStorm,\nVisual Studio Code,\nmany more that support Java + Maven.\n"},{"id":976,"path":"../website/pages/docs/master-mrchecker.asciidoc_test-framework-modules.html#Core-Test-Module-Externalize-test-environment-DEV-QA-SIT-PROD.asciidoc","type":"docs","title":"System under test environments","body":"78.1.13. System under test environments\nQuality assurance or QA is a way of preventing mistakes or defects in manufactured products and avoiding problems when delivering solutions or services to customers; which ISO 9000 defines as &quot;part of quality management focused on providing confidence that quality requirements will be fulfilled&quot;.\nSystem integration testing or SIT is a high-level software testing process in which testers verify that all related systems maintain data integrity and can operate in coordination with other systems in the same environment. The testing process ensures that all sub-components are integrated successfully to provide expected results.\nDevelopment or Dev testing is performed by the software developer or engineer during the construction phase of the software development life-cycle. Rather than replace traditional QA focuses, it augments it. Development testing aims to eliminate construction errors before code is promoted to QA; this strategy is intended to increase the quality of the resulting software as well as the efficiency of the overall development and QA process.\nProd If the customer accepts the product, it is deployed to a production environment, making it available to all users of the system.\n"},{"id":977,"path":"../website/pages/docs/master-mrchecker.asciidoc_test-framework-modules.html#Core-Test-Module-Externalize-test-environment-DEV-QA-SIT-PROD.asciidoc","type":"docs","title":"How to use system environment","body":"78.1.14. How to use system environment\nIn Page classes, when you load / start web, it is uncommon to save fixed main url.\nValue flexibility is a must, when your web application under test, have different main url, dependence on environmnent (DEV, QA, SIT, &#x2026;&#x200B;, PROD)\nInstead of hard coded main url variable, you build your Page classe with dynamic variable.\nExample of dynamic variable GetEnvironmentParam.WWW_FONT_URL\n"},{"id":978,"path":"../website/pages/docs/master-mrchecker.asciidoc_test-framework-modules.html#Core-Test-Module-Externalize-test-environment-DEV-QA-SIT-PROD.asciidoc","type":"docs","title":"How to create / update system environment","body":"78.1.15. How to create / update system environment\nExternal file with variable values\nDynamic variable values are stored under path mrchecker-app-under-test\\src\\resources\\enviroments\\environments.csv.\nNOTE: As environments.csv is Comma-separated file, please be aware of any edition and then save it under Excel.\nEncrypting sensitive data\nSome types of data you might want to store as environment settings are sensitive in nature (e.g. passwords). You might not want to store them (at least not in their plaintext form) in your repository. To be able to encrypt sensitive data you need to do following:\nCreate a secret (long, random chain of characters) and store it under mrchecker-app-under-test\\src\\resources\\secretData.txt. Example: LhwbTm9V3FUbBO5Tt5PiTUEQrXGgWrDLCMthnzLKNy1zA5FVTFiTdHRQAyPRIGXmsAjPUPlJSoSLeSBM\nExclude the file from being checked into the git repository by adding it to git.ignore. You will need to pass the file over a different channel among your teammates.\nEncrypt the values before putting them into the environments.csv file by creating following script (put the script where your jasypt library resides, e.g. C:\\MrChecker_Test_Framework\\m2\\repository\\org\\jasypt\\jasypt\\1.9.2):\n@ECHO OFF\nset SCRIPT_NAME=encrypt.bat\nset EXECUTABLE_CLASS=org.jasypt.intf.cli.JasyptPBEStringEncryptionCLI\nset EXEC_CLASSPATH=jasypt-1.9.2.jar\nif &quot;%JASYPT_CLASSPATH%&quot; == &quot;&quot; goto computeclasspath\nset EXEC_CLASSPATH=%EXEC_CLASSPATH%;%JASYPT_CLASSPATH%\n:computeclasspath\nIF &quot;%OS%&quot; == &quot;Windows_NT&quot; setlocal ENABLEDELAYEDEXPANSION\nFOR %%c in (%~dp0..\\lib\\*.jar) DO set EXEC_CLASSPATH=!EXEC_CLASSPATH!;%%c\nIF &quot;%OS%&quot; == &quot;Windows_NT&quot; setlocal DISABLEDELAYEDEXPANSION\nset JAVA_EXECUTABLE=java\nif &quot;%JAVA_HOME%&quot; == &quot;&quot; goto execute\nset JAVA_EXECUTABLE=&quot;%JAVA_HOME%\\bin\\java&quot;\n:execute\n%JAVA_EXECUTABLE% -classpath %EXEC_CLASSPATH% %EXECUTABLE_CLASS% %SCRIPT_NAME% %*\nEncrypt the values by calling\n.\\encrypt.bat input=someinput password=secret\n----ENVIRONMENT-----------------\nRuntime: Oracle Corporation Java HotSpot(TM) 64-Bit Server VM 25.111-b14\n----ARGUMENTS-------------------\ninput: someinput\npassword: secret\n----OUTPUT----------------------\nJN3nOFol2GMZoUxR5z2wI2qdipcNH1UD\nMark the value as encrypted by adding a prefix &apos;ENC(&apos; and suffix &apos;)&apos; like: ENC(JN3nOFol2GMZoUxR5z2wI2qdipcNH1UD)\nBridge between external file nad Page class\nTo map values from external file with Page class you ought to use class GetEnvironmentParam.\nTherefore when you add new variable (row) in environments.csv you might need to add this variable to GetEnvironmentParam.\n"},{"id":979,"path":"../website/pages/docs/master-mrchecker.asciidoc_test-framework-modules.html#Core-Test-Module-Externalize-test-environment-DEV-QA-SIT-PROD.asciidoc","type":"docs","title":"Run test case with system environment","body":"78.1.16. Run test case with system environment\nTo run test case with system environment, please use:\n-Denv=&lt;NameOfEnvironment&gt;\n&lt;NameOfEnvironment&gt; is taken as column name from file mrchecker-app-under-test\\src\\test\\resources\\enviroments\\environments.csv\nCommand Line\nmvn test site -Dtest=RegistryPageTest -Denv=DEV\nEclipse\n"},{"id":980,"path":"../website/pages/docs/master-mrchecker.asciidoc_test-framework-modules.html#Core-Test-Module-Different-Environments.asciidoc","type":"docs","title":"System under test environments","body":"78.1.17. System under test environments\nQuality assurance or QA is a way of preventing mistakes or defects in manufactured products and avoiding problems when delivering solutions or services to customers which ISO 9000 defines as &quot;part of quality management focused on providing confidence that quality requirements will be fulfilled&quot;.\nSystem integration testing or SIT is a high-level software testing process in which testers verify that all related systems maintain data integrity and can operate in coordination with other systems in the same environment. The testing process ensures that all sub-components are integrated successfully to provide expected results.\nDevelopment or Dev testing is performed by the software developer or engineer during the construction phase of the software development life-cycle. Rather than replace traditional QA focuses, it augments it. Development testing aims to eliminate construction errors before code is promoted to QA; this strategy is intended to increase the quality of the resulting software as well as the efficiency of the overall development and QA process.\nProd If the customer accepts the product, it is deployed to a production environment, making it available to all users of the system.\n"},{"id":981,"path":"../website/pages/docs/master-mrchecker.asciidoc_test-framework-modules.html#Core-Test-Module-Different-Environments.asciidoc","type":"docs","title":"How to use system environment","body":"78.1.18. How to use system environment\nIn Page classes, when you load / start web, it is uncommon to save fixed main url.\nValue flexibility is a must, when your web application under test has different main url, depending on the environmnent (DEV, QA, SIT, &#x2026;&#x200B;, PROD)\nInstead of hard coded main url variable, you build your Page classes with dynamic variable.\nAn example of dynamic variable GetEnvironmentParam.WWW_FONT_URL\n"},{"id":982,"path":"../website/pages/docs/master-mrchecker.asciidoc_test-framework-modules.html#Core-Test-Module-Different-Environments.asciidoc","type":"docs","title":"How to create / update system environment","body":"78.1.19. How to create / update system environment\nExternal file with variable values\nDynamic variable values are stored under mrchecker-app-under-test\\src\\resources\\enviroments\\environments.csv.\nNOTE: As environments.csv is a comma-separated file, please be careful while editing and then save it under Excel.\nEncrypting sensitive data\nSome types of data you might want to store as environment settings are sensitive in nature (e.g. passwords). You might not want to store them (at least not in their plaintext form) in your repository. To be able to encrypt sensitive data you need to do following:\nCreate a secret (long, random chain of characters) and store it under mrchecker-app-under-test\\src\\resources\\secretData.txt. Example: LhwbTm9V3FUbBO5Tt5PiTUEQrXGgWrDLCMthnzLKNy1zA5FVTFiTdHRQAyPRIGXmsAjPUPlJSoSLeSBM\nExclude the file from being checked into the git repository by adding it to git.ignore. You will need to pass the file over a different channel among your teammates.\nEncrypt the values before putting them into the environments.csv file by creating following script (put the script where your jasypt library resides, e.g. C:\\MrChecker_Test_Framework\\m2\\repository\\org\\jasypt\\jasypt\\1.9.2):\n@ECHO OFF\nset SCRIPT_NAME=encrypt.bat\nset EXECUTABLE_CLASS=org.jasypt.intf.cli.JasyptPBEStringEncryptionCLI\nset EXEC_CLASSPATH=jasypt-1.9.2.jar\nif &quot;%JASYPT_CLASSPATH%&quot; == &quot;&quot; goto computeclasspath\nset EXEC_CLASSPATH=%EXEC_CLASSPATH%;%JASYPT_CLASSPATH%\n:computeclasspath\nIF &quot;%OS%&quot; == &quot;Windows_NT&quot; setlocal ENABLEDELAYEDEXPANSION\nFOR %%c in (%~dp0..\\lib\\*.jar) DO set EXEC_CLASSPATH=!EXEC_CLASSPATH!;%%c\nIF &quot;%OS%&quot; == &quot;Windows_NT&quot; setlocal DISABLEDELAYEDEXPANSION\nset JAVA_EXECUTABLE=java\nif &quot;%JAVA_HOME%&quot; == &quot;&quot; goto execute\nset JAVA_EXECUTABLE=&quot;%JAVA_HOME%\\bin\\java&quot;\n:execute\n%JAVA_EXECUTABLE% -classpath %EXEC_CLASSPATH% %EXECUTABLE_CLASS% %SCRIPT_NAME% %*\nEncrypt the values by calling\n.\\encrypt.bat input=someinput password=secret\n----ENVIRONMENT-----------------\nRuntime: Oracle Corporation Java HotSpot(TM) 64-Bit Server VM 25.111-b14\n----ARGUMENTS-------------------\ninput: someinput\npassword: secret\n----OUTPUT----------------------\nJN3nOFol2GMZoUxR5z2wI2qdipcNH1UD\nMark the value as encrypted by adding a prefix &apos;ENC(&apos; and suffix &apos;)&apos; like: ENC(JN3nOFol2GMZoUxR5z2wI2qdipcNH1UD)\nBridge between external file nad Page class\nTo map values from external file with Page class you ought to use class GetEnvironmentParam\nTherefore when you add new variable (row) in environments.csv you might need to add this variable to GetEnvironmentParam.\n"},{"id":983,"path":"../website/pages/docs/master-mrchecker.asciidoc_test-framework-modules.html#Core-Test-Module-Different-Environments.asciidoc","type":"docs","title":"Run test case with system environment","body":"78.1.20. Run test case with system environment\nTo run test case with system environment, please use:\n* -Denv=\\&lt;NameOfEnvironment\\&gt;\n* \\&lt;NameOfEnvironment\\&gt; is taken as column name from file mrchecker-app-under-test\\src\\test\\resources\\enviroments\\environments.csv\nSince mrchecker-core-module version 5.6.2.1\nCommand Line\nmvn test site -Dgroups=RegistryPageTestTag -Denv=DEV\nEclipse\nPrior to mrchecker-core-module version 5.6.2.1\nCommand Line\nmvn test site -Dtest=RegistryPageTest -Denv=DEV\nEclipse\n"},{"id":984,"path":"../website/pages/docs/master-mrchecker.asciidoc_test-framework-modules.html#master-mrchecker.asciidoc_selenium-module","type":"docs","title":"Selenium Module","body":"78.2. Selenium Module\n"},{"id":985,"path":"../website/pages/docs/master-mrchecker.asciidoc_test-framework-modules.html#Selenium-Test-Module.asciidoc","type":"docs","title":"Selenium Test Module","body":"78.2.1. Selenium Test Module\nWhat is MrChecker E2E Selenium Test Module\nSelenium Structure\nWhat is Selenium\nWhat is WebDriver\nWhat is Page Object Model/Pattern\nFramework Features\nConstruction of Framework Page Class\nEvery Page class must extend BasePage\nWhat are isLoaded(), load() and pageTitle() for\nHow to create selector variable - private static final By ButtonOkSelector = By.Css(&#x2026;&#x200B;)\nHow to prepare an &apos;everlasting&apos; selector\nMethod/action naming convention\nWhy we should use findElementDynamic() and findElementQuietly() instead of classic Selenium findElement\nList of well-rounded groups of user friendly actions (ElementButton, ElementCheckbox, ElementInput, etc.)\nVerification points of well-defined Page classes and Test classes\nRun on different browsers: Chrome, Firefox, IE, Safari, Edge\nRun with different browser options\nRun with full range of resolution (mobile, desktop): Testing responsible Design Webpage\nHow to start?\nRead: My first Selenium Test\nSelenium Best Practices\nTable of best practices\nSelenium UFT Comparison\nSelenium UFT Comparison\n"},{"id":986,"path":"../website/pages/docs/master-mrchecker.asciidoc_test-framework-modules.html#master-mrchecker.asciidoc_selenium-structure","type":"docs","title":"Selenium Structure","body":"78.3. Selenium Structure\n"},{"id":987,"path":"../website/pages/docs/master-mrchecker.asciidoc_test-framework-modules.html#Selenium-Test-Module-What-is-Selenium.asciidoc","type":"docs","title":"What is Selenium","body":"78.3.1. What is Selenium\nSelenium is a framework for testing browser applications. The test automation supports:\nFrequent regression testing\nRepeating test case executions\nDocumentation of test cases\nFinding defects\nMultiple Browsers\nThe Selenium testing framework consists of multiple tools:\nSelenium IDE\nThe Selenium Integrated Development Environment is a prototyping tool for building test scripts. It is a Firefox Plugin and provides an easy-to-use interface for developing test cases. Additionally, Selenium IDE contains a recording feature, that allows the user to record user inputs that can be automatically re-executed in future.\nSelenium 1\nSelenium 1, also known as Selenium RC, commands a Selenium Server to launch and kill browsers, interpreting the Selenese commands passed from the test program. The Server acts as an HTTP proxy. This tool is deprecated.\nSelenium 2\nSelenium 2, also known as Selenium WebDriver, is designed to supply a well-designed, object-oriented API that provides improved support for modern advanced web-app testing problems.\nSelenium 3.0\nThe major change in Selenium 3.0 is removing the original Selenium Core implementation and replacing it with one backed by WebDriver. There is now a W3C specification for browser automation, based on the Open Source WebDriver.\nSelenium Grid\nSelenium Grid allows the scaling of Selenium RC test cases, that must be run in multiple and potentially variable environments. The tests can be run in parallel on different remote machines.\nSelenium on the Production Line\nMore information on Selenium on the Production Line can be found here.\ntl;dr\nThe Production Line has containers running Chrome and Firefox Selenium Nodes. The communication with these nodes is accomplished using Selenium Grid.\nHaving issues using Selenium on the Production Line? Check the Production Line issue list, maybe it&#x2019;s a known issue that can be worked around.\n"},{"id":988,"path":"../website/pages/docs/master-mrchecker.asciidoc_test-framework-modules.html#Selenium-Test-Module-What-is-WebDriver.asciidoc","type":"docs","title":"What is WebDriver","body":"78.3.2. What is WebDriver\nOn the one hand, it is a very convenient API for a programmer that allows for interaction with the browser, on the other hand it is a driver concept that enables this direct communication.\nHow does it work?\nA tester, through their test script, can command WebDriver to perform certain actions on the WAUT on a certain browser. The way the user can command WebDriver to perform something is by using the client libraries or language bindings provided by WebDriver.\nBy using the language-binding client libraries, a tester can invoke browser-specific implementations of WebDriver, such as Firefox Driver, IE Driver, Opera Driver, and so on, to interact with the WAUT of the respective browser. These browser-specific implementations of WebDriver will work with the browser natively and execute commands from outside the browser to simulate exactly what the application user does.\nAfter execution, WebDriver will send the test result back to the test script for developer&#x2019;s analysis.\n"},{"id":989,"path":"../website/pages/docs/master-mrchecker.asciidoc_test-framework-modules.html#Selenium-Test-Module-What-is-Page-Object-Model-Pattern.asciidoc","type":"docs","title":"What is Page Object Model?","body":"78.3.3. What is Page Object Model?\nCreating Selenium test cases can result in an unmaintainable project. One of the reasons is that too much duplicated code is used. Duplicated code could result from duplicated functionality leading to duplicated usage of locators. The main disadvantage of duplicated code is that the project is less maintainable. If a locator changes, you have to walk through the whole test code to adjust locators where necessary. By using the page object model we can make non-brittle test code and reduce or eliminate duplicate test code. In addition, it improves the readability and allows us to create interactive documentation. Last but not least, we can create tests with less keystroke. An implementation of the page object model can be achieved by separating the abstraction of the test object and the test scripts.\n"},{"id":990,"path":"../website/pages/docs/master-mrchecker.asciidoc_test-framework-modules.html#Selenium-Test-Module-List-of-web-elements.asciidoc","type":"docs","title":"Basic Web elements","body":"78.3.4. Basic Web elements\nThis page will provide an overview of basic web elements.\nName\nMethod to use element\nForm: Input Text\nelementInputText()\nForm: Label\nelementLabel()\nForm: Submit Button\nelementButton()\nPage: Button\nelementButton()\nCheckbox\nelementCheckbox()\nRadio\nelementRadioButton()\nElements (Tabs, Cards, Account, etc.)\nelementTab()\nDropdown List\nelementDropdownList()\nLink\n-\nCombobox\nelementList()\nComparision how picking value from checkbox can be done:\nby classic Selenium atomic actions\nby our enhanced Selenium wrapper\nClassic Selenium atomic actions\nList&lt;WebElement&gt; checkboxesList = getDriver()\n.findElements(selectorHobby);\nWebElement currentElement;\nfor (int i = 0; i &lt; checkboxesList.size(); i++) {\ncurrentElement = checkboxesList.get(i);\nif (currentElement.getAttribute(&quot;value&quot;)\n.equals(hobby.toString()) &amp;&amp; currentElement.isSelected() != true)\n{\ncurrentElement.click();\n}\n}\nEnhanced Selenium in E2E test framework\ngetDriver().elementCheckbox(selectorHobby)\n.setCheckBoxByValue(hobby.toString());\n"},{"id":991,"path":"../website/pages/docs/master-mrchecker.asciidoc_test-framework-modules.html#master-mrchecker.asciidoc_framework-features","type":"docs","title":"Framework Features","body":"78.4. Framework Features\n"},{"id":992,"path":"../website/pages/docs/master-mrchecker.asciidoc_test-framework-modules.html#Selenium-Test-Module-Construction-of-Framework-Page-Class.asciidoc","type":"docs","title":"Page Class","body":"78.4.1. Page Class\nPage Object Models allow for the representation of a webpage as a Java Class. The class contains all required web elements like buttons, textfields, labels, etc. When initializing a new project, create a new package to store the Page Object Models in.\nInitialization\nSource folder: allure-app-under-test/src/main/java\nName: com.example.selenium.pages.YOUR_PROJECT\nClasses being created inside of this new package have to extend the BasePage class. As a result, a few abstract methods from BasePage have to be implemented.\npublic class DemoPage extends BasePage {\n@Override\npublic boolean isLoaded() {\n}\n@Override\npublic void load() {\n}\n@Override\npublic String pageTitle() {\n}\n}\nThe example above demonstrates a minimum valid Page Object class with all required methods included.\nBasePage method: isLoaded\nThe inherited method isLoaded() can be used to check if the current Page Object Model has been loaded correctly. There are multiple ways to verify a correctly loaded page. One example would be to compare the actual page title with the expected page title.\npublic boolean isLoaded() {\nif(getDriver().getTitle().equals(&quot;EXPECTED_TITLE&quot;)) {\nreturn true;\n}\nreturn false;\n}\nBasePage method: load\nThe method load() can be used to tell the webdriver to load a specific page.\npublic void load() {\ngetDriver().get(&quot;http://SOME_PAGE&quot;);\n}\nBasePage method: pageTitle\nThe pageTitle() method returns a String containing the page title.\nCreating a selector variable\nTo initialize web elements, a large variety of selectors can be used.\nWe recommend creating a private and constant field for every web element you&#x2019;d like to represent in Java. Use the guide above to find the preferred selector and place it in the code below at &quot;WEB_ELEMENT_SELECTOR&quot;.\nprivate static final By someWebElementSelector = By.CSS(&quot;WEB_ELEMENT_SELECTOR&quot;);\nAs soon as you create the selector above, you can make use of it to initialize a WebElement object.\nWebElement someWebElement = getDriver().findDynamicElement(someWebElementSelector);\nNote: The examples displayed in the cssSelector.docx file use the Selenium method driver.findElement() to find elements. However, using this framework we recommend findDynamicElement() or findQuietlyElement().findDynamicElement() allows waiting for dynamic elements, for example buttons that pop up.\nCreating a page method\nTo interact with the page object, we recommend creating methods for each action.\npublic void enterGoogleSearchInput(String query) {\n...\n}\nCreating a method like the one above allows the test case to run something like googleSearchPage.enterGoogleSearchInput(&quot;Hello&quot;) to interact with the page object.\nNaming Conventions\nFor code uniformity and readability, we provide a few method naming conventions.\nElement\nAction\nName (example)\nForm: Input text\nenter\nenterUsernameInput()\nis (label)\nisUsernameInputPresent()\nis (value)\nisUsernameEmpty()\nget\ngetUsernameValue()\nForm: Label\nget\ngetCashValue()\nis (value)\nisCashValueEmpty()\nis (label)\nisCashLabelPresent()\nForm: Submit Button\nsubmit\nsubmitLoginForm()\nis\nisLoginFormPresent()\nPage: Button\nclick\nclickInfoButton()\nis\nisInfoButtonpresent()\nCheckbox\nset\nsetRememberMeCheckbox()\nunset\nunsetRememberMeCheckbox()\nis (present)\nisRememberMeCheckboxPresent()\nis (value)\nisRememberMeCheckboxSet()\nRadio\nset\nsetMaleRadioValue(&quot;Woman&quot;)\nis (present)\nisMaleRadioPresent()\nis (visible)\nisMaleRadioVisible()\nget\ngetSelectedMaleValue()\nElements (Tabs, Cards, Account, etc.)\nclick\nclickPositionTab() / clickMyBilanceCard()\nis\nisMyBilanceCardPresent()\nDropdown List\nselect\nselectAccountTypeValue(typeName)\nunselect\nunselectAccountTypeValue(typeName)\nmultiple select\nselectAccountTypesValues(List typeNames)\nis (list)\nisAccountTypeDropdownListPresent()\nis (element present)\nisAccountTypeElementPresent(typeName)\nis (element selected)\nisAccountTypeSelected(typeName)\nLink\nclick\nclickMoreLink()\nis\nisMoreLinkPresent()\nCombobox\nselect\nselectSortCombobox()\nis (present)\nisSortComboboxPresent(name)\nis (contain)\nselectSortComboboxContain(name)\nElement Attribute\nget\ngetPositionTabCss()\nget\ngetMoreLinkHref() / getRememberMeCheckboxName()\nA css selector is used to select elements from an HTML page.\nSelection by element tag, class or id are the most common selectors.\n&lt;p class=&apos;myText&apos; id=&apos;123&apos;&gt;\nThis text element (p) can be found by using any one of the following selectors:\nThe HTML element: &quot;p&quot;. Note: in practical use this will be too generic, if a preceding text section is added, the selected element will change.\nThe class attribute preceded by &quot;.&quot;: &quot;.myText&quot;\nThe id attribute preceded by &quot;#&quot;: &quot;#123&quot;\nUsing other attributes\nWhen a class or an id attribute is not sufficient to identify an element, other attributes can be used as well, by using &quot;[attribute=value]&quot;: For example:\n&lt;a href=&apos;https://ns.nl/example.html&apos;&gt;\nThis can be selected by using the entire value: &quot;a[href=&apos;https://ns.nl/example.html&apos;\\]&quot;. For selecting links starting with, containing, ending with see the list below.\nUsing sub-elements\nThe css selectors can be stacked, by appending them:\n&lt;div id=&apos;1&apos;&gt;&lt;a href=&apos;ns.nl&apos;&gt;&lt;/div&gt;\n&lt;div id=&apos;2&apos;&gt;&lt;a href=&apos;nsinternational.nl&apos;&gt;&lt;/div&gt;\nIn the example above, the link element to nsinternational can be obtained with: &quot;#2 a&quot;.\nWhen possible avoid\nUsing paths of commonly used HTML elements within the containers (HTML: div). This will cause failures when a container is added, a common occurrence during development, e.g. &quot;div div p&quot;. Use class or id instead, if those are not available, request them to be added in the production code.\nMagic order numbers. It is possible to get the second text element in its parent container by using the selector &quot;p:nth-child(2)&quot;. If the items are representing different items, ask the developer to add specific attributes. It is also possible to request all items, with a selector similar to &quot;.myList li&quot;, and iterate through them later.\nList\nA good list with CSS Selectors can be found at W3Schools:\nhttps://www.w3schools.com/cssref/css_selectors.asp\n"},{"id":993,"path":"../website/pages/docs/master-mrchecker.asciidoc_test-framework-modules.html#Selenium-Test-Module-Selenium-UFT-Comparison.asciidoc","type":"docs","title":"Selenium UFT Comparison","body":"78.4.2. Selenium UFT Comparison\nSubject\nHP UFT\nHP LeanFT\nSelenium\nSelenium IDE\nLanguage\nVBScript\nSame as Selenium\nSupports several languages.\nJava\nJavascript\nLearning curve\nBased on VBScript which is relatively easy to learn\nLess intuitive, more coding knowledge necessary\nLess intuitive, more coding skills necessary\nRecord/playback possible. Generated code difficult to maintain\nProject type\nTraditional\nAgile\nAgile\nAgile\nUser oriented\nMore Tester\nMore Developer\nMore Developer\nMore Tester\nObject recognition\nTest object identification and storage in object repository\nSame as UFT\nWith Firebug\nSame as SE\nCustomizations\nOnly the available standard. No custimization\nSame as UFT\nLots of customizations possible\nFewer then SE\nFramework\nNeeded.\nExists in ATaaS\nNeeded.\nIntegration with Fitnesse, Cucumber, Gauche\nNo Framework. Limited capabilities of the tool.\nOperating System support\nRuns on Windows\nRuns on Windows\nMultiple OS support. With Grid: testing on multiple devices at same time\nPlugin for Firefox\nApplication coverage\nMany\nMany\nWeb only\nWeb only\nMultiple browsers\nIn UFT 12.5 available\nIn 12.5 available\nMultiple tests in multiple browser windows at once and faster support for new browser versions\nMultiple tests in multiple browser windows at once and faster support for new browser versions\nSystem Load\nHigh system load (RAM &amp; CPU usage)\nLower load than HP UFT?\nLower load than HP UFT\nLower load than HP UFT\nALM integration\nWith HP ALM &#x2013; full integration\nJira, Jenkins\nNot with ALM tool\nSame as SE\nIntegration with other tools\nA lot can be built, but many are already covered.\nMore than UFT.\nFreeware and can be integrated with different open source tools\nFreeware and can be integrated with different open source tools\nAddins\nAdd-ins necessary to access all capabilities of the tool &#x2013; license related\nSame as UFT\nSee integration with other tools\nSee integration with other tools\nReporting\nComplete, link to ALM\nSame as UFT\nNo native mechanism for generating reports, but multiple plugins available for reporting\nNo native mechanism for generating reports, but multiple plugins available for reporting\nSupport\nHP full support\nSame as UFT\nLimited support as it is open source\nLimited support as it is open source\nLicense costs\nAbout 17K &#x2013; Capgemini price 5K.\nIncluded in the S2 service charge\nSame price as HP UFT\nFree\nFree\nlimited functionality (no iterations / conditional statements)\niVAL Service\nATaaS\nNot in a S2 service\nNot in a S2 service\nNot in a S2 service\nBold for key differentiators.\nProjects also choose an available resource and the knowledge of that resource.\nBoth: Framework determines the quality of automation. Needs to be set up by someone with experience with the tool\n"},{"id":994,"path":"../website/pages/docs/master-mrchecker.asciidoc_test-framework-modules.html#Selenium-Test-Module-Run-on-different-browsers.asciidoc","type":"docs","title":"Run on different browsers","body":"78.4.3. Run on different browsers\nTo execute each test with a chosen installed browser, specific arguments are required in Run configuration.\nIt is necessary to enter -Dbrowser= with browser parameter name as an argument (in &apos;Arguments&apos; tab):\nfirefox\nie\nphantomjs\nchrome\nchromeheadless\nFor example: -Dbrowser=ie\n_-ea_ should be entered as an argument to restore default settings.\n"},{"id":995,"path":"../website/pages/docs/master-mrchecker.asciidoc_test-framework-modules.html#Selenium-Test-Module-Run-with-different-browser-options.asciidoc","type":"docs","title":"Browser options","body":"78.4.4. Browser options\nTo run a browser with specific options during runtime, please use\n-DbrowserOptions=&quot;&lt; options &gt;&quot;\n&gt; mvn test -DbrowserOptions=&quot;param1&quot;\n&gt; mvn test -DbrowserOptions=&quot;param1=value1&quot;\nexamples:\nOne parameter -DbrowserOptions=&quot;headless&quot;\nOne parameter -DbrowserOptions=&quot;--incognito&quot;\nMany parameters -DbrowserOptions=&quot;headless;param1=value1;testEquals=FirstEquals=SecondEquals;--testMe&quot;\nList of options/capabilites supported by:\nSelenium Grid\nChrome Driver\n"},{"id":996,"path":"../website/pages/docs/master-mrchecker.asciidoc_test-framework-modules.html#Selenium-Test-Module-Run-with-full-range-of-resolution.asciidoc","type":"docs","title":"Run with full range of resolution","body":"78.4.5. Run with full range of resolution\nIn order to execute tests in different browser resolutions, it is required to provide these resolutions as a test parameter.\nTest example with resolutions included may be found in ResolutionTest test class\nExample of resolution notation is available in ResolutionEnum class\nTest with given resolution parameters will be launched as many times as the number of resolutions provided.\n"},{"id":997,"path":"../website/pages/docs/master-mrchecker.asciidoc_test-framework-modules.html#Selenium-Test-Module-Selenium-Best-Practices.asciidoc","type":"docs","title":"Selenium Best Practices","body":"78.4.6. Selenium Best Practices\nThe following table displays a few best practices that should be taken into consideration when developing Selenium test cases.\nBest Practices\nDescription\n&quot;Keep it Simple&quot;\nDo not force use every Selenium feature available - Plan before creating the actual test cases\nUsing Cucumber\nCucumber can be used to create initial testcases for further decision making\nSupporting multiple browsers\nTest on multiple browsers (in parallel, if applicable) if the application is expected to support multiple environments\nTest reporting\nMake use of test reporting modules like Junit which is included in the framework\nMaintainability\nAlways be aware of the maintainability of tests - You should always be able to adapt to changes\nTesting types\nWhich tests should be created? Rule of thumb: 70% Unit test cases, 20% Integration test cases and 10% UI Test cases\nTest data\nConsider before actually developing tests and choosing tools: Where to get test data from, how to reset test data\n"},{"id":998,"path":"../website/pages/docs/master-mrchecker.asciidoc_test-framework-modules.html#master-mrchecker.asciidoc_web-api-module","type":"docs","title":"Web API Module","body":"78.5. Web API Module\nService Virtualization\nWhat is service virtualization\nHow to plug in service virtualization into Application Under Test\nHow to make a virtual asset\nSmoke Tests virtualization\n"},{"id":999,"path":"../website/pages/docs/master-mrchecker.asciidoc_test-framework-modules.html#Web-API-Test-Module-What-is-service-virtualization.asciidoc","type":"docs","title":"Is it doable to keep pace in QA with today&#x2019;s software agile approach?","body":"78.5.2. Is it doable to keep pace in QA with today&#x2019;s software agile approach?\nDevOps + Microservices + Shift left + Time to Market == ? Service virtualization ?\nTest pyramid\nWhat is service virtualization\nService Virtualization has become recognized as one of the best ways to speed up testing and accelerate your time to market.\nService virtualization lets you automatically execute tests even when the application under test&#x2019;s dependent system components (APIs, third-party applications, etc.) cannot be properly accessed or configured for testing. By simulating these dependencies, you can ensure that your tests will encounter the appropriate dependency behaviour and data each and every time that they execute.\nService virtualization is the simulation of interfaces &#x2013; not the virtualization of systems.\nAccording to Wikipedia&#x2019;s service virtualization entry: Service virtualization emulates the behaviour of software components to remove dependency constraints on development and testing teams. Such constraints occur in complex, interdependent environments when a component connected to the application under test is:\nNot yet completed\nStill evolving\nControlled by a third-party or partner\nAvailable for testing only in a limited capacity or at inconvenient times\nDifficult to provision or configure in a test environment\nNeeded for simultaneous access by different teams with varied test data setup and other requirements\nRestricted or costly to use for load and performance testing\nFor instance, instead of virtualizing an entire database (and performing all associated test data management as well as setting up the database for every test session), you monitor how the application interacts with the database, then you emulate the related database behaviour (the SQL queries that are passed to the database, the corresponding result sets that are returned, and so forth).\nMocks, stubs and virtual services\nThe most commonly discussed categories of test doubles are mocks, stubs and virtual services.\nStub: a minimal implementation of an interface that normally returns hardcoded data that is tightly coupled to the test suite. It is most useful when the suite of tests is simple and keeping the hardcoded data in the stub is not an issue. Some stubs are handwritten; some can be generated by tools. A stub is normally written by a developer for personal use. It can be shared with testers, but wider sharing is typically limited by interoperability issues related to software platform and deployment infrastructure dependencies that were hardcoded. A common practice is when a stub works in-process directly with classes, methods, and functions for the unit, module, and acceptance testing. Some developers will say that a stub can also be primed, but you cannot verify an invocation on a stub. Stubs can also be communicating &quot;over the wire&quot;, for example, HTTP, but some would argue that they should be called virtual services in that case.\nMock: a programmable interface observer, that verifies outputs against expectations defined by the test. It is frequently created using a third party library, for example in Java that is Mockito, JMock or WireMock. It is most useful when you have a large suite of tests and a stub will not be sufficient because each test needs a different data set up and maintaining them in a stub would be costly. The mock lets us keep the data set-up in the test. A mock is normally written by a developer for personal use but it can be shared with testers. However, wider sharing is typically limited by interoperability issues related to software platform and deployment infrastructure dependencies that were hardcoded. They are most often work-in-progress directly with classes, methods, and functions for a unit, module, and acceptance testing. Mock provides responses based on a given request satisfying predefined criteria (also called request or parameter matching). A mock also focuses on interactions rather than state so mocks are usually stateful. For example, you can verify how many times a given method was called or the order of calls made to a given object.\nVirtual service: a test double often provided as a Software-as-a-Service (SaaS), is always called remotely, and is never working in-process directly with methods or functions. A virtual service is often created by recording traffic using one of the service virtualization platforms instead of building the interaction pattern from scratch based on interface or API documentation. A virtual service can be used to establish a common ground for teams to communicate and facilitate artefact sharing with other development teams as well as testing teams. A virtual service is called remotely (over HTTP, TCP, etc.) normally supports multiple protocols (e.g. HTTP, MQ, TCP, etc.), while a stub or mock normally supports only one. Sometimes virtual services will require users to authorize, especially when deployed in environments with enterprise-wide visibility. Service virtualization tools used to create virtual services will most often have user interfaces that allow less tech-savvy software testers to hit the ground running, before diving into the details of how specific protocols work. They are sometimes backed by a database. They can also simulate non-functional characteristics of systems such as response times or slow connections. You can sometimes find virtual services that provide a set of stubbed responses for given request criteria and pass every other request to a live backend system (partial stubbing). Similar to mocks, virtual services can have quite complex request matchers, that allow having one response returned for many different types of requests. Sometimes, virtual services simulate system behaviours by constructing parts of the response based on request attributes and data.\nIt is often difficult to say definitely which of the following categories a test double fits into. They should be treated as a spectrum rather than strict definitions.\n"},{"id":1000,"path":"../website/pages/docs/master-mrchecker.asciidoc_test-framework-modules.html#Web-API-Test-Module-How-plug-in-service-virtualization-into-Application-Under-Test.asciidoc","type":"docs","title":"Plug in service virtualization","body":"78.5.3. Plug in service virtualization\nClassic application structure\nThis is a quite common application structure, where we have any of the following in Application Under Test (AUT):\nUI / GUI\nWebAPI\n3rd party service\nClassic application structure with virtualization\nThis classic application is quite fragile for development and/or test process. Especially so, if the component (WebAPI) connected to the Application Under Test is:\nNot yet completed\nStill evolving\nControlled by a third-party or partner\nAvailable for testing only in limited capacity or at inconvenient times\nDifficult to provision or configure in a test environment\nNeeded for simultaneous access by different teams with varied test data setup and other requirements\nRestricted or costly to use for load and performance testing\nYou can find the full list of such &quot;classic application structure&quot; limitations here What-is-service-virtualization.\n*Service virtualization is the key solution to address such a list of impediments. *\nFor simplicity, AUT connects to other components by TCP/IP protocol. Therefore AUT has an IP address and port number where given components operate. To plug in virtualization server, the author of AUT ought to switch IP and port to &quot;proxy server&quot; instead of real endpoint component (WebAPI) . Finally, &quot;proxy server&quot; maps requests come from AUT with either virtual assets or real endpoint component (WebAPI). How do maps work in such a &quot;proxy server&quot;? Have a look here How-to-make-virtual-asset\nTherefore AUT is build either with:\nswitchable property file acquired on startup\nor\n&quot;on the fly&quot; operation to change IP and ports of connected components.\nClassic APP structure with full scope - Binding in service virtualization\n"},{"id":1001,"path":"../website/pages/docs/master-mrchecker.asciidoc_test-framework-modules.html#Web-API-Test-Module-How-to-make-virtual-asset.asciidoc","type":"docs","title":"How to make a virtual asset","body":"78.5.4. How to make a virtual asset\nThis can be done in four ways:\nRecord all traffic (Mappings and Responses) that comes through proxy - by UI\nRecord all traffic (Mappings and Responses) that comes through proxy - by Code\nCreate Mappings and Responses manually by text files\nCreate Mappings and Responses manually by code\nRecord all traffic (Mappings and Responses) that comes through proxy - UI\nFull article here Wiremock record-playback.\nFirst, start an instance of WireMock running standalone. Once that&#x2019;s running, visit the recorder UI page at http://localhost:8080/__admin/recorder (assuming you started WireMock on the default port of 8080).\nEnter the URL you wish to record from in the target URL field and click the Record button. You can use http://example.mocklab.io to try it out.\nNow you need to make a request through WireMock to the target API so that it can be recorded. If you&#x2019;re using the example URL, you can generate a request using curl:\n$ curl http://localhost:8080/recordables/123\nNow click stop. You should see a message indicating that one stub was captured.\nYou should also see that a file has been created called something like recordables_123-40a93c4a-d378-4e07-8321-6158d5dbcb29.json under the mappings directory created when WireMock started up, and that a new mapping has appeared at http://localhost:8080/__admin/mappings.\nRequesting the same URL again (possibly disabling your wifi first if you want a firm proof) will now serve the recorded result:\n$ curl http://localhost:8080/recordables/123\n{\n&quot;message&quot;: &quot;Congratulations on your first recording!&quot;\n}\nRecord all traffic (Mappings and Responses) that comes through proxy - by Code\nAn example of how such a record can be achieved\n@Test\npublic void startRecording() {\nSnapshotRecordResult recordedMappings;\nDriverManager.getDriverVirtualService()\n.start();\nDriverManager.getDriverVirtualService()\n.startRecording(&quot;http://example.mocklab.io&quot;);\nrecordedMappings = DriverManager.getDriverVirtualService()\n.stopRecording();\nBFLogger.logDebug(&quot;Recorded messages: &quot; + recordedMappings.toString());\n}\nCreate Mappings and Responses manually by text files\nEMPTY\nCreate Mappings and Responses manually by code\nLink to full file structure: REST_FarenheitToCelsiusMethod_Test.java\nStart up Virtual Server\npublic void startVirtualServer() {\n// Start Virtual Server\nWireMockServer driverVirtualService = DriverManager.getDriverVirtualService();\n// Get Virtual Server running http and https ports\nint httpPort = driverVirtualService.port();\nint httpsPort = driverVirtualService.httpsPort();\n// Print is Virtual server running\nBFLogger.logDebug(&quot;Is Virtual server running: &quot; + driverVirtualService.isRunning());\nString baseURI = &quot;http://localhost&quot;;\nendpointBaseUri = baseURI + &quot;:&quot; + httpPort;\n}\nPlug in a virtual asset\nREST_FarenheitToCelsiusMethod_Test.java\npublic void activateVirtualAsset() {\n/*\n* ----------\n* Mock response. Map request with virtual asset from file\n* -----------\n*/\nBFLogger.logInfo(&quot;#1 Create Stub content message&quot;);\nBFLogger.logInfo(&quot;#2 Add resource to virtual server&quot;);\nString restResourceUrl = &quot;/some/thing&quot;;\nString restResponseBody = &quot;{ \\&quot;FahrenheitToCelsiusResponse\\&quot;:{\\&quot;FahrenheitToCelsiusResult\\&quot;:37.7777777777778}}&quot;;\nnew StubREST_Builder //For active virtual server ...\n.StubBuilder(restResourceUrl) //Activate mapping, for this Url AND\n.setResponse(restResponseBody) //Send this response AND\n.setStatusCode(200) // With status code 200 FINALLY\n.build(); //Set and save mapping.\n}\nLink to full file structure: StubREST_Builder.java\nSource link to How to create Stub.\nStubREST_Builder.java\npublic class StubREST_Builder {\n// required parameters\nprivate String endpointURI;\n// optional parameters\nprivate int statusCode;\npublic String getEndpointURI() {\nreturn endpointURI;\n}\npublic int getStatusCode() {\nreturn statusCode;\n}\nprivate StubREST_Builder(StubBuilder builder) {\nthis.endpointURI = builder.endpointURI;\nthis.statusCode = builder.statusCode;\n}\n// Builder Class\npublic static class StubBuilder {\n// required parameters\nprivate String endpointURI;\n// optional parameters\nprivate int statusCode = 200;\nprivate String response = &quot;{ \\&quot;message\\&quot;: \\&quot;Hello\\&quot; }&quot;;\npublic StubBuilder(String endpointURI) {\nthis.endpointURI = endpointURI;\n}\npublic StubBuilder setStatusCode(int statusCode) {\nthis.statusCode = statusCode;\nreturn this;\n}\npublic StubBuilder setResponse(String response) {\nthis.response = response;\nreturn this;\n}\npublic StubREST_Builder build() {\n// GET\nDriverManager.getDriverVirtualService()\n.givenThat(\n// Given that request with ...\nget(urlMatching(this.endpointURI))\n.withHeader(&quot;Content-Type&quot;, equalTo(ContentType.JSON.toString()))\n// Return given response ...\n.willReturn(aResponse()\n.withStatus(this.statusCode)\n.withHeader(&quot;Content-Type&quot;, ContentType.JSON.toString())\n.withBody(this.response)\n.withTransformers(&quot;body-transformer&quot;)));\n// POST\nDriverManager.getDriverVirtualService()\n.givenThat(\n// Given that request with ...\npost(urlMatching(this.endpointURI))\n.withHeader(&quot;Content-Type&quot;, equalTo(ContentType.JSON.toString()))\n// Return given response ...\n.willReturn(aResponse()\n.withStatus(this.statusCode)\n.withHeader(&quot;Content-Type&quot;, ContentType.JSON.toString())\n.withBody(this.response)\n.withTransformers(&quot;body-transformer&quot;)));\n// PUT\nDriverManager.getDriverVirtualService()\n.givenThat(\n// Given that request with ...\nput(urlMatching(this.endpointURI))\n.withHeader(&quot;Content-Type&quot;, equalTo(ContentType.JSON.toString()))\n// Return given response ...\n.willReturn(aResponse()\n.withStatus(this.statusCode)\n.withHeader(&quot;Content-Type&quot;, ContentType.JSON.toString())\n.withBody(this.response)\n.withTransformers(&quot;body-transformer&quot;)));\n// DELETE\nDriverManager.getDriverVirtualService()\n.givenThat(\n// Given that request with ...\ndelete(urlMatching(this.endpointURI))\n.withHeader(&quot;Content-Type&quot;, equalTo(ContentType.JSON.toString()))\n// Return given response ...\n.willReturn(aResponse()\n.withStatus(this.statusCode)\n.withHeader(&quot;Content-Type&quot;, ContentType.JSON.toString())\n.withBody(this.response)\n.withTransformers(&quot;body-transformer&quot;)));\n// CATCH any other requests\nDriverManager.getDriverVirtualService()\n.givenThat(\nany(anyUrl())\n.atPriority(10)\n.willReturn(aResponse()\n.withStatus(404)\n.withHeader(&quot;Content-Type&quot;, ContentType.JSON.toString())\n.withBody(&quot;{\\&quot;status\\&quot;:\\&quot;Error\\&quot;,\\&quot;message\\&quot;:\\&quot;Endpoint not found\\&quot;}&quot;)\n.withTransformers(&quot;body-transformer&quot;)));\nreturn new StubREST_Builder(this);\n}\n}\n}\n"},{"id":1002,"path":"../website/pages/docs/master-mrchecker.asciidoc_test-framework-modules.html#Web-API-Test-Module-Smoke-Tests-virtualization.asciidoc","type":"docs","title":"Start a virtual server","body":"78.5.5. Start a virtual server\nThe following picture presents the process of executing Smoke Tests in a virtualized environment:\nInstall docker service\nIf docker is not already installed on machine (this should be checked during C2C creation), install docker, docker-compose, apache2-utils, openssl (You can use script to install docker &amp; docker-compose OR refer to this post and add Alias for this machine &lt;C2C_Alias_Name&gt;):\nrun the script\nsudo apt-get install -y apache2-utils\nBuild a docker image\nDockerfile:\nFROM docker.xxx.com/ubuntu:16.04\nMAINTAINER Maintainer Name &quot;maintainer@email.address&quot;\nLABEL name=ubuntu_java \\\nversion=v1-8.0 \\\nbase=&quot;ubuntu:16.04&quot; \\\nbuild_date=&quot;03-22-2018&quot; \\\njava=&quot;1.8.0_162&quot; \\\nwiremock=&quot;2.14.0&quot; \\\ndescription=&quot;Docker to use with Ubuntu, JAVA and WIREMOCK &quot;\n# Update and install the applications needed\nCOPY 80proxy /etc/apt/apt.conf.d/80proxy\nRUN apt-get update\nRUN apt-get install -y \\\nwget \\\nlibfontconfig \\\nunzip \\\nzip\nksh \\\ncurl \\\ngit\nCOPY wgetrc /etc/wgetrc\n#Env parameters\n### JAVA PART ###\n#TO UPDATE:please verify url link to JDK http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html\n##Download and install JAVA JDK8\nRUN mkdir /opt/jdk\nRUN wget -qq --header &quot;Cookie: oraclelicense=accept-securebackup-cookie&quot; http://download.oracle.com/otn-pub/java/jdk/8u162-b12/0da788060d494f509bf8624735fa2f1/jdk-8u162-linux-x64.tar.gz &amp;&amp; tar -zxf jdk-8u162-linux-x64.tar.gz -C /opt/jdk &amp;&amp; rm jdk-8u162-linux-x64.tar.gz &amp;&amp; update-alternatives --install /usr/bin/javac javac /opt/jdk/jdk1.8.0_162/bin/javac 100 &amp;&amp; java -version &amp;&amp; chmod 755 -R /opt/jdk/jdk1.8.0_162/\nRUN java -version\n##Add user\nRUN useradd -u 29001 -g 100 srvpwiredev\n##Add app\nRUN mkdir -p -m 777 /app\nCOPY wiremock-standalone-2.14.0.jar /app/wiremock-standalone-2.14.0.jar\n##Expose port\nEXPOSE 8080\n##Set workdir\nWORKDIR /App\n##Run app\nCDM java -jar /app/wiremock-standalone-2.14.0.jar\nExecute the following steps with a specified version to build a docker image and push it to the repository :\n## Build image\nsudo docker build -t docker.xxx.com/app/build/wiremock:v2.14.0.\n## Push image\nsudo docker login docker.xxx.com\nsudo docker push docker.xxx.com/app/build/wiremock:v2.14.0.\nRun docker image\nTo run a docker image, execute the following command:\nsudo docker run -td -p 8080:8080 -v /home/wiremock/repo/app/docker/QA/mappings:/app/mappings -v /home/wiremock/repo/app/docker/QA/__files:/app/__files --restart always docker.xxx.com/app/build/wiremock:v2.14.0.\nWhere:\n-p - publish a container&#x2019;s port to the host\n-v - bind mount a volume. WireMock server creates two directories under the current one: mappings and __files. It is necessary to mount directories with already created mappings and responses to make it work.\n-restart always - restart policy to apply when a container exists\nAll of the parameters are described in: official docker documentation\n"},{"id":1003,"path":"../website/pages/docs/master-mrchecker.asciidoc_test-framework-modules.html#Web-API-Test-Module-Smoke-Tests-virtualization.asciidoc","type":"docs","title":"Map requests with virtual assets","body":"78.5.6. Map requests with virtual assets\nWhat is WireMock?\nWireMock is an HTTP mock server. At its core it is a web server that can be primed to serve canned responses to particular requests (stubing) and that captures incoming requests so that they can be checked later (verification). It also has an assortment of other useful features including record/playback of interactions with other APIs, injection of faults and delays, simulation of stateful behaviour.\nFull documentation can be found under the following link: WireMock\nRecord / create virtual assets mappings\nRecord\nWireMock can create stub mappings from requests it has received. Combined with its proxying feature, this allows you to &quot;record&quot; stub mappings from interaction with existing APIs.\nRecord and playback (Legacy): documentation\njava -jar wiremock-standalone-2.16.0.jar --proxy-all=&quot;http://search.twitter.com&quot; --record-mappings --verbose\nOnce it&#x2019;s started and request is sent to it, it will be redirected to &quot;http://search.twitter.com&quot; and traffic (response) is saved to files in mappings and __files directories for further use.\nRecord and playback (New): documentation\nEnable mappings in a virtual server\nWhen the WireMock server starts, it creates two directories under the current one: mappings and __files. To create a stub, it is necessary to drop a file with a .json extension under mappings.\nRun docker with mounted volumes\nMappings are in a repository. It is necessary to mount directories with already created mappings and responses to make it work:\nsudo docker run -td -p 8080:8080 -v /home/wiremock/repo/app/docker/QA/mappings:/app/mappings -v /home/wiremock/repo/app/docker/QA/__files:/app/__files --restart always docker.xxx.com/app/build/wiremock:v2.14.0.\nThe description of how to build and run docker is available under: Docker run command description\nRecorded mappings\nRecorded mappings are kept in the project repository.\nCreate a user and map them to docker user\nTo enable the connection from Jenkins to Virtual Server (C2C), it is necessary to create a user and map them to docker group user. It can be done using the following command:\nadduser -G docker -m wiremock\nTo set the password for a wiremock user:\npasswd wiremock\nCreate SSH private and public keys for a wiremock user\nSSH keys serve as a means of identifying yourself to an SSH server using public-key cryptography and challenge-response authentication. One immediate advantage this method has over traditional password is that you can be authenticated by the server without ever having to send your password over the network.\nTo create an SSH key, log in as wiremock (previously created user).\nsu wiremock\nThe .ssh directory is not by default created below user home directory. Therefore, it is necessary to create it:\nmkdir ~/.ssh\nNow we can proceed with creating an RSA key using ssh-keygen (a tool for creating new authentication key pairs for SSH):\nssh-keygen -t rsa\nA key should be created under /.ssh/id_rsa\nAppending the public keys to authorized_keys:\nwiremock@vc2crptXXXXXXXn:~/ssh$ cat id_rsa.pub &gt;&gt; authorized_keys\nInstall an SSH key in Jenkins\nTo add an SSH key to Jenkins, go to credentials in your job location. Choose the folder within credentials, then &apos;global credentials&apos;, &apos;Add credentials&apos;. Fill in the fields. Finally, the entry should be created.\nBuild a Jenkins Groovy script\nThe description of how to use SSH Agent plugin in Jenkins pipeline can be found under: https://www.karthikeyan.tech/2017/09/ssh-agent-blue-ocean-via-jenkins.html\nExample of use:\nsshagent (credentials: [env.WIREMOCK_CREDENTIALS]) {\nsh &quot;&quot;&quot;\nssh -T -o StrictHostKeyChecking=no -l ${env.WIREMOCK_USERNAME} ${env.WIREMOCK_IP_ADDRESS} &quot;docker container restart ${env.WIREMOCK_CONTAINER_NAME}&quot;\n&quot;&quot;&quot;\n}\nWhere: env.WIREMOCK_CREDENTIALS is a credential id of previously created wiremock credentials. Now that it is present, we can execute commands on a remote machine, where in ssh command:\nenv.WIREMOCK_USERNAME - user name of user connected with configured private key\nenv.WIREMOCK_IP_ADDRESS - ip address of the machine where this user with this private key exists\nPull repository with virtual assets\nTo pull the repository on a remote machine, it is necessary to use the previously described SSH Agent plugin. An example of use:\nsshagent (credentials: [env.WIREMOCK_CREDENTIALS]) {\nwithCredentials([usernamePassword(credentialsId: end.STASH_CREDENTIALS, passwordVariable: &apos;PASS&apos;, usernameVariable: &apos;USER&apos;)]) {\nsh &quot;&quot;&quot;\nssh -T -o StrictHostKeyChecking=no -l ${env.WIREMOCK_USERNAME} ${env.WIREMOCK_IP_ADDRESS} &quot;cd ~/${env.APPLICATION_DIRECTORY_WIREMOCK}/${env.PROJET_HOME}; git fetch https://&amp;USER:$PASS@${env.GIT_WITHOUT_HTTPS} ${env.GIT_BRANCH}; git reset --hard FETCH_HEAD; git clean -df&quot;\n&quot;&quot;&quot;\n}\n}\nWhere:\nwithCredentials allows various kinds of credentials (secrets) to be used in idiosyncratic ways. Each binding will define an environment variable active within the scope of the step. Then the necessary commands are executed:\ncd &#x2026;&#x200B; - command will change from current directory to the specified directory with git repository\ngit fetch &#x2026;&#x200B; ;git reset &#x2026;&#x200B; ;git clean &#x2026;&#x200B; - pull from GIT branch. Git pull or checkout are not used here to prevent the situation with wrong coding between Mac OSX/Linux etc.\nPLEASE remember that when using this script for the first time, the code from previous block should be changed to:\nstage(&quot;ssh-agent&quot;){\nsshagent (credentials: [env.WIREMOCK_CREDENTIALS]) {\nwithCredentials([usernamePassword(credentialsId: end.STASH_CREDENTIALS, passwordVariable: &apos;PASS&apos;, usernameVariable: &apos;USER&apos;)]) {\nsh &quot;&quot;&quot;\nssh -T -o StrictHostKeyChecking=no -l ${env.WIREMOCK_USERNAME} ${env.WIREMOCK_IP_ADDRESS} &quot;cd ~/${env.APPLICATION_DIRECTORY_WIREMOCK} ;git clone --depth=1 --branch=develop https://&amp;USER:$PASS@${env.GIT_WITHOUT_HTTPS}&quot;&apos;;\n&quot;&quot;&quot;\n}\n}\n"},{"id":1004,"path":"../website/pages/docs/master-mrchecker.asciidoc_test-framework-modules.html#Web-API-Test-Module-Smoke-Tests-virtualization.asciidoc","type":"docs","title":"Install an application with Smoke environment","body":"78.5.7. Install an application with Smoke environment\nUpdate properties settings file\nNew settings file is pushed to the repository. Example configuration:\n...\n&lt;key&gt;autocomplete&lt;/key&gt;\n&lt;string&gt;http://server:port&lt;/string&gt;\n&lt;key&gt;benefitsummary&lt;/key&gt;\n&lt;string&gt;http://server:port&lt;/string&gt;\n&lt;key&gt;checkscan&lt;/key&gt;\n&lt;string&gt;http://server:port&lt;/string&gt;\n&lt;key&gt;dpesb&lt;/key&gt;\n&lt;string&gt;http://server:port&lt;/string&gt;\n...\nAddress of service (backend) should be changed to wiremock address as it is shown on listing to change the default route.\nBuild an application with updated properties file\nNew versions of application are prepared by Jenkins job.\nInstall an application on target properties file\nInstallation of an application is actually executed in a non-automated way using SeeTest environment.\n"},{"id":1005,"path":"../website/pages/docs/master-mrchecker.asciidoc_test-framework-modules.html#Web-API-Test-Module-Smoke-Tests-virtualization.asciidoc","type":"docs","title":"UI tests","body":"78.5.8. UI tests\nRun Jenkins job\nJenkinsfile:\n// Jenkins parameters are overriding the properties below\ndef properties = [\nJENKINS_LABELS : &apos;PWI_LINUX_DEV&apos;,\nAPPLICATION_FOLDER : &apos;app_dir&apos;,\nPROJECT_HOME : &apos;app_home_folder&apos;,\n//WIREMOCK\nWIREMOCK_CREDENTIALS : &apos;vc2crptXXXXXXn&apos;,\nWIREMOCK_USERNAME : &apos;wiremock&apos;,\nWIREMOCK_ADDRESS : &apos;http://vc2crptXXXXXXn.xxx.com:8080&apos;,\nWIREMOCK_IP_ADDRESS : &apos;10.196.67.XXX&apos;,\nWIREMOCK_CONTAINER_NAME : &apos;wiremock&apos;,\nAPPLICATION_DIRECTORY_WIREMOCK : &apos;repo&apos;,\n//GIT\nGIT_CREDENTIALS : &apos;e47742cc-bb66-4321-2341-a2342er24f2&apos;,\nGIT_BRANCH : &apos;develop&apos;,\nGIT_SSH : &apos;ssh://git@stash.xxx.com/app/app.git&apos;\nGIT_HTTPS : &apos;HTTPS://git@stash.xxx.com/app/app.git&apos;,\nSTASH_CREDENTIALS : &apos;e47742cc-bb66-4321-2341-a2342er24f2&apos;,\n//DOCKER\nARTIFACTORY_USER_CREDENTIALS : &apos;e47742cc-bb66-4321-2341-a2342er24f2&apos;,\nSEETEST_DOCKER_IMAGE : &apos;docker.xxx.com/project/images/app:v1-8.3&apos;,\n//SEETEST_DOCKER_IMAGE\nSEETEST_APPLICATION_FOLDER : &apos;seetest_dir&apos;,\nSEETEST_PROJECT_HOME : &apos;Automated Scripts&apos;,\nSEETEST_GIT_SSH : &apos;ssh://git@stash.xxx.com/pr/seetest_automation_cucumber.git&apos;\nSEETEST_GIT_BRANCH : &apos;develop&apos;,\nSEETEST_GRID_USER_CREDENTIALS : &apos;e47742cc-bb66-4321-2341-a2342er24f2&apos;,\nSEETEST_CUCUMBER_TAG : &apos;@Virtualization&apos;,\nSEETEST_CLOUD_NAME : &apos;Core Group&apos;,\nSEETEST_IOS_VERSION : &apos;11&apos;,\nSEETEST_IOS_APP_URL : &apos;&apos;,\nSEETEST_INSTALL_APP : &apos;No&apos;,\nSEETEST_APP_ENVIRONMENT : &apos;SmokeTests&apos;,\nSEETEST_DEVICE_QUERY : &apos;&apos;,\n]\nnode(properties.JENKINS_LABELS) {\ntry {\nprepareEnv(properties)\ngitCheckout()\nstageStartVirtualServer()\nstageMapApiRequests()\nstageInstallApplication()\nstageUITests()\n} catch(Exception ex) {\ncurrentBuild.result = &apos;FAILURE&apos;\nerror = &apos;Error&apos; + ex\n}\n}\n//====================================END OF PIPELINE==========================================\nprivate void prepareEnv(properties) {\ncleanWorkspace()\noverrideProperties(properties)\nsetWorkspace()\n}\nprivate void gitCheckout() {\ndir(env.APPLICATION_FOLDER) {\ncheckout([$class: &apos;GitSCM&apos;, branches: [[Web-API-Test-Module-Smoke-Tests-virtualization.asciidoc_name: env.GIT_BRANCH]], doGenerateSubmoduleConfiguration: false, extensions: [[Web-API-Test-Module-Smoke-Tests-virtualization.asciidoc_$class: &apos;CloneOption&apos;, depth: 0, noTags: false, reference: &apos;&apos;, shallow: false, timeout: 50]], gitTool: &apos;Default&apos;, submoduleCfg: [], userRemoteConfigs: [[Web-API-Test-Module-Smoke-Tests-virtualization.asciidoc_credentialsId: env.GIT_CREDENTIALS, url: env.GIT_SSH]])\n}\n}\nprivate void stageStartVirtualServer() {\ndef module = load &quot;${env.SUBMODULES_DIR}/stageStartVirtualServer.groovy&quot;\nmodule()\n}\nprivate void stageMapApiRequests() {\ndef module = load &quot;${env.SUBMODULES_DIR}/stageMapApiRequests.groovy&quot;\nmodule()\n}\nprivate void stageInstallApplication() {\ndef module = load &quot;${env.SUBMODULES_DIR}/stageInstallApplication.groovy&quot;\nmodule()\n}\nprivate void stageUITests() {\ndef module = load &quot;${env.SUBMODULES_DIR}/stageUITests.groovy&quot;\nmodule()\n}\nprivate void setWorkspace() {\nString workspace = pwd()\nenv.APPLICATION_DIRECTORY = &quot;/${env.APPLICATION_DIRECTORY}&quot;\nenv.WORKSPACE_LOCAL - workspace + env.APPLICATION_DIRECTORY\nenv.SEETEST_PROJECT_HOME_ABSOLute_PATH = &quot;${workspace}/${env.SEETEST_APPLICATION_FOLDER}/${env.SEETEST_PROJECT_HOME}&quot;\nenv.SUBMODULES_DIR = env.WORKSPACE_LOCAL + &quot;/pipelines/SmokeTests.submodules&quot;\nenv.COMMONS_DIR = env.WORKSPACE_LOCAL + &quot;/pipelines/commons&quot;\n}\n/*\nfunction ovverrides env vales based on provided properties\n*/\nprivate void overrideProperties(properties) {\nfor (param in properties) {\nif (env.(param.key) == null) {\necho &quot;Adding parameter &apos;${param.key}&apos; with default value: &apos;$param.value}&apos;&quot;\nenv.(param.key) = param.value\n} else {\necho &quot;Parameter &apos;${param.key}&apos; has overriden value: &apos;${env.(param.key)}&apos;&quot;\n}\n}\necho sh(script: &quot;env | sort&quot;, returnStdout: true)\n}\nprivate void cleanWorkspace() {\nsh &apos;rm-rf *&apos;\n}\nstageStartVirtualServer.groovy:\ndef call () {\nstage(&quot;Check virtual server&quot;) {\ndef statusCode\ntry {\ndef response = httpRequest &quot;${env.WIREMOCK_ADDRESS}/__admin/&quot;\nstatusCode = response.status\n} catch(Exception ex) {\ncurrentBuild.result = &apos;FAILURE&apos;\nerror &apos;WireMock server os unreachable.&apos;\n}\nif(statusCode !=200) {\ncurrentBuild.result = &apos;FAILURE&apos;\nerror &apos;WireMock server is unreachable. Return code: ${statusCode}&apos;\n}\n}\n}\nstageMapApiRequests.groovy:\ndef call() {\nstage(&quot;Map API requests with virtual assets&quot;) {\ncheckoutRepository()\nrestartWiremock()\ncheckWiremockStatus()\n}\n}\nprivate checkoutRepository() {\nextractHTTPSUrl()\nsshagent (credentials: [env.WIREMOCK_CREDENTIALS]) {\nwithCredentials([usernamePassword(credentialsId: env.STASH_CREDENTIALS, passwordVariable: &apos;PASS&apos;, usernameVariable: &apos;USER&apos;)]) {\nsh &quot;&quot;&quot;\nssh -T -o StrictHostKeyChecking=no -l ${env.WIREMOCK_USERNAME} ${env.WIREMOCK_IP_ADDRESS} &quot;cd~/${env.APPLICATION_DIRECTORY_WIREMOCK}/${env.PROJECT_HOME}; git fetch https://$USER:$PASS@${env.GIT_WITHOUT_HTTPS} ${env.GIT_BRANCH}; git reset --hard FETCH_HEAD; git clean -df&quot;\n&quot;&quot;&quot;\n}\n}\n}\nprivate restartWiremock() {\nsshagent (credentials: [env.WIREMOCK_CREDENTIALS]) {\nsh &quot;&quot;&quot;\nssh -T -o StrictHostKeyChecking=no -l ${env.WIREMOCK_USERNAME} ${env.WIREMOCK_IP_ADDRESS} &quot;docker container restart ${env.WIREMOCK_CONTAINER_NAME}&quot;\n&quot;&quot;&quot;\n}\n}\nprivate checkWiremockStatus() {\nint wiremockStatusCheckCounter =6\nint sleepTimeInSeconds = 10\ndef wiremockStatus\nfor (i = 0; i &lt; wiremockStatusCheckCounter; i++) {\ntry {\nwiremockStatus = getHttpRequestStatus()\necho &quot;WireMock server status code: ${wiremockStatus}&quot;\n} catch(Exceprion ex) {\necho &quot;Exception when checking connection to WireMock&quot;\n}\nif(wiremockStatus == 200) break\nelse sh &quot;sleep $(sleepTimeInSeconds}&quot;\n}\nif(wiremockStatus != 200) {\ncurrentBuild.result = &apos;FAILURE&apos;\nerror &apos;WireMock server is unreachable. Return code: ${wiremockStatus}&apos;\n}\n}\nprivate def getHttpRequestStatus() {\ndef response = httpRequest &quot;${env.WIREMOCK_ADDRESS}/__admin&quot;\nreturn response.status\nprivate extractHTTPSUrl() {\nenv.GIT_WITHOUT_HTTPS = env.GIT_HTTPS.replace(&quot;https://&quot;, &quot;&quot;)\n}\nreturn this\nstageInstallApplication.groovy:\ndef call() {\nstage(&apos;Install application with smoke tests environment&apos;) {\ndir(env.SEETEST_APPLICATION_FOLDER) {\ncheckout([$class: &apos;GitSCM&apos;, branches: [[Web-API-Test-Module-Smoke-Tests-virtualization.asciidoc_name: env.SEETEST_GIT_BRANCH]], doGenerateSubmoduleConfigurations: false, extensions: [], gitTool: &apos;default&apos;, submoduleCfg: [], userRemoteConfigs: [[Web-API-Test-Module-Smoke-Tests-virtualization.asciidoc_credentialsId: env.GIT_CREDENTIALS, url: env.SEETEST_GIT_SSH]])\n}\n}\n}\nreturn this\nstageUITests.groovy:\ndef call() {\nstage(&apos;UI tests&apos;) {\ndef utils = load &quot;${env.SUBMODULES_DIR}/utils.groovy&quot;\ntry {\nutils.generateUserIDVariable(); //Generate USER_ID and USER_GROUP\ndocker.image(env.SEETEST_DOCKER_IMAGE).inside(&quot;-u ${env.USER_ID}:${env.USER_GROUP}&quot;) {\nwithCredentials([[Web-API-Test-Module-Smoke-Tests-virtualization.asciidoc_$class: &apos;UsernamePasswordMultiBinding&apos;, credentialsId: &quot;${env.ARTIFACTORY_USER_CREDENTIALS}&quot;, passwordVariable: &apos;ARTIFACTORY_PASSWORD&apos;, usernameVariable: &apos;ARTIFACTORY_USERNAME]]) {\nexecuteTests()\ncompressArtifacts()\npublishJUnitTestResultReport()\narchiveArtifacts()\npublishHTMLReports()\npublishCucumberReports()\n}\n}\n} catch (Exception exc) {\nthrow exc\n}\n}\n}\nprivate executeTests() {\nwithCredentials([usernamePassword(credentialsId: env.SEETEST_GRID_USER_CREDENTIALS, passwordVariable: &apos;GRID_USER_PASSWORD&apos;, usernameVariable: &apos;GRID_USER_NAME&apos;)]) {\nsh &quot;&quot;&quot;\ncd ${env.SEETEST_PROJECT_HOME_ABSOLUTE_PATH}\nmvn clean test -B -Ddriver=&quot;grid&quot; -Dtags=&quot;${env.SEETEST_CUCUMBER_TAG}&quot; -DcloudName=&quot;${env.SEETEST_CLOUD_NAME}&quot; -DdeviceQuery=&quot;${env.SEETEST_DEVICE_QUERY} -DgridUser=&quot;${GRID_USER_NAME}&quot; -DgridPassword=&quot;${GRID_USER_PASSWORD}&quot; -Dinstall=&quot;${env.SEETEST_INSTALL_APP}&quot; -DiosUrl=&quot;${env.SEETEST_IOS_APP_URL}&quot; -DdeviceType=&quot;iPhone&quot; -DiosVersion=&quot;$env.SEETEST_IOS_VERSION}&quot; -DparallelMode=&quot;allonall&quot; -Denv=&quot;${env.SEETEST_APP_ENVIRONMENT}&quot; site\n&quot;&quot;&quot;\n}\n}\nprivate compressartifacts() {\necho &quot;Compressing artifacts from /target/site&quot;\nsh &quot;&quot;&quot;\nzip -r allure_report.zip **/${env.SEETEST_PROJECT_homE}/target/site\n&quot;&quot;&quot;\nprivate publishJUnitTestResultReport() {\necho &quot;Publishing JUnit reports from ${env.SEETEST_APPLICATION_FOLDER}/${env.SEETEST_PROJECT_HOME}/target/surefire-reports/junitreporters/*.xml&quot;\ntry {\njunit &quot;${env.SEETEST_APPLICATION_FOLDER}/${env.SEETEST_PROJECT_HOME}/target/surefire-reports/junitreporters/*.xml&quot;\n} catch(e) {\necho(&quot;No JUnit report found&quot;)\n}\n}\nprivate archiveArtifacts() {\necho &quot;Archiving artifacts&quot;\ntry {\narchiveArtifacts allowEmptyArchive: true, artifacts: &quot;**/allure_report.zip&quot;\n} catch(e) {\necho(&quot;No artifacts found&quot;)\n}\n}\nprivate publishHTMLReports() {\necho &quot;Publishing HTML reports from ${env.SEETEST_APPLICATION_FOLDER}/${env.SEETEST_PROJECT_HOME}/target/site/allure-maven-plugin&quot;\ntry {\npublishHTML([allowMissing: false, alwaysLinkToLastBuild: true, keepAll: true, reportDir: &quot;${env.SEETEST_APPLICATION_FOLDER/${env.SEETEST_PROJECT_HOME}/target/site/allure-maven-plugin&quot;, reportFiles: &apos;index.html&apos;, reportName: &apos;Allure report&apos;, reportTitles: &apos;Allure report&apos;])\n} catch(e) {\necho(&quot;No artifacts found&quot;)\n}\n}\nprivate publishCucumberREPORTS() {\necho &quot;Publishing Cucumber reports from ${env.SEETEST_APPLICATION_FOLDER}/${env.SEETEST_PROJECT_HOME}/target/cucumber-parallel/*.json&quot;\ntry {\nstep([$class: &apos;CucumberReportPublisher&apos;, fileExcludePattern &apos;&apos;, fileIncludePattern: &quot;#{env.SEETEST_APPLICATION_FOLDER}/${env.SEETEST_PROJECT_HOME}/target/cucumber-parallel/*.json&quot;, ignoreFailedTests: false, jenkinsBasePath: &apos;&apos;, jsonReportDirectory: &apos;&apos;, missingFails: false, parallelTesting: false, pendingFails: false, skippedFails: false, undefinedFails: false])\n} catch(e) {\necho(&quot;No Cucumber report found&quot;)\n}\n}\nreturn this\nConfiguration\nIt is possible to configure Jenkins job in two ways. First one is to edit the Jenkinsfile. All of the properties are in properties collection as below:\ndef properties = [\nJENKINS_LABELS : &apos;PWI_LINUX_DEV&apos;\n...\n//Docker\nARTIFACTORY_USER_CREDENTIALS : &apos;ba2e4f46-56f1-4467-ae97-17b356d6s643&apos;,\nSEETEST_DOCKER_IMAGE : &apos;docker.XXX.com/app/base-images/seetest:v1-8.3&apos;,\n//SeeTest\nSEETEST_APPLICATION_FOLDER : &apos;seetest_dit&apos;,\nSEETEST_PROJECT_HOME : &apos;Automated_Scripts&apos;,\nSEETEST_GIT_SSH : &apos;ssh://stash.xxx.com/app/seetest_automation_cucumber.git&apos;,\nSEETEST_GIT_BRANCH : &apos;develop&apos;,\n...\n]\nSecond way is to add properties in &apos;Configure job&apos;. All of the properties there are overriding properties from Jenkinsfile (the have the highest priority). They can then be set durring &apos;Build with Paremeters&apos; process.\nReports\nAfter a job execution &apos;Allure report&apos; and &apos;Cucumber-JVM&apos; reports should be visible. If any tests fail, You can check on which screen (printscreen from failures is attached, why and etc.)\n"},{"id":1006,"path":"../website/pages/docs/master-mrchecker.asciidoc_test-framework-modules.html#master-mrchecker.asciidoc_security-module","type":"docs","title":"Security Module","body":"78.6. Security Module\n"},{"id":1007,"path":"../website/pages/docs/master-mrchecker.asciidoc_test-framework-modules.html#Security-Test-Module.asciidoc","type":"docs","title":"Security Test Module","body":"78.6.1. Security Test Module\nWhat is Security\nApplication Security is concerned with Integrity, Availability and Confidentiality of data processed, stored and transferred by the application.\nApplication Security is a cross-cutting concern which touches every aspect of the Software Development Lifecycle. You can introduce some SQL injection flaws in your application and make it exploitable, but you can also expose your secrets (which will have nothing to do with code itself) due to poor secret management process, and fail as well.\nBecause of this and many other reasons, not every aspect of security can be automatically verified. Manual tests and audits will still be needed. Nevertheless, every security requirement which is automatically verified will prevent code degeneration and misconfiguration in a continuous manner.\nHow to test Security\nSecurity tests can be performed in many different ways, such as:\nStatic Code Analysis - improves the security by (usually) automated code review. A good way to search for vulnerabilities, which are &apos;obvious&apos; on the code level ( e.g. SQL injection). The downside of this approach is that professional tools to perform such scans are very expensive and still produce many false positives.\nDynamic Code Analysis - tests are run against a working environment. A good way to search for vulnerabilities, which require all client- and server-side components to be present and running (like e.g. Cross-Site Scripting). Tests are performed in a semi-automated manner and require a proxy tool (like e.g. OWASP ZAP)\nUnit tests - self-written and self-maintained tests. They usually work on the HTTP/REST level (this defines the trust boundary between the client and the server) and run against a working environment. Unit tests are best suited for verifying requirements which involve business knowledge of the system or which assure secure configuration on the HTTP level.\nIn the current release of the Security Module, the main focus will be Unit Tests.\nAlthough the most common choice of environment for running security tests on will be integration(the environment offers the right stability and should mirror the production closely), it is not uncommon for some security tests to run on production as well. This is done for e.g. TLS configuration testing to ensure proper configuration of the most relevant environment in a continuous manner.\n"},{"id":1008,"path":"../website/pages/docs/master-mrchecker.asciidoc_test-framework-modules.html#master-mrchecker.asciidoc_database-module","type":"docs","title":"Database Module","body":"78.7. Database Module\n"},{"id":1009,"path":"../website/pages/docs/master-mrchecker.asciidoc_test-framework-modules.html#Database-Test-Module.asciidoc","type":"docs","title":"Database Test Module","body":"78.7.1. Database Test Module\nWhat is MrChecker Database Test Module\nDatabase module is based on Object-Relational Mapping programming technique. All functionalities are built using Java Persistence API but examples use Hibernate as a main provider.\nJPA structure schema\nThis module was written to allow the use of any JPA provider. The structure is represented in the schema below.\nORM representation applied in Framework\n"},{"id":1010,"path":"../website/pages/docs/master-mrchecker.asciidoc_test-framework-modules.html#master-mrchecker.asciidoc_mobile-test-module","type":"docs","title":"Mobile Test Module","body":"78.8. Mobile Test Module\n"},{"id":1011,"path":"../website/pages/docs/master-mrchecker.asciidoc_test-framework-modules.html#Mobile-Test-Module.asciidoc","type":"docs","title":"Mobile Test Module","body":"78.8.1. Mobile Test Module\nWhat is MrChecker E2E Mobile Test Module\nMrChecker E2E Mobile test Module is a suitable solution for testing Remote Web Design, Mobile Browsers and application.\nA user can write tests suitable for all mobile browsers with a full range of resolution. The way of working is similar to Selenium and uses the same rules and patterns as the Web Driver. For more information please look in the Selenium test module.\nWhat is Page Object Architecture\nCreating Selenium test cases can result in an unmaintainable project. One of the reasons is that too many duplicated code is used. Duplicated code could be caused by the duplicated functionality and this will result in duplicated usage of locators. The disadvantage of duplicated code is that the project is less maintainable. If some locator will change, you have to walk through the whole test code to adjust locators where necessary. By using the page object model we can make non-brittle test code and reduce or eliminate duplicate test code. Beside of that it improves the readability and allows us to create interactive documentation. Last but not least, we can create tests with less keystroke. An implementation of the page object model can be achieved by separating the abstraction of the test object and the test scripts.\nPage Object Pattern\nMobile Structure\nIt is build on the top of the Appium library.\nAppium is an open-source tool for automating native, mobile web, and hybrid applications on iOS mobile, Android mobile, and Windows desktop platforms. Native apps are those written using iOS, Android, or Windows SDKs. Mobile web apps are web apps accessed using a mobile browser (Appium supports Safari on iOS and Chrome or the built-in &apos;Browser&apos; app on Android). Hybrid apps have a wrapper around a &quot;webview&quot; - a native control that enables interaction with web content.\nRun on different mobile devices\nTo execute each test with chosen connected mobile devices, it is required to use specific arguments in Run configuration.\nDefault supported arguments in MrChecker:\ndeviceUrl - http url to Appium Server, default value &quot;http://127.0.0.1:4723&quot;\nautomationName - which automation engine to use , default value &quot;Appium&quot;\nplatformName - which mobile OS platform to use , default value &quot;Appium&quot;\nplatformVersion - mobile OS version , default value &quot;&quot;\ndeviceName - the kind of mobile device or emulator to use , default value &quot;Android Emulator&quot;\napp - the absolute local path or remote http URL to a .ipa file (IOS), .app folder (IOS Simulator), .apk file (Android) or .apks file (Android App Bundle), or a .zip file, default value &quot;.&quot;\nbrowserName - name of mobile web browser to automate. Should be an empty string if automating an app instead, default value &quot;&quot;\nnewCommandTimeout - how long (in seconds) Appium will wait for a new command from the client before assuming the client quit and ending the session, default value &quot;4000&quot;\ndeviceOptions - any other capabilites not covered in essential ones, default value none\nExample usage:\nmvn clean test -Dtest=MyTest -DdeviceUrl=&quot;http://192.168.0.1:1234&quot; -DplatformName=&quot;iOS&quot; -DdeviceName=&quot;iPhone Simulator&quot; -Dapp=&quot;.\\\\Simple_App.ipa&quot;\nmvn clean test -Dtest=MyTest -Dapp=&quot;.\\\\Simple_App.apk -DdeviceOptions=&quot;orientation=LANDSCAPE;appActivity=MainActivity;chromeOptions=[&apos;--disable-popup-blocking&apos;]&quot;\nCheck also:\n+\nMy First Selenium Test\n+\nHow to use Mobile test Module\n+\nExample TestCase\n+\nFull list of Generic Capabilities\n+\nList of additional capabilities for Android\n+\nList of additional capabilities for iOS\n"},{"id":1012,"path":"../website/pages/docs/master-mrchecker.asciidoc_test-framework-modules.html#Mobile-Test-Module-How-to-use.asciidoc","type":"docs","title":"How to use mobile test Module","body":"78.8.2. How to use mobile test Module\nInstall IDE with MrChecker\nSwitch branch to &apos;feature/Create-mobile-module-#213&apos; - by default it is &apos;develop&apos;\ngit checkout feature/Create-mobile-module-#213\nInstall and setup git checkout feature/Create-mobile-module-#213[Appium Server]\nConnect to local Device by Appium Server\n1.\nInstall Android SDK https://developer.android.com/studio/index.html#command-tools -&gt;\n2.\nDownload Platform and Build-Tools (Android versions - &gt; https://en.wikipedia.org/wiki/Android_version_history )\n* sdkmanager &quot;platform-tools&quot; &quot;platforms;android-19&quot;\n* sdkmanager &quot;build-tools;19.0.0&quot;\n* copy from /build-tools file &quot;aapt.exe&quot; to /platform-tools\n3.\nSet Environment:\nANDROID_SDK_ROOT = D:\\sdk-tools-windows-4333796\nPATH = %PATH%; %ANDROID_SDK_ROOT%\n4.\nStart Appium Server\n5.\nStart Session in Appium Server, capabilities\n{\n&quot;platformName&quot;: &quot;Android&quot;,\n&quot;deviceName&quot;: &quot;Android Emulator&quot;,\n&quot;app&quot;: &quot;D:\\\\Repo\\\\mrchecker-source\\\\mrchecker-framework-modules\\\\mrchecker-mobile-module\\\\src\\\\test\\\\resources\\\\Simple App_v2.0.1_apkpure.com.apk&quot;,\n&quot;automationName&quot;: &quot;UiAutomator1&quot;\n}\nRun Mobile tests with runtime parameters.\nList of supported parameters could be found here\nFrom command line (as in Jenkins):\nmvn clean compile test -Dapp=&quot;.\\\\Simple_App_v2.0.1_apkpure.com.apk&quot; -DautomationName=&quot;UiAutomator1&quot; -Dthread.count=1\nfrom IDE:\n"},{"id":1013,"path":"../website/pages/docs/master-mrchecker.asciidoc_test-framework-modules.html#master-mrchecker.asciidoc_devops-test-module","type":"docs","title":"DevOps Test Module","body":"78.9. DevOps Test Module\n"},{"id":1014,"path":"../website/pages/docs/master-mrchecker.asciidoc_test-framework-modules.html#DevOPS-Test-Module.asciidoc","type":"docs","title":"DevOPS Test Module","body":"78.9.1. DevOPS Test Module\nWhat does DevOps mean for us?\nDevOps consists of a mixture of three key components in a technical project:\nPeople&#x2019;s skills and mindset\nProcesses\nTools\nUsing E2E MrChecker Test Framework it is possible to cover the majority of these areas.\nQA Team Goal\nFor QA engineers, it is essential to take care of the product code quality.\nTherefore, we have to understand, that a test case is also code which has to be validated against quality gates. As a result, we must test our developed test case like it is done during standard Software Delivery Life Cycle.\nWell rounded test case production process\nHow do we define top-notch test cases development process in E2E MrChecker Test Framework\nContinuous Integration (CI) and Continuous Delivery (CD)\nContinuous Integration (CI) - a procedure where quality gates validate test case creation process\nContinuous Delivery (CD) - a procedure where we include created test cases, validated against CI, as smoke/regression/security\nWhat should you receive from this DevOps module\nWhat will you gain with our DevOps module\nThe CI procedure has been divided into transparent modules. This solution makes configuration and maintenance very easy because everyone is able to manage versions and customize the configuration independently for each module. A separate security module ensures the protection of your credentials and assigned access roles regardless of changes in other modules.\nYour CI process will be matched to the current project. You can easily go back to the previous configuration, test a new one or move a selected one to other projects.\nDevOps module supports a delivery model in which executors are made available to the user as needed. It has such advantages as:\nSaving computing resources\nEliminating guessing on your infrastructure capacity needs\nNot spending time on running and maintaining additional executors\nHow to build this DevOps module\nOnce you have implemented the module, you can learn more about it here:\nDocker commands\n"},{"id":1015,"path":"../website/pages/docs/master-mrchecker.asciidoc_test-framework-modules.html#DevOPS-Test-Module-Continuous-Integration-CI.asciidoc","type":"docs","title":"Continuous Integration","body":"78.9.2. Continuous Integration\nEmbrace quality with Continuous Integration while you produce test case(s).\nOverview\nThere are two ways to set up your Continuous Integration environment:\nCreate a Jenkins instance from scratch (e.g. by using the Jenkins Docker image)\nUsing a clean Jenkins instance requires the installation of additional plugins. The plugins required and their versions can be found on this page.\nUse thre pre-configured custom Docker image provided by us\nNo more additional configuration is required (but optional) using this custom Docker image. Additionally, this Jenkins setup allows dynamical scaling across multiple machines and even cloud (AWS, Azure, Google Cloud etc.).\nJenkins Overview\nJenkins is an Open Source Continuous Integration Tool. It allows the user to create automated build jobs which will run remotely on so called Jenkins Slaves. A build job can be triggered by several events, for example on new pull request on specified repositories or timed (e.g. at midnight).\nJenking Configuration\nTests created by using the testing framework can easily be implemented on a Jenkins instance. The following chapter will describe such a job configuration. If you&#x2019;re running your own Jenkins instance, you may have to install additional plugins listed on the page Jenkins Plugins for a trouble-free integration of your tests.\nInitial Configuration\nThe test job is configured as a so-called parameterized job. This means, after starting the job, parameters can be specified, which will then be used in the build process. In this case, branch and testname will be expected when starting the job. These parameters specify which branch in the code repository should be checked out (possibly feature branch) and the name of the test that should be executed.\nBuild Process Configuration\nThe first step inside the build process configuration is to get the author of the commit that was made. The mail will be extracted and gets stored in a file called build.properties. This way, the author can be notified if the build fails.\nNext up, Maven will be used to check if the code can be compiled, without running any tests.\nAfter making sure that the code can be compiled, the actual tests will be executed.\nFinally, reports will be generated.\nPost Build Configuration\nAt first, the results will be imported to the Allure System\nJUnit test results will be reported as well. Using this step, the test result trend graph will be displayed on the Jenkins job overview.\nFinally, an E-Mail will be sent to the previously extracted author of the commit.\nUsing the Pre-Configured Custom Docker Image\nIf you are starting a new Jenkins instance for your tests, we&#x2019;d suggest using the pre-configured Docker image. This image already contains all the configurations and additional features.\nThe configurations are e.g. Plugins and Pre-Installed job setup samples. This way, you don&#x2019;t have to set up the entire CI-Environment from the ground up.\nAdditional features from this docker image allow dynamic creation and deletion of Jenkins slaves, by creating Docker containers. Also, Cloud Solutions can be implemented to allow wide-spread load balancing.\n"},{"id":1016,"path":"../website/pages/docs/master-mrchecker.asciidoc_test-framework-modules.html#DevOPS-Test-Module-Continuous-Delivery-CD.asciidoc","type":"docs","title":"Continuous Delivery","body":"78.9.3. Continuous Delivery\nInclude quality with Continuous Delivery during product release.\nOverview\nCD from Jenkins point of view does not change a lot from Continuous Integration one.\nJenkins Overview\nUse the same Jenkins settings for Jenkins CD setup as for CI, please. link. The only difference is:\nWhat type of test you will execute. Before, we have been choosing test case(s), now we will choose test suite(s)\nWho will trigger the given Smoke/Integration/Performance job\nWhat is the name of official branch. This branch ought always to use be used in every CD execution. It will be either master or develop.\nJenkins for Smoke Tests\nIn the $TESTNAME variable, where we input the test name( link ), please input the name of a test suite assembled together of tests tagged as smoke tests -( link ) thus running all the smoke tests.\nJenkins for Performance Tests\nUnder construction - added when WebAPI module is included.\n"},{"id":1017,"path":"../website/pages/docs/master-mrchecker.asciidoc_test-framework-modules.html#DevOPS-Test-Module-Pipeline-structure.asciidoc","type":"docs","title":"Pipeline structure","body":"78.9.4. Pipeline structure\nPipeline configuration:\nThe default interaction with Jenkins required manual jobs. This keeps configuration of a job in Jenkins separate from source code. With Pipeline plugin users can implement a pipeline procedure in Jenkinsfile and store it in repository with other code. This approach is used in Mr Checker framework. More info: https://jenkins.io/solutions/pipeline/\nOur CI &amp; CD processes are divided into a few separate files: Jenkins_node.groovy is the file to manage all processes. It defines all operations executed on a Jenkins node, so all code in this file is closed in node closure. Workflow in Jenkinsfile:\nRead all parameters from a Jenkins job\nExecute stage to prepare the environment\nExecute git pull command\nSet Jenkins job description\nExecute compilation of the project in a special prepared docker container\nExecute unit tests\nExecute integration tests\nDeploy artifacts to a local repository\nDeploy artifacts to an external repository (nexus/arifactory)\nNot all the steps must be present in the Jenkins files. This should be configured for particular job requirements.\nDescription of stages:\nStage &#x201C;Prepare environment&#x201D;\nFirst thing to do in this stage is overwriting properties loaded from Jenkins job. It is defined in &#x201C;overrideProperties&#x201D; function. The next function, &#x201C;setJenkinsJobVariables&#x201D; defines environment variables such as :\nJOB_NAME_UPSTREAM\nBUILD_DISPLAY_NAME_UPSTREAM\nBUILD_URL_UPSTREAM\nGIT_CREDENTIALS\nJENKINS_CREDENTIALS\nThe last function in the stage &#x2013; &#x201C;setWorkspace&#x201D; -creates an environment variable with path to local workspace. This is required beacuse when using pipeline plugin, Jenkins does not create the WORKSPACE env variables.\nStage &quot;Git pull&quot;\nIt pulls sources from the repository and loads &#x201C;git pull&#x201D; file which contains additional methods:\nsetGitAuthor &#x2013; setting properties about git author to the file &#x201C;build.properties&#x201D; and loading created file\ntryMergeWithBranch &#x2013; checking if actual branch can be merged with default main branch\nStage &#x201C;Build compile&#x201D;\nVerify with maven that code builds without errors\nStage &#x201C;Unit test&#x201D;\nExecute unit tests with mvn surefire test and publish reports in junit and allure format\nStage &#x201C;Integration test&#x201D;\nExecute integration tests with mvn surefire test and publish reports in junit and allure format\n[[devops-test-module-pipeline-structure.asciidoc_stage-deploy-&#x2013;-local-repo]]\n=== Stage &#x201C;Deploy &#x2013; local repo&#x201D;\nArchive artifacts as a jar file in the local repository\n[[devops-test-module-pipeline-structure.asciidoc_stage-deploy-&#x2013;-nexu-repo]]\n=== Stage &#x201D;Deploy &#x2013; nexu repo&#x201D;\nDeploy to the external repository with maven release deploy command with credentials stored in Jenkins machine. Additional files:\nmailSender.groovy &#x2013; contains methods for sending mail with generated content\nstashNotification.groovy &#x2013; send job status for bitbucket by a curl command\nutils.groovy - contains additional functions to load properties, files and generate additional data\n"},{"id":1018,"path":"../website/pages/docs/master-mrchecker.asciidoc_test-framework-modules.html#DevOPS-Test-Module-Selenium-Grid.asciidoc","type":"docs","title":"Selenium Grid","body":"78.9.5. Selenium Grid\nWhat is Selenium Grid\nSelenium Grid allows running web/mobile browsers test cases to fulfill basic factors, such as:\nIndependent infrastructure, similar to end-users&apos;\nScalable infrastructure (\\~50 simultaneous sessions at once)\nHuge variety of web browsers (from mobile to desktop)\nContinuous Integration and Continuous Delivery process\nSupporting multi-type programming languages (java, javascript, python, &#x2026;&#x200B;).\nOn a daily basis, a test automation engineer uses their local environments for test case execution/development. However, a created browser test case has to be able to run on any infrastructure. Selenium Grid enables this portability.\nSelenium Grid Structure\nFull documentation of Selenium Grid can be found here and here.\n&apos;Vanilla flavour&apos; Selenium Grid is based on two, not very complicated ingredients:\nSelenium Hub - as one machine, accepting connections to grid from test cases executors. It also plays a managerial role in connection to/from Selenium Nodes\nSelenium Node - from one to many machines, where on each machine a browser used during test case execution is installed.\nHow to setup\nThere are two options of Selenium Grid setup:\nClassic, static solution - link\nCloud, scalable solution - link\nAdvantages and disadvantages of both solutions:\nHow to use Selenium Grid with E2E Mr Checker Test Frameworks\nRun the following command either in Eclipse or in Jenkins:\n&gt; mvn test -Dtest=com.capgemini.ntc.selenium.tests.samples.resolutions.ResolutionTest -DseleniumGrid=&quot;http://10.40.232.61:4444/wd/hub&quot; -Dos=LINUX -Dbrowser=chrome\nAs a result of this command:\n-Dtest=com.capgemini.ntc.selenium.features.samples.resolutions.ResolutionTest - name of test case to execute\n-DseleniumGrid=&quot;http://10.40.232.61:4444/wd/hub&quot; - IP address of Selenium Hub\n-Dos=LINUX - what operating system must be assumed during test case execution\n-Dbrowser=chrome - what type of browser will be used during test case execution\n"},{"id":1019,"path":"../website/pages/docs/master-mrchecker.asciidoc_test-framework-modules.html#DevOPS-Test-Module-Jenkins-Plugins.asciidoc","type":"docs","title":"List of Jenkins Plugins","body":"78.9.6. List of Jenkins Plugins\nPlugin Name\nVersion\nblueocean-github-pipeline\n1.1.4\nblueocean-display-url\n2.0\nblueocean\n1.1.4\nworkflow-support\n2.14\nworkflow-api\n2.18\nplain-credentials\n1.4\npipeline-stage-tags-metadata\n1.1.8\ncredentials-binding\n1.12\ngit\n3.5.1\nmaven-plugin\n2.17\nworkflow-durable-task-step\n2.12\njob-dsl\n1.64\ngit-server\n1.7\nwindows-slaves\n1.3.1\ngithub\n1.27.0\nblueocean-personalization\n1.1.4\njackson2-api\n2.7.3\nmomentjs\n1.1.1\nworkflow-basic-steps\n2.6\nworkflow-aggregator\n2.5\nblueocean-rest\n1.1.4\ngradle\n1.27.1\npipeline-maven\n3.0.0\nblueocean-pipeline-editor\n0.2.0\ndurable-task\n1.14\nscm-api\n2.2.2\npipeline-model-api\n1.1.8\nconfig-file-provider\n2.16.3\ngithub-api\n1.85.1\npam-auth\n1.3\nworkflow-cps-global-lib\n2.8\ngithub-organization-folder\n1.6\nworkflow-job\n2.12.1\nvariant\n1.1\ngit-client\n2.5.0\nsse-gateway\n1.15\nscript-security\n1.29.1\ntoken-macro\n2.1\njquery-detached\n1.2.1\nblueocean-web\n1.1.4\ntimestamper\n1.8.8\ngreenballs\n1.15\nhandlebars\n1.1.1\nblueocean-jwt\n1.1.4\npipeline-stage-view\n2.8\nblueocean-i18n\n1.1.4\nblueocean-git-pipeline\n1.1.4\nace-editor\n1.1\npipeline-stage-step\n2.2\nemail-ext\n2.58\nenvinject-api\n1.2\nrole-strategy\n2.5.1\nstructs\n1.9\nlocale\n1.2\ndocker-workflow\n1.13\nssh-credentials\n1.13\nblueocean-pipeline-scm-api\n1.1.4\nmetrics\n3.1.2.10\nexternal-monitor-job\n1.7\njunit\n1.21\ngithub-branch-source\n2.0.6\nblueocean-config\n1.1.4\ncucumber-reports\n3.8.0\npipeline-model-declarative-agent\n1.1.1\nblueocean-dashboard\n1.1.4\nsubversion\n2.9\nblueocean-autofavorite\n1.0.0\npipeline-rest-api\n2.8\npipeline-input-step\n2.7\nmatrix-project\n1.11\npipeline-github-lib\n1.0\nworkflow-multibranch\n2.16\ndocker-plugin\n0.16.2\nresource-disposer\n0.6\nicon-shim\n2.0.3\nworkflow-step-api\n2.12\nblueocean-events\n1.1.4\nworkflow-scm-step\n2.6\ndisplay-url-api\n2.0\nfavorite\n2.3.0\nbuild-timeout\n1.18\nmapdb-api\n1.0.9.0\npipeline-build-step\n2.5.1\nantisamy-markup-formatter\n1.5\njavadoc\n1.4\nblueocean-commons\n1.1.4\ncloudbees-folder\n6.1.2\nssh-slaves\n1.20\npubsub-light\n1.10\npipeline-graph-analysis\n1.4\nallure-jenkins-plugin\n2.23\nmailer\n1.20\nws-cleanup\n0.33\nauthentication-tokens\n1.3\nblueocean-pipeline-api-impl\n1.1.4\nldap\n1.16\ndocker-commons\n1.8\nbranch-api\n2.0.10\nworkflow-cps\n2.36.1\npipeline-model-definition\n1.1.8\nblueocean-rest-impl\n1.1.4\nant\n1.7\ncredentials\n2.1.14\nmatrix-auth\n1.7\npipeline-model-extensions\n1.1.8\npipeline-milestone-step\n1.3.1\njclouds-jenkins\n2.14\nbouncycastle-api\n2.16.1\n"},{"id":1020,"path":"../website/pages/docs/master-mrchecker.asciidoc_test-framework-modules.html#DevOPS-Test-Module-Docker-commands.asciidoc","type":"docs","title":"What is Docker","body":"78.9.7. What is Docker\nDocker is an open source software platform to create, deploy and manage virtualized application containers on a common operating system (OS), with an ecosystem of allied tools.\n"},{"id":1021,"path":"../website/pages/docs/master-mrchecker.asciidoc_test-framework-modules.html#DevOPS-Test-Module-Docker-commands.asciidoc","type":"docs","title":"Where do we use Docker","body":"78.9.8. Where do we use Docker\nDevOps module consists of Docker images\nJenkins image\nJenkins job image\nJenkins management image\nSecurity image\nin addition, each new node is also based on Docker\n"},{"id":1022,"path":"../website/pages/docs/master-mrchecker.asciidoc_test-framework-modules.html#DevOPS-Test-Module-Docker-commands.asciidoc","type":"docs","title":"Exploring basic Docker options","body":"78.9.9. Exploring basic Docker options\nLet&#x2019;s show some of the most important commands that are needed when working with our DevOps module based on the Docker platform. Each command given below should be preceded by a sudo call by default. If you don&#x2019;t want to use sudo command create a Unix group called docker and add a user to it.\n$ sudo groupadd docker\n$ sudo usermod -aG docker $USER\nBuild an image from a Dockerfile\n# docker build [OPTIONS] PATH | URL | -\n#\n# Options:\n# --tag , -t : Name and optionally a tag in the &#x2018;name:tag&#x2019; format\n$ docker build -t vc_jenkins_jobs .\nContainer start\n# docker run [OPTIONS] IMAGE[:TAG|@DIGEST] [COMMAND] [ARG...]\n#\n# Options:\n# -d : To start a container in detached mode (background)\n# -it : interactive terminal\n# --name : assign a container name\n# --rm : clean up\n# --volumes-from=&quot;&quot;: Mount all volumes from the given container(s)\n# -p : explicitly map a single port or range of ports\n# --volume : storage associated with the image\n$ docker run -d --name vc_jenkins_jobs vc_jenkins_jobs\nRemove one or more containers\n# docker rm [OPTIONS] CONTAINER\n#\n# Options:\n# --force , -f : Force the removal of a running container\n$ docker rm -f jenkins\nList containers\n# docker ps [OPTIONS]\n# --all, -a : Show all containers (default shows just running)\n$ docker ps\nPull an image or a repository from a registry\n# docker pull [OPTIONS] NAME[:TAG|@DIGEST]\n$ docker pull jenkins/jenkins:2.73.1\nPush the image or a repository to a registry\nPushing new image takes place in two steps. First save the image by adding container ID to the commit command and next use push:\n# docker push [OPTIONS] NAME[:TAG]\n$ docker ps\n# copy container ID from the result\n$ docker commit b46778v943fh vc_jenkins_mng:project_x\n$ docker push vc_jenkins_mng:project_x\nReturn information on Docker object\n# docker inspect [OPTIONS] NAME|ID [NAME|ID...]\n#\n# Options:\n# --format , -f : output format\n$ docker inspect -f &apos;{{ .Mounts }}&apos; vc_jenkins_mng\nList images\n# docker images [OPTIONS] [REPOSITORY[:TAG]]\n#\n# Options:\n--all , -a : show all images with intermediate images\n$ docker images\n$ docker images jenkins\nRemove one or more images\n# docker rmi [OPTIONS] IMAGE [IMAGE...]\n#\n# Options:\n# --force , -f : Force removal of the image\n$ docker rmi jenkins/jenkins:latest\nRun a command in a running container\n# docker exec [OPTIONS] CONTAINER COMMAND [ARG...]\n# -d : run command in the background\n# -it : interactive terminal\n# -w : working directory inside the container\n# -e : Set environment variables\n$ docker exec vc_jenkins_jobs sh -c &quot;chmod 755 config.xml&quot;\n"},{"id":1023,"path":"../website/pages/docs/master-mrchecker.asciidoc_test-framework-modules.html#DevOPS-Test-Module-Docker-commands.asciidoc","type":"docs","title":"Advanced commands","body":"78.9.10. Advanced commands\nRemove dangling images\n$ docker rmi $(docker images -f dangling=true -q)\nRemove all images\n$ docker rmi $(docker images -a -q)\nRemoving images according to a pattern\n$ docker images | grep &quot;pattern&quot; | awk &apos;{print $2}&apos; | xargs docker rm\nRemove all exited containers\n$ docker rm $(docker ps -a -f status=exited -q)\nRemove all stopped containers\n$ docker rm $(docker ps --no-trunc -aq)\nRemove containers according to a pattern\n$ docker ps -a | grep &quot;pattern&quot; | awk &apos;{print $1}&apos; | xargs docker rmi\nRemove dangling volumes\n$ docker volume rm $(docker volume ls -f dangling=true -q)\n&#x2190;&#xA0;Previous:&#xA0;Who Is MrChecker&#xA0;| &#x2191;&#xA0;Up:&#xA0;MrChecker - devonfw testing tool&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;MrChecker download&#xA0;&#x2192;\n"},{"id":1024,"path":"../website/pages/docs/master-mrchecker.asciidoc_tutorials.html#master-mrchecker.asciidoc_tutorials","type":"docs","title":"Tutorials","body":"80. Tutorials\nIn order to learn more about MrChecker structure, start from Project Organisation section and then check out our fantastic tutorials:\nThis tutorial will guide you through the series of test which perform basic actions on webpages using MrChecker.\nMake sure you already have MrChecker Test Framework installed on your PC. How to install?\nYour Product Under Test will be the following website: http://the-internet.herokuapp.com/\n"},{"id":1025,"path":"../website/pages/docs/master-mrchecker.asciidoc_tutorials.html#Project-Organisation.asciidoc","type":"docs","title":"Project organization","body":"80.1. Project organization\n"},{"id":1026,"path":"../website/pages/docs/master-mrchecker.asciidoc_tutorials.html#project-organisation.asciidoc_importing-projects","type":"docs","title":"Importing projects","body":"80.1.1. Importing projects\nEvery MrChecker project should be imported as a Maven Project.\nExample from Eclipse IDE:\nEnter the project path and select projects to import.\nWhen the import is finished, update the project structure - ALT + F5\n"},{"id":1027,"path":"../website/pages/docs/master-mrchecker.asciidoc_tutorials.html#project-organisation.asciidoc_exporting-projects","type":"docs","title":"Exporting projects","body":"80.1.2. Exporting projects\nIn order to create a new standalone MrChecker project, you can use template-app-under-test and export it to the new folder:\nCreate a new folder for the project and enter its path. Select project and files to export:\nChange project name and other properties, if necessary, in pom.xml file:\nThen you can import the project to the workspace and create new packages and classes.\n"},{"id":1028,"path":"../website/pages/docs/master-mrchecker.asciidoc_tutorials.html#project-organisation.asciidoc_creating-new-packages","type":"docs","title":"Creating new packages","body":"80.1.3. Creating new packages\nYou will need two new packages: one for the new page classes, the other one for test classes:\nCreate a package for page classes\nOpen Eclipse\nUse the &quot;Project Explorer&quot; on the left\nNavigate to [your-project] &#x2192; src/main/java &#x2192; com.capgemini.mrchecker &#x2192; selenium\nRight-click on &quot;selenium&quot;\nClick on &quot;New&quot; &#x2192; New Package\nName the new package &quot;com.capgemini.mrchecker.selenium.pages.[your-product-name]&quot;\nCreate a package for test classes\nNavigate to [your-project] &#x2192; src/test/java &#x2192; com.capgemini.mrchecker &#x2192; selenium\nRight click on &quot;selenium&quot;\nClick on &quot;New&quot; &#x2192; New Package\nName the new package &quot;com.capgemini.mrchecker.selenium.tests.[your-product-name]&quot;\nExample:\n"},{"id":1029,"path":"../website/pages/docs/master-mrchecker.asciidoc_tutorials.html#project-organisation.asciidoc_creating-new-page-classes","type":"docs","title":"Creating new Page Classes","body":"80.1.4. Creating new Page Classes\nNavigate to: [your-project] &#x2192; src/main/java &#x2192; com.capgemini.mrchecker &#x2192; selenium.pages.[your-product-name]\nClick on &quot;New&quot; &#x2192; New Class\nEnter the name &quot;YourPage&quot;\nEvery Page Class should extend BasePage class. Import all necessary packages and override all required methods:\npublic boolean isLoaded() - returns true if the page is loaded and false if not\npublic void load() - loads the page\npublic String pageTitle() - returns page title\nExample:\npublic class MainPage extends BasePage {\n@Override\npublic boolean isLoaded() {\nreturn false;\n}\n@Override\npublic void load() {\nBFLogger.logDebug(&quot;Load &apos;Main Page&apos;&quot;);\n}\n@Override\npublic String pageTitle() {\nreturn &quot;Main Page Title&quot;;\n}\n}\n"},{"id":1030,"path":"../website/pages/docs/master-mrchecker.asciidoc_tutorials.html#project-organisation.asciidoc_creating-new-test-classes","type":"docs","title":"Creating new Test Classes","body":"80.1.5. Creating new Test Classes\nNavigate to [your-project] &#x2192; src/test/java &#x2192; com.capgemini.mrchecker &#x2192; selenium.tests.[your-product-name]\nClick on &quot;New&quot; &#x2192; New Class\nEnter the name &quot;YourCaseTest&quot;\nTest classes should extend BaseTest class, import all necessary packages and override all required methods:\npublic void setUp() - executes before each test\npublic void tearDown() - executes after each test\nOptionally, it is also possible to implement the following methods:\n@BeforeClass\npublic static void setUpBeforeClass() - runs only once before all tests\n@AfterClass\npublic static void tearDownAfterClass() - runs only once after performing all tests\nEvery test method has to be signed with &quot;@Test&quot; parameter.\npublic class YourCaseTest extends BaseTest {\nprivate static MainPage mainPage = new MainPage();\n@BeforeClass\npublic static void setUpBeforeClass() {\nmainPage.load();\n}\n@AfterClass\npublic static void tearDownAfterClass() {\n}\n@Override\npublic void setUp() {\nif (!mainPage.isLoaded()) {\nmainPage.load();\n}\n}\n@Override\npublic void tearDown() {\n}\n@Test\npublic void shouldTestRunWithoutReturningError {\n}\n}\n"},{"id":1031,"path":"../website/pages/docs/master-mrchecker.asciidoc_tutorials.html#project-organisation.asciidoc_running-tests","type":"docs","title":"Running Tests","body":"80.1.6. Running Tests\nRun the test by right-clicking on the test method &#x2192; Run as &#x2192; JUnit test.\n"},{"id":1032,"path":"../website/pages/docs/master-mrchecker.asciidoc_tutorials.html#master-mrchecker.asciidoc_basic-tutorials","type":"docs","title":"Basic Tutorials","body":"80.2. Basic Tutorials\n"},{"id":1033,"path":"../website/pages/docs/master-mrchecker.asciidoc_tutorials.html#master-mrchecker.asciidoc_basic-tests","type":"docs","title":"Basic Tests","body":"80.2.1. Basic Tests\nThe goal of this test is to open A/B Test subpage and redirect to another website.\nSteps:\nOpen The Internet Main Page\nClick A/B Testing link and go to A/B Test subpage\nClick Elemental Selenium link and open it in new tab\nSwitch to Elemental Selenium page and check if it&#x2019;s loaded\nPage Class\nCreate a Page class for AB Testing page. Override all the required methods:\npublic class ABtestPage extends BasePage {\n@Override\npublic boolean isLoaded() {\ngetDriver().waitForPageLoaded();\nreturn getDriver().getCurrentUrl()\n.contains(PageSubURLsProjectYEnum.ABTEST.getValue());\n}\n@Override\npublic void load() {\nBFLogger.logDebug(&quot;Load &apos;A/B Test Control&apos; page.&quot;);\ngetDriver().get(GetEnvironmentParam.THE_INTERNET_MAIN_PAGE.getValue() +\nPageSubURLsProjectYEnum.ABTEST.getValue());\ngetDriver().waitForPageLoaded();\n}\n@Override\npublic String pageTitle() {\nreturn getActualPageTitle();\n}\n}\nHow to use Enum?\nSimilarly as in environmental variables case, create an enum for storing values of subURLs:\npublic enum PageSubURLsProjectYEnum {\nBASIC_AUTH(&quot;basic_auth&quot;),\nNEW_WINDOW(&quot;windows/new&quot;),\nWINDOW(&quot;windows&quot;),\nCHECKBOX(&quot;checkboxes&quot;),\nCONTEXT_MENU(&quot;context_menu&quot;),\nKEY_PRESS(&quot;key_presses&quot;),\nDYNAMIC_CONTENT(&quot;dynamic_content&quot;),\nHOVERS(&quot;hovers&quot;),\nSORTABLE_DATA_TABLES(&quot;tables&quot;),\nREDIRECT(&quot;redirector&quot;),\nJAVASCRIPT_ALERTS(&quot;javascript_alerts&quot;),\nCHALLENGING_DOM(&quot;challenging_dom&quot;),\nSTATUS_CODES(&quot;status_codes&quot;),\nLOGIN(&quot;login&quot;),\nABTEST(&quot;abtest&quot;),\nBROKEN_IMAGES(&quot;broken_images&quot;),\nDROPDOWN(&quot;dropdown&quot;),\nHORIZONTAL_SLIDER(&quot;horizontal_slider&quot;),\nDOWNLOAD(&quot;download&quot;),\nFORGOT_PASSWORD(&quot;forgot_password&quot;),\nFORGOT_PASSWORD_EMAIL_SENT(&quot;email_sent&quot;),\nEXIT_INTENT(&quot;exit_intent&quot;),\nDYNAMIC_LOADING(&quot;dynamic_loading&quot;),\nDISAPPEARING_ELEMENTS(&quot;disappearing_elements&quot;),\nDRAG_AND_DROP(&quot;drag_and_drop&quot;),\nDYNAMIC_CONTROLS(&quot;dynamic_controls&quot;),\nUPLOAD(&quot;upload&quot;),\nFLOATING_MENU(&quot;floating_menu&quot;),\nFRAMES(&quot;frames&quot;),\nGEOLOCATION(&quot;geolocation&quot;),\nINFINITE_SCROLL(&quot;infinite_scroll&quot;),\nJQUERY_UI(&quot;jqueryui/menu&quot;),\nJAVASCRIPT_ERROR(&quot;javascript_error&quot;),\nLARGE_AND_DEEP_DOM(&quot;large&quot;),\nNESTED_FRAMES(&quot;nested_frames&quot;),\nNOTIFICATION_MESSAGE(&quot;notification_message&quot;),\nDOWNLOAD_SECURE(&quot;download_secure&quot;),\nSHIFTING_CONTENT(&quot;shifting_content&quot;),\nSLOW_RESOURCES(&quot;slow&quot;),\nTYPOS(&quot;typos&quot;),\nWYSIWYGEDITOR(&quot;tinymce&quot;);\n/*\n* Sub URLs are used as real locations in the test environment\n*/\nprivate String subURL;\nprivate PageSubURLsProjectYEnum(String subURL) {\nthis.subURL = subURL;\n}\n;\nprivate PageSubURLsProjectYEnum() {\n}\n@Override\npublic String toString() {\nreturn getValue();\n}\npublic String getValue() {\nreturn subURL;\n}\n}\nInstead of mapping data from an external file, you can store and access them directly from the enum class:\nPageSubURLsProjectYEnum.ABTEST.getValue()\nSelector\nIn this test case you need selector for only one page element:\nprivate static final By elementalSeleniumLinkSelector = By.cssSelector(&quot;div &gt; div &gt; a&quot;);\nPage methods\nYou need two methods for performing page actions:\n/**\n* Clicks &apos;Elemental Selenium&apos; link at the bottom of the page.\n*\n* @return ElementalSeleniumPage object.\n*/\npublic ElementalSeleniumPage clickElementalSeleniumLink() {\ngetDriver().findElementDynamic(elementalSeleniumLinkSelector)\n.click();\ngetDriver().waitForPageLoaded();\nreturn new ElementalSeleniumPage();\n}\n/**\n* Switches window to the next one - different than the current.\n*/\npublic void switchToNextTab() {\nArrayList&lt;String&gt; tabsList = new ArrayList&lt;String&gt;(getDriver().getWindowHandles());\ngetDriver().switchTo()\n.window(tabsList.get(1));\n}\nElemental Selenium Page Class\nTo return new Elemental Selenium Page object, implement its class. You only need to write basic methods to check if the page is loaded. There is no need to interact with objects on the site:\npublic class ElementalSeleniumPage extends BasePage {\n@Override\npublic boolean isLoaded() {\ngetDriver().waitForPageLoaded();\nreturn getDriver().getCurrentUrl()\n.contains(GetEnvironmentParam.ELEMENTAL_SELENIUM_PAGE.getValue());\n}\n@Override\npublic void load() {\nBFLogger.logDebug(&quot;Load &apos;Elemental Selenium&apos; page.&quot;);\ngetDriver().get(GetEnvironmentParam.ELEMENTAL_SELENIUM_PAGE.getValue());\ngetDriver().waitForPageLoaded();\n}\n@Override\npublic String pageTitle() {\nreturn getActualPageTitle();\n}\n}\nTest Class\nCreate a Test class and write a @Test method to execute the scenario:\n@Category({ TestsSelenium.class, TestsChrome.class, TestsFirefox.class, TestsIE.class })\npublic class ABtestingTest extends TheInternetBaseTest {\nprivate static ABtestPage abTestPage;\n@Test\npublic void shouldOpenElementalSeleniumPageWhenClickElementalSeleniumLink() {\nlogStep(&quot;Click Elemental Selenium link&quot;);\nElementalSeleniumPage elementalSeleniumPage = abTestPage.clickElementalSeleniumLink();\nlogStep(&quot;Switch browser&apos;s tab to newly opened one&quot;);\nabTestPage.switchToNextTab();\nlogStep(&quot;Verify if Elemental Selenium Page is opened&quot;);\nassertTrue(&quot;Unable to open Elemental Selenium page&quot;, elementalSeleniumPage.isLoaded());\n}\n}\nAssert\nAsserts methods are used for creating test pass or fail conditions. The optional first parameter is a message which will be displayed in the test failure description.\nassertTrue(boolean condition) - test passes if condition returns true\nassertFalse(boolean condition) - test passes if condition returns false\nAlso, add the @BeforeClass method to open the tested page:\n@BeforeClass\npublic static void setUpBeforeClass() {\nabTestPage = shouldTheInternetPageBeOpened().clickABtestingLink();\nlogStep(&quot;Verify if ABTest page is opened&quot;);\nassertTrue(&quot;Unable to open ABTest page&quot;, abTestPage.isLoaded());\n}\n@BeforeClass method executes only once before all other\n@Test cases in the class. There is also a possibility to create a\n@AfterClass method which is performed also once after all @Test cases.\nYou don&#x2019;t need to implement @setUp and @tearDown methods because they&#x2019;re already in TheInternetBaseTest class which you extend.\nCategories\nYou can group tests in categories. It&#x2019;s useful when running many tests at once. Use this parameter:\n@Category({ TestsSelenium.class, TestsChrome.class, TestsFirefox.class, TestsIE.class })\nThen create an interface representing each category. Example:\npublic interface TestsSelenium {\n/* For test which are testing web pages considering UI (user interface) and using selenium webdriver */\n}\nTo run a test from specified category create Test Suite class:\n@RunWith(WildcardPatternSuite.class) //search for test files under /src/test/java\n@IncludeCategories({ TestsChrome.class }) // search all test files with category TestsChrome.class\n@ExcludeCategories({ TestsLocal.class, TestsNONParallel.class }) //exclude all test files with category TestsLocal.class and TestsNONParallel.class\n@SuiteClasses({ &quot;../**/*Test.class&quot; }) //search only test files, where file name ends with &lt;anyChar/s&gt;Test.class\npublic class _TestSuiteChrome {\n}\nYou can run a Test Suite as a JUnit test.\nIn this test case, the goal is to pass username and password authorization and login to the next page.\nSteps:\nOpen The Internet Main Page\nClick on Basic Auth link\nOpen pop-up login window\nEnter valid username and password\nOpen next subpage and verify if the user logged in successfully.\nPage Class\nCreate a page class which represents Basic Auth subpage after proper login.\nOverride all the required methods:\npublic class BasicAuthPage extends BasePage {\npublic BasicAuthPage() {\n}\npublic BasicAuthPage(String login, String password) {\nthis.enterLoginAndPasswordByUrl(login, password);\n}\n@Override\npublic boolean isLoaded() {\nreturn true;\n}\n@Override\npublic void load() {\nBFLogger.logDebug(&quot;load&quot;);\n}\n@Override\npublic String pageTitle() {\nreturn getActualPageTitle();\n}\nIn order to verify a login, create a selector to access the visible message.\nprivate static final By selectorTextMessage = By.cssSelector(&quot;#content &gt; div &gt; p&quot;);\nThen create a method to get message value:\n/**\n* Returns message displayed by system after user&apos;s log in.\n* @return String object representing message displayed by system after user&apos;s log in\n*/\npublic String getMessageValue() {\nreturn getDriver().findElementDynamic(selectorTextMessage)\n.getText();\n}\nAlso, create a method to access the pop-up login window and enter user credentials:\n/**\n* Authenticates user using standard simple authentication popup.\n*\n* @param login User&apos;s login\n* @param password User&apos;s password\n* @throws AWTException\n* @throws InterruptedException\n*/\npublic void enterLoginAndPassword(String login, String password) throws AWTException, InterruptedException {\nRobot rb = new Robot();\nThread.sleep(2000);\nStringSelection username = new StringSelection(login);\nToolkit.getDefaultToolkit()\n.getSystemClipboard()\n.setContents(username, null);\nrb.keyPress(KeyEvent.VK_CONTROL);\nrb.keyPress(KeyEvent.VK_V);\nrb.keyRelease(KeyEvent.VK_V);\nrb.keyRelease(KeyEvent.VK_CONTROL);\nrb.keyPress(KeyEvent.VK_TAB);\nrb.keyRelease(KeyEvent.VK_TAB);\nThread.sleep(2000);\nStringSelection pwd = new StringSelection(password);\nToolkit.getDefaultToolkit()\n.getSystemClipboard()\n.setContents(pwd, null);\nrb.keyPress(KeyEvent.VK_CONTROL);\nrb.keyPress(KeyEvent.VK_V);\nrb.keyRelease(KeyEvent.VK_V);\nrb.keyRelease(KeyEvent.VK_CONTROL);\nrb.keyPress(KeyEvent.VK_ENTER);\nrb.keyRelease(KeyEvent.VK_ENTER);\nThread.sleep(2000);\n}\nRobot class\nCreating a Robot object allows performing basic system actions such as pressing keys, moving the mouse or taking screenshots. In this case, it&#x2019;s used to paste login and password text from the clipboard using &apos;Ctrl + V&apos; shortcut, go to the next field using &apos;Tab&apos; key and submit by clicking &apos;Enter&apos;.\nToolkit\nStatic class Toolkit can perform basic window actions such as scrolling to a specified position or moving context between components. In this case, it&#x2019;s used to set clipboard content to username and password value.\nThread.sleep(long millis)\nWeb drivers like Selenium perform actions much faster than the normal user. This may cause unexpected consequences e.g. some elements may not be loaded before the driver wants to access them. To avoid this problem you can use Thread.sleep(long millis) to wait given time and let browser load wanted component.\nBEWARE: Using Thread.sleep(long millis) is not the recommended approach. Selenium driver gives methods to wait for a specified element to be enabled or visible with a timeout parameter. This is a more stable and effective way. Also, method waitForPageLoaded() will not solve that issue because it only waits for the ready state from the browser while some javascript actions might be performed after that.\nTest Class\nCreate a Test class and write a @Test method to execute the scenario. Save parameters as class fields:\n@Category({ TestsLocal.class, TestsNONParallel.class })\npublic class BasicAuthTest extends TheInternetBaseTest {\nprivate static BasicAuthPage basicAuthPage;\nprivate String login = &quot;admin&quot;;\nprivate String password = &quot;admin&quot;;\nprivate String message = &quot;Congratulations! You must have the proper credentials.&quot;;\n@Test\npublic void shouldUserLogInWithValidCredentials() throws InterruptedException, AWTException {\nbasicAuthPage = shouldTheInternetPageBeOpened().clickBasicAuthLink();\nlogStep(&quot;Enter login and password&quot;);\nbasicAuthPage.enterLoginAndPassword(login, password);\nlogStep(&quot;Verify if user logged in successfully&quot;);\nassertEquals(&quot;Unable to login user with valid credentials&quot;, message,\nbasicAuthPage.getMessageValue());\n}\n@Override\npublic void tearDown() {\nlogStep(&quot;Navigate back to The-Internet page&quot;);\ntheInternetPage.load();\n}\n}\nassertEquals(Object expected, Object actual) - test passes if parameters are equal .\nAlternative scenario:\nThere is also a possibility to log in with credentials as a part of URL: http://login:password@the-internet.herokuapp.com/basic_auth\nAnother page class method:\n/**\n* Authenticates user passing credentials into URL.\n*\n* @param login User&apos;s login\n* @param password User&apos;s password\n*/\nprivate void enterLoginAndPasswordByUrl(String login, String password) {\ngetDriver().get(&quot;http://&quot; + login + &quot;:&quot; + password + &quot;@&quot; + &quot;the-internet.herokuapp.com/&quot; +\nPageSubURLsProjectYEnum.BASIC_AUTH.getValue());\n}\nAnother test class method:\n@Test\npublic void shouldUserLogInWithValidCredentialsSetInURL() {\nlogStep(&quot;Enter user&apos;s credentials into URL to log in&quot;);\nbasicAuthPage = new BasicAuthPage(login, password);\nlogStep(&quot;Verify if user logged in successfully&quot;);\nassertEquals(&quot;Unable to login user with valid credentials&quot;, message,\nbasicAuthPage.getMessageValue());\n}\nAfter running test class as a JUnit test, both test cases will be performed.\nThis test goal is to check the dimensions of broken images on the subpage.\nSteps:\nOpen The Internet Main Page\nClick Broken Image link and go to Broken Image subpage\nGet the 3 images&apos; dimensions and compare them with expected values\nPage Class\nIn this case, create an array of selectors to access images by index number:\npublic class BrokenImagePage extends BasePage {\nprivate static final By[] selectorsImages = { By.cssSelector(&quot;div &gt; img:nth-child(2)&quot;),\nBy.cssSelector(&quot;div &gt; img:nth-child(3)&quot;),\nBy.cssSelector(&quot;div &gt; img:nth-child(4)&quot;) };\n@Override\npublic boolean isLoaded() {\ngetDriver().waitForPageLoaded();\nreturn getDriver().getCurrentUrl()\n.contains(PageSubURLsProjectYEnum.BROKEN_IMAGES.getValue());\n}\n@Override\npublic void load() {\nBFLogger.logDebug(&quot;Load &apos;Broken Images&apos; page.&quot;);\ngetDriver().get(GetEnvironmentParam.THE_INTERNET_MAIN_PAGE.getValue() +\nPageSubURLsProjectYEnum.BROKEN_IMAGES.getValue());\ngetDriver().waitForPageLoaded();\n}\n@Override\npublic String pageTitle() {\nreturn getActualPageTitle();\n}\n/**\n* Returns an image height in pixels.\n*\n* @param imageIndex An index of given image.\n* @return Height of an image in pixels.\n*/\npublic int getImageHeight(int imageIndex) {\nreturn getImageDimension(imageIndex).getHeight();\n}\n/**\n* Returns an image width in pixels.\n*\n* @param imageIndex An index of given image.\n* @return Width of an image in pixels.\n*/\npublic int getImageWidth(int imageIndex) {\nreturn getImageDimension(imageIndex).getWidth();\n}\nprivate Dimension getImageDimension(int imageIndex) {\nreturn getDriver().findElementDynamic(selectorsImages[imageIndex])\n.getSize();\n}\n}\nTest Class\nCreate @Test and @BeforeClass methods. Save expected images&apos; dimensions in class fields:\n@Category({ TestsSelenium.class, TestsChrome.class, TestsFirefox.class, TestsIE.class })\npublic class BrokenImagesTest extends TheInternetBaseTest {\nprivate static BrokenImagePage brokenImagePage;\nprivate final int expectedHeight = 90;\nprivate final int expectedWidth = 120;\n@BeforeClass\npublic static void setUpBeforeClass() {\nbrokenImagePage = shouldTheInternetPageBeOpened().clickBrokenImageLink();\nlogStep(&quot;Verify if Broken Image page is opened&quot;);\nassertTrue(&quot;Unable to open Broken Image page&quot;, brokenImagePage.isLoaded());\n}\n@Test\npublic void shouldImageSizesBeEqualToExpected() {\nfor (int i = 0; i &lt; 3; i++) {\nlogStep(&quot;Verify size of image with index: &quot; + i);\nassertEquals(&quot;Height of image with index: &quot; + i + &quot; is incorrect&quot;, expectedHeight,\nbrokenImagePage.getImageHeight(i));\nassertEquals(&quot;Width of image with index: &quot; + i + &quot; is incorrect&quot;, expectedWidth,\nbrokenImagePage.getImageWidth(i));\n}\n}\n}\nThe test will pass if every image had the correct width and height.\nThis case goal is to find out how to create stable selectors.\nIn the browser&#x2019;s developer mode, you can see how the page is built. Notice, that buttons&apos; IDs change after click and values in the table haven&#x2019;t got unique attributes, which might be helpful in order to find them.\nDOM - Document Object Model\nHTML DOM is a model of the page created by the browser. The page could be represented as the tree of objects. Read more.\nTo create locators you can use element attributes such as id, class name etc.\nIt this case, since there are no unique attributes, the best approach is to use HTML document structure and identify page elements by their place in an object hierarchy.\nPage Class\npublic class ChallengingDomPage extends BasePage {\nprivate final By selectorTableRows = By.cssSelector(&quot;.large-10 &gt; table &gt; tbody &gt; tr&quot;);\nprivate final By selectorFirstButton = By.cssSelector(&quot;.large-2.columns &gt; .button:nth-\nchild(1)&quot;);\n@Override\npublic boolean isLoaded() {\ngetDriver().waitForPageLoaded();\nreturn getDriver().getCurrentUrl()\n.contains(PageSubURLsProjectYEnum.CHALLENGING_DOM.getValue());\n}\n@Override\npublic void load() {\nBFLogger.logDebug(&quot;Load &apos;Challenging DOM&apos; page.&quot;);\ngetDriver().get(GetEnvironmentParam.THE_INTERNET_MAIN_PAGE.getValue() +\nPageSubURLsProjectYEnum.CHALLENGING_DOM.getValue());\ngetDriver().waitForPageLoaded();\n}\n@Override\npublic String pageTitle() {\nreturn getActualPageTitle();\n}\n/**\n* Returns table text content as a list of String objects.\n*\n* @return A list of table values.\n*/\npublic List&lt;String&gt; getTableValues() {\nreturn JsoupHelper.findTexts(selectorTableRows);\n}\n/**\n* Clicks top button on the page from available button set.\n*/\npublic void clickFirstButton() {\ngetDriver().elementButton(selectorFirstButton)\n.click();\ngetDriver().waitForPageLoaded();\n}\n}\nJsoup Helper\nJsoup Helper is the tool which helps to parse HTML document and get searched values. This is especially useful when values are organized in a generic structure such as a table.\nJsoupHelper.findTexts(By selector) - this method returns text content of a table as a list of Strings\nTest Class\nSteps:\nOpen The Internet Main Page\nClick Challenging DOM link and go to Challenging DOM subpage\nGet and save table values\nClick the first button\nGet table values again\nCompare table values before and after button click\n@Category({ TestsSelenium.class, TestsChrome.class, TestsFirefox.class, TestsIE.class })\npublic class ChallengingDomTest extends TheInternetBaseTest {\nprivate static ChallengingDomPage challengingDomPage;\n@BeforeClass\npublic static void setUpBeforeClass() {\nchallengingDomPage = shouldTheInternetPageBeOpened().clickChallengingDomLink();\nlogStep(&quot;Verify if Challenging Dom page is opened&quot;);\nassertTrue(&quot;Unable to open Challenging Dom page&quot;, challengingDomPage.isLoaded());\n}\n@Test\npublic void shouldValuesInTableCellsStayUnchangedAfterClick() {\nlogStep(&quot;Get table values (before click any button)&quot;);\nList&lt;String&gt; tableValuesBeforeClick = challengingDomPage.getTableValues();\nlogStep(&quot;Click first button&quot;);\nchallengingDomPage.clickFirstButton();\nlogStep(&quot;Get table values (after click first button)&quot;);\nList&lt;String&gt; tableValuesAfterClick = challengingDomPage.getTableValues();\nlogStep(&quot;Verify equality of table values before and after click&quot;);\nassertEquals(&quot;Values from table cells were changed after click&quot;, tableValuesBeforeClick,\ntableValuesAfterClick);\n}\n}\nBecause values in the table don&#x2019;t change, the test should pass if object locators are solid.\nIn this example, you will learn how to test checkboxes on the page.\nA checkbox is a simple web element which can be selected or unselected by clicking on it.\nSteps:\nOpen The Internet Main Page\nClick Checkboxes link and go to Checkboxes page\nTest if the first checkbox is unchecked\nSelect the first checkbox\nTest if the first checkbox is checked\nTest if the second checkbox is checked\nUnselect second checkbox\nTest if the second checkbox is unchecked\nPage Class\nBecause both checkboxes are in one form, it&#x2019;s possible to locate them by one selector and then access each individual one by index.\npublic class CheckboxesPage extends BasePage {\nprivate final static By checkboxesFormSelector = By.cssSelector(&quot;#checkboxes&quot;);\n@Override\npublic boolean isLoaded() {\ngetDriver().waitForPageLoaded();\nreturn getDriver().getCurrentUrl()\n.contains(PageSubURLsProjectYEnum.CHECKBOX.getValue());\n}\n@Override\npublic void load() {\nBFLogger.logDebug(&quot;Load &apos;Checkboxes&apos; page.&quot;);\ngetDriver().get(GetEnvironmentParam.THE_INTERNET_MAIN_PAGE.getValue() +\nPageSubURLsProjectYEnum.CHECKBOX.getValue());\ngetDriver().waitForPageLoaded();\n}\n@Override\npublic String pageTitle() {\nreturn getActualPageTitle();\n}\n/**\n* Verifies if checkbox form is visible on the page.\n*\n* @return true if checkboxes are present and displayed on the page\n*/\npublic boolean isElementCheckboxesFormVisible() {\nreturn getDriver().elementCheckbox(checkboxesFormSelector)\n.isDisplayed();\n}\n/**\n* Verifies if given checkbox is selected or not.\n*\n* @param index The index of given checkbox\n* @return true if given checkbox is selected\n*/\npublic boolean isCheckboxSelected(int index) {\nreturn getDriver().elementCheckbox(checkboxesFormSelector)\n.isCheckBoxSetByIndex(index);\n}\n/**\n* Selects given checkbox. Unselects, if it is already selected.\n*\n* @param index The index of given checkbox\n*/\npublic void selectCheckbox(int index) {\nCheckBox checkbox = getDriver().elementCheckbox(checkboxesFormSelector);\nif (isCheckboxSelected(index)) {\ncheckbox.unsetCheckBoxByIndex(index);\n} else {\ncheckbox.setCheckBoxByIndex(index);\n}\n}\n}\nCheckBox\nCheckBox class contains a method to perform actions on checkboxes such as setting and unsetting or verifying if the specified box is checked.\nUse method elementCheckbox(By selector) to create CheckBox Object.\nTest Class\n@Category({ TestsSelenium.class, TestsChrome.class, TestsFirefox.class, TestsIE.class })\npublic class CheckboxesTest extends TheInternetBaseTest {\nprivate static CheckboxesPage checkboxesPage;\n@Override\npublic void setUp() {\ncheckboxesPage = shouldTheInternetPageBeOpened().clickCheckboxesLink();\nlogStep(&quot;Verify if Checkboxes page is opened&quot;);\nassertTrue(&quot;Unable to open Checkboxes page&quot;, checkboxesPage.isLoaded());\n}\n@Test\npublic void shouldCheckboxBeSelectedAfterClick() {\nlogStep(&quot;Verify if first checkbox is not selected&quot;);\nassertFalse(&quot;The checkbox is selected&quot;, checkboxesPage.isCheckboxSelected(0));\nlogStep(&quot;Select first checkbox&quot;);\ncheckboxesPage.selectCheckbox(0);\nlogStep(&quot;Verify if first checkbox is selected&quot;);\nassertTrue(&quot;The checkbox is not selected&quot;, checkboxesPage.isCheckboxSelected(0));\n}\n@Test\npublic void shouldCheckboxBeUnselectedAfterClick() {\nlogStep(&quot;Verify if second checkbox is selected&quot;);\nassertTrue(&quot;The checkbox is not selected&quot;, checkboxesPage.isCheckboxSelected(1));\nlogStep(&quot;Select second checkbox&quot;);\ncheckboxesPage.selectCheckbox(1);\nlogStep(&quot;Verify if second checkbox is not selected&quot;);\nassertFalse(&quot;The checkbox is selected&quot;, checkboxesPage.isCheckboxSelected(1));\n}\n}\nAfter running Test Class both @Test cases will be performed. Before each one, overrode setUp method will be executed.\nThis case will show how to test changing website content.\nAfter refreshing page (F5) a few times, a new element should appear:\nThen, after another couple of refreshes, it should disappear.\nYou can check in developer mode that Gallery element does not exist in HTML document either, until appearing on the page. The element is created by Javascript.\nSteps:\nLoad The Internet Main Page\nClick Disappearing Elements link and go to that subpage\nCheck if Menu Buttons exist on the page\nRefresh the page until a new element appears\nCheck if Gallery Button exists\nCheck if the number of buttons equals the expected value\nRefresh the page until an element disappears\nCheck if Gallery Button does not exist\nCheck if the number of buttons is smaller than before\nPage Class\npublic class DisappearingElementsPage extends BasePage {\nprivate static final By selectorGalleryMenuButton = By.cssSelector(&quot;li &gt; a[href*=gallery]&quot;);\nprivate static final By selectorMenuButtons = By.cssSelector(&quot;li&quot;);\n@Override\npublic boolean isLoaded() {\ngetDriver().waitForPageLoaded();\nreturn getDriver().getCurrentUrl()\n.contains(PageSubURLsProjectYEnum.DISAPPEARING_ELEMENTS.getValue());\n}\n@Override\npublic void load() {\nBFLogger.logDebug(&quot;Load &apos;Disappearing Elements&apos; page.&quot;);\ngetDriver().get(GetEnvironmentParam.THE_INTERNET_MAIN_PAGE.getValue() +\nPageSubURLsProjectYEnum.DISAPPEARING_ELEMENTS.getValue());\ngetDriver().waitForPageLoaded();\n}\n@Override\npublic String pageTitle() {\nreturn getActualPageTitle();\n}\n/**\n* Returns a number of WebElements representing menu buttons.\n*\n* @return A number of WebElements.\n*/\npublic int getNumberOfMenuButtons() {\nreturn getDriver().findElementDynamics(selectorMenuButtons)\n.size();\n}\n/**\n* Returns WebElement representing disappearing element of menu.\n*\n* @return Disappearing WebElement if visible, null otherwise.\n*/\npublic WebElement getGalleryMenuElement() {\nreturn getDriver().findElementQuietly(selectorGalleryMenuButton);\n}\n/**\n* Refreshes web page as many times as it is required to appear/disappear menu button\n* WebElement.\n*\n* @param shouldAppear Determines if element should appear (true) or disappear (false).\n*/\npublic void refreshPageUntilWebElementAppears(boolean shouldAppear) {\nint numberOfAttempts = 5;\nint counter = 0;\nwhile (!isVisibilityAsExpected(shouldAppear) || isMaxNumberOfAttemptsReached(counter++,\nnumberOfAttempts)) {\nrefreshPage();\n}\n}\n/**\n* Verify if visibility of Gallery button is the same as expected\n*\n* @param expected Determines if element should be visible (true) or not visible (false).\n*/\nprivate boolean isVisibilityAsExpected(boolean expected) {\nboolean isVisibilityDifferentThanExpected = isGalleryMenuElementVisible() ^ expected;\nreturn !isVisibilityDifferentThanExpected;\n}\nprivate boolean isGalleryMenuElementVisible() {\nboolean result = false;\nWebElement gallery = getGalleryMenuElement();\nif (gallery != null)\nresult = gallery.isDisplayed();\nreturn result;\n}\nprivate boolean isMaxNumberOfAttemptsReached(int attemptNo, int maxNumberOfAttempts) {\nreturn attemptNo == maxNumberOfAttempts;\n}\n}\nfindElementQuietly(By selector) works similar as findElementDynamics(By selector) but won&#x2019;t throw an exception if an element wasn&#x2019;t found. In this case, the searched WebElement will have a NULL value.\nTest Class\n@Category({ TestsSelenium.class, TestsChrome.class, TestsFirefox.class, TestsIE.class })\npublic class DisappearingElementsTest extends TheInternetBaseTest {\nprivate static final int totalNumberOfMenuButtons = 5;\nprivate static DisappearingElementsPage disappearingElementsPage;\nprivate static int numberOfMenuButtons = 0;\n@BeforeClass\npublic static void setUpBeforeClass() {\ndisappearingElementsPage = shouldTheInternetPageBeOpened().clickDisappearingElementsLink();\nlogStep(&quot;Verify if Disappearing Elements page is opened&quot;);\nassertTrue(&quot;Unable to open Disappearing Elements page&quot;,\ndisappearingElementsPage.isLoaded());\nlogStep(&quot;Verify if menu button elements are visible&quot;);\nnumberOfMenuButtons = disappearingElementsPage.getNumberOfMenuButtons();\nassertTrue(&quot;Unable to display menu&quot;, numberOfMenuButtons &gt; 0);\n}\n@Test\npublic void shouldMenuButtonElementAppearAndDisappearAfterRefreshTest() {\nlogStep(&quot;Click refresh button until menu button appears&quot;);\ndisappearingElementsPage.refreshPageUntilWebElementAppears(true);\nlogStep(&quot;Verify if menu button element appeared&quot;);\nassertNotNull(&quot;Unable to disappear menu button element&quot;,\ndisappearingElementsPage.getGalleryMenuElement());\nassertEquals(&quot;The number of button elements after refresh is incorrect&quot;,\ntotalNumberOfMenuButtons, disappearingElementsPage.getNumberOfMenuButtons());\nlogStep(&quot;Click refresh button until menu button disappears&quot;);\ndisappearingElementsPage.refreshPageUntilWebElementAppears(false);\nlogStep(&quot;Verify if menu button element disappeared&quot;);\nassertNull(&quot;Unable to appear menu button element&quot;,\ndisappearingElementsPage.getGalleryMenuElement());\nassertTrue(&quot;The number of button elements after refresh is incorrect&quot;,\ntotalNumberOfMenuButtons &gt; disappearingElementsPage.getNumberOfMenuButtons());\n}\n}\nassertNull(Objetc object) - test passes if Object returns NULL\nassertNotNull(Objetc object) - test passes if Object does not return NULL\nThis case shows how to move draggable elements on the page.\nimage::images/example13.png[]\nTry to move A to B position and see what happens. Also, open browser developer mode and see how the DOM changes.\nThe page can easily be broken. You can try to do so and check how the page structure changed in browser developer mode.\nSteps:\nOpen The Internet Main Page\nClick Drag and Drop link and open subpage\nCheck if the Drag and Drop message is visible\nCheck if element A is in container A and B in container B\nMove element A to position B\nCheck if element A is in container B and B in container A\nMove element B to position A\nAgain check if element A is in container A and B in container B\nPage Class\npublic class DragAndDropPage extends BasePage {\nprivate static final By selectorDragAndDropText = By.cssSelector(&quot;div#content h3&quot;);\nprivate static final By selectorAElementContainer = By.cssSelector(&quot;div#column-a&quot;);\nprivate static final By selectorBElementContainer = By.cssSelector(&quot;div#column-b&quot;);\nprivate static final By selectorDescriptionElement = By.cssSelector(&quot;header&quot;);\nprivate static final String dndHelperPath = &quot;src/test/resources/js/drag_and_drop_helper.js&quot;;\n@Override\npublic boolean isLoaded() {\ngetDriver().waitForPageLoaded();\nreturn getDriver().getCurrentUrl()\n.contains(PageSubURLsProjectYEnum.DRAG_AND_DROP.getValue());\n}\n@Override\npublic void load() {\nBFLogger.logDebug(&quot;Load &apos;Drag and Drop&apos; page.&quot;);\ngetDriver().get(GetEnvironmentParam.THE_INTERNET_MAIN_PAGE.getValue() + PageSubURLsProjectYEnum.DRAG_AND_DROP.getValue());\ngetDriver().waitForPageLoaded();\n}\n@Override\npublic String pageTitle() {\nreturn getActualPageTitle();\n}\n/**\n* Returns information if drag and drop message is visible or not.\n*\n* @return true if exit drag and drop message was found on web page.\n*/\npublic boolean isDragAndDropMessageVisible() {\nreturn getDriver().findElementDynamic(selectorDragAndDropText)\n.isDisplayed();\n}\n/**\n* Verifies if specified element is placed in designated container.\n*\n* @param element WebElement to be verified.\n* @return true if element described as A exists in container A or element B exists in container B, false otherwise.\n*/\npublic boolean isElementPlacedInCorrectContainer(String element) {\nreturn getDescriptionElement(findElementByDescription(element)).getText()\n.equals(element);\n}\nprivate WebElement findElementByDescription(String element) {\nWebElement result;\nswitch (element) {\ncase &quot;A&quot;:\nresult = getContainerElement(selectorAElementContainer);\nbreak;\ncase &quot;B&quot;:\nresult = getContainerElement(selectorBElementContainer);\nbreak;\ndefault:\nresult = null;\nBFLogger.logDebug(&quot;Chosen element doesn&apos;t exist on web page&quot;);\n}\nreturn result;\n}\nprivate WebElement getContainerElement(By container) {\nreturn getDriver().findElementDynamic(container);\n}\nprivate WebElement getDescriptionElement(WebElement container) {\nreturn container.findElement(selectorDescriptionElement);\n}\n/**\n* Drags element to designated container and drops it.\n*\n* @param element String describing WebElement expected to be dragged.\n* @param from String describing WebElement representing container of element expected to be dragged.\n* @param destinationDesc String describing WebElement representing destination container where other element will be dragged.\n*/\npublic void dragElementToPosition(String element, String from, String destinationDesc) {\nWebElement source = findElementByDescription(from);\nWebElement description = getDescriptionElement(source);\nWebElement destination = findElementByDescription(destinationDesc);\nif (description.getText()\n.equals(element))\ndragElement(source, destination);\n}\n}\nSince HTML5, normal Selenium drag-and-drop action stopped working, thus it&#x2019;s necessary to execute Javascript which performs the drag-and-drop. To do so, create a JavascriptExecutor object, then read the script from a file drag_and_drop_helper.js and execute it with additional arguments using method executeScript(String script).\nAn example drag-and-drop solution:\n/**\n* Drags and drops given WebElement to it&apos;s destination location.\n* &lt;p&gt;\n* Since HTML5 all Selenium Actions performing drag and drop operations stopped working as expected, e.g.\n* original implementation, which was:\n* &lt;code&gt;\n* BasePage.getAction()\n* .clickAndHold(draggable)\n* .moveToElement(target)\n* .release()\n* .build()\n* .perform();\n* &lt;/code&gt;\n* finishes with no effect. For this reason, there is javaScript function used, to make sure that\n* drag and drop operation will be successful.\n* JavaScript function is stored under the following path: &apos;src/test/resources/js/drag_and_drop_helper.js&apos;.\n* Original source of the script:\n* &lt;a href=&quot;https://gist.github.com/rcorreia/2362544&quot;&gt;drag_and_drop_helper&lt;/a&gt;\n* &lt;/p&gt;\n*\n* @param draggable A WebElement to be dragged and dropped.\n* @param target A destination, where element will be dropped.\n* @see JavascriptExecutor\n* @see Actions\n*/\nprivate void dragElement(WebElement draggable, WebElement target) {\nJavascriptExecutor js;\nINewWebDriver driver = getDriver();\nList&lt;String&gt; fileContent;\nString draggableId = draggable.getAttribute(&quot;id&quot;);\nString targetId = target.getAttribute(&quot;id&quot;);\nString script = null;\nif (draggable.getAttribute(&quot;draggable&quot;)\n.contains(&quot;true&quot;)) {\nif (driver instanceof JavascriptExecutor) {\njs = (JavascriptExecutor) driver;\nPath path = Paths.get(dndHelperPath);\ntry {\nfileContent = Files.readAllLines(path);\nscript = fileContent.stream()\n.collect(Collectors.joining());\n} catch (IOException e) {\nBFLogger.logDebug(&quot;Unable to read file content: &quot; + e.getMessage());\n}\nif (script != null &amp;&amp; !script.isEmpty()) {\nString arguments = &quot;$(&apos;#%s&apos;).simulateDragDrop({ dropTarget: &apos;#%s&apos;});&quot;;\njs.executeScript(script + String.format(arguments, draggableId, targetId));\n}\n}\n}\n}\nDrag and Drop helper file:\n(function( $ ) {\n$.fn.simulateDragDrop = function(options) {\nreturn this.each(function() {\nnew $.simulateDragDrop(this, options);\n});\n};\n$.simulateDragDrop = function(elem, options) {\nthis.options = options;\nthis.simulateEvent(elem, options);\n};\n$.extend($.simulateDragDrop.prototype, {\nsimulateEvent: function(elem, options) {\n/*Simulating drag start*/\nvar type = &apos;dragstart&apos;;\nvar event = this.createEvent(type);\nthis.dispatchEvent(elem, type, event);\n/*Simulating drop*/\ntype = &apos;drop&apos;;\nvar dropEvent = this.createEvent(type, {});\ndropEvent.dataTransfer = event.dataTransfer;\nthis.dispatchEvent($(options.dropTarget)[0], type, dropEvent);\n/*Simulating drag end*/\ntype = &apos;dragend&apos;;\nvar dragEndEvent = this.createEvent(type, {});\ndragEndEvent.dataTransfer = event.dataTransfer;\nthis.dispatchEvent(elem, type, dragEndEvent);\n},\ncreateEvent: function(type) {\nvar event = document.createEvent(&quot;CustomEvent&quot;);\nevent.initCustomEvent(type, true, true, null);\nevent.dataTransfer = {\ndata: {\n},\nsetData: function(type, val){\nthis.data[type] = val;\n},\ngetData: function(type){\nreturn this.data[type];\n}\n};\nreturn event;\n},\ndispatchEvent: function(elem, type, event) {\nif(elem.dispatchEvent) {\nelem.dispatchEvent(event);\n}else if( elem.fireEvent ) {\nelem.fireEvent(&quot;on&quot;+type, event);\n}\n}\n});\n})(jQuery);\nTest Class\n@Category({ TestsSelenium.class, TestsChrome.class, TestsFirefox.class, TestsIE.class })\npublic class DragAndDropTest extends TheInternetBaseTest {\nprivate static final String ELEMENT_A = &quot;A&quot;;\nprivate static final String CONTAINER_A = &quot;A&quot;;\nprivate static final String ELEMENT_B = &quot;B&quot;;\nprivate static final String CONTAINER_B = &quot;B&quot;;\nprivate static DragAndDropPage dragAndDropPage;\n@BeforeClass\npublic static void setUpBeforeClass() {\ndragAndDropPage = shouldTheInternetPageBeOpened().clickDragAndDropLink();\nlogStep(&quot;Verify if Drag And Drop page is opened&quot;);\nassertTrue(&quot;Unable to open Drag And Drop page&quot;, dragAndDropPage.isLoaded());\nlogStep(&quot;Verify if Drag And Drop message is visible&quot;);\nassertTrue(&quot;Drag And Drop message is not visible&quot;, dragAndDropPage.isDragAndDropMessageVisible());\n}\n@Test\npublic void shouldDraggableElementBeMovedAndDropped() {\nlogStep(&quot;Verify if elements are placed in proper containers&quot;);\nassertTrue(&quot;Element A doesn&apos;t exist in container A&quot;, dragAndDropPage.isElementPlacedInCorrectContainer(ELEMENT_A));\nassertTrue(&quot;Element B doesn&apos;t exist in container B&quot;, dragAndDropPage.isElementPlacedInCorrectContainer(ELEMENT_B));\nlogStep(&quot;Step 7: Drag and drop element A into container B&quot;);\ndragAndDropPage.dragElementToPosition(ELEMENT_A, CONTAINER_A, CONTAINER_B);\nlogStep(&quot;Step 8: Verify if elements are placed in improper containers&quot;);\nassertFalse(&quot;Element A doesn&apos;t exist in container B&quot;, dragAndDropPage.isElementPlacedInCorrectContainer(ELEMENT_A));\nassertFalse(&quot;Element B doesn&apos;t exist in container A&quot;, dragAndDropPage.isElementPlacedInCorrectContainer(ELEMENT_B));\nlogStep(&quot;Drag and drop element B back into container B&quot;);\ndragAndDropPage.dragElementToPosition(ELEMENT_A, CONTAINER_B, CONTAINER_A);\nlogStep(&quot;Verify if elements are placed in proper containers&quot;);\nassertTrue(&quot;Element A doesn&apos;t exist in container A&quot;, dragAndDropPage.isElementPlacedInCorrectContainer(ELEMENT_A));\nassertTrue(&quot;Element B doesn&apos;t exist in container B&quot;, dragAndDropPage.isElementPlacedInCorrectContainer(ELEMENT_B));\n}\n}\nThis example shows how to select an element from the dropdown list.\nCheck in the developer mode how a Dropdown List&#x2019;s content has been organized.\nNotice that the Dropdown Options have different attributes, such as &quot;disabled&quot; or &quot;selected&quot;.\nSteps:\nOpen The Internet Main Page\nClick the Dropdown link and go to the subpage\nSelect first dropdown Option\nCheck if Option 1 is selected\nSelect second dropdown Option\nCheck if Option 2 is selected\nPage Class\npublic class DropdownPage extends BasePage {\nprivate static final By dropdownListSelector = By.cssSelector(&quot;#dropdown&quot;);\n@Override\npublic boolean isLoaded() {\ngetDriver().waitForPageLoaded();\nreturn getDriver().getCurrentUrl()\n.contains(PageSubURLsProjectYEnum.DROPDOWN.getValue());\n}\n@Override\npublic void load() {\nBFLogger.logDebug(&quot;Load &apos;Dropdown List&apos; page.&quot;);\ngetDriver().get(GetEnvironmentParam.THE_INTERNET_MAIN_PAGE.getValue() +\nPageSubURLsProjectYEnum.DROPDOWN.getValue());\ngetDriver().waitForPageLoaded();\n}\n@Override\npublic String pageTitle() {\nreturn getActualPageTitle();\n}\n/**\n* Selects doropdown&apos;s value by given index.\n*\n* @param index Index of option to be selected\n*/\npublic void selectDropdownValueByIndex(int index) {\ngetDriver().elementDropdownList(dropdownListSelector)\n.selectDropdownByIndex(index);\n}\n/**\n* Returns text value of first selected dropdown&apos;s option.\n*\n* @return String object representing value of dropdown&apos;s option\n*/\npublic String getSelectedDropdownValue() {\nreturn getDriver().elementDropdownList(dropdownListSelector)\n.getFirstSelectedOptionText();\n}\n}\nDropdownListElement class\nDropdownListElement is MrChecker&#x2019;s class, which contains methods for performing the dropdown list of actions:\nelementDropdownList() - returns DropdownListElement Object\nTest Class\n@Category({ TestsSelenium.class, TestsChrome.class, TestsFirefox.class, TestsIE.class })\npublic class DropdownTest extends TheInternetBaseTest {\nprivate static final String expectedFirstOptionValue = &quot;Option 1&quot;;\nprivate static final String expectedSecondOptionValue = &quot;Option 2&quot;;\nprivate static DropdownPage dropdownPage;\n@BeforeClass\npublic static void setUpBeforeClass() {\ndropdownPage = shouldTheInternetPageBeOpened().clickDropdownLink();\nlogStep(&quot;Verify if Dropdown page is opened&quot;);\nassertTrue(&quot;Unable to open Dropdown page&quot;, dropdownPage.isLoaded());\n}\n@Test\npublic void shouldGetExpectedDropdownTextOptionAfterSelection() {\nlogStep(&quot;Select first drodown option&quot;);\ndropdownPage.selectDropdownValueByIndex(1);\nlogStep(&quot;Verify if selected option text is equal to the expected one&quot;);\nassertEquals(&quot;Selected value is different than expected&quot;, expectedFirstOptionValue,\ndropdownPage.getSelectedDropdownValue());\nlogStep(&quot;Select first drodown option&quot;);\ndropdownPage.selectDropdownValueByIndex(2);\nlogStep(&quot;Verify if selected option text is equal to the expected one&quot;);\nassertEquals(&quot;Selected value is different than expected&quot;, expectedSecondOptionValue,\ndropdownPage.getSelectedDropdownValue());\n}\n}\nThis case shows how to compare dynamic content.\nNote that after site refresh, some of the content is different. You can see in the browser&#x2019;s developer mode how the text and image sources are being changed.\nSteps:\nOpen The Internet Main Page\nClick Dynamic Content link and load subpage\nSave page images sources and descriptions before the refresh\nRefresh page\nSave page images sources and it&#x2019;s descriptions after refresh\nCompare page content before and after refresh and verify if it&#x2019;s different\nPage Class\npublic class DynamicContentPage extends BasePage {\nprivate static final By imagesLinksSelector = By.cssSelector(&quot;div#content &gt; div.row img&quot;);\nprivate static final By imagesDescriptionsSelector = By.cssSelector(&quot;div#content &gt; div.row div.large-10&quot;);\n@Override\npublic boolean isLoaded() {\ngetDriver().waitForPageLoaded();\nreturn getDriver().getCurrentUrl()\n.contains(PageSubURLsProjectYEnum.DYNAMIC_CONTENT.getValue());\n}\n@Override\npublic void load() {\nBFLogger.logDebug(&quot;Load &apos;Dynamic Content&apos; page.&quot;);\ngetDriver().get(GetEnvironmentParam.THE_INTERNET_MAIN_PAGE.getValue() +\nPageSubURLsProjectYEnum.DYNAMIC_CONTENT.getValue());\ngetDriver().waitForPageLoaded();\n}\n@Override\npublic String pageTitle() {\nreturn getActualPageTitle();\n}\n/**\n* Returns list of picture descriptions being present on the web page.\n*\n* @return List of String objects representing descriptions\n*/\npublic List&lt;String&gt; getDescriptions() {\nreturn new ListElements(imagesDescriptionsSelector).getTextList();\n}\n/**\n* Returns a list of image links being present on the web page.\n*\n* @return List of String objects representing paths to pictures\n*/\npublic List&lt;String&gt; getImageLinks() {\nreturn new ListElements(imagesLinksSelector)\n.getList()\n.stream()\n.map(element -&gt; element.getAttribute(&quot;src&quot;))\n.collect(Collectors.toList());\n}\n}\nListElements\nListElements is MrChecker collection which can store WebElement Objects. Constructing ListElements with cssSelector allows you to store every element on the page which fits the selector. Example methods:\ngetList() - returns WebElements list,\ngetTextList() - returns list of contents of each Element,\ngetSize() - returns number of stored Elements\nIn getImageLinks() example it&apos;s shown how to get a list of specified Elements&apos; attributes.\nTest Class\n@Category({ TestsSelenium.class, TestsChrome.class, TestsFirefox.class, TestsIE.class })\npublic class DynamicContentTest extends TheInternetBaseTest {\nprivate static DynamicContentPage dynamicContentPage;\n@BeforeClass\npublic static void setUpBeforeClass() {\ndynamicContentPage = shouldTheInternetPageBeOpened().clickDynamicContentLink();\nlogStep(&quot;Verify if Dynamic Content page is opened&quot;);\nassertTrue(&quot;Unable to open Dynamic Content page&quot;, dynamicContentPage.isLoaded());\n}\n@Test\npublic void shouldImagesAndDescriptionsDifferAfterRefresh() {\nlogStep(&quot;Read images and descriptions before refresh&quot;);\nList&lt;String&gt; descriptionsBeforeRefresh = dynamicContentPage.getDescriptions();\nList&lt;String&gt; imagesBeforeRefresh = dynamicContentPage.getImageLinks();\nlogStep(&quot;Refres page&quot;);\ndynamicContentPage.refreshPage();\nassertTrue(&quot;The Dynamic Content page hasn&apos;t been refreshed&quot;, dynamicContentPage.isLoaded());\nlogStep(&quot;Read images and descriptions after refresh&quot;);\nList&lt;String&gt; descriptionsAfterRefresh = dynamicContentPage.getDescriptions();\nList&lt;String&gt; imagesAfterRefresh = dynamicContentPage.getImageLinks();\nlogStep(&quot;Verify if descriptions are different after refresh&quot;);\nassertEquals(&quot;Different number of descriptions before and after refresh&quot;,\ndescriptionsAfterRefresh.size(), descriptionsBeforeRefresh.size());\nboolean diversity = false;\nfor (int i = 0; i &lt; descriptionsAfterRefresh.size(); i++) {\nif (!descriptionsAfterRefresh.get(i)\n.equals(descriptionsBeforeRefresh.get(i))) {\ndiversity = true;\nbreak;\n}\n}\nassertTrue(&quot;There are no differences between descriptions before and after refresh&quot;,\ndiversity);\nlogStep(&quot;Verify if images are different after refresh&quot;);\nassertEquals(&quot;Different number of descriptions before and after refresh&quot;,\nimagesAfterRefresh.size(), imagesBeforeRefresh.size());\ndiversity = false;\nfor (int i = 0; i &lt; imagesAfterRefresh.size(); i++) {\nif (!imagesAfterRefresh.get(i)\n.equals(imagesBeforeRefresh.get(i))) {\ndiversity = true;\nbreak;\n}\n}\nassertTrue(&quot;There are no differences between images before and after refresh&quot;, diversity);\n}\n}\nIn the test method, during differences verification, the goal is to compare every element from the first and second list and find first diversity.\nThis example shows how to test a page with dynamically loading content. Some elements don&#x2019;t load during page loading, but during JavaScript execution.\nGo to Example 1:\nClick &quot;start&quot; and see what happens:\nWhen loading ends, you should see the following message:\nIn the developer mode, you can see that the element with the &quot;Hello World!&quot; message exists in page DOM but it&#x2019;s not displayed. However, the loading bar does not exist there - it&#x2019;s created by JavaScript. The script is also visible in developer mode:\nAfter clicking the &quot;Start&quot; button, the element &quot;Loading&quot; is created by the script, and the &quot;Start&quot; button becomes invisible. When loading ends, &quot;Hello World&quot; message is displayed and the loading bar is hidden. Follow the changes the in developer mode:\nGo to example 2:\nFrom a user perspective, there is no difference in page functioning. However, in this case the element with the &quot;Hello World!&quot; message does not exist on the page before clicking &quot;Start&quot;. It&#x2019;s created by the script.\nAfter clicking &quot;Start&quot;, the element with the loading bar is been created.\nAfter a certain time, the loading bar becomes invisible, and then the script creates &quot;Hello World!&quot; element and displays it.\nPage Class\npublic class DynamicLoadingPage extends BasePage {\nprivate static final By selectorExampleOneLink =\nBy.cssSelector(&quot;a[href*=&apos;dynamic_loading/1&apos;]&quot;);\nprivate static final By selectorExampleTwoLink =\nBy.cssSelector(&quot;a[href*=&apos;dynamic_loading/2&apos;]&quot;);\nprivate static final By selectorDynamicLoadingText = By.cssSelector(&quot;div#content h3&quot;);\nprivate static final By selectorStartButton = By.cssSelector(&quot;div#start button&quot;);\nprivate static final By selectorLoadingBar = By.cssSelector(&quot;div#loading&quot;);\nprivate static final By selectorExampleText = By.cssSelector(&quot;div#finish h4&quot;);\n@Override\npublic boolean isLoaded() {\ngetDriver().waitForPageLoaded();\nreturn getDriver().getCurrentUrl()\n.contains(PageSubURLsProjectYEnum.DYNAMIC_LOADING.getValue());\n}\n@Override\npublic void load() {\nBFLogger.logDebug(&quot;Load &apos;Dynamically Loaded Page Elements&apos; page.&quot;);\ngetDriver().get(GetEnvironmentParam.THE_INTERNET_MAIN_PAGE.getValue() +\nPageSubURLsProjectYEnum.DYNAMIC_LOADING.getValue());\ngetDriver().waitForPageLoaded();\n}\n@Override\npublic String pageTitle() {\nreturn getActualPageTitle();\n}\n/**\n* Returns information if dynamic loading message is visible or not.\n*\n* @return true if dynamic loading message was found on web page.\n*/\npublic boolean isDynamicLoadingMessageVisible() {\nreturn getDriver().findElementDynamic(selectorDynamicLoadingText)\n.isDisplayed();\n}\n/**\n* Clicks Example 1 link.\n*/\npublic void clickExampleOneLink() {\ngetDriver().findElementDynamic(selectorExampleOneLink)\n.click();\n}\n/**\n* Clicks Example 2 link.\n*/\npublic void clickExampleTwoLink() {\ngetDriver().findElementDynamic(selectorExampleTwoLink)\n.click();\n}\n/**\n* Returns information if Start button is visible or not.\n*\n* @return true if Start button was found on web page.\n*/\npublic boolean isStartButtonVisible() {\nreturn getDriver().findElementDynamic(selectorStartButton)\n.isDisplayed();\n}\n/**\n* Clicks Start button.\n*/\npublic void clickStartButton() {\ngetDriver().findElementDynamic(selectorStartButton)\n.click();\n}\n/**\n* Waits until WebElement representing waiting bar disappears and returns example text.\n*\n* @param waitTime The amount of time designated for waiting until waiting bar disappears.\n* @return String representing example&apos;s text.\n*/\npublic String getExampleOneDynamicText(int waitTime) {\nWebDriverWait wait = new WebDriverWait(getDriver(), waitTime);\nwait.until((Function&lt;? super WebDriver, Boolean&gt;)\nExpectedConditions.invisibilityOfElementLocated(selectorLoadingBar));\nreturn getDriver().findElementDynamic(selectorExampleText)\n.getText();\n}\n/**\n* Returns example text.\n* &lt;p&gt;\n* Waits until WebElement representing waiting bar disappear. Then waits until example text\n* shows up.\n* And after that returns example text.\n* &lt;/p&gt;\n*\n* @param waitTime The amount of time designated for waiting until waiting bar disappears and\n* example text shows.\n* @return String representing example&apos;s text.\n*/\npublic String getExampleTwoDynamicText(int waitTime) {\nWebDriverWait wait = new WebDriverWait(getDriver(), waitTime);\nwait.until((Function&lt;? super WebDriver, Boolean&gt;)\nExpectedConditions.invisibilityOfElementLocated(selectorLoadingBar));\nwait.until((Function&lt;? super WebDriver, WebElement&gt;)\nExpectedConditions.visibilityOfElementLocated(selectorExampleText));\nreturn getDriver().findElementDynamic(selectorExampleText)\n.getText();\n}\n}\nWebDriverWait\nThis class performs waiting for actions using Selenium Web Driver:\nWebDriverWait(WebDriver driver, long timeOutInSeconds) - constructor, first parameter takes WebDriver, in a second you can specify a timeout in seconds.\nFluentWait method:\nuntil(Function&lt;? super T, V&gt; isTrue) - waits until condition function given as parameter returns expected value. If waiting time reaches timeout, it throws timeoutException.\nMrChecker implements various condition functions in the ExpectedConditions class :\nvisibilityOfElementLocated(By selector) - returns WebElement if it&#x2019;s visible\ninvisibilityOfElementLocated(By selector) - returns true if Element under given selector is invisible\nWebDriver also has methods which wait for some conditions:\nwaitForElement(By selector)\nwaitForElementVisible(By selector)\nwaitUntilElementClickable(By selector)\nIt&#x2019;s possible to write your own condition function e.g.:\npublic static ExpectedCondition&lt;Boolean&gt; invisibilityOfElementLocated(final By locator) {\nreturn new ExpectedCondition&lt;Boolean&gt;() {\n@Override\npublic Boolean apply(WebDriver driver) {\ntry {\nreturn !(findElement(locator, driver).isDisplayed());\n} catch (NoSuchElementException e) {\nreturn true;\n} catch (StaleElementReferenceException e) {\nreturn true;\n}\n}\n};\n}\nOr as a lambda expression:\nWebDriverWait wait = new WebDriverWait(getDriver(), waitTime);\nwait.until((WebDriver driver) -&gt; {\ntry {\nreturn !(driver.findElement(selectorExampleText)\n.isDisplayed());\n} catch (NoSuchElementException e) {\nreturn true;\n} catch (StaleElementReferenceException e) {\nreturn true;\n}\n});\nTest Class\nCase 1 steps:\nOpen The Internet Main Page\nClick Dynamic Loading link and go to a subpage with examples\nCheck if the page is loaded and &quot;Dynamically Loaded Page Elements&quot; header is visible\nClick Example 1 link and load site\nVerify if the &quot;Start&quot; button is visible\nClick &quot;Start&quot;\nWait for the loading bar to disappear and check if the displayed message is as it should be\nGo back to Dynamic Loading page\nCase 2 steps:\nCheck if the page is loaded and &quot;Dynamically Loaded Page Elements&quot; header is visible\nClick Example 2 link and load site\nVerify if the &quot;Start&quot; button is visible\nClick &quot;Start&quot;\nWait for the loading bar to disappear\nWait for the message to appear and check if it is as it should be\nGo back to Dynamic Loading page\n@Category({ TestsSelenium.class, TestsChrome.class, TestsFirefox.class, TestsIE.class })\npublic class DynamicLoadingTest extends TheInternetBaseTest {\nprivate static final int EXAMPLE_WAITING_TIME = 30;\nprivate static final String EXAMPLE_TEXT = &quot;Hello World!&quot;;\nprivate static DynamicLoadingPage dynamicLoadingPage;\n@BeforeClass\npublic static void setUpBeforeClass() {\ndynamicLoadingPage = shouldTheInternetPageBeOpened().clickDynamicLoadingLink();\n}\n@Override\npublic void setUp() {\nlogStep(&quot;Verify if Dynamic Loading page is opened&quot;);\nassertTrue(&quot;Unable to open Dynamic Loading page&quot;, dynamicLoadingPage.isLoaded());\nlogStep(&quot;Verify if dynamic loading message is visible&quot;);\nassertTrue(&quot;Dynamic loading message is invisible&quot;,\ndynamicLoadingPage.isDynamicLoadingMessageVisible());\n}\n@Test\npublic void shouldExampleTextBeDisplayedAterRunExampleOne() {\nlogStep(&quot;Click Example 1 link&quot;);\ndynamicLoadingPage.clickExampleOneLink();\nlogStep(&quot;Verify if Example 1 link opened content&quot;);\nassertTrue(&quot;Fail to load Example 1 content&quot;, dynamicLoadingPage.isStartButtonVisible());\nlogStep(&quot;Click Start button&quot;);\ndynamicLoadingPage.clickStartButton();\nlogStep(&quot;Verify if expected text is displayed on the screen&quot;);\nassertEquals(&quot;Fail to display example text&quot;, EXAMPLE_TEXT,\ndynamicLoadingPage.getExampleOneDynamicText(EXAMPLE_WAITING_TIME));\n}\n@Test\npublic void shouldExampleTextBeDisplayedAterRunExampleTwo() {\nlogStep(&quot;Click Example 2 link&quot;);\ndynamicLoadingPage.clickExampleTwoLink();\nlogStep(&quot;Verify if Example 2 link opened content&quot;);\nassertTrue(&quot;Fail to load Example 2 content&quot;, dynamicLoadingPage.isStartButtonVisible());\nlogStep(&quot;Click Start button&quot;);\ndynamicLoadingPage.clickStartButton();\nlogStep(&quot;Verify if expected text is displayed on the screen&quot;);\nassertEquals(&quot;Fail to display example text&quot;, EXAMPLE_TEXT,\ndynamicLoadingPage.getExampleTwoDynamicText(EXAMPLE_WAITING_TIME));\n}\n@Override\npublic void tearDown() {\nlogStep(&quot;Click back to reset Dynamic Loading page&quot;);\nBasePage.navigateBack();\n}\n}\nPerform both cases running Test Class as JUnit Test.\nWARNING: In this example, there is a visible loading bar signalizing that content is loading.On many websites elements are created by scripts without clear communique. This may cause problems with test stability. When your tests aren&#x2019;t finding page elements, try to add wait functions with a short timeout.\nThis case shows how to perform mouse actions and test modal windows.\nAfter you move the mouse cursor out of the website, you should see a new window appearing:\nCheck in the browser&#x2019;s developer mode if this window exists in Page DOM\nBefore you move the mouse out, the window exists, but it&#x2019;s not displayed.\nWhen the mouse is moved, JavaScript changes display attribute. It also hides window after clicking &quot;Close&quot;.\nPage Class\npublic class ExitIntentPage extends BasePage {\nprivate static final String MODAL_WINDOW_HIDDEN = &quot;display: none;&quot;;\nprivate static final String MODAL_WINDOW_DISPLAYED = &quot;display: block;&quot;;\nprivate static final String MODAL_WINDOW_STYLE_ATTRIBUTTE = &quot;style&quot;;\nprivate static final By selectorModalWindow = By.cssSelector(&quot;div#ouibounce-modal&quot;);\nprivate static final By selectorExitIntentText = By.cssSelector(&quot;div#content h3&quot;);\nprivate static final By selectorModalWindowTitle = By.cssSelector(&quot;h3&quot;);\nprivate static final By selectorModalWindowCloseButton = By.cssSelector(&quot;div.modal-footer &gt; p&quot;);\n@Override\npublic boolean isLoaded() {\ngetDriver().waitForPageLoaded();\nreturn getDriver().getCurrentUrl()\n.contains(PageSubURLsProjectYEnum.EXIT_INTENT.getValue());\n}\n@Override\npublic void load() {\nBFLogger.logDebug(&quot;Load &apos;Exit Intent&apos; page.&quot;);\ngetDriver().get(GetEnvironmentParam.THE_INTERNET_MAIN_PAGE.getValue() +\nPageSubURLsProjectYEnum.EXIT_INTENT.getValue());\ngetDriver().waitForPageLoaded();\n}\n@Override\npublic String pageTitle() {\nreturn getActualPageTitle();\n}\n/**\n* Returns information if exit intent message is visible or not.\n*\n* @return true if exit intent message was found on web page.\n*/\npublic boolean isIntentMessageVisible() {\nreturn getDriver().findElementDynamic(selectorExitIntentText)\n.isDisplayed();\n}\n/**\n* Returns information if modal window is hidden.\n*\n* @return true if modal window is hidden.\n*/\npublic boolean isModalWindowHidden() {\nreturn getDriver().findElementDynamic(selectorModalWindow)\n.getAttribute(MODAL_WINDOW_STYLE_ATTRIBUTTE)\n.equals(MODAL_WINDOW_HIDDEN);\n}\n/**\n* Returns information if modal window is showed on web page.\n*\n* @return true if modal window is displayed.\n*/\npublic boolean isModalWindowVisible() {\nreturn getDriver().findElementDynamic(selectorModalWindow)\n.getAttribute(MODAL_WINDOW_STYLE_ATTRIBUTTE)\n.equals(MODAL_WINDOW_DISPLAYED);\n}\n/**\n* Returns information if modal window title is shown and correct.\n*\n* @param expectedValue String representing expected value of modal window&apos;s title.\n* @return true if modal window&apos;s title is equal to expected value.\n*/\npublic boolean verifyModalWindowTitle(String expectedValue) {\nreturn getDriver().elementLabel(new ByChained(selectorModalWindow,\nselectorModalWindowTitle))\n.getText()\n.equals(expectedValue);\n}\n/**\n* Closes modal window by pressing &apos;close&apos; button.\n*/\npublic void closeModalWindow() {\ngetDriver().elementButton(new ByChained(selectorModalWindow,\nselectorModalWindowCloseButton))\n.click();\n}\n/**\n* Moves mouse pointer to the top middle of screen, then to the centre of screen and\n* again to the top.\n* &lt;p&gt;\n* This move simulates leaving the viewport and encourages the modal to show up. There is\n* java.awt.Robot used\n* to move mouse pointer out of the viewport. There are timeouts used to let the browser detect\n* mouse move.\n* &lt;/p&gt;\n*\n* @see java.awt.Robot\n*/\npublic void moveMouseOutOfViewport() {\nRobot robot;\nDimension screenSize = getDriver().manage()\n.window()\n.getSize();\nint halfWidth = new BigDecimal(screenSize.getWidth() / 2).intValue();\nint halfHeight = new BigDecimal(screenSize.getHeight() / 2).intValue();\ntry {\nrobot = new Robot();\nrobot.mouseMove(halfWidth, 1);\ngetDriver().manage()\n.timeouts()\n.implicitlyWait(1, TimeUnit.SECONDS);\nrobot.mouseMove(halfWidth, halfHeight);\ngetDriver().manage()\n.timeouts()\n.implicitlyWait(1, TimeUnit.SECONDS);\nrobot.mouseMove(halfWidth, 1);\n} catch (AWTException e) {\nBFLogger.logError(&quot;Unable to connect with remote mouse&quot;);\ne.printStackTrace();\n}\n}\n}\nAttributes\nElements on pages have attributes like &quot;id&quot;, &quot;class&quot;, &quot;name&quot;, &quot;style&quot; etc. In order to check them, use method getAttribute(String name). In this case attribute &quot;style&quot; determinates if the element is displayed.\nRobot\nRobot class can perform mouse movement. Method mouseMove(int x, int y) moves the remote mouse to given coordinates.\nManage Timeouts\nmanage().timeouts() methods allows you to change WebDriver timeouts values such as:\npageLoadTimeout(long time, TimeUnit unit) - the amount of time to wait for a page to load before throwing an exception\nsetScriptTimeout(long time, TimeUnit unit) - the amount of time to wait for finish execution of a script before throwing an exception\nimplicitlyWait(long time, TimeUnit unit) - the amount of time the driver should wait when searching for an element if it is not immediately present. After that time, it throws an exception.\nChanging timeouts can improve test stability but can also make them run slower.\nTest Class\nSteps:\nOpen The Internet Main Page\nClick Exit Intent link and load subpage\nCheck if the page is loaded and &quot;Exit Intent&quot; message is visible\nVerify if Modal Window is hidden\nMove mouse out of the viewport\nCheck if Modal Window is visible\nVerify if Modal Window title is correct\nClick &apos;close&apos; button\nAgain verify if Modal Window is hidden\n@Category({ TestsLocal.class, TestsNONParallel.class })\npublic class ExitIntentTest extends TheInternetBaseTest {\nprivate static final String MODAL_WINDOW_TITLE = &quot;This is a modal window&quot;;\nprivate static ExitIntentPage exitIntentPage;\n@BeforeClass\npublic static void setUpBeforeClass() {\nexitIntentPage = shouldTheInternetPageBeOpened().clickExitIntentLink();\nlogStep(&quot;Verify if Exit Intent page is opened&quot;);\nassertTrue(&quot;Unable to open Exit Intent page&quot;, exitIntentPage.isLoaded());\nlogStep(&quot;Verify if exit intent message is visible&quot;);\nassertTrue(&quot;Exit intent message is not visible&quot;, exitIntentPage.isIntentMessageVisible());\n}\n@Test\npublic void shouldModalWindowAppearWhenMouseMovedOutOfViewportTest() {\nlogStep(&quot;Verify if modal window is hidden&quot;);\nassertTrue(&quot;Fail to hide modal window&quot;, exitIntentPage.isModalWindowHidden());\nlogStep(&quot;Move mouse pointer out of viewport&quot;);\nexitIntentPage.moveMouseOutOfViewport();\nlogStep(&quot;Verify if modal window showed up&quot;);\nassertTrue(&quot;Fail to show up modal window&quot;, exitIntentPage.isModalWindowVisible());\nlogStep(&quot;Verify if modal window title displays properly&quot;);\nassertTrue(&quot;Fail to display modal window&apos;s title&quot;,\nexitIntentPage.verifyModalWindowTitle(MODAL_WINDOW_TITLE.toUpperCase()));\nlogStep(&quot;Close modal window&quot;);\nexitIntentPage.closeModalWindow();\nlogStep(&quot;Verify if modal window is hidden again&quot;);\nassertTrue(&quot;Fail to hide modal window&quot;, exitIntentPage.isModalWindowHidden());\n}\n}\nRemember not to move mouse manually during test execution.\nThis example shows how to check if file downloads properly.\nAfter clicking on one of these links, a specific file should be downloaded to your computer.\nSteps:\nOpen The Internet Main Page\nClick on the File Download link and open subpage\nClick on &quot;some-file.txt&quot; download link and download file\nCheck if the file exists in the appropriate folder\nDelete the file\nCheck if the file doesn&#x2019;t exist in the folder\nPage Class\npublic class FileDownloadPage extends BasePage {\nprivate static final By selectorSomeFileTxt = By.cssSelector(&quot;a[href*=some-file]&quot;);\nprivate final String DOWNLOAD_DIR = System.getProperty(&quot;java.io.tmpdir&quot;);\n@Override\npublic boolean isLoaded() {\ngetDriver().waitForPageLoaded();\nreturn getDriver().getCurrentUrl()\n.contains(PageSubURLsProjectYEnum.DOWNLOAD.getValue());\n}\n@Override\npublic void load() {\nBFLogger.logDebug(&quot;Load &apos;File Downloader&apos; page.&quot;);\ngetDriver().get(GetEnvironmentParam.THE_INTERNET_MAIN_PAGE.getValue() +\nPageSubURLsProjectYEnum.DOWNLOAD.getValue());\ngetDriver().waitForPageLoaded();\n}\n@Override\npublic String pageTitle() {\nreturn getActualPageTitle();\n}\n/**\n* Verifies if the chosen file is already downloaded and if not, downloads it .\n* Throws RuntimeException otherwise.\n*\n* @return Downloaded file\n*/\npublic File downloadTextFile() {\nString nameOfDownloadFile = getNameOfDownloadFile();\nFile fileToDownload = new File(DOWNLOAD_DIR + nameOfDownloadFile);\nif (fileToDownload.exists()) {\nthrow new RuntimeException(&quot;The file that you want to download already exists. &quot;\n+ &quot;Please remove it manually. Path to the file: &quot; + fileToDownload.getPath());\n}\ngetDriver().elementButton(selectorSomeFileTxt)\n.click();\nwaitForFileDownload(2000, fileToDownload);\nreturn fileToDownload;\n}\nprivate void waitForFileDownload(int totalTimeoutInMillis, File expectedFile) {\nFluentWait&lt;WebDriver&gt; wait = new FluentWait&lt;WebDriver&gt;(getDriver())\n.withTimeout(totalTimeoutInMillis, TimeUnit.MILLISECONDS)\n.pollingEvery(200, TimeUnit.MILLISECONDS);\nwait.until((WebDriver wd) -&gt; expectedFile.exists());\n}\nprivate String getNameOfDownloadFile() {\nString urlToDownload = getDriver().findElementDynamic(selectorSomeFileTxt)\n.getAttribute(&quot;href&quot;);\nString[] urlHierachy = urlToDownload.split(&quot;/&quot;);\nreturn urlHierachy[urlHierachy.length - 1];\n}\n}\nUse FluentWait class and create an expected condition using a lambda expression to wait until the file downloads.\nTo perform operations on files, use java File class. To get a file name, find it in download URL.\nTest Class\n@Category({ TestsLocal.class, TestsNONParallel.class })\npublic class FileDownloadTest extends TheInternetBaseTest {\nprivate static FileDownloadPage fileDownloadPage;\n@BeforeClass\npublic static void setUpBeforeClass() {\nfileDownloadPage = shouldTheInternetPageBeOpened().clickFileDownloadLink();\nlogStep(&quot;Verify if File Download page is opened&quot;);\nassertTrue(&quot;Unable to open File Download page&quot;, fileDownloadPage.isLoaded());\n}\n@Test\npublic void shouldfileBeDownloaded() {\nlogStep(&quot;Download the some-file.txt&quot;);\nFile downloadedFile = fileDownloadPage.downloadTextFile();\nlogStep(&quot;Verify if downloaded file exists&quot;);\nassertTrue(&quot;Downloaded file does not exist&quot;, downloadedFile.exists());\nlogStep(&quot;Remove downloaded file&quot;);\ndownloadedFile.delete();\nlogStep(&quot;Verify if downloaded file has been removed&quot;);\nassertFalse(&quot;Downloaded file still exists&quot;, downloadedFile.exists());\n}\n}\nThis case shows how to pass through the standard authentication page.\nWhen you enter the correct credentials, you should see the next page:\nIf user data is wrong, an appropriate message appears:\nPage Class\npublic class FormAuthenticationPage extends BasePage {\nprivate final static By selectorInputUsername = By.cssSelector(&quot;#username&quot;);\nprivate final static By selectorInputUserPassword = By.cssSelector(&quot;#password&quot;);\nprivate final static By selectorLoginMessage = By.cssSelector(&quot;#flash&quot;);\nprivate final static By selectorLoginButton = By.cssSelector(&quot;#login &gt; button &gt; i&quot;);\nprivate final static By selectorLogoutButton = By.cssSelector(&quot;#content &gt; div &gt; a &quot;);\n@Override\npublic boolean isLoaded() {\ngetDriver().waitForPageLoaded();\nreturn getDriver().getCurrentUrl()\n.contains(PageSubURLsProjectYEnum.LOGIN.getValue());\n}\n@Override\npublic void load() {\nBFLogger.logDebug(&quot;Load &apos;Login Page&apos; page.&quot;);\ngetDriver().get(GetEnvironmentParam.THE_INTERNET_MAIN_PAGE.getValue() + PageSubURLsProjectYEnum.LOGIN.getValue());\ngetDriver().waitForPageLoaded();\n}\n@Override\npublic String pageTitle() {\nreturn getActualPageTitle();\n}\n/**\n* Sets user name to designated form&apos;s field.\n*\n* @param username String representing a user&apos;s name\n* @return FormAuthenticationPage object with user name set to the given one\n*/\npublic FormAuthenticationPage setUsername(String username) {\nInputTextElement elementInputUsername = new InputTextElement(selectorInputUsername);\nelementInputUsername.clearInputText();\nelementInputUsername.setInputText(username);\nreturn this;\n}\n/**\n* Sets user password to designated form&apos;s field.\n*\n* @param userPassword String representing a user&apos;s password\n* @return FormAuthenticationPage object with user&apos;s password set to the given one\n*/\npublic FormAuthenticationPage setUserPassword(String userPassword) {\nInputTextElement elementInputPassword = new InputTextElement(selectorInputUserPassword);\nelementInputPassword.clearInputText();\nelementInputPassword.setInputText(userPassword);\nreturn this;\n}\n/**\n* Returns login message.\n*\n* @return String object representing the message returned after login operation is performed\n*/\npublic String getLoginMessageText() {\nreturn new LabelElement(selectorLoginMessage).getText();\n}\n/**\n* Clicks &apos;Login&apos; button.\n*/\npublic void clickLoginButton() {\nnew Button(selectorLoginButton).click();\n}\n/**\n* Clicks &apos;Logout&apos; button.\n*/\npublic void clickLogoutButton() {\nnew Button(selectorLogoutButton).click();\n}\n}\n"},{"id":1034,"path":"../website/pages/docs/master-mrchecker.asciidoc_tutorials.html#example-13-form-authentication-test.asciidoc_inputtextelement","type":"docs","title":"First Steps","body":"InputTextElement\nUse methods from this class to perform actions on text fields:\nclearInputText() - remove all text from selected input field\nsetInputText(String text) - enter given text\nLabelElement\nString getText() method returns visible text from label\nTestClass\nPrepare six test cases:\nTry to login with empty user data and check if the error message appears\nTry to login with empty username and valid password and check if the error message appears\nTry to login with a valid username and empty password and check if the error message appears\nTry to login with invalid username and invalid password and check if the error message appears\nTry to login with a valid username and valid password and check if success login message appears, then log out\nTry to login with a valid username and valid password and check if success login message appears, then log out and check if success logout message is displayed\nBefore all tests: Open The Internet Main Page\nBefore each case: Click on the Form Authentication link and open login page\nAfter each case: Go back to The Internet Main Page\n@Category({ TestsLocal.class, TestsNONParallel.class })\npublic class FormAuthenticationTest extends TheInternetBaseTest {\nprivate static FormAuthenticationPage formAuthenticationPage;\nprivate String errorUsernameMessage = &quot;Your username is invalid!\\n&quot; + &quot;&#xD7;&quot;;\nprivate String errorPasswordMessage = &quot;Your password is invalid!\\n&quot; + &quot;&#xD7;&quot;;\nprivate String loginMessage = &quot;You logged into a secure area!\\n&quot; + &quot;&#xD7;&quot;;\nprivate String logoutMessage = &quot;You logged out of the secure area!\\n&quot; + &quot;&#xD7;&quot;;\nprivate String emptyUsername = &quot;&quot;;\nprivate String emptyUserPassword = &quot;&quot;;\nprivate String validUsername = &quot;tomsmith&quot;;\nprivate String validPassword = &quot;SuperSecretPassword!&quot;;\nprivate String randomUsername = UUID.randomUUID()\n.toString();\nprivate String randomUserPassword = UUID.randomUUID()\n.toString();\n@BeforeClass\npublic static void setUpBeforeClass() {\nlogStep(&quot;Open the Url http://the-internet.herokuapp.com/&quot;);\ntheInternetPage = new TheInternetPage();\ntheInternetPage.load();\nlogStep(&quot;Verify if Url http://the-internet.herokuapp.com/ is opened&quot;);\nassertTrue(&quot;Unable to load The Internet Page&quot;, theInternetPage.isLoaded());\n}\n@Override\npublic void setUp() {\nlogStep(&quot;Click subpage link&quot;);\nformAuthenticationPage = theInternetPage.clickFormAuthenticationLink();\nlogStep(&quot;Verify if subpage is opened&quot;);\nassertTrue(&quot;The Internet subpage: FormAuthenticationPage was not open&quot;, formAuthenticationPage.isLoaded());\n}\n@Test\npublic void shouldErrorMessageBeDisplayedWhenUserLogsWithEmptyData() {\nlogStep(&quot;Log user with empty username and password&quot;);\nformAuthenticationPage.setUsername(emptyUsername)\n.setUserPassword(emptyUserPassword)\n.clickLoginButton();\nassertEquals(&quot;Unexpectedly user logged in with empty data&quot;, errorUsernameMessage,\nformAuthenticationPage.getLoginMessageText());\n}\n@Test\npublic void shouldErrorMessageBeDisplayedWhenUserLogsWithEmptyUsernameAndValidPassword() {\nlogStep(&quot;Log user with empty username and valid password&quot;);\nformAuthenticationPage.setUsername(emptyUsername)\n.setUserPassword(validPassword)\n.clickLoginButton();\nassertEquals(&quot;Unexpectedly user logged in with empty username&quot;, errorUsernameMessage,\nformAuthenticationPage.getLoginMessageText());\n}\n@Test\npublic void shouldErrorMessageBeDisplayedWhenUserLogsWithValidUsernameAndEmptyPassword() {\nlogStep(&quot;Log user with valid username and empty password&quot;);\nformAuthenticationPage.setUsername(validUsername)\n.setUserPassword(emptyUserPassword)\n.clickLoginButton();\nassertEquals(&quot;Unexpectedly user logged in with empty password&quot;, errorPasswordMessage,\nformAuthenticationPage.getLoginMessageText());\n}\n@Test\npublic void shouldErrorMessageBeDisplayedWhenUserLogsWithInvalidUsernameAndInvalidPassword() {\nlogStep(&quot;Log user with invalid username and invalid password&quot;);\nformAuthenticationPage.setUsername(randomUsername)\n.setUserPassword(randomUserPassword)\n.clickLoginButton();\nassertEquals(&quot;Unexpectedly user logged in with random credentials&quot;, errorUsernameMessage,\nformAuthenticationPage.getLoginMessageText());\n}\n@Test\npublic void shouldUserLogInWithValidCredentials() {\nlogStep(&quot;Log user with valid username and valid password&quot;);\nformAuthenticationPage.setUsername(validUsername)\n.setUserPassword(validPassword)\n.clickLoginButton();\nassertEquals(&quot;Unable to login user with valid credentials&quot;, loginMessage,\nformAuthenticationPage.getLoginMessageText());\nlogStep(&quot;Log out user&quot;);\nformAuthenticationPage.clickLogoutButton();\n}\n@Test\npublic void shouldUserLogOutAfterProperLogInAndClickLogoutButon() {\nlogStep(&quot;Log user with valid username and valid password&quot;);\nformAuthenticationPage.setUsername(validUsername)\n.setUserPassword(validPassword)\n.clickLoginButton();\nassertEquals(&quot;Unable to login user with valid credentials&quot;, loginMessage,\nformAuthenticationPage.getLoginMessageText());\nlogStep(&quot;Log out user&quot;);\nformAuthenticationPage.clickLogoutButton();\nassertEquals(&quot;User cannot log out after prper log in&quot;, logoutMessage,\nformAuthenticationPage.getLoginMessageText());\n}\n@Override\npublic void tearDown() {\nlogStep(&quot;Navigate back to The-Internet page&quot;);\ntheInternetPage.load();\n}\n}\nAfter running Test Class, cases might be performed in a different order.\nThis example shows how to approach elements dynamically appearing after the user&#x2019;s action.\nMove the mouse over an image to see the additional label.\nLabels exist in page DOM all the time but their display attributes change. In this case, there is no JavaScript. Elements&apos; visibility is managed by CSS.\nPage Class\npublic class HoversPage extends BasePage {\nprivate final static By selectorImages = By.cssSelector(&quot;div.figure &gt; img&quot;);\nprivate final static By selectorNames = By.cssSelector(&quot;div.figcaption h5&quot;);\n@Override\npublic boolean isLoaded() {\ngetDriver().waitForPageLoaded();\nreturn getDriver().getCurrentUrl()\n.contains(PageSubURLsProjectYEnum.HOVERS.getValue());\n}\n@Override\npublic void load() {\nBFLogger.logDebug(&quot;Load &apos;Hovers&apos; page.&quot;);\ngetDriver().get(GetEnvironmentParam.THE_INTERNET_MAIN_PAGE.getValue() +\nPageSubURLsProjectYEnum.HOVERS.getValue());\ngetDriver().waitForPageLoaded();\n}\n@Override\npublic String pageTitle() {\nreturn getActualPageTitle();\n}\n/**\n* Moves mouse pointer over an image with given index.\n*\n* @param index An index of the picture, where mouse pointer should be moved\n*/\npublic void hoverOverAvatar(int index) {\nActions action = new Actions(getDriver());\nWebElement avatarImage = getDriver().findElementDynamics(selectorImages)\n.get(index);\naction.moveToElement(avatarImage)\n.perform();\n}\n/**\n* Returns the information displayed under a picture with given index.\n*\n* @param index An index of the picture, where the information should be read\n* @return String object representing picture&apos;s information\n*/\npublic String getAvatarsInformation(int index) {\nreturn getDriver().findElementDynamics(selectorNames)\n.get(index)\n.getText();\n}\n}\nActions\nActions class contains methods used to execute basic user actions such as mouse moving and clicking or keys sending. Action or actions series will be performed after calling perform() method.\nTest Class\nSteps:\nOpen The Internet Main Page\nGo to Hovers page\nMove mouse over random image\nCheck if displayed text is equal to expected.\n@Category({ TestsSelenium.class, TestsChrome.class, TestsFirefox.class, TestsIE.class })\npublic class HoversTest extends TheInternetBaseTest {\nprivate static HoversPage hoversPage;\nprivate final String names[] = { &quot;name: user1&quot;, &quot;name: user2&quot;, &quot;name: user3&quot; };\n@BeforeClass\npublic static void setUpBeforeClass() {\nhoversPage = shouldTheInternetPageBeOpened().clickHoversLink();\nlogStep(&quot;Verify if Hovers page is opened&quot;);\nassertTrue(&quot;Unable to open Hovers page&quot;, hoversPage.isLoaded());\n}\n@Test\npublic void shouldProperInformationBeDisplayedWhenMousePointerHoveredOverRandomElement() {\nlogStep(&quot;Hover mouse pointer over random element&quot;);\nint randomIndex = new Random().nextInt(names.length);\nhoversPage.hoverOverAvatar(randomIndex);\nassertEquals(&quot;Picture&apos;s information is different than expected&quot;, names[randomIndex],\nhoversPage.getAvatarsInformation(randomIndex));\n}\n}\nBecause in this case the tested content is being chosen randomly, each test run could check a different element.\nThis case shows how to test pop-up JS alerts.\nAfter clicking one of the buttons, an adequate alert should appear.\nPerformed action will be displayed under &quot;Result&quot; label.\nIn developer mode, you can view JavaScript which creates alerts.\nPage Class\npublic class JavaScriptAlertsPage extends BasePage {\nprivate static final By selectorAlertButton = By.cssSelector(&quot;button[onclick*=jsAlert]&quot;);\nprivate static final By selectorConfirmButton = By.cssSelector(&quot;button[onclick*=jsConfirm]&quot;);\nprivate static final By selectorPromptButton = By.cssSelector(&quot;button[onclick*=jsPrompt]&quot;);\nprivate static final By resultLabelSelector = By.cssSelector(&quot;p#result&quot;);\n@Override\npublic boolean isLoaded() {\ngetDriver().waitForPageLoaded();\nreturn getDriver().getCurrentUrl()\n.contains(PageSubURLsProjectYEnum.JAVASCRIPT_ALERTS.getValue());\n}\n@Override\npublic void load() {\nBFLogger.logDebug(&quot;Load &apos;JavaScript Alerts&apos; page.&quot;);\ngetDriver().get(GetEnvironmentParam.THE_INTERNET_MAIN_PAGE.getValue() +\nPageSubURLsProjectYEnum.JAVASCRIPT_ALERTS.getValue());\ngetDriver().waitForPageLoaded();\n}\n@Override\npublic String pageTitle() {\nreturn getActualPageTitle();\n}\n/**\n* Clicks &apos;JS alert&apos; button.\n*/\npublic void clickAlertButton() {\nnew Button(selectorAlertButton).click();\nWebDriverWait wait = new WebDriverWait(getDriver(), 2);\nwait.until(ExpectedConditions.alertIsPresent());\n}\n/**\n* Clicks &apos;JS confirm&apos; button.\n*/\npublic void clickConfirmButton() {\nnew Button(selectorConfirmButton).click();\nWebDriverWait wait = new WebDriverWait(getDriver(), 2);\nwait.until(ExpectedConditions.alertIsPresent());\n}\n/**\n* Clicks &apos;JS prompt&apos; button.\n*/\npublic void clickPromptButton() {\nnew Button(selectorPromptButton).click();\nWebDriverWait wait = new WebDriverWait(getDriver(), 2);\nwait.until(ExpectedConditions.alertIsPresent());\n}\n/**\n* Returns message displayed by popup.\n*\n* @return String object representing message displayed by popup\n*/\npublic String readResultLabel() {\nreturn new LabelElement(resultLabelSelector).getText();\n}\n/**\n* Clicks alert&apos;s &apos;OK&apos; button.\n*/\npublic void clickAlertAccept() {\ngetDriver().switchTo()\n.alert()\n.accept();\n}\n/**\n* Clicks alert&apos;s &apos;Cancel&apos; button.\n*/\npublic void clickAlertDismiss() {\ngetDriver().switchTo()\n.alert()\n.dismiss();\n}\n/**\n* Types text into alert&apos;s text field.\n*\n* @param text String object sent into alert&apos;s text field\n*/\npublic void writeTextInAlert(String text) {\ngetDriver().switchTo()\n.alert()\n.sendKeys(text);\n}\n}\nalert()\nUsing switchTo() method you can change processed content. switchTo().alert() allows performing actions on appearing alerts such as accepting, dismissing or entering keys.\nTest Class\nBefore all tests: Open The Internet Main Page and go to JavaScript Alert page\nClick JS Alert button, accept alert and check if Result message returns performed an action\nClick JS Confirm button, accept alert and check if Result message returns performed action\nClick JS Confirm button, dismiss alert and check if Result message returns performed action\nClick JS Prompt button, write random text, accept alert and check if Result message returns performed action with written text\nClick JS Prompt button, dismiss the alert and check if Result message returns performed action\nAfter each case: Refresh Page\nAfter all tests: Navigate back to The Internet Main Page\n@Category({ TestsSelenium.class, TestsChrome.class, TestsFirefox.class, TestsIE.class })\npublic class JavaScriptAlertsTest extends TheInternetBaseTest {\nprivate static JavaScriptAlertsPage javaScriptAlertsPage;\nprivate final String jsAlertCofirmMessage = &quot;You successfuly clicked an alert&quot;;\nprivate final String jsConfirmConfirmMessage = &quot;You clicked: Ok&quot;;\nprivate final String jsConfirmCancelMessage = &quot;You clicked: Cancel&quot;;\nprivate final String jsPromptConfirmMessage = &quot;You entered: &quot;;\nprivate final String jsPromptCancelMessage = &quot;You entered: null&quot;;\nprivate final String randomString = &quot;random&quot;;\n@BeforeClass\npublic static void setUpBeforeClass() {\njavaScriptAlertsPage = shouldTheInternetPageBeOpened().clickJavaScriptAlertLink();\nlogStep(&quot;Verify if JavaScript Alerts page is opened&quot;);\nassertTrue(&quot;Unable to open JavaScript Alerts page&quot;, javaScriptAlertsPage.isLoaded());\n}\n@AfterClass\npublic static void tearDownAfterClass() {\nlogStep(&quot;Navigate back to The-Internet page&quot;);\nBasePage.navigateBack();\n}\n@Test\npublic void shouldJSAlertCloseWithProperMessageAfterPressOkButton() {\nlogStep(&quot;Click Alert button&quot;);\njavaScriptAlertsPage.clickAlertButton();\nlogStep(&quot;Click &apos;OK&apos; button on alert&quot;);\njavaScriptAlertsPage.clickAlertAccept();\nlogStep(&quot;Verify returned message&quot;);\nassertEquals(&quot;Incorrect message returned after click&quot;,\njsAlertCofirmMessage, javaScriptAlertsPage.readResultLabel());\n}\n@Test\npublic void shouldJSConfirmCloseWithProperMessageAfterPressOkButton() {\nlogStep(&quot;Click Confirm button&quot;);\njavaScriptAlertsPage.clickConfirmButton();\nlogStep(&quot;Click &apos;OK&apos; button on alert&quot;);\njavaScriptAlertsPage.clickAlertAccept();\nlogStep(&quot;Verify returned message&quot;);\nassertEquals(&quot;Incorrect message returned after click&quot;,\njsConfirmConfirmMessage, javaScriptAlertsPage.readResultLabel());\n}\n@Test\npublic void shouldJSConfirmCloseWithProperMessageAfterPressCancelButton() {\nlogStep(&quot;Click Confirm button&quot;);\njavaScriptAlertsPage.clickConfirmButton();\nlogStep(&quot;Click &apos;Cancel&apos; button on alert&quot;);\njavaScriptAlertsPage.clickAlertDismiss();\nlogStep(&quot;Verify returned message&quot;);\nassertEquals(&quot;Incorrect message returned after click&quot;,\njsConfirmCancelMessage, javaScriptAlertsPage.readResultLabel());\n}\n@Test\npublic void shouldJSPromptCloseWithProperMessageAfterPressOKButton() {\nlogStep(&quot;Click Prompt button&quot;);\njavaScriptAlertsPage.clickPromptButton();\nlogStep(&quot;Insert text to alert: &quot; + randomString);\njavaScriptAlertsPage.writeTextInAlert(randomString);\nlogStep(&quot;Click &apos;OK&apos; button on alert&quot;);\njavaScriptAlertsPage.clickAlertAccept();\nlogStep(&quot;Verify returned message&quot;);\nassertEquals(&quot;Incorrect message returned after click&quot;,\njsPromptConfirmMessage + randomString, javaScriptAlertsPage.readResultLabel());\n}\n@Test\npublic void shouldJSPromptCloseWithProperMessageAfterPressCancelButton() {\nlogStep(&quot;Click Prompt button&quot;);\njavaScriptAlertsPage.clickPromptButton();\nlogStep(&quot;Click &apos;Cancel&apos; button on alert&quot;);\njavaScriptAlertsPage.clickAlertDismiss();\nlogStep(&quot;Verify returned message&quot;);\nassertEquals(&quot;Incorrect message returned after click&quot;,\njsPromptCancelMessage, javaScriptAlertsPage.readResultLabel());\n}\n@Override\npublic void tearDown() {\nlogStep(&quot;Refresh JavaScriptAlersPage&quot;);\njavaScriptAlertsPage.refreshPage();\n}\n}\nThis simple case shows how to test key pressing\nThis site uses JavaScript to read the key pressed and display its value.\nPage Class\npublic class KeyPressesPage extends BasePage {\nprivate static final By selectorResult = By.cssSelector(&quot;#result&quot;);\n@Override\npublic boolean isLoaded() {\ngetDriver().waitForPageLoaded();\nreturn getDriver().getCurrentUrl()\n.contains(PageSubURLsProjectYEnum.KEY_PRESS.getValue());\n}\n@Override\npublic void load() {\nBFLogger.logDebug(&quot;Load &apos;Key Presses&apos; page.&quot;);\ngetDriver().get(GetEnvironmentParam.THE_INTERNET_MAIN_PAGE.getValue() +\nPageSubURLsProjectYEnum.KEY_PRESS.getValue());\ngetDriver().waitForPageLoaded();\n}\n@Override\npublic String pageTitle() {\nreturn getActualPageTitle();\n}\n/**\n* Presses given keyboard key.\n*\n* @param keyToPress Key to be pressed on keyboard\n*/\npublic void pressKey(String keyToPress) {\ngetAction().sendKeys(keyToPress)\n.perform();\n}\n/**\n* Returns information from web page about pressed keyboard key.\n*\n* @return Information from web page about pressed key\n*/\npublic String getPressedKeyInformation() {\nreturn getDriver().findElementDynamic(selectorResult)\n.getText();\n}\n}\nTest Class\nSteps:\nOpen The Internet Main Page\nGo to Key Presses site\nPress a key\nCheck if a displayed message contains the pressed key\n@Category({ TestsSelenium.class, TestsChrome.class, TestsFirefox.class, TestsIE.class })\npublic class KeyPressesTest extends TheInternetBaseTest {\nprivate static KeyPressesPage keyPressesPage;\nprivate final String keyToBePressed = &quot;Q&quot;;\nprivate final String expectedMessage = &quot;You entered: Q&quot;;\n@BeforeClass\npublic static void setUpBeforeClass() {\nkeyPressesPage = shouldTheInternetPageBeOpened().clickKeyPressesLink();\nlogStep(&quot;Verify if Key Presses page is opened&quot;);\nassertTrue(&quot;Unable to open Key Presses page&quot;, keyPressesPage.isLoaded());\n}\n@Test\npublic void shouldWebsiteReturnInformationAboutPressedKey() {\nlogStep(&quot;Press a keyboard key&quot;);\nkeyPressesPage.pressKey(keyToBePressed);\nlogStep(&quot;Verify if website give valid information about pressed keyboard key&quot;);\nassertEquals(&quot;Information about the pressed key is invalid&quot;, expectedMessage,\nkeyPressesPage.getPressedKeyInformation());\n}\n}\nThis simple example shows how operate on many browser tabs\nWhen you click the link, a new website will be opened in the second tab.\nPage Class\npublic class MultipleWindowsPage extends BasePage {\nprivate final static By selectorLink = By.cssSelector(&quot;#content &gt; div &gt; a&quot;);\n@Override\npublic boolean isLoaded() {\ngetDriver().waitForPageLoaded();\nreturn getDriver().getCurrentUrl()\n.contains(PageSubURLsProjectYEnum.WINDOW.getValue());\n}\n@Override\npublic void load() {\nBFLogger.logDebug(&quot;Load &apos;Opening a new window&apos; page.&quot;);\ngetDriver().get(GetEnvironmentParam.THE_INTERNET_MAIN_PAGE.getValue() +\nPageSubURLsProjectYEnum.WINDOW.getValue());\ngetDriver().waitForPageLoaded();\n}\n@Override\npublic String pageTitle() {\nreturn getActualPageTitle();\n}\n/**\n* Clicks &apos;click here&apos; link.\n*\n* @return NewWindowPage object\n*/\npublic NewWindowPage clickHereLink() {\ngetDriver().findElementDynamic(selectorLink)\n.click();\ngetDriver().waitForPageLoaded();\nreturn new NewWindowPage();\n}\n}\nYou also need a second page class for New Window Page. Implement only the required methods.\npublic class NewWindowPage extends BasePage {\n@Override\npublic boolean isLoaded() {\ngetDriver().waitForPageLoaded();\nreturn getDriver().getCurrentUrl()\n.contains(PageSubURLsProjectYEnum.NEW_WINDOW.getValue());\n}\n@Override\npublic void load() {\nBFLogger.logDebug(&quot;Load &apos;New window&apos; page.&quot;);\ngetDriver().get(GetEnvironmentParam.THE_INTERNET_MAIN_PAGE.getValue() +\nPageSubURLsProjectYEnum.NEW_WINDOW.getValue());\ngetDriver().waitForPageLoaded();\n}\n@Override\npublic String pageTitle() {\nreturn getActualPageTitle();\n}\n}\nTest Class\nSteps:\nOpen The Internet Main Page\nGo to Multiple Windows Page\nClick the link\nCheck if a new page is opened in the second tab\n@Category({ TestsSelenium.class, TestsChrome.class, TestsFirefox.class, TestsIE.class })\npublic class MultipleWindowsTest extends TheInternetBaseTest {\nprivate static MultipleWindowsPage multipleWindowsPage;\nprivate static NewWindowPage newWindowPage;\n@BeforeClass\npublic static void setUpBeforeClass() {\nmultipleWindowsPage = shouldTheInternetPageBeOpened().clickmultipleWindowsLink();\nlogStep(&quot;Verify if Multiple Windows page is opened&quot;);\nassertTrue(&quot;Unable to open Multiple Windows page&quot;, multipleWindowsPage.isLoaded());\n}\n@Test\npublic void verifyIfNewBrowserWindowOpen() {\nlogStep(&quot;Click &apos;Click here&apos; link&quot;);\nnewWindowPage = multipleWindowsPage.clickHereLink();\nlogStep(&quot;Verify if &apos;New window page&apos; is opened&quot;);\nassertTrue(&quot;Unable to open a new browser window&quot;, newWindowPage.isLoaded());\n}\n}\nThis simple case shows how to approach redirecting links.\nAfter clicking on the link, you will be redirected to Status Codes Page.\nPage Class\nRedirect Link Page\npublic class RedirectLinkPage extends BasePage {\nprivate static final By selectorRedirectHere = By.cssSelector(&quot;a#redirect&quot;);\n@Override\npublic boolean isLoaded() {\ngetDriver().waitForPageLoaded();\nreturn getDriver().getCurrentUrl()\n.contains(PageSubURLsProjectYEnum.REDIRECT.getValue());\n}\n@Override\npublic void load() {\nBFLogger.logDebug(&quot;Load &apos;Redirection&apos; page.&quot;);\ngetDriver().get(GetEnvironmentParam.THE_INTERNET_MAIN_PAGE.getValue() +\nPageSubURLsProjectYEnum.REDIRECT.getValue());\ngetDriver().waitForPageLoaded();\n}\n@Override\npublic String pageTitle() {\nreturn getActualPageTitle();\n}\n/**\n* Clicks &apos;Redirect here&apos; link.\n*\n* @return StatusCodesHomePage object\n*/\npublic StatusCodesHomePage clickRedirectHereLink() {\nnew Button(selectorRedirectHere).click();\nreturn new StatusCodesHomePage();\n}\n}\nStatus Codes Page\npublic class StatusCodesHomePage extends BasePage {\nprivate static final By selectorLink200Code = By.linkText(&quot;200&quot;);\nprivate static final By selectorLink301Code = By.linkText(&quot;301&quot;);\nprivate static final By selectorLink404Code = By.linkText(&quot;404&quot;);\nprivate static final By selectorLink500Code = By.linkText(&quot;500&quot;);\n@Override\npublic boolean isLoaded() {\ngetDriver().waitForPageLoaded();\nreturn getDriver().getCurrentUrl()\n.contains(PageSubURLsProjectYEnum.STATUS_CODES.getValue());\n}\n@Override\npublic void load() {\nBFLogger.logDebug(&quot;Load &apos;Status Codes&apos; page.&quot;);\ngetDriver().get(GetEnvironmentParam.THE_INTERNET_MAIN_PAGE.getValue() +\nPageSubURLsProjectYEnum.STATUS_CODES.getValue());\ngetDriver().waitForPageLoaded();\n}\n@Override\npublic String pageTitle() {\nreturn getActualPageTitle();\n}\n}\nTest Class\nSteps:\nOpen The Internet Main Page\nGo to Redirection Page\nClick the link\nCheck if Status Codes Page is loaded\n@Category({ TestsSelenium.class, TestsChrome.class, TestsFirefox.class, TestsIE.class })\npublic class RedirectLinkTest extends TheInternetBaseTest {\nprivate static RedirectLinkPage redirectLinkPage;\nprivate static StatusCodesHomePage statusCodesHomePage;\n@BeforeClass\npublic static void setUpBeforeClass() {\nredirectLinkPage = shouldTheInternetPageBeOpened().clickRedirectLink();\nlogStep(&quot;Verify if Redirect Link page is opened&quot;);\nassertTrue(&quot;Unable to open Redirect Link page&quot;, redirectLinkPage.isLoaded());\n}\n@Test\npublic void shouldUserBeRedirectedToStatusCodePage() {\nlogStep(&quot;Click &apos;Redirect here&apos; link&quot;);\nstatusCodesHomePage = redirectLinkPage.clickRedirectHereLink();\nlogStep(&quot;Verify redirection to Status Code page&quot;);\nassertTrue(&quot;User hasn&apos;t been redirected to the expected website&quot;,\nstatusCodesHomePage.isLoaded());\n}\n}\nThis case shows how to move horizontal slider.\nYou can move the slider by dragging it with a mouse or using arrow keys. The page uses a simple script to get slider position and display set value.\nPage Class\npublic class HorizontalSliderPage extends BasePage {\nprivate static final By selectorHorizontalSlider = By.cssSelector(&quot;div.sliderContainer&quot;);\nprivate static final By sliderSelector = By.cssSelector(&quot;input&quot;);\nprivate static final By valueSelector = By.cssSelector(&quot;#range&quot;);\nprivate HorizontalSliderElement horizontalSlider;\npublic HorizontalSliderPage() {\nhorizontalSlider = getDriver().elementHorizontalSlider(selectorHorizontalSlider,\nsliderSelector, valueSelector, BigDecimal.ZERO, new BigDecimal(5),\nnew BigDecimal(0.5));\n}\n@Override\npublic boolean isLoaded() {\ngetDriver().waitForPageLoaded();\nreturn getDriver().getCurrentUrl()\n.contains(PageSubURLsProjectYEnum.HORIZONTAL_SLIDER.getValue());\n}\n@Override\npublic void load() {\nBFLogger.logDebug(&quot;Load &apos;Horizontal Slider&apos; page.&quot;);\ngetDriver().get(GetEnvironmentParam.THE_INTERNET_MAIN_PAGE.getValue() +\nPageSubURLsProjectYEnum.HORIZONTAL_SLIDER.getValue());\ngetDriver().waitForPageLoaded();\n}\n@Override\npublic String pageTitle() {\nreturn getActualPageTitle();\n}\n/**\n* Validates if WebElement representing horizontal slider is visible on the page.\n*\n* @return true if horizontal slider is visible, false otherwise.\n*/\npublic boolean isElementHorizontalSliderVisible() {\nreturn getDriver().elementHorizontalSlider(selectorHorizontalSlider)\n.isDisplayed();\n}\n/**\n* Returns the value of slider&apos;s start position.\n*\n* @return BigDecimal representing the lowest possible value of slider.\n*/\npublic BigDecimal getStartPosition() {\nreturn horizontalSlider.getMinRange();\n}\n/**\n* Returns the value of slider&apos;s middle position.\n*\n* @return BigDecimal representing the average value between start and end position.\n*/\npublic BigDecimal getMiddlePosition() {\nreturn horizontalSlider.getMaxRange()\n.subtract(horizontalSlider.getMinRange())\n.divide(new BigDecimal(2));\n}\n/**\n* Returns the value of slider&apos;s end position.\n*\n* @return BigDecimal representing the highest possible value of slider.\n*/\npublic BigDecimal getEndPosition() {\nreturn horizontalSlider.getMaxRange();\n}\n/**\n* Returns current value of slider&apos;s position.\n*\n* @return BigDecimal representing current value of slider.\n*/\npublic BigDecimal getCurrentPosition() {\nreturn horizontalSlider.getCurrentSliderValue();\n}\n/**\n* Sets horizontal slider to a given position using one of the available methods: using keyboard\n* or using mouse move.\n*\n* @param position\n* @param method\n*/\npublic void setSliderPositionTo(BigDecimal position, int method) {\nhorizontalSlider.setSliderPositionTo(position, method);\n}\n/**\n* Verifies the correctness of the given position value and rounds it when necessary.\n*\n* @param position\n* @return Correct value of horizontal slider&apos;s position.\n*/\npublic BigDecimal verifyAndCorrectPositionValue(BigDecimal position) {\nreturn horizontalSlider.verifyAndCorrectPositionValue(position);\n}\n}\nHorizontal Slider Element\nThis class implements methods wich can perform actions on slider:\nCreate Slider Object using method:\ngetDriver().elementHorizontalSlider(By sliderContainerSelector, By sliderSelector, By valueSelector, BigDecimal minRange, BigDecimal maxRange, BigDecimal step)\nAnd use:\nBigDecimal getMaxRange()\nBigDecimal getMinRange()\nBigDecimal getCurrentSliderValue()\nsetSliderPositionTo(BigDecimal position, int method) - moves slider to a given position. If the position is not valid, it changes it to the nearest proper value. Second parameter determinates movement method: 0 - Keyboard, 1 - Mouse\nBigDecimal verifyAndCorrectPositionValue(BigDecimal position) - returns nearest correct position\nTest Class\nBefore all tests: Open The Internet Main Page\nBefore each case:\nGo to Horizontal Slider Page\nCheck if the slider is visible\nSave start, middle and end position\nCase 1 - Moving with the keyboard:\nMove slider to start position, and check if the current position equals the beginning value\nMove the slider to middle position, and check if the current position equals the middle value\nMove slider to end position, and check if the current position equals the end value\nTry to move slider before start position, and check if the current position equals the beginning value\nTry to move slider after end position, and check if the current position equals the end value\nTry to move the slider to an improperly defined position between start and middle, and check if the current position equals the corrected value\nTry to move the slider to an improperly defined random position, and check if the current position equals the corrected value\nMove the slider back to start position, and check if the current position equals the beginning value\nCase 2 - Moving with a mouse: Repeat each Case 1 step using a mouse instead of keyboard\n@Category({ TestsSelenium.class, TestsChrome.class, TestsFirefox.class, TestsIE.class })\npublic class SliderTest extends TheInternetBaseTest {\nprivate static HorizontalSliderPage horizontalSliderPage;\nBigDecimal startPosition;\nBigDecimal middlePosition;\nBigDecimal endPosition;\n@BeforeClass\npublic static void setUpBeforeClass() {\nlogStep(&quot;Open the Url http://the-internet.herokuapp.com/&quot;);\ntheInternetPage = new TheInternetPage();\ntheInternetPage.load();\nlogStep(&quot;Verify if Url http://the-internet.herokuapp.com/ is opened&quot;);\nassertTrue(&quot;Unable to load The Internet Page&quot;, theInternetPage.isLoaded());\n}\n@Override\npublic void setUp() {\nlogStep(&quot;Click Horizontal Slider link&quot;);\nhorizontalSliderPage = theInternetPage.clickHorizontalSliderLink();\nlogStep(&quot;Verify if Horizontal Slider page is opened&quot;);\nassertTrue(&quot;Unable to load Horizontal Slider page&quot;, horizontalSliderPage.isLoaded());\nlogStep(&quot;Verify if horizontal slider element is visible&quot;);\nassertTrue(&quot;Horizontal slider is not visible&quot;,\nhorizontalSliderPage.isElementHorizontalSliderVisible());\nstartPosition = horizontalSliderPage.getStartPosition();\nmiddlePosition = horizontalSliderPage.getMiddlePosition();\nendPosition = horizontalSliderPage.getEndPosition();\n}\n@Test\npublic void shouldHorizontalSliderMoveWhenKeyboardArrowButtonsArePressed() {\nBigDecimal position;\nlogStep(&quot;Move slider to start position: &quot; + startPosition);\nhorizontalSliderPage.setSliderPositionTo(startPosition, HorizontalSliderElement.KEYBOARD);\nassertEquals(&quot;Fail to set horizontal sliders position&quot;, startPosition,\nhorizontalSliderPage.getCurrentPosition());\nlogStep(&quot;Move slider to middle position: &quot; + middlePosition);\nhorizontalSliderPage.setSliderPositionTo(middlePosition, HorizontalSliderElement.KEYBOARD);\nassertEquals(&quot;Fail to set horizontal sliders position&quot;,\nhorizontalSliderPage.verifyAndCorrectPositionValue(middlePosition),\nhorizontalSliderPage.getCurrentPosition());\nlogStep(&quot;Move slider to end position: &quot; + endPosition);\nhorizontalSliderPage.setSliderPositionTo(endPosition, HorizontalSliderElement.KEYBOARD);\nassertEquals(&quot;Fail to set horizontal sliders position&quot;, endPosition,\nhorizontalSliderPage.getCurrentPosition());\nposition = startPosition.subtract(BigDecimal.ONE);\nlogStep(&quot;Move slider to position before start position: &quot; + position);\nhorizontalSliderPage.setSliderPositionTo(position, HorizontalSliderElement.KEYBOARD);\nassertEquals(&quot;Fail to set horizontal sliders position&quot;, startPosition,\nhorizontalSliderPage.getCurrentPosition());\nposition = endPosition.add(BigDecimal.ONE);\nlogStep(&quot;Move slider to position after end position: &quot; + position);\nhorizontalSliderPage.setSliderPositionTo(position, HorizontalSliderElement.KEYBOARD);\nassertEquals(&quot;Fail to set horizontal sliders position&quot;, endPosition,\nhorizontalSliderPage.getCurrentPosition());\nposition = middlePosition.divide(new BigDecimal(2));\nlogStep(&quot;Move slider to improperly defined position: &quot; + position);\nhorizontalSliderPage.setSliderPositionTo(position, HorizontalSliderElement.KEYBOARD);\nassertEquals(&quot;Fail to set horizontal sliders position&quot;,\nhorizontalSliderPage.verifyAndCorrectPositionValue(position),\nhorizontalSliderPage.getCurrentPosition());\nposition = new BigDecimal(new BigInteger(&quot;233234&quot;), 5);\nlogStep(&quot;Move slider to improperly defined random position: &quot; + position);\nhorizontalSliderPage.setSliderPositionTo(position, HorizontalSliderElement.KEYBOARD);\nassertEquals(&quot;Fail to set horizontal sliders position&quot;,\nhorizontalSliderPage.verifyAndCorrectPositionValue(position),\nhorizontalSliderPage.getCurrentPosition());\nlogStep(&quot;Move slider back to start position: &quot; + startPosition);\nhorizontalSliderPage.setSliderPositionTo(startPosition, HorizontalSliderElement.KEYBOARD);\nassertEquals(&quot;Fail to set horizontal sliders position&quot;, startPosition,\nhorizontalSliderPage.getCurrentPosition());\n}\n@Test\npublic void shouldHorizontalSliderMoveWhenMouseButtonIsPressedAndMouseIsMoving() {\nBigDecimal position;\nlogStep(&quot;Move slider to start position: &quot; + startPosition);\nhorizontalSliderPage.setSliderPositionTo(startPosition, HorizontalSliderElement.MOUSE);\nassertEquals(&quot;Fail to set horizontal sliders position&quot;, startPosition,\nhorizontalSliderPage.getCurrentPosition());\nlogStep(&quot;Move slider to middle position: &quot; + middlePosition);\nhorizontalSliderPage.setSliderPositionTo(middlePosition, HorizontalSliderElement.MOUSE);\nassertEquals(&quot;Fail to set horizontal sliders position&quot;,\nhorizontalSliderPage.verifyAndCorrectPositionValue(middlePosition),\nhorizontalSliderPage.getCurrentPosition());\nlogStep(&quot;Move slider to end position: &quot; + endPosition);\nhorizontalSliderPage.setSliderPositionTo(endPosition, HorizontalSliderElement.MOUSE);\nassertEquals(&quot;Fail to set horizontal sliders position&quot;, endPosition,\nhorizontalSliderPage.getCurrentPosition());\nposition = startPosition.subtract(BigDecimal.ONE);\nlogStep(&quot;Move slider to position before start position: &quot; + position);\nhorizontalSliderPage.setSliderPositionTo(position, HorizontalSliderElement.MOUSE);\nassertEquals(&quot;Fail to set horizontal sliders position&quot;, startPosition,\nhorizontalSliderPage.getCurrentPosition());\nposition = endPosition.add(BigDecimal.ONE);\nlogStep(&quot;Move slider to position after end position: &quot; + position);\nhorizontalSliderPage.setSliderPositionTo(position, HorizontalSliderElement.MOUSE);\nassertEquals(&quot;Fail to set horizontal sliders position&quot;, endPosition,\nhorizontalSliderPage.getCurrentPosition());\nposition = middlePosition.divide(new BigDecimal(2));\nlogStep(&quot;Move slider to improperly defined position: &quot; + position);\nhorizontalSliderPage.setSliderPositionTo(position, HorizontalSliderElement.MOUSE);\nassertEquals(&quot;Fail to set horizontal sliders position&quot;,\nhorizontalSliderPage.verifyAndCorrectPositionValue(position),\nhorizontalSliderPage.getCurrentPosition());\nposition = new BigDecimal(new BigInteger(&quot;212348&quot;), 5);\nlogStep(&quot;Move slider to improperly defined random position: &quot; + position);\nhorizontalSliderPage.setSliderPositionTo(position, HorizontalSliderElement.MOUSE);\nassertEquals(&quot;Fail to set horizontal sliders position&quot;,\nhorizontalSliderPage.verifyAndCorrectPositionValue(position),\nhorizontalSliderPage.getCurrentPosition());\nlogStep(&quot;Move slider back to start position: &quot; + startPosition);\nhorizontalSliderPage.setSliderPositionTo(startPosition, HorizontalSliderElement.MOUSE);\nassertEquals(&quot;Fail to set horizontal sliders position&quot;, startPosition,\nhorizontalSliderPage.getCurrentPosition());\n}\n}\nThis example shows how to sort and read data from tables.\nAfter clicking on a column header, the data will be sorted descending and after another click sorted ascending by selected attribute. Watch how both tables&apos; content changes on page DOM. Sorting is performed by JavaScript functions.\nPage Class\npublic class SortableDataTablesPage extends BasePage {\nprivate static final By selectorTable = By.cssSelector(&quot;table.tablesorter&quot;);\nprivate static final By selectorHeader = By.cssSelector(&quot;th&quot;);\n@Override\npublic boolean isLoaded() {\ngetDriver().waitForPageLoaded();\nreturn getDriver().getCurrentUrl()\n.contains(PageSubURLsProjectYEnum.SORTABLE_DATA_TABLES.getValue());\n}\n@Override\npublic void load() {\nBFLogger.logDebug(&quot;Load &apos;Data Tables&apos; page.&quot;);\ngetDriver().get(GetEnvironmentParam.THE_INTERNET_MAIN_PAGE.getValue() +\nPageSubURLsProjectYEnum.SORTABLE_DATA_TABLES.getValue());\ngetDriver().waitForPageLoaded();\n}\n@Override\npublic String pageTitle() {\nreturn getActualPageTitle();\n}\n/**\n* Sorts data in given column using ascending order.\n*\n* @param columnNumber The number of column where data should be sorted\n* @param tableNumber The number of table where data should be sorted\n*/\npublic void sortColumnAscending(int columnNumber, int tableNumber) {\nWebElement header = this.getTableHeaders(columnNumber, tableNumber);\nString className = header.getAttribute(&quot;class&quot;);\nif (className.contains(&quot;headerSortUp&quot;) || !className.contains(&quot;headerSortDown&quot;)) {\nheader.click();\n}\n}\n/**\n* Sorts data in given column using descending order.\n*\n* @param columnNumber The number of the column where data should be sorted\n* @param tableNumber The number of the table where data should be sorted\n*/\npublic void sortColumnDescending(int columnNumber, int tableNumber) {\nWebElement header = this.getTableHeaders(columnNumber, tableNumber);\nString className = header.getAttribute(&quot;class&quot;);\nif (!className.contains(&quot;headerSortUp&quot;)) {\nheader.click();\nif (!className.contains(&quot;headerSortDown&quot;)) {\nheader.click();\n}\n}\n}\n/**\n* Return given column values from chosen table.\n*\n* @param columnNumber The number of the column the data should be retrieved from\n* @param tableNumber The number of the table the data should be retrieved from\n* @return list of values from given column\n*/\npublic List&lt;String&gt; getColumnValues(int columnNumber, int tableNumber) {\nWebElement table = getTable(tableNumber);\nreturn JsoupHelper.findTexts(table, By.cssSelector(&quot;tr &gt; td:nth-child(&quot; + (columnNumber + 1)\n+ &quot;)&quot;));\n}\n/**\n* Returns column&apos;s class name.\n*\n* @param columnNumber The number of the column to get class number from\n* @param tableNumber The number of the table to get column class name from\n* @return String object representing column&apos;s class name\n*/\npublic String readColumnClass(int columnNumber, int tableNumber) {\nreturn this.getTableHeaders(columnNumber, tableNumber)\n.getAttribute(&quot;class&quot;);\n}\nprivate WebElement getTable(int tableNumber) {\nreturn new ListElements(selectorTable).getList()\n.get(tableNumber);\n}\nprivate WebElement getTableHeaders(int columnNumber, int tableNumber) {\nreturn getTable(tableNumber).findElements(selectorHeader)\n.get(columnNumber);\n}\n}\nFinding values\nUsing proper selectors, save elements such as tables and their columns&apos; headers as Web Element Lists. Afterwards, you can get the desired element finding it by index (e. g. table or column number). To get column values, use JsoupHelper and to check if the column is sorted get its class attribute.\nTest Class\nBefore all tests: Open The Internet Main Page\nBefore each case: Go to Sortable Data Tables Page\nCase 1:\nChoose a random table\nSort first column &quot;Last Name&quot; in ascending order\nCheck if column header class contains &quot;headerSortDown&quot;\nSave column content to the List\nCreate List copy and sort it\nCompare sorted values and values from the table\nCase 2:\nChoose a random table\nSort second column &quot;First Name&quot; in descending order\nCheck if column header class contains &quot;headerSortUp&quot;\nSave column content to the List\nCreate List copy and sort it then reverse it\nCompare reversed sorted values and values from the table\n@Category({ TestsSelenium.class, TestsChrome.class, TestsFirefox.class, TestsIE.class })\npublic class SortableDataTablesTest extends TheInternetBaseTest {\nprivate static SortableDataTablesPage sortableDataTablesPage;\nprivate List&lt;String&gt; actualValues;\nprivate List&lt;String&gt; expectedValues;\n@BeforeClass\npublic static void setUpBeforeClass() {\nlogStep(&quot;Open the Url http://the-internet.herokuapp.com/&quot;);\ntheInternetPage = new TheInternetPage();\ntheInternetPage.load();\nlogStep(&quot;Verify if Url http://the-internet.herokuapp.com/ is opened&quot;);\nassertTrue(&quot;Unable to load The Internet Page&quot;, theInternetPage.isLoaded());\n}\n@Override\npublic void setUp() {\nlogStep(&quot;Click subpage link&quot;);\nsortableDataTablesPage = theInternetPage.clickSortableDataTablesLink();\nlogStep(&quot;Verify if subpage is opened&quot;);\nassertTrue(&quot;Unable to open Sortable Data Tables page&quot;, sortableDataTablesPage.isLoaded());\n}\n@Test\npublic void shouldLastNameColumnBeOrderedAscendingAfterSort() {\nint columnNumber = 0;\nint tableNumber = new Random().nextInt(2);\nlogStep(&quot;Sort &apos;Last Name&apos; column&quot;);\nsortableDataTablesPage.sortColumnAscending(columnNumber, tableNumber);\nassertTrue(&quot;Unable to set ascending order for &apos;Last Name&apos; column&quot;,\nsortableDataTablesPage.readColumnClass(columnNumber, tableNumber)\n.contains(&quot;headerSortDown&quot;));\nlogStep(&quot;Verify data order for &apos;Last Name&apos; column&quot;);\nactualValues = sortableDataTablesPage.getColumnValues(columnNumber, tableNumber);\nexpectedValues = new ArrayList&lt;String&gt;(actualValues);\nCollections.sort(expectedValues);\nassertEquals(&quot;&apos;Last Name&apos; column is not sorted in ascending order&quot;,\nexpectedValues, actualValues);\n}\n@Test\npublic void shouldFirstNameColumnBeOrderedDescendingAfterSort() {\nint columnNumber = 1;\nint tableNumber = new Random().nextInt(2);\nlogStep(&quot;Sort &apos;First Name&apos; column&quot;);\nsortableDataTablesPage.sortColumnDescending(columnNumber, tableNumber);\nassertTrue(&quot;Unable to set descending order for &apos;First Name&apos; column&quot;,\nsortableDataTablesPage.readColumnClass(columnNumber, tableNumber)\n.contains(&quot;headerSortUp&quot;));\nlogStep(&quot;Verify data order for &apos;First Name&apos; column&quot;);\nactualValues = sortableDataTablesPage.getColumnValues(columnNumber, tableNumber);\nexpectedValues = new ArrayList&lt;String&gt;(actualValues);\nCollections.sort(expectedValues);\nCollections.reverse(expectedValues);\nassertEquals(&quot;&apos;First Name&apos; column is not sorted in descending order&quot;,\nexpectedValues, actualValues);\n}\n}\nThis example shows how to process HTTP status codes returned by page\nWhen you click status code link, you will be redirected to the subpage which returns the proper HTTP status code. In order to check what code was returned:\nOpen developer tools\nGo to Network tab\nClick request name\nFind a code number in Headers section\nPage Class\nAdd new methods to existing Status Codes Home Page Class\npublic class StatusCodesHomePage extends BasePage {\nprivate static final By selectorLink200Code = By.linkText(&quot;200&quot;);\nprivate static final By selectorLink301Code = By.linkText(&quot;301&quot;);\nprivate static final By selectorLink404Code = By.linkText(&quot;404&quot;);\nprivate static final By selectorLink500Code = By.linkText(&quot;500&quot;);\n@Override\npublic boolean isLoaded() {\ngetDriver().waitForPageLoaded();\nreturn getDriver().getCurrentUrl()\n.contains(PageSubURLsProjectYEnum.STATUS_CODES.getValue());\n}\n@Override\npublic void load() {\nBFLogger.logDebug(&quot;Load &apos;Status Codes&apos; page.&quot;);\ngetDriver().get(GetEnvironmentParam.THE_INTERNET_MAIN_PAGE.getValue() +\nPageSubURLsProjectYEnum.STATUS_CODES.getValue());\ngetDriver().waitForPageLoaded();\n}\n@Override\npublic String pageTitle() {\nreturn getActualPageTitle();\n}\n/**\n* Verifies if given link is displayed.\n*\n* @param selector Selector of the given link\n* @return true if link is displayed\n*/\npublic boolean isLinkCodeDisplayed(By selector) {\nreturn getDriver().findElementDynamic(selector)\n.isDisplayed();\n}\n/**\n* Clicks &apos;200&apos; link.\n*\n* @return StatusCodesCodePage object\n*/\npublic StatusCodesCodePage clickCode200Link() {\nreturn clickCodeLink(selectorLink200Code);\n}\n/**\n* Clicks &apos;301&apos; link.\n*\n* @return StatusCodesCodePage object\n*/\npublic StatusCodesCodePage clickCode301Link() {\nreturn clickCodeLink(selectorLink301Code);\n}\n/**\n* Clicks &apos;404&apos; link.\n*\n* @return StatusCodesCodePage object\n*/\npublic StatusCodesCodePage clickCode404Link() {\nreturn clickCodeLink(selectorLink404Code);\n}\n/**\n* Clicks &apos;500&apos; link.\n*\n* @return StatusCodesCodePage object\n*/\npublic StatusCodesCodePage clickCode500Link() {\nreturn clickCodeLink(selectorLink500Code);\n}\n/**\n* Clicks code link according to given code number.\n*\n* @param code Given code\n* @return StatusCodesCodePage object\n*/\npublic StatusCodesCodePage clickCodeLink(String code) {\nreturn clickCodeLink(By.linkText(code));\n}\nprivate StatusCodesCodePage clickCodeLink(By selector) {\nString codeNumber = getCodeNumberToCheck(selector);\ngetDriver().findElementDynamic(selector)\n.click();\nreturn new StatusCodesCodePage(codeNumber);\n}\nprivate String getCodeNumberToCheck(By selector) {\nreturn getDriver().findElementDynamic(selector)\n.getText();\n}\n}\nCreate a page class for status codes subpages as well. In the class constructor specify which code number should be returned.\npublic class StatusCodesCodePage extends BasePage {\nprivate static final By selectorDisplayedText = By.cssSelector(&quot;#content &gt; div &gt; p&quot;);\nprivate static final By selectorLinkToCodesPage = By.cssSelector(&quot;#content &gt; div &gt; p &gt; a&quot;);\nprivate String codeNumber;\npublic StatusCodesCodePage(String codeNumber) {\nthis.codeNumber = codeNumber;\n}\n@Override\npublic boolean isLoaded() {\ngetDriver().waitForPageLoaded();\nreturn getDriver().getCurrentUrl()\n.contains(PageSubURLsProjectYEnum.STATUS_CODES.getValue() + &apos;/&apos;);\n}\n@Override\npublic void load() {\nBFLogger.logDebug(&quot;Load &apos;Status Codes&apos; page.&quot;);\ngetDriver().get(GetEnvironmentParam.THE_INTERNET_MAIN_PAGE.getValue() +\nPageSubURLsProjectYEnum.STATUS_CODES.getValue() + &apos;/&apos; + codeNumber);\ngetDriver().waitForPageLoaded();\n}\n@Override\npublic String pageTitle() {\nreturn getActualPageTitle();\n}\npublic String getCodeNumber() {\nreturn codeNumber;\n}\n/**\n* Verifies if page is loaded with given code number.\n*\n* @param codeNumber Expected code number\n* @return true if expected code number is loaded with web page\n*/\npublic boolean isLoadedWithStatusCode(String codeNumber) {\nreturn getDriver().getCurrentUrl()\n.equals(GetEnvironmentParam.THE_INTERNET_MAIN_PAGE.getValue() +\nPageSubURLsProjectYEnum.STATUS_CODES.getValue() + &quot;/&quot; + codeNumber);\n}\n/**\n* Returns displayed code number.\n* &lt;p&gt;\n* Code number is retrieved from following text displayed on the page:&lt;b&gt;\n* &apos;This page returned a *** status code.&apos;, where *** represent the code number to be\n* returned.\n* &lt;/p&gt;\n*\n* @return String object representing the displayed code number retrieved from specific sentence.\n*/\npublic String getDisplayedCodeNumber() {\nreturn getDriver().findElementDynamic(selectorDisplayedText)\n.getText()\n.substring(21, 24);\n}\n/**\n* Clicks link to return to &apos;Code Page&apos;.\n*\n* @return StatusCodesHomePage object\n*/\npublic StatusCodesHomePage clickLinkToCodePage() {\ngetDriver().findElementDynamic(selectorLinkToCodesPage)\n.click();\nreturn new StatusCodesHomePage();\n}\n}\nTest Class\nBefore all tests: Open The Internet Main Page, go to Status Codes page\nSteps:\nFor each status code\nClick code link\nCheck if the page is loaded with an expected code number\nCheck if the displayed code number equals the expected number\nGo back to Status Codes Home Page\n@Category({ TestsSelenium.class, TestsChrome.class, TestsFirefox.class, TestsIE.class })\npublic class StatusCodeTest extends TheInternetBaseTest {\nprivate static StatusCodesHomePage statusCodesHomePage;\nprivate StatusCodesCodePage statusCodesCodePage;\nprivate String[] codes = { &quot;200&quot;, &quot;301&quot;, &quot;404&quot;, &quot;500&quot; };\n@BeforeClass\npublic static void setUpBeforeClass() {\nstatusCodesHomePage = shouldTheInternetPageBeOpened().clickStatusCodesLink();\nlogStep(&quot;Verify if Status Codes Home page is opened&quot;);\nassertTrue(&quot;Unable to open Status Codes Home page&quot;, statusCodesHomePage.isLoaded());\n}\n@Test\npublic void shouldProperCodeBeDisplayedAfterClickCodeLink() {\nfor (String code : codes) {\nlogStep(&quot;Click link to &quot; + code + &quot; code&quot;);\nstatusCodesCodePage = statusCodesHomePage.clickCodeLink(code);\nlogStep(&quot;Verify if proper web page corresponding to the code is opened&quot;);\nassertTrue(&quot;Unable to open proper web page&quot;,\nstatusCodesCodePage.isLoadedWithStatusCode(code));\nlogStep(&quot;Verify if the displayed code is equal to the expected one&quot;);\nassertEquals(code, statusCodesCodePage.getDisplayedCodeNumber());\nlogStep(&quot;Click link to come back to &apos;Status Codes&apos; page&quot;);\nstatusCodesCodePage.clickLinkToCodePage();\n}\n}\n}\n80.2.2. First Steps\nPage Object\nYour Product Under Test will be the following website: http://the-internet.herokuapp.com/\nAt first, create an Object to represent The Internet Main Page:\npublic class TheInternetPage extends BasePage\nEach class which extends BasePage class must override three methods:\npublic boolean isLoaded() - returns true if the page is loaded and false if not\npublic void load() - loads the page\npublic String pageTitle() - returns page title\npublic class TheInternetPage extends BasePage {\n@Override\npublic boolean isLoaded() {\nBFLogger.logDebug(&quot;The internet page is loaded: &quot; + getDriver().getCurrentUrl());\nreturn getDriver().getCurrentUrl()\n.equals(GetEnvironmentParam.THE_INTERNET_MAIN_PAGE.getValue());\n}\n@Override\npublic void load() {\nBFLogger.logDebug(&quot;Load &apos;The internet&apos; page.&quot;);\ngetDriver().get(GetEnvironmentParam.THE_INTERNET_MAIN_PAGE.getValue());\ngetDriver().waitForPageLoaded();\n}\n@Override\npublic String pageTitle() {\nreturn getActualPageTitle();\n}\n}\nEnvironment Variables\nIn Page classes, when you load/start web, it is uncommon to save fixed main URL.\nInstead of hardcoded main URL variable, you build your Page class with a dynamic variable.\nHow to create / update system environment\nDynamic variable values are stored under path \\src\\resources\\enviroments\\environments.csv.\nBy default, the environment takes value from DEV column.\nAccess to the external file variables\nCreate a class GetEnvironmentParam to map values from an external file with Page class:\npublic enum GetEnvironmentParam {\n// Name if enum must be in line with cell name in /src/resources/environments/environment.csv\nWWW_FONT_URL,\nTOOLS_QA,\nWEB_SERVICE,\nTHE_INTERNET_MAIN_PAGE,\nELEMENTAL_SELENIUM_PAGE;\npublic String getValue() {\nif (null == BaseTest.getEnvironmentService()) {\nthrow new BFInputDataException(&quot;Environment Parameters class wasn&apos;t initialized properly&quot;);\n}\nreturn BaseTest.getEnvironmentService()\n.getValue(this.name());\n}\n@Override\npublic String toString() {\nreturn this.getValue();\n}\n}\nWhen you add a new row to environments.csv also add a new variable to GetEnvironmentParam class.\nIn Page class access environmental variable using this method:\nGetEnvironmentParam.THE_INTERNET_MAIN_PAGE.getValue();\nSelectors\nCreate selectors\nCreate a selector for every interactable element on a webpage using By type. Find elements and it&#x2019;s attributes using browser developer mode (F12).\nprivate static final By abTestLinkSelector = By.cssSelector(&quot;li &gt;\na[href*=&apos;abtest&apos;]&quot;);\nprivate static final By basicAuthLinkSelector = By.cssSelector(&quot;li &gt;\na[href*=&apos;basic_auth&apos;]&quot;);\nprivate static final By brokenImageLinkSelector = By.cssSelector(&quot;li &gt;\na[href*=&apos;broken_images&apos;]&quot;);\nprivate static final By challengingDomLinkSelector = By.cssSelector(&quot;li &gt;\na[href*=&apos;challenging_dom&apos;]&quot;);\nprivate static final By checkboxesLinkSelector = By.cssSelector(&quot;li &gt;\na[href*=&apos;checkboxes&apos;]&quot;);\nprivate static final By contextMenuLinkSelector = By.cssSelector(&quot;li &gt;\na[href*=&apos;context_menu&apos;]&quot;);\nprivate static final By disappearingElementsLinkSelector = By.cssSelector(&quot;li &gt;\na[href*=&apos;disappearing_elements&apos;]&quot;);\nprivate static final By dragAndDropLinkSelector = By.cssSelector(&quot;li &gt;\na[href*=&apos;drag_and_drop&apos;]&quot;);\nprivate static final By dropdownLinkSelector = By.cssSelector(&quot;li &gt;\na[href*=&apos;dropdown&apos;]&quot;);\nprivate static final By dynamicContentLinkSelector = By.cssSelector(&quot;li &gt;\na[href*=&apos;dynamic_content&apos;]&quot;);\nprivate static final By dynamicControlsLinkSelector = By.cssSelector(&quot;li &gt;\na[href*=&apos;dynamic_controls&apos;]&quot;);\nprivate static final By dynamicLoadingLinkSelector = By.cssSelector(&quot;li &gt;\na[href*=&apos;dynamic_loading&apos;]&quot;);\nprivate static final By exitIntentLinkSelector = By.cssSelector(&quot;li &gt;\na[href*=&apos;exit_intent&apos;]&quot;);\nprivate static final By fileDownloadLinkSelector = By.cssSelector(&quot;li &gt;\na[href$=&apos;download&apos;]&quot;);\nprivate static final By fileUploadLinkSelector = By.cssSelector(&quot;li &gt;\na[href*=&apos;upload&apos;]&quot;);\nprivate static final By floatingMenuLinkSelector = By.cssSelector(&quot;li &gt;\na[href*=&apos;floating_menu&apos;]&quot;);\nprivate static final By forgotPasswordLinkSelector = By.cssSelector(&quot;li &gt;\na[href*=&apos;forgot_password&apos;]&quot;);\nprivate static final By formAuthenticationLinkSelector = By.cssSelector(&quot;li &gt;\na[href*=&apos;login&apos;]&quot;);\nprivate static final By framesLinkSelector = By.cssSelector(&quot;li &gt;\na[href*=&apos;frames&apos;]&quot;);\nprivate static final By geolocationLinkSelector = By.cssSelector(&quot;li &gt;\na[href*=&apos;geolocation&apos;]&quot;);\nprivate static final By horizontalSliderLinkSelector = By.cssSelector(&quot;li &gt;\na[href*=&apos;horizontal_slider&apos;]&quot;);\nprivate static final By hoversLinkSelector = By.cssSelector(&quot;li &gt;\na[href*=&apos;hovers&apos;]&quot;);\nprivate static final By infiniteScrollLinkSelector = By.cssSelector(&quot;li &gt;\na[href*=&apos;infinite_scroll&apos;]&quot;);\nprivate static final By javaScriptAlertLinkSelector = By.cssSelector(&quot;li &gt;\na[href*=&apos;javascript_alerts&apos;]&quot;);\nprivate static final By javaScriptErrorLinkSelector = By.cssSelector(&quot;li &gt;\na[href*=&apos;javascript_error&apos;]&quot;);\nprivate static final By jQueryUIMenuLinkSelector = By.cssSelector(&quot;li &gt;\na[href*=&apos;jqueryui/menu&apos;]&quot;);\nprivate static final By keyPressesLinkSelector = By.cssSelector(&quot;li &gt;\na[href*=&apos;key_presses&apos;]&quot;);\nprivate static final By largeAndDeepDOMLinkSelector = By.cssSelector(&quot;li &gt;\na[href*=&apos;large&apos;]&quot;);\nprivate static final By multipleWindowsLinkSelector = By.cssSelector(&quot;li &gt;\na[href*=&apos;windows&apos;]&quot;);\nprivate static final By nestedFramesLinkSelector = By.cssSelector(&quot;li &gt;\na[href*=&apos;nested_frames&apos;]&quot;);\nprivate static final By notificationMessagesLinkSelector = By.cssSelector(&quot;li &gt;\na[href*=&apos;notification_message&apos;]&quot;);\nprivate static final By redirectLinkSelector = By.cssSelector(&quot;li &gt;\na[href*=&apos;redirector&apos;]&quot;);\nprivate static final By secureFileDownloadLinkSelector = By.cssSelector(&quot;li &gt;\na[href*=&apos;download_secure&apos;]&quot;);\nprivate static final By shiftingContentLinkSelector = By.cssSelector(&quot;li &gt;\na[href*=&apos;shifting_content&apos;]&quot;);\nprivate static final By slowResourcesLinkSelector = By.cssSelector(&quot;li &gt;\na[href*=&apos;slow&apos;]&quot;);\nprivate static final By sortableDataTablesLinkSelector = By.cssSelector(&quot;li &gt;\na[href*=&apos;tables&apos;]&quot;);\nprivate static final By statusCodesLinkSelector = By.cssSelector(&quot;li &gt;\na[href*=&apos;status_codes&apos;]&quot;);\nprivate static final By typosLinkSelector = By.cssSelector(&quot;li &gt;\na[href*=&apos;typos&apos;]&quot;);\nprivate static final By wYSIWYGEditorLinkSelector = By.cssSelector(&quot;li &gt;\na[href*=&apos;tinymce&apos;]&quot;);\nImplement methods\nThen use these selectors to create Objects and perform actions on page elements:\npublic ABtestPage clickABtestingLink() {\nnew Button(abTestLinkSelector).click();\nreturn new ABtestPage();\n}\npublic BasicAuthPage clickBasicAuthLink() {\ngetDriver().waitForPageLoaded();\nWebElement link = getDriver().findElementDynamic(basicAuthLinkSelector);\nJavascriptExecutor executor = (JavascriptExecutor) getDriver();\nexecutor.executeScript(&quot;var elem=arguments[0]; setTimeout(function() {elem.click();}, 100)&quot;,\nlink);\nreturn new BasicAuthPage();\n}\npublic BrokenImagePage clickBrokenImageLink() {\nnew Button(brokenImageLinkSelector).click();\nreturn new BrokenImagePage();\n}\npublic ChallengingDomPage clickChallengingDomLink() {\nnew Button(challengingDomLinkSelector).click();\nreturn new ChallengingDomPage();\n}\npublic CheckboxesPage clickCheckboxesLink() {\nnew Button(checkboxesLinkSelector).click();\nreturn new CheckboxesPage();\n}\npublic ContextMenuPage clickContextMenuLink() {\nnew Button(contextMenuLinkSelector).click();\nreturn new ContextMenuPage();\n}\npublic DisappearingElementsPage clickDisappearingElementsLink() {\nnew Button(disappearingElementsLinkSelector).click();\nreturn new DisappearingElementsPage();\n}\npublic DragAndDropPage clickDragAndDropLink() {\nnew Button(dragAndDropLinkSelector).click();\nreturn new DragAndDropPage();\n}\npublic DropdownPage clickDropdownLink() {\nnew Button(dropdownLinkSelector).click();\nreturn new DropdownPage();\n}\npublic DynamicContentPage clickDynamicContentLink() {\nnew Button(dynamicContentLinkSelector).click();\nreturn new DynamicContentPage();\n}\npublic DynamicControlsPage clickDynamicControlsLink() {\nnew Button(dynamicControlsLinkSelector).click();\nreturn new DynamicControlsPage();\n}\npublic DynamicLoadingPage clickDynamicLoadingLink() {\nnew Button(dynamicLoadingLinkSelector).click();\nreturn new DynamicLoadingPage();\n}\npublic ExitIntentPage clickExitIntentLink() {\nnew Button(exitIntentLinkSelector).click();\nreturn new ExitIntentPage();\n}\npublic FileDownloadPage clickFileDownloadLink() {\nnew Button(fileDownloadLinkSelector).click();\nreturn new FileDownloadPage();\n}\npublic FileUploadPage clickFileUploadLink() {\nnew Button(fileUploadLinkSelector).click();\nreturn new FileUploadPage();\n}\npublic FloatingMenuPage clickFloatingMenuLink() {\nnew Button(floatingMenuLinkSelector).click();\nreturn new FloatingMenuPage();\n}\npublic ForgotPasswordPage clickForgotPasswordLink() {\nnew Button(forgotPasswordLinkSelector).click();\nreturn new ForgotPasswordPage();\n}\npublic FormAuthenticationPage clickFormAuthenticationLink() {\nnew Button(formAuthenticationLinkSelector).click();\nreturn new FormAuthenticationPage();\n}\npublic FramesPage clickFramesLink() {\nnew Button(framesLinkSelector).click();\nreturn new FramesPage();\n}\npublic GeolocationPage clickGeolocationLink() {\nnew Button(geolocationLinkSelector).click();\nreturn new GeolocationPage();\n}\npublic HorizontalSliderPage clickHorizontalSliderLink() {\nnew Button(horizontalSliderLinkSelector).click();\nreturn new HorizontalSliderPage();\n}\npublic HoversPage clickHoversLink() {\nnew Button(hoversLinkSelector).click();\nreturn new HoversPage();\n}\npublic InfiniteScrollPage clickInfiniteScrollLink() {\nnew Button(infiniteScrollLinkSelector).click();\nreturn new InfiniteScrollPage();\n}\npublic JavaScriptAlertsPage clickJavaScriptAlertLink() {\nnew Button(javaScriptAlertLinkSelector).click();\nreturn new JavaScriptAlertsPage();\n}\npublic JavaScriptErrorPage clickJavaScriptErrorLink() {\nnew Button(javaScriptErrorLinkSelector).click();\nreturn new JavaScriptErrorPage();\n}\npublic JQueryUIMenuPage clickJQueryUIMenuLink() {\nnew Button(jQueryUIMenuLinkSelector).click();\nreturn new JQueryUIMenuPage();\n}\npublic KeyPressesPage clickKeyPressesLink() {\nnew Button(keyPressesLinkSelector).click();\nreturn new KeyPressesPage();\n}\npublic LargeAndDeepDOMPage clickLargeAndDeepDOMLink() {\nnew Button(largeAndDeepDOMLinkSelector).click();\nreturn new LargeAndDeepDOMPage();\n}\npublic MultipleWindowsPage clickmultipleWindowsLink() {\nnew Button(multipleWindowsLinkSelector).click();\nreturn new MultipleWindowsPage();\n}\npublic NestedFramesPage clickNestedFramesLink() {\nnew Button(nestedFramesLinkSelector).click();\nreturn new NestedFramesPage();\n}\npublic NotificationMessagesPage clickNotificationMessagesLink() {\nnew Button(notificationMessagesLinkSelector).click();\nreturn new NotificationMessagesPage();\n}\npublic RedirectLinkPage clickRedirectLink() {\nnew Button(redirectLinkSelector).click();\nreturn new RedirectLinkPage();\n}\npublic SecureFileDownloadPage clickSecureFileDownloadLink() {\nnew Button(secureFileDownloadLinkSelector).click();\nreturn new SecureFileDownloadPage();\n}\npublic ShiftingContentPage clickShiftingContentLink() {\nnew Button(shiftingContentLinkSelector).click();\nreturn new ShiftingContentPage();\n}\npublic SlowResourcesPage clickSlowResourcesLink() {\nnew Button(slowResourcesLinkSelector).click();\nreturn new SlowResourcesPage();\n}\npublic SortableDataTablesPage clickSortableDataTablesLink() {\nnew Button(sortableDataTablesLinkSelector).click();\nreturn new SortableDataTablesPage();\n}\npublic StatusCodesHomePage clickStatusCodesLink() {\nnew Button(statusCodesLinkSelector).click();\nreturn new StatusCodesHomePage();\n}\npublic TyposPage clickTyposLink() {\nnew Button(typosLinkSelector).click();\nreturn new TyposPage();\n}\npublic WYSIWYGEditorPage clickWYSIWYGEditorLink() {\nnew Button(wYSIWYGEditorLinkSelector).click();\nreturn new WYSIWYGEditorPage();\n}\nThese methods create a Button object for every link on The Internet Page and click it to redirect on a different subpage.\nElements types\nMrChecker includes Object types for various elements existing on webpages such as Button, TextBox etc. There is also WebElement class and getDriver().findElementDynamic(By selector) method for creating webpage objects dynamically and performing basic actions:\nInstead of using static types you can use:\npublic TyposPage clickTyposLink() {\nWebElement checkboxesLink = getDriver().findElementDynamic(checkboxesLinkSelector);\ncheckboxesLink.click();\nreturn new TyposPage();\n}\nOr perform actions without creating a variable:\npublic TyposPage clickTyposLink() {\ngetDriver().findElementDynamic(checkboxesLinkSelector).click();\nreturn new TyposPage();\n}\nThe Internet Base Test\nTest Class\nCreate Test class and override methods:\npublic void setUp() - executes before each test\npublic void tearDown() - executes after each test\npublic class TheInternetBaseTest extends BaseTest {\n@Override\npublic void setUp() {\n}\n@Override\npublic void tearDown() {\nlogStep(&quot;Navigate back to The-Internet page&quot;);\nBasePage.navigateBack();\n}\n}\nlogStep(String message) method doesn&#x2019;t exist yet so you should create it:\nprotected static int step = 0;\n/**\n* Logs test step including step number calculated individually for each test.\n*\n* @param message Text message representing step description.\n*/\npublic static void logStep(String message) {\nBFLogger.logInfo(&quot;Step &quot; + ++step + &quot;: &quot; + message);\n}\nWrite a method for loading The Internet Page and checking if it is properly opened:\nprotected static TheInternetPage theInternetPage;\n/**\n* Performs operations required for verifying if The Internet Page is properly opened.\n*\n* @return TheInternetPage\n*/\npublic static TheInternetPage shouldTheInternetPageBeOpened() {\nlogStep(&quot;Open the Url http://the-internet.herokuapp.com/&quot;);\ntheInternetPage = new TheInternetPage();\ntheInternetPage.load();\nlogStep(&quot;Verify if Url http://the-internet.herokuapp.com/ is opened&quot;);\nassertTrue(&quot;Unable to load The Internet Page&quot;, theInternetPage.isLoaded());\nreturn theInternetPage;\n}\nThis Test class can&#x2019;t be launched because it doesn&#x2019;t contain any @Test methods. It&#x2019;s been created only for supporting other Test classes.\nBFLogger\nBFLogger is a default MrChecker logging tool. Use it to communicate important information from test execution. There are three basic logging methods:\nlogInfo(String message) - used for test steps\nlogDebug(String message) - used for non-official information, either during the test build process or in Page Object files\nlogError(String message) - used to emphasize critical information\nLogs will be visible in the console and in the log file under path: MrChecker_Test_Framework\\workspace\\project-folder\\logs\n"},{"id":1035,"path":"../website/pages/docs/master-mrchecker.asciidoc_tutorials.html#master-mrchecker.asciidoc_e2e-tutorials","type":"docs","title":"E2E Tutorials","body":"80.3. E2E Tutorials\n"},{"id":1036,"path":"../website/pages/docs/master-mrchecker.asciidoc_tutorials.html#Tutorial1.asciidoc","type":"docs","title":"MrChecker E2E tutorials","body":"80.3.1. MrChecker E2E tutorials\nIn order to learn more about MrChecker structure, start from Project Organisation section and then check out our fantastic tutorials:\nHow to create a basic test in MrChecker\nExample: Booking a table\nAs an example to test we will use MyThaiStar booking page.\nIn order to book a table, do the following steps:\nOpen MyThaiStar Book Table Page\nEnter booking data: Date and time, Name, Email and number of Table guests\nClick Accept terms\nClick Book table\nDisplay confirmation box and send booking\nCheck if the booking was successful.\nYou can go through these steps manually and doublecheck the result.\nHow to prepare a test\n1. Create BookTablePage class\nYou will need a class which will represent MyThaiStart booking page.\nFill the required methods with the following code:\npublic class BookTablePage extends BasePage {\n@Override\npublic boolean isLoaded() {\ngetDriver().waitForPageLoaded(); //waits untli the page is loaded\nreturn getDriver().getCurrentUrl()\n.equals(&quot;http://de-mucdevondepl01:8090/bookTable&quot;); //checks if current page address equals MyThaiStar booking page adress\n}\n@Override\npublic void load() {\ngetDriver().get(&quot;http://de-mucdevondepl01:8090/bookTable&quot;); //loads page under specified adress\ngetDriver().waitForPageLoaded(); //waits until the page is loaded\n}\n@Override\npublic String pageTitle() {\nreturn &quot;My Thai Star&quot;; //returns page title\n}\n}\ngetDriver() method allows accessing Selenium Web Driver which performs actions on the webpage.\nAs this page class represents the MyThaiStar booking page, you have to set up selectors for web elements required in the test case. In the example you have to create selectors for elements we&#x2019;ll interact with:\nDate and time input field\nName input field\nEmail input field\nTable guests input field\nAccept terms checkbox\nBook table button\nSelectors will be implemented as fields.\nExample of the selector for Date and time input field:\n/** Date field search criteria */\nprivate static final By dateSearch = By.cssSelector(&quot;input[formcontrolname=&apos;bookingDate&apos;]&quot;);\nThe input field&#x2019;s name &quot;bookingDate&quot; was found by using the developer console in Google Chrome. How to prepare an everlasting selector?\nThis selector can be used to create a WebElement object of the said input field. Therefore, you will create a new method and call it &quot;enterTimeAndDate&quot;.\npublic void enterTimeAndDate(String date) {\nWebElement dateInput = getDriver().findElementDynamic(dateSearch); //creates a new WebElement to access Date and time input field\ndateInput.sendKeys(date); //enters date value\n}\nNow you can create other selectors and objects and methods for every element on the webpage:\n/** Name input field search criteria */\nprivate static final By nameSearch = By.cssSelector(&quot;input[formcontrolname=&apos;name&apos;]&quot;);\n/** Email input field search criteria */\nprivate static final By emailSearch = By.cssSelector(&quot;input[formcontrolname=&apos;email&apos;]&quot;);\n/** Number of guests search criteria */\nprivate static final By guestsSearch = By.cssSelector(&quot;input[formcontrolname=&apos;assistants&apos;]&quot;);\n/** Check box search criteria */\nprivate static final By checkboxSearch = By.cssSelector(&quot;mat-checkbox[data-name=&apos;bookTableTerms&apos;]&quot;);\n/** Book table button search criteria */\nprivate static By bookTableSearch = By.name(&quot;bookTableSubmit&quot;);\npublic void enterName(String name) {\nWebElement nameInput = getDriver().findElementDynamic(nameSearch); //creates a new WebElement to access name input field\nnameInput.sendKeys(name); //enters name value\n}\npublic void enterEmail(String email) {\nWebElement emailInput = getDriver().findElementDynamic(emailSearch); //creates a new WebElement to access email input field\nemailInput.sendKeys(email); //enters email value\n}\npublic void enterGuests(int amountOfGuests) {\nWebElement guestsInput = getDriver().findElementDynamic(guestsSearch); //creates a new WebElement to access amount of guests input field\nguestsInput.sendKeys(Integer.toString(amountOfGuests)); //enters the number of guests value converted from integer to string\n}\npublic void acceptTerms() {\nWebElement checkbox = getDriver().findElementDynamic(checkboxSearch); //creates aa new WebElement to access accept terms checkbox\nWebElement square = checkbox.findElement(By.className(&quot;mat-checkbox-inner-container&quot;)); //creates a new WebElement to access inner square\nJavascriptExecutor js = (JavascriptExecutor) getDriver(); //creates a Javascript executor object\njs.executeScript(&quot;arguments[0].click()&quot;, square); //executes a script which clicks the square\n}\npublic void clickBookTable() {\nWebElement buttonbutton = getDriver().findElementDynamic(bookTableSearch); //creates a new WebElement to access book table button\ngetDriver().waitUntilElementIsClickable(bookTableSearch); //waits until a button might be clicked\nbuttonbutton.click(); //clicks the button\n}\nYou can use those methods in order to create a new method to go through the whole booking process:\npublic ConfirmBookPage enterBookingData(String date, String name, String email, int guests) {\nenterTimeAndDate(date);\nenterName(name);\nenterEmail(email);\nenterGuests(guests);\nacceptTerms();\nclickBookTable();\nreturn new ConfirmBookPage();\n}\n2. Create ConfirmBookPage class\nAs you can see, this method returns another page object that has not yet been created. This step is required, as the booking information that you would like to check is on another webpage. This means that you will have to create another page class and call it ConfirmBookPage:\npublic class ConfirmBookPage extends BasePage {\n/** Confirmation dialog search criteria */\nprivate static final By confirmationDialogSearch = By.className(&quot;mat-dialog-container&quot;);\n/** Send confirmation button search criteria */\nprivate static final By sendButtonSearch = By.name(&quot;bookTableConfirm&quot;);\n/** Cancel confirmation button search criteria */\nprivate static final By cancelButtonSearch = By.name(&quot;bookTableCancel&quot;);\n@Override\npublic boolean isLoaded() {\n//creates a new WebElement to access confirmation dialog box\nWebElement confirmationDialog = getDriver().findElementDynamic(confirmationDialogSearch);\nreturn confirmationDialog.isDisplayed(); //checks if the box is displayed\n}\n//this method won&apos;t be called because the page is loaded only after clicking book table button\n@Override\npublic void load() {\nBFLogger.logError(&quot;MyThaiStar booking confirmation page was not loaded.&quot;); //logs error\n}\n@Override\npublic String pageTitle() {\nreturn &quot;My Thai Star&quot;;\n}\npublic void confirmBookingData() {\nWebElement sendButton = getDriver().findElementDynamic(sendButtonSearch); //creates a new WebElement to access confirmation button\nsendButton.click(); //clicks the send button\n}\npublic void cancelBookingData() {\nWebElement cancelButton = getDriver().findElementDynamic(cancelButtonSearch); //creates a new WebElement to access resignation button\ncancelButton.click(); //clicks the cancel button\n}\n}\nAfter the click on Send button - the green confirmation dialogue appears with the message &quot;Table successfully booked&quot;:\nTo be able to check if the booking was successful, you should go back to the BookTablePage class and add one more method in order to check if the green box was displayed:\n/** Dialog search criteria */\nprivate static final By dialogSearch = By.className(&quot;bgc-green-600&quot;);\npublic boolean checkConfirmationDialog() {\nWebElement greenConfirmationDialog = getDriver().findElementDynamic(dialogSearch); //creates a new WebElement to access confirmation dialog\nreturn greenConfirmationDialog.isDisplayed(); //checks if the dialog is displayed\n}\n3. Create BookTableTest class\nAt this point you can start creating a test class:\nimport static org.junit.Assert.assertTrue;\npublic class BookTableTest extends BaseTest {\nprivate static BookTablePage bookTablePage = new BookTablePage(); //the field contains book table page object\n@BeforeClass\npublic static void setUpBeforeClass() {\nbookTablePage.load(); //loads book table page\n}\n@AfterClass\npublic static void tearDownAfterClass() {\n}\n@Override\npublic void setUp() {\nif (!bookTablePage.isLoaded()) {\nbookTablePage.load(); //if the page is not loaded, loads it\n}\n}\n@Override\npublic void tearDown() {\n}\n}\n4. Write the first test\nYou can prepare our first test method using the methods from page classes\n@Test\npublic void Test_BookTableAndCheckConfirmation() {\nString date = &quot;07/23/2019 1:00 PM&quot;; //replace with tommorow&apos;s date in format &quot;MM/dd/yyyy hh:mm a&quot;\nString name = &quot;Smith&quot;; //name field\nString email = &quot;smith@somemail.com&quot;; //email field\nint guests = 3; //number of guests\n//enters booking data and returns a new confirmation page\nConfirmBookPage confirmBookPage = bookTablePage.enterBookingData(date, name, email, guests);\nconfirmBookPage.confirmBookingData(); //confirms booking\n//checks if the green dialog box appears, if it does, test is passed, if not, the test failed and displays message given in the first argument\nassertTrue(&quot;Test failed: Table not booked&quot;, bookTablePage.checkConfirmationDialog()); //returns true if dialog box appears and false if not\n}\n5. Run the test\nRun the test by right-clicking on the test method &#x2192; Run as &#x2192; JUnit test.\n&#x2190;&#xA0;Previous:&#xA0;MrChecker download&#xA0;| &#x2191;&#xA0;Up:&#xA0;MrChecker - devonfw testing tool&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Migration from JUnit4 to JUnit5&#xA0;&#x2192;\n"},{"id":1037,"path":"../website/pages/docs/master-mrchecker.asciidoc_who-is-mrchecker.html#master-mrchecker.asciidoc_who-is-mrchecker","type":"docs","title":"Who Is MrChecker","body":"77. Who Is MrChecker\n"},{"id":1038,"path":"../website/pages/docs/master-mrchecker.asciidoc_who-is-mrchecker.html#home.asciidoc","type":"docs","title":"Who is MrChecker?","body":"77.1. Who is MrChecker?\nMrChecker Test Framework is an end to end test automation framework written in Java.\nIt is an automated testing framework for functional testing of web applications, API web services, Service Virtualization, Security, native mobile apps and, in the near future, databases. All modules have tangible examples of how to build resilient integration test cases based on delivered functions.\n"},{"id":1039,"path":"../website/pages/docs/master-mrchecker.asciidoc_who-is-mrchecker.html#home.asciidoc","type":"docs","title":"Where does MrChecker apply?","body":"77.2. Where does MrChecker apply?\nThe aim of MrChecker is to achieve standardize way to build BlackBox tests. It provides the possibility to have one common software standard in order to build Component, Integration and System tests.\nA Test Engineer does not have access to the application source code in order to perform BlackBox tests, but they are able to attach their tests to any application interfaces, such as - IP address - Domain Name - communication protocol - Command Line Interface.\n"},{"id":1040,"path":"../website/pages/docs/master-mrchecker.asciidoc_who-is-mrchecker.html#home.asciidoc","type":"docs","title":"MrChecker&#x2019;s specification:","body":"77.3. MrChecker&#x2019;s specification:\nResponsive Web Design application: Selenium Browser\nREST/SOAP: RestAssure\nService Virtualization: Wiremock\nDatabase: JDBC drivers for SQL\nSecurity: RestAssure + RestAssure Security lib\nStandalone Java application: SWING\nNative mobile application for Android: Appium\n"},{"id":1041,"path":"../website/pages/docs/master-mrchecker.asciidoc_who-is-mrchecker.html#benefits.asciidoc","type":"docs","title":"Benefits","body":"77.4. Benefits\nEvery customer may benefit from using MrChecker Test Framework. The main profits for your project are:\nResilient and robust building and validation process\nQuality gates shifted closer to the software development process\nTeam quality awareness increase - including Unit Tests, Static Analysis, Security Tests, Performance in the testing process\nTest execution environment transparent to any infrastructure\nTouch base with the Cloud solution\nFaster Quality and DevOps-driven delivery\nProven frameworks, technologies and processes.\n"},{"id":1042,"path":"../website/pages/docs/master-mrchecker.asciidoc_who-is-mrchecker.html#Test-Stages.asciidoc","type":"docs","title":"Test stages","body":"77.5. Test stages\n"},{"id":1043,"path":"../website/pages/docs/master-mrchecker.asciidoc_who-is-mrchecker.html#test-stages.asciidoc_unit-test","type":"docs","title":"Unit test","body":"77.5.1. Unit test\nA module is the smallest compilable unit of source code. It is often too small to be tested by the functional tests (black-box tests). However, it is the ideal candidate for white-box testing. White-box tests have to be performed as the first static tests (e.g. Lint and inspections), followed by dynamic tests in order to check boundaries, branches and paths. Usually, that kind of testing would require enabling stubs and special test tools.\n"},{"id":1044,"path":"../website/pages/docs/master-mrchecker.asciidoc_who-is-mrchecker.html#test-stages.asciidoc_component-test","type":"docs","title":"Component test","body":"77.5.2. Component test\nThis is the black-box test of modules or groups of modules which represent certain functionalities. There are no rules about what could be called a component. Whatever a tester defines as a component, should make sense and be a testable unit. Components can be integrated into bigger components step by step and tested as such.\n"},{"id":1045,"path":"../website/pages/docs/master-mrchecker.asciidoc_who-is-mrchecker.html#test-stages.asciidoc_integration-test","type":"docs","title":"Integration test","body":"77.5.3. Integration test\nFunctions are tested by feeding them input and examining the output, and internal program structure is rarely considered. The software is completed step by step and tested by tests covering a collaboration between modules or classes. The integration depends on the kind of system. For example, the steps could be as follows: run the operating system first and gradually add one component after another, then check if the black-box tests are still running (the test cases will be extended together with every added component). The integration is done in the laboratory. It may be also completed by using simulators or emulators. Additionally, the input signals could be stimulated.\n"},{"id":1046,"path":"../website/pages/docs/master-mrchecker.asciidoc_who-is-mrchecker.html#test-stages.asciidoc_software--system-test","type":"docs","title":"Software / System test","body":"77.5.4. Software / System test\nSystem testing is a type of testing conducted on a complete integrated system to evaluate the system&#x2019;s compliance with its specified requirements. This is a type of black-box testing of the complete software in the target system. The most important factor in successful system testing is that the environmental conditions for the software have to be as realistic as possible (complete original hardware in the destination environment).\n&#x2191;&#xA0;Up:&#xA0;MrChecker - devonfw testing tool&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Test Framework Modules&#xA0;&#x2192;\n"},{"id":1047,"path":"../website/pages/docs/master-my-thai-star.asciidoc.html#master-my-thai-star.asciidoc","type":"docs","title":"XIII. MyThaiStar","body":"XIII. MyThaiStar\n1.\tMy Thai Star &#x2013; Agile Framework\n2.\tMy Thai Star &#x2013; Agile Diary\nUser Stories\nTechnical design\nSecurity\nTesting\nUI design\nCI/CD\n&#x2190;&#xA0;Previous:&#xA0;FAQ&#xA0;| &#x2191;&#xA0;Up:&#xA0;devonfw guide&#xA0;| Next:&#xA0;1.\tMy Thai Star &#x2013; Agile Framework&#xA0;&#x2192;\n"},{"id":1048,"path":"../website/pages/docs/master-my-thai-star.asciidoc_cicd.html#master-my-thai-star.asciidoc_cicd","type":"docs","title":"CI/CD","body":"90. CI/CD\n"},{"id":1049,"path":"../website/pages/docs/master-my-thai-star.asciidoc_cicd.html#production-line-ci.asciidoc","type":"docs","title":"My Thai Star in Production Line","body":"90.1. My Thai Star in Production Line\nWhat is PL?\nThe Production Line Project is a set of server-side collaboration tools for Capgemini engagements. It has been developed for supporting project engagements with individual tools like issue tracking, continuous integration, continuous deployment, documentation, binary storage and much more!\nIntroduction\nAlthough the PL Project is a wide set of tools, only 3 are going to be mainly used for My Thai Star projects to build a Continuous Integration and Continuos Delivery environment. All three are available in the PL instance used for this project.\nJenkins\nThis is going to be the &quot;main tool&quot;. Jenkins helps to automate the non-human part of the development with Continuos Integration and is going to host all Pipelines (and, obviously, execute them).\nNexus\nNexus manages software &quot;artifacts&quot; required for development. It is possible to both download dependencies from Nexus and publish artifacts as well. It allows to share resources within an organization.\nSonarQube\nIt is a platform for continuous inspection of the code. It is going to be used for the Java back-end.\n"},{"id":1050,"path":"../website/pages/docs/master-my-thai-star.asciidoc_cicd.html#production-line-ci.asciidoc_where-can-i-find-all-my-thai-star-pipelines","type":"docs","title":"Where can I find all My Thai Star Pipelines?","body":"90.1.3. Where can I find all My Thai Star Pipelines?\nThey are located under the MTS folder of the PL instance:\nThose Jenkins Pipelines will not have any code to execute. They&#x2019;re just pointing to all Jenkinsfiles under the /jenkins folder of the repository. They can be found here.\n"},{"id":1051,"path":"../website/pages/docs/master-my-thai-star.asciidoc_cicd.html#production-line-ci.asciidoc_ci-in-my-thai-star-stack","type":"docs","title":"CI in My Thai Star stack","body":"90.1.4. CI in My Thai Star stack\nAngular CI\nJava CI\n"},{"id":1052,"path":"../website/pages/docs/master-my-thai-star.asciidoc_cicd.html#production-line-ci.asciidoc_how-to-configure-everything-out-of-the-box","type":"docs","title":"How to configure everything out of the box","body":"90.1.5. How to configure everything out of the box\nProduction Line currently has a template to integrate My Thai Star. All information can be found at devonfw production line repository\n"},{"id":1053,"path":"../website/pages/docs/master-my-thai-star.asciidoc_cicd.html#angular-ci.asciidoc","type":"docs","title":"Angular CI","body":"90.1.6. Angular CI\nThe Angular client-side of My Thai Star is going to have some specific needs for the CI-CD Pipeline to perform mandatory operations.\nPipeline\nThe Pipeline for the Angular client-side is going to be called MyThaiStar_FRONTEND_BUILD. It is located in the PL instance, under the MTS folder (as previously explained). It is going to follow a process flow like this one:\nEach of those steps are called stages in the Jenkins context.Let&#x2019;s see what those steps mean in the context of the Angular application:\nDeclarative: Checkout SCM\nRetrieves the project from the GitHub repository which it&#x2019;s located. This step is not defined directly in our pipeline, but as it is loaded from the repository this step should always be done at the beginning.\nDeclarative: Tool Install\nThe Pipeline needs some Tools to perform some operations with the Angular project. These tool is a correct version of NodeJS (10.17.0 LTS) with Yarn installed as global package.\ntools {\nnodejs &quot;NodeJS 10.14.0&quot;\n}\nLoading Custom Tools\nThe Pipeline also needs a browser in order to execute the tests, so in this step the chrome-stable will be loaded. We will use it in a headless mode.\ntool chrome\nFresh Dependency Installation\nThe script $ yarn does a package installation. As we always clean the workspace after the pipeline, all packages must be installed in every execution.\nCode Linting\nThis script executes a linting process of TypeScript. Rules can be defined in the tslint.json file of the project. It throws an exception whenever a file contains a non-compliant piece of code.\nExecute Angular tests\nThe CI testing of the Angular client is different than the standard local testing (adapted to CI environments, as specified in the Adaptation section of document). This script just executes the following commands:\nng test --browsers ChromeHeadless --watch=false\nCheck dependencies\nBefore continue, we print the result of yarn audit. It shows the vulnerabilities in the dependencies. It do not process the reponse. The purpose is only to track the result of the command.\nyarn audit\nSonarQube code analysis\nThe script load and execute the tool sonar-scanner. This tool is loaded here because it&#x2019;s not used in any other part of the pipeline. The sonar-scanner will take all code, upload it to sonarQube and wait until sonarQube send us a response with the quality of our code. If the code do not pass the quality gate, the pipeline will stop at this point.\nBuild Application\nThe building process of the Angular client would result in a folder called /dist in the main Angular&#x2019;s directory. That folder is the one that is going to be served afterwards as an artifact. This process has also been adapted to some Deployment needs. This building script executes the following:\nng build --configuration=docker\nDeliver application into Nexus\nOnce the scripts produce the Angular artifact (/dist folder), it&#x2019;s time to package it and store into nexus.\nDeclarative: Post Actions\nAt the end, this step is always executed, even if a previous stage fail. We use this step to clean up the workspace for future executions\npost {\nalways {\ncleanWs()\n}\n}\nAdjustments\nThe Angular project Pipeline needed some &quot;extra&quot; features to complete all planned processes. Those features resulted in some additions to the project.\nPipeline Environment\nIn order to easily reuse the pipeline in other angular projects, all variables have been defined in the block environment. All variables have the default values that Production Line uses, so if you&#x2019;re going to work in production line you won&#x2019;t have to change anything. Example:\nenvironment {\n// Script for build the application. Defined at package.json\nbuildScript = &apos;build --configuration=docker&apos;\n// Script for lint the application. Defined at package.json\nlintScript = &apos;lint&apos;\n// Script for test the application. Defined at package.json\ntestScript = &apos;test:ci&apos;\n// Angular directory\nangularDir = &apos;angular&apos;\n// SRC folder. It will be angularDir/srcDir\nsrcDir = &apos;src&apos;\n// Name of the custom tool for chrome stable\nchrome = &apos;Chrome-stable&apos;\n// sonarQube\n// Name of the sonarQube tool\nsonarTool = &apos;SonarQube&apos;\n// Name of the sonarQube environment\nsonarEnv = &quot;SonarQube&quot;\n// Nexus\n// Artifact groupId\ngroupId = &apos;com.devonfw.mythaistar&apos;\n// Nexus repository ID\nrepositoryId = &apos;pl-nexus&apos;\n// Nexus internal URL\nrepositoryUrl = &apos;http://nexus3-core:8081/nexus3/repository/maven-snapshots&apos;\n// Maven global settings configuration ID\nglobalSettingsId = &apos;MavenSettings&apos;\n// Maven tool id\nmavenInstallation = &apos;Maven3&apos;\n}\nDescription\nbuildScript: script for build the application. It must be defined at package.json.\nExample (package.json):\n{\n&quot;name&quot;: &quot;mythaistar-restaurant&quot;,\n...\n&quot;scripts&quot;: {\n...\n&quot;build&quot;: &quot;ng build&quot;,\n...\n}\n...\n}\nThis will be used as follows:\nsh &quot;&quot;&quot;yarn ${buildScript}&quot;&quot;&quot;\nlintScript: Script for lint the application. Defined at package.json\nExample (package.json):\n{\n&quot;name&quot;: &quot;mythaistar-restaurant&quot;,\n...\n&quot;scripts&quot;: {\n...\n&quot;lint&quot;: &quot;ng lint&quot;,\n...\n}\n...\n}\nThis will be used as follows:\nsh &quot;&quot;&quot;yarn ${lintScript}&quot;&quot;&quot;\ntestScript: Script for test the application. Defined at package.json\nExample (package.json):\n{\n&quot;name&quot;: &quot;mythaistar-restaurant&quot;,\n...\n&quot;scripts&quot;: {\n...\n&quot;test:ci&quot;: &quot;npm run postinstall:web &amp;&amp; ng test --browsers ChromeHeadless --watch=false&quot;,\n...\n}\n...\n}\nThis will be used as follows:\nsh &quot;&quot;&quot;yarn ${testScript}&quot;&quot;&quot;\nangularDir: Relative route to angular application. In My Thai Star this is the angular folder. The actual directory (.) is also allowed.\nsrcDir: Directory where you store the source code. For angular applications the default value is src\nchrome: Since you need a browser to run your tests, we must provide one. This variable contains the name of the custom tool for google chrome.\nsonarTool: Name of the sonarQube scanner installation.\nsonarEnv: Name of the sonarQube environment. SonarQube is the default value for PL.\ngroupId: Group id of the application. It will be used to storage the application in nexus3\nrepositoryId: Id of the nexus3 repository. It must be defined at maven global config file.\nrepositoryUrl: The url of the repository.\nglobalSettingsId: The id of the global settings file.\nmavenInstallation: The name of the maven tool.\n"},{"id":1054,"path":"../website/pages/docs/master-my-thai-star.asciidoc_cicd.html#java-ci.asciidoc","type":"docs","title":"Java CI","body":"90.1.7. Java CI\nThe Java server-side of My Thai Star is an devon4j-based application. As long as Maven and a Java 8 are going to be needed, the Pipeline should have those tools available as well.\nPipeline\nThis Pipeline is called MyThaiStar_SERVER_BUILD, and it is located exactly in the same PL instance&#x2019;s folder than MyThaiStar_FRONTEND_BUILD. Let&#x2019;s see how the Pipeline&#x2019;s flow behaves.\nCheck those Pipeline stages with more detail:\nDeclarative: Checkout SCM\nGets the code from https://github.com/devonfw/my-thai-star . This step is not defined directly in our pipeline, but as it is loaded from the repository this step should always be done at the beginning.\nDeclarative: Tool Install\nThe My Thai Star application works with JDK11. In this step, if JDK11 is not installed, we install it and then put the JDK folder into PATH.\ntools {\njdk &apos;OpenJDK11&apos;\n}\nLoading Custom Tools\nIn this step we load the tools that can not be loaded in the previous step. As My Thai Star is delivered as docker container, in this step we load docker as custom tool.\ntool dockerTool\nInstall dependencies\nThis step will download all project dependencies.\nmvn clean install -Dmaven.test.skip=true\nUnit Tests\nThis step will execute the project unit test with maven.\nmvn clean test\nDependeny Checker\nExecute the OWASP Dependency Checker in order to validate the project dependencies. It will generate a report that can be used in SonarQube\ndependencyCheck additionalArguments: &apos;--project &quot;mtsj&quot; --scan java/mtsj --format XML&apos;, odcInstallation: &apos;dependency-check&apos;\ndependencyCheckPublisher pattern: &apos;&apos;\nSonarQube analysis\nThe code is evaluated using the integrated PL instance&#x2019;s SonarQube. Also, it will wait for the quality gate status. If the status is failing, the pipeline execution will be stopped.\nwithSonarQubeEnv(sonarEnv) {\nsh &quot;mvn sonar:sonar&quot;\n}\ndef qg = waitForQualityGate()\nif (qg.status != &apos;OK&apos;) {\nerror &quot;Pipeline aborted due to quality gate failure: ${qg.status}&quot;\n}\nDeliver application into Nexus\nStore all artifacts into nexus.\nmvn deploy -Dmaven.test.skip=true\nCreate the Docker image\nCreate the docker image and then publish the image into a docker registry.\nAdjustments\nPipeline Environment\nIn order to easily reuse the pipeline in other java projects, all variables have been defined in the block environment. All variables have the default values that Production Line uses, so if you&#x2019;re going to work in production line you won&#x2019;t have to change anything. Example:\nenvironment {\n// Directory with java project\njavaDir = &apos;java/mtsj&apos;\n// sonarQube\n// Name of the sonarQube environment\nsonarEnv = &quot;SonarQube&quot;\n// Nexus 3\n// Maven global settings configuration ID\nglobalSettingsId = &apos;MavenSettings&apos;\n// Maven tool id\nmavenInstallation = &apos;Maven3&apos;\n// Docker\ndockerRegistryCredentials = &apos;nexus-api&apos;\ndockerRegistryProtocol = &apos;https://&apos;\ndockerTool = &apos;docker-global\n}\nDescription\njavaDir: Relative route to java application. In My Thai Star this is the java/mtsj folder. The actual directory (.) is also allowed.\nsonarEnv: Name of the sonarQube environment. SonarQube is the default value for PL.\nglobalSettingsId: The id of the global settings file. MavenSettings is the default value for PL.\nmavenInstallation: The name of the maven tool. Maven3 is the default value for PL.\nDistribution management\nThe only extra thing that needs to be added to the Java server-side is some information that determines where the artifact of the project is going to be stored in Nexus. This is going to be a section in the main pom.xml file called &lt;distributionManagement&gt;. This section will point to the PL instance&#x2019;s Nexus. Let&#x2019;s have a look at it. It&#x2019;s already configured with the PL default values.\n&lt;distributionManagement&gt;\n&lt;repository&gt;\n&lt;id&gt;pl-nexus&lt;/id&gt;\n&lt;name&gt;PL Releases&lt;/name&gt;\n&lt;url&gt;http://nexus3-core:8081/nexus/content/repositories/maven-releases/&lt;/url&gt;\n&lt;/repository&gt;\n&lt;snapshotRepository&gt;\n&lt;id&gt;pl-nexus&lt;/id&gt;\n&lt;name&gt;PL Snapshots&lt;/name&gt;\n&lt;url&gt;http://nexus3-core:8081/nexus3/repository/maven-snapshots&lt;/url&gt;\n&lt;/snapshotRepository&gt;\n&lt;/distributionManagement&gt;\n"},{"id":1055,"path":"../website/pages/docs/master-my-thai-star.asciidoc_cicd.html#deployment.asciidoc","type":"docs","title":"Deployment","body":"90.2. Deployment\nThe main deployment tool used for My Thai Star is be Docker.\nIt is a tool to run application in isolated environments. Those isolated environments will be what we call Docker containers. For instance, it won&#x2019;t be necessary any installation of nginx or Apache tomcat or anything necessary to deploy, because there will be some containers that actually have those technologies inside.\n"},{"id":1056,"path":"../website/pages/docs/master-my-thai-star.asciidoc_cicd.html#deployment.asciidoc_where-docker-containers-will-be-running","type":"docs","title":"Where Docker containers will be running?","body":"90.2.1. Where Docker containers will be running?\nOf course, it is necessary to have an external Deployment Server. Every Docker process will run in it. It will be accessed from Production Line pipelines via SSH. Thus, the pipeline itself will manage the scenario of, if every previous process like testing passes as OK, stop actual containers and create new ones.\nThis external server will be located in http://de-mucdevondepl01 .\n"},{"id":1057,"path":"../website/pages/docs/master-my-thai-star.asciidoc_cicd.html#deployment.asciidoc_container-schema","type":"docs","title":"Container Schema","body":"90.2.2. Container Schema\n3 Docker containers are being used for the deployment of My Thai Star:\nnginx for the Reverse Proxy\ntomcat for the Java Server\nnginx for the Angular Client\nThe usage of the Reverse Proxy will allow the client to call via /api every single Java Server&#x2019;s REST operation. Moreover, there will only be 1 port in usage in the remote Docker host, the one mapped for the Reverse Proxy: 8080.\nBesides the deployment itself using nginx and tomcat, both client and server are previously built using nodejs and maven images. Artifacts produced by them will be pasted in servers&apos; containers using multi-stage docker builds. It will all follow this schema:\nThis orchestration of all 3 containers will be done by using a docker-compose.yml file. To redirect traffic from one container to another (i.e. reverse-proxy to angular client or angular client to java server) will be done by using, as host names, the service name docker-compose defines for each of them, followed by the internally exposed port:\nhttp://reverse-proxy:80\nhttp://angular:80\nhttp://java:8080\nNote\nA implementation using Traefik as reverse proxy instead of NGINX is also available.\n"},{"id":1058,"path":"../website/pages/docs/master-my-thai-star.asciidoc_cicd.html#deployment.asciidoc_run-my-thai-star","type":"docs","title":"Run My Thai Star","body":"90.2.3. Run My Thai Star\nThe steps to run My Thai Star are:\nClone the repository $ git clone https://github.com/devonfw/my-thai-star.git\nRun the docker compose command: $ docker-compose up\n"},{"id":1059,"path":"../website/pages/docs/master-my-thai-star.asciidoc_cicd.html#deployment-pipelines.asciidoc","type":"docs","title":"Deployment Pipelines","body":"90.2.4. Deployment Pipelines\nAs PL does not support deployments, we have created separate pipelines for this purpose. Those pipelines are: MyThaiStar_REVERSE-PROXY_DEPLOY, MyThaiStar_FRONTEND_DEPLOY and MyThaiStar_SERVER_DEPLOY.\nThe application will be deployed using docker on a remote machine. The architecture is as follows:\nThe parts to be deployed are: an NGINX reverse proxy, the java application and the angular application.\nMyThaiStar_SERVER_DEPLOY Pipeline\nDeploys on the server the Java part of My Thai Star.\nParameters\nregistryUrl: The url to the docker registry where the image is stored.\nregistryCredentialsId: Credentials to publish/download images from registry.\ndockerNetwork: Network of your My Thai Star application. You can deploy several versions of MTS in the same server by changing the dockerNetwork.\nVERSION: The version that you can to deploy.\nPipeline steps\nCreate docker network: Create the docker network with the name provided as parameter.\nDeploy new image: Deploy a new java container. If it already exists, first it delete the previous one.\nMyThaiStar_FRONTEND_DEPLOY\nDeploys on the server the Angular part of My Thai Star\nParameters\nregistryUrl: The url to the docker registry where the image is stored.\nregistryCredentialsId: Credentials to publish/download images from registry.\ndockerNetwork: Network of your My Thai Star application. You can deploy several versions of MTS in the same server by changing the dockerNetwork.\nVERSION: The version that you can to deploy.\nPipeline steps\nCreate docker network: Create the docker network with the name provided as parameter.\nDeploy new image: Deploy a new angular container. If it already exists, first it delete the previous one.\nMyThaiStar_REVERSE-PROXY_DEPLOY Pipeline\nNote\nAs reverse proxy connects to the Java and Angular application, both must be deployed before you execute this pipeline.\nThe MyThaiStar_REVERSE-PROXY_DEPLOY pipeline will deploy the My Thai Star reverse proxy into a remote machine using docker.\nParameters\nregistryUrl: The url to the docker registry where the image is stored.\nregistryCredentialsId: Credentials to publish/download images from registry.\nbuildReverseProxy: If yes, it will build and publish a new version of reverse-proxy.\nport: Port of the MTS application. You must ensure that those port is available in the deployment machine.\ndockerNetwork: Network of your My Thai Star application. You can deploy several versions of MTS in the same server by changing the port and the dockerNetwork.\nVERSION: The version that you can to deploy.\nPipeline steps\nCreate docker network: Create the docker network with the name provided as parameter.\nCreate the Docker image: If buildReverseProxy is enabled, this step will create a new docker image and publish it to the docker registry.\nDeploy new image: Deploy a new reverse proxy container. If it already exists, first it delete the previous one.\n"},{"id":1060,"path":"../website/pages/docs/master-my-thai-star.asciidoc_cicd.html#deployment-strategies.asciidoc","type":"docs","title":"Deployment Strategies","body":"90.2.5. Deployment Strategies\nIn this chapter different way of deploying My Thai Star are explained. Everything will be based in Docker.\nIndependent Docker containers\nThe first way of deployment will use isolated Docker containers. That means that if the client-side container is deployed, it does not affect the server-side container&#x2019;s life cycle and vice versa.\nLet&#x2019;s show how the containers will behave during their life cycle.\n0) Copy everything you need into the Deployment Server directory\n1) Remove existing container (Nginx or Tomcat)\n2) Run new one from the Docker images collection of the external Deployment Server.\n3) Add the artifact /dist to the &quot;deployable&quot; folder of the Docker container (/usr/share/nginx/html/)\nNow, let&#x2019;s see how it&#x2019;s being executed in the command line (simplified due to documentation purposes). The next block of code represents what is inside of the last stage of the Pipeline.\nsshagent (credentials: [&apos;my_ssh_token&apos;]) {\nsh &quot;&quot;&quot;\n// Copy artifact from workspace to deployment server\n// Manage container:\ndocker rm -f [mts-container]\ndocker run -itd --name=[mts-container] [base_image]\ndocker exec [mts-container] bash -C \\\\&quot;rm [container_deployment_folder]/*\\\\&quot;\ndocker cp [artifact] [mts-container]:[container_deployment_folder]\n&quot;&quot;&quot;\n}\nFor every operation performed in the external Deployment Server, it is necessary to define where those commands are going to be executed. So, for each one of previous docker commands, this should appear before:\nssh -o StrictHostKeyChecking=no root@10.40.235.244\nDocker Compose\nThe second way of deployment will be by orchestrating both elements of the application: The Angular client-side and the Java server-side. Both elements will be running in Docker containers as well, but in this case they won&#x2019;t be independent anymore. Docker Compose will be in charge of keeping both containers up, or to put them down.\nProject adjustment\nIn order to perform this second way of deployment, some files will be created in the project. The first one is the Dockerfile for the Angular client-side. This file will pull (if necessary) an nginx Docker image and copy the Angular artifact (/dist folder) inside of the deployment folder of the image. It will be located in the main directory of the Angular client-side project.\nThe second file is the Dockerfile for the Java server-side. Its function will be quite similar to the Angular one. It will run a tomcat Docker image and copy the Java artifact (mythaistar.war file) in its deployment folder.\nFinally, as long as the docker-compose is being used, a file containing its configuration will be necessary as well. A new folder one the main My That Star&#x2019;s directory is created, and it&#x2019;s called /docker. Inside there is just a docker-compose.yml file. It contains all the information needed to orchestrate the deployment process. For example, which port both containers are going to be published on, and so on. This way of deployment will allow the application to be published or not just with one action.\ndocker-compose rm -f # down\ndocker-compose up --build -d # up fresh containers\nLet&#x2019;s have a look at the file itself:\nversion: &apos;3&apos;\nservices:\nclient_compose:\nbuild: &quot;angular&quot;\nports:\n- &quot;8091:80&quot;\ndepends_on:\n- server_compose\nserver_compose:\nbuild: &quot;java&quot;\nports:\n- &quot;9091:8080&quot;\nThis Orchestrated Deployment will offer some interesting possibilities for the future of the application.\n"},{"id":1061,"path":"../website/pages/docs/master-my-thai-star.asciidoc_cicd.html#future-deployment.asciidoc","type":"docs","title":"Future Deployment","body":"90.2.6. Future Deployment\nThe My Thai Star project is going to be built in many technologies. Thus, let&#x2019;s think about one deployment schema that allow the Angular client to communicate to all three back ends: Java, Node and .NET.\nAs long as Docker containers are being used, it shouldn&#x2019;t be that hard to deal with this &quot;distributed&quot; deployment. The schema represents 6 Docker containers that will have client-side(s) and server-side(s). Each of 3 Angular client containers (those in red) are going to communicate with different back-ends. So, when the deployment is finished, it would be possible to use all three server-sides just by changing the &quot;port&quot; in the URL.\nLet&#x2019;s see how it would look like:\nReverse proxy strategy using Traefik\nThis implementation is the same as described at My Thai Star deployment wiki page. The only thing that changes is that Traefik is used instead of NGINX.\nUsing Traefik as reverse proxy, we can define the routes using labels in the docker containers instead of using a nginx.conf file. With this, it is not necessary to modify the reverse proxy container for each application. In addition, as Traefik is listening to the docker daemon, it can detect new containers and create routes for them without rebooting.\nExample of labels:\nlabels:\n- &quot;traefik.http.routers.angular.rule=PathPrefix(`/`)&quot;\n- &quot;traefik.http.services.angular.loadBalancer.healthcheck.path=/health&quot;\n- &quot;traefik.http.services.angular.loadBalancer.healthcheck.interval=10s&quot;\n- &quot;traefik.http.services.angular.loadBalancer.healthcheck.scheme=http&quot;\nHow to use it\nIf you want to build the images from code, change to My Thai Star root folder and execute:\n$ docker-compose -f docker-compose.traefik.yml up -d --build\nIf you want to build the images from artifacts, change to traefik folder (reverse-proxy/traefik) and execute:\n$ docker-compose up -d --build\nAfter a seconds, when the healthcheck detects that containers are running, your application will be available at http://localhost:8090. Also, the Traefik dashboard is available at http://localhost:8080.\nIf you want to check the behaviour of the application when you scale up the backend, you can execute:\n$ docker-compose scale java=5\nWith this, the access to the java backend will be using the load balacing method: Weighted Round Robin.\n"},{"id":1062,"path":"../website/pages/docs/master-my-thai-star.asciidoc_cicd.html#nkaas.asciidoc","type":"docs","title":"MyThaiStar on Native Kubernetes as a Service (nKaaS)","body":"90.3. MyThaiStar on Native Kubernetes as a Service (nKaaS)\nThe MyThaiStar sample application can be deployed on a nKaaS environment. The required Kubernetes configuration files can be found in the MyThaiStar repository. There are no additional changes required in order to deploy the application.\n"},{"id":1063,"path":"../website/pages/docs/master-my-thai-star.asciidoc_cicd.html#nkaas.asciidoc_setting-up-the-environment","type":"docs","title":"Setting up the environment","body":"90.3.1. Setting up the environment\nFollowing the nKaaS guide\nAfter requesting access to the nKaaS platform you&#x2019;ll be greeted with a welcome mail which contains your personal credentials. Make sure to change the given password to a personal one within the 24 hour time period, otherwise the credentials will expire.\nAfter successfully following the guide mentioned in the welcome mail you should be able to establish a connection to the nKaaS VPN and have access to all their services (Jenkins, BitBucket, etc.). You should also be able to communicate with Kubernetes using kubectl.\nKnown issues: The nKaaS guide provides a download link for OpenVPN Connect. However, some users experienced connection issues with this client. If you&#x2019;re having issues connecting to the VPN with OpenVPN Connect, you may try out the client by OVPN.\nRequesting a namespace\nInitially, you won&#x2019;t be able to edit anything on Kubernetes, as you don&#x2019;t have any privileges on any namespace. To request your own namespace you should raise a ticket at the Customer Support Portal containing your desired name for the namespace.\nAs soon as the namespace was created you can change your kubectl context:\nkubectl config set-context --current -namespace=YOUR-NAMESPACE\nOn your own namespace you should have permissions to create/delete deployments/services etc. and perform other actions.\n"},{"id":1064,"path":"../website/pages/docs/master-my-thai-star.asciidoc_cicd.html#nkaas.asciidoc_setting-up-harbor","type":"docs","title":"Setting up Harbor","body":"90.3.2. Setting up Harbor\nJenkins will build the MyThaiStar Docker images and push them to the nKaaS Harbor registry. The Jenkinsfile defaults to a Harbor project called &quot;my-thai-star&quot;. If there&#x2019;s no such project on Harbor, simply create a new one.\n"},{"id":1065,"path":"../website/pages/docs/master-my-thai-star.asciidoc_cicd.html#nkaas.asciidoc_setting-up-jenkins","type":"docs","title":"Setting up Jenkins","body":"90.3.3. Setting up Jenkins\nAs MyThaiStar includes all required Jenkinsfiles for nKaaS, almost no configurations have to be performed by the user.\nCreate a new Pipeline on Jenkins and configure its definition to be a &quot;Pipeline script from SCM&quot;. The SCM used is &quot;Git&quot; and the repository URL is the MyThaiStar repository https://github.com/devonfw/my-thai-star.git or your fork of it.\nThe Branch Specifier should point to */develop, the Script Path is jenkins/nKaaS/Jenkinsfile as that&#x2019;s where the Jenkinsfile is located at the MyThaiStar repository.\nChecking the &quot;Lightweight checkout&quot; could speed up the Pipeline.\nNote: If you&#x2019;re using the nKaaS Bitbucket as repository for your MyThaiStar clone you have to perform some additional configurations. First you&#x2019;ll have to create a new SSH keypair, for example with ssh-keygen. Add the public key to the Bitbucket authentication methods and the private key in Jenkins to a new pair of credentials. This step is required for Jenkins to be able to authenticate against Bitbucket.\nAfterwards, instead of the official MyThaiStar repository, specify your Bitbucket repository:\nssh://git@bitbucket.demo.xpaas.io:7999/YOUR-PROJECT/YOUR-MTS-REPO.git\nUnder &quot;Credentials&quot; choose the credentials that contain your Bitbucket private key you&#x2019;ve created earlier.\n"},{"id":1066,"path":"../website/pages/docs/master-my-thai-star.asciidoc_cicd.html#nkaas.asciidoc_deploying-mts","type":"docs","title":"Deploying MTS","body":"90.3.4. Deploying MTS\nAfter setting up the Jenkins Pipeline, you can simply run it by clicking on the &quot;Build&quot; button. This will trigger the pipeline, Jenkins will:\nCheck out the MTS project\nBuild the docker images\nPush the docker images to the Harbor registry\nDeploy the MTS application onto Kubernetes\nFinally, the applications should be available at http://my-thai-star.demo.xpaas.io.\nThe first part, my-thai-star, ist specified in the MTS ingress configuration at host. The second part, demo.xpaas.io, is the host of the nKaaS you&#x2019;re working on.\n&#x2190;&#xA0;Previous:&#xA0;UI design&#xA0;| &#x2191;&#xA0;Up:&#xA0;MyThaiStar&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;devonfw dashboard&#xA0;&#x2192;\n"},{"id":1067,"path":"../website/pages/docs/master-my-thai-star.asciidoc_security.html#master-my-thai-star.asciidoc_security","type":"docs","title":"Security","body":"87. Security\n"},{"id":1068,"path":"../website/pages/docs/master-my-thai-star.asciidoc_security.html#twofactor.asciidoc","type":"docs","title":"Two-Factor Authentication","body":"87.1. Two-Factor Authentication\nTwo-factor Authentication (2FA) provides an additional level of security to your account. Once enabled, in addition to supplying your username and password to login, you&#x2019;ll be prompted for a code generated by your Google authenticator. For example, a password manager on one of your devices.\nBy enabling 2FA, to log into your account an additional one-time password is required what requires access to your paired device. This massively increases the barrier for an attacker to break into your account.\nBackend mechanism\nIn the backend, we utilize Spring Security for any authentication.\nFollowing the arrows, one can see all processes regarding authentication. The main idea is to check all credentials depending on their 2FA status and then either grand access to the specific user or deny access. This picture illustrates a normal authentication with username and password.\nWhen dealing with 2FA, another provider and filter is handling the request from /verify\nHere you can observe which filter will be used.\nJWTAuthenticationFilter does intercept any request, which enforces being authenticated via JWT\nNote\nWhenever the secret or qr code gets transferred between two parties, one must enforce SSL/TLS or IPsec to be comply with RFC 6238.\nActivating Two-Factor Authentication\nIn the current state, TOTP\nwill be used for OTP generation. For this purpose we recommend the Google Authenticator or any TOTP generator out there.\nLogin with your account\nOpen the 2FA settings\nActivate the 2FA Status\nInitialize your device with either a QR-Code or a secret\nFrontend\nThese are the two main options, which you can obtain my toggling between QR-Code and secret.\nAfter an activation and logout. This prompt will ask you to enter the OTP given from your device.\n&#x2190;&#xA0;Previous:&#xA0;Technical design&#xA0;| &#x2191;&#xA0;Up:&#xA0;MyThaiStar&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Testing&#xA0;&#x2192;\n"},{"id":1069,"path":"../website/pages/docs/master-my-thai-star.asciidoc_technical-design.html#master-my-thai-star.asciidoc_technical-design","type":"docs","title":"Technical design","body":"86. Technical design\n"},{"id":1070,"path":"../website/pages/docs/master-my-thai-star.asciidoc_technical-design.html#master-my-thai-star.asciidoc_data-model","type":"docs","title":"Data Model","body":"86.1. Data Model\n"},{"id":1071,"path":"../website/pages/docs/master-my-thai-star.asciidoc_technical-design.html#My-Thai-Star-data-model.asciidoc","type":"docs","title":"Data Model","body":"86.1.1. Data Model\n"},{"id":1072,"path":"../website/pages/docs/master-my-thai-star.asciidoc_technical-design.html#my-thai-star-nosql-data-model.asciidoc","type":"docs","title":"NoSQL Data Model","body":"86.1.2. NoSQL Data Model\n"},{"id":1073,"path":"../website/pages/docs/master-my-thai-star.asciidoc_technical-design.html#master-my-thai-star.asciidoc_server-side","type":"docs","title":"Server Side","body":"86.2. Server Side\n"},{"id":1074,"path":"../website/pages/docs/master-my-thai-star.asciidoc_technical-design.html#java-design.asciidoc","type":"docs","title":"Java design","body":"86.2.1. Java design\nIntroduction\nThe Java backend for My Thai Star application is going to be based on:\nDEVON4J as the Java framework\nDevonfw as the Development environment\nCobigen as code generation tool\nTo know more details about the above technologies please visit the following documentation:\nDEVON4J\nDevonfw\nCobigen\nBasic architecture details\nFollowing the DEVON4J conventions the Java My Thai Star backend is going to be developed dividing the application in Components and using a three layers architecture.\nProject modules\nUsing the DEVON4J approach for the Java backend project we will have a structure of a Maven project formed by three projects\napi: Stores all the REST interfaces and corresponding Request/Response objects.\ncore: Stores all the logic and functionality of the application.\nserver: Configures the packaging of the application.\nWe can automatically generate this project structure using the DEVON4J Maven archetype\nComponents\nThe application is going to be divided in different components to encapsulate the different domains of the application functionalities.\nAs main components we will find:\nBookingmanagement: Manages the bookings part of the application. With this component the users (anonymous/logged in) can create new bookings or cancel an existing booking. The users with waiter role can see all scheduled bookings.\nOrdermanagement: This component handles the process to order dishes (related to bookings). A user (as a host or as a guest) can create orders (that contain dishes) or cancel an existing one. The users with waiter role can see all ordered orders.\nDishmanagement: This component groups the logic related to the menu (dishes) view. Its main feature is to provide the client with the data of the available dishes but also can be used by other components (Ordermanagement) as a data provider in some processes.\nUsermanagement: Takes care of the User Profile management, allowing to create and update the data profiles.\nAs common components (that don&#x2019;t exactly represent an application&#x2019;s area but provide functionalities that can be used by the main components):\nImagemanagement: Manages the images of the application. In a first approach the Dishmanagement component and the Usermanagement component will have an image as part of its data. The Imagemanagement component will expose the functionality to store and retrieve this kind of data.\nMailservice: with this service we will provide the functionality for sending email notifications. This is a shared service between different app components such as bookingmanagement or ordercomponent.\nOther components:\nSecurity (will manage the access to the private part of the application using a jwt implementation).\nTwitter integration: planned as a Microservice will provide the twitter integration needed for some specific functionalities of the application.\nLayers\nService Layer: this layer will expose the REST api to exchange information with the client applications.\nLogic Layer: the layer in charge of hosting the business logic of the application.\nData Access Layer: the layer to communicate with the data base.\nThis architecture is going to be reflected dividing each component of the application in different packages to match those three layers.\nComponent structure\nEach one of the components defined previously are going to be structured using the three-layers architecture. In each case we will have a service package, a logic package and a dataaccess package to fit the layers definition.\nDependency injection\nAs it is explained in the devonfw documentation we are going to implement the dependency injection pattern basing our solution on Spring and the Java standards: java.inject (JSR330) combined with JSR250.\nSeparation of API and implementation: Inside each layer we will separate the elements in different packages: api and impl. The api will store the interface with the methods definition and inside the impl we will store the class that implements the interface.\nUsage of JSR330: The Java standard set of annotations for dependency injection (@Named, @Inject, @PostConstruct, @PreDestroy, etc.) provides us with all the needed annotations to define our beans and inject them.\n@Named\npublic class MyBeanImpl implements MyBean {\n@Inject\nprivate MyOtherBean myOtherBean;\n@PostConstruct\npublic void init() {\n// initialization if required (otherwise omit this method)\n}\n@PreDestroy\npublic void dispose() {\n// shutdown bean, free resources if required (otherwise omit this method)\n}\n}\nLayers communication\nThe connection between layers, to access to the functionalities of each one, will be solved using the dependency injection and the JSR330 annotations.\nConnection Service - Logic\n@Named(&quot;DishmanagementRestService&quot;)\npublic class DishmanagementRestServiceImpl implements DishmanagementRestService {\n@Inject\nprivate Dishmanagement dishmanagement;\n// use the &apos;this.dishmanagement&apos; object to access to the functionalities of the logic layer of the component\n...\n}\nConnection Logic - Data Access\n@Named\npublic class DishmanagementImpl extends AbstractComponentFacade implements Dishmanagement {\n@Inject\nprivate DishDao dishDao;\n// use the &apos;this.dishDao&apos; to access to the functionalities of the data access layer of the component\n...\n}\nService layer\nThe services layer will be solved using REST services with the JAX-RS implementation.\nTo give service to the defined User Stories we will need to implement the following services:\nprovide all available dishes.\nsave a booking.\nsave an order.\nprovide a list of bookings (only for waiters) and allow filtering.\nprovide a list of orders (only for waiters) and allow filtering.\nlogin service (see the Security section).\nprovide the current user data (see the Security section)\nFollowing the naming conventions proposed for Devon4j applications we will define the following end points for the listed services.\n(POST) /mythaistar/services/rest/dishmanagement/v1/dish/search.\n(POST) /mythaistar/services/rest/bookingmanagement/v1/booking.\n(POST) /mythaistar/services/rest/ordermanagement/v1/order.\n(POST) /mythaistar/services/rest/bookingmanagement/v1/booking/search.\n(POST) /mythaistar/services/rest/ordermanagement/v1/order/search.\n(POST) /mythaistar/services/rest/ordermanagement/v1/order/filter (to filter with fields that does not belong to the Order entity).\n(POST) /mythaistar/login.\n(GET) /mythaistar/services/rest/security/v1/currentuser/.\nYou can find all the details for the services implementation in the Swagger definition included in the My Thai Star project on Github.\nService api\nThe api.rest package in the service layer of a component will store the definition of the service by a Java interface. In this definition of the service we will set-up the endpoints of the service, the type of data expected and returned, the HTTP method for each endpoint of the service and other configurations if needed.\n@Path(&quot;/dishmanagement/v1&quot;)\n@Consumes(MediaType.APPLICATION_JSON)\n@Produces(MediaType.APPLICATION_JSON)\npublic interface DishmanagementRestService {\n@GET\n@Path(&quot;/dish/{id}/&quot;)\npublic DishCto getDish(@PathParam(&quot;id&quot;) long id);\n...\n}\nService impl\nOnce the service api is defined we need to implement it using the Java interface as reference. We will add the service implementation class to the impl.rest package and implement the RestService interface.\n@Named(&quot;DishmanagementRestService&quot;)\npublic class DishmanagementRestServiceImpl implements DishmanagementRestService {\n@Inject\nprivate Dishmanagement dishmanagement;\n@Override\npublic DishCto getDish(long id) {\nreturn this.dishmanagement.findDish(id);\n}\n...\n}\nNote\nYou can see the Devon4j conventions for REST services here. And the My Thai Star services definition here as part of the My Thai Star project.\nLogic layer\nIn the logic layer we will locate all the business logic of the application. We will keep the same schema as we have done for the service layer, having an api package with the definition of the methods and a impl package for the implementation.\nAlso, inside the api package, a to package will be the place to store the transfer objects needed to pass data through the layers of the component.\nThe logic api definition:\npublic interface Dishmanagement {\nDishCto findDish(Long id);\n...\n}\nThe logic impl class:\n@Named\npublic class DishmanagementImpl extends AbstractComponentFacade implements Dishmanagement {\n@Inject\nprivate DishDao dishDao;\n@Override\npublic DishCto findDish(Long id) {\nreturn getBeanMapper().map(this.dishDao.findOne(id), DishCto.class);\n}\n...\n}\nThe BeanMapper will provide the needed transformations between entity and transfer objects.\nAlso, the logic layer is the place to add validation for Authorization based on roles as we will see later.\nData Access layer\nThe data-access layer is responsible for managing the connections to access and process data. The mapping between java objects to a relational database is done in Devon4j with the spring-data-jpa.\nAs in the previous layers, the data-access layer will have both api and impl packages. However, in this case, the implementation will be slightly different. The api package will store the component main entities and, inside the _api package, another api.repo package will store the Repositories. The repository interface will extend DefaultRepository interface (located in com.devonfw.module.jpa.dataaccess.api.data package of devon4j-starter-spring-data-jpa ).\nFor queries we will differentiate between static queries (that will be located in a mapped file) and dynamic queries (implemented with QueryDsl). You can find all the details about how to manage queries with Devon4j here.\nThe default data base included in the project will be the H2 instance included with the Devon4j projects.\nTo get more details about pagination, data base security, _concurrency control, inheritance or how to solve the different relationships between entities visit the official devon4j dataaccess documentation.\nSecurity with Json Web Token\nFor the Authentication and Authorization the app will implement the json web token protocol.\nJwt basics\nA user will provide a username / password combination to our auth server.\nThe auth server will try to identify the user and, if the credentials match, will issue a token.\nThe user will send the token as the Authorization header to access resources on server protected by JWT Authentication.\nJwt implementation details\nThe Json Web Token pattern will be implemented based on the Spring Security framework that is provided by default in the Devon4j projects.\nAuthentication\nBased on the Spring Security approach, we will implement a class extending WebSecurityConfigurerAdapter (Devon4j already provides the BaseWebSecurityConfig class) to define the security entry point and filters. Also, as My Thai Star is a mainly public application, we will define here the resources that won&#x2019;t be secured.\nList of unsecured resources:\n/services/rest/dishmanagement/**: to allow anonymous users to see the dishes info in the menu section.\n/services/rest/ordermanagement/v1/order: to allow anonymous users to save an order. They will need a booking token but they won&#x2019;t be authenticated to do this task.\n/services/rest/bookingmanagement/v1/booking: to allow anonymous users to create a booking. Only a booking token is necessary to accomplish this task.\n/services/rest/bookingmanagement/v1/booking/cancel/**: to allow cancelling a booking from an email. Only the booking token is needed.\n/services/rest/bookingmanagement/v1/invitedguest/accept/**: to allow guests to accept an invite. Only a guest token is needed.\n/services/rest/bookingmanagement/v1/invitedguest/decline/**: to allow guests to reject an invite. Only a guest token is needed.\nTo configure the login we will set up the HttpSecurity object in the configure method of the class. We will define a JWTLoginFilter class that will handle the requests to the /login endpoint.\nhttp.[...].antMatchers(HttpMethod.POST, &quot;/login&quot;).permitAll().[...].addFilterBefore(new JWTLoginFilter(&quot;/login&quot;, authenticationManager()), UsernamePasswordAuthenticationFilter.class);\nIn the same HttpSecurity object we will set up the filter for the rest of the requests, to check the presence of the JWT token in the header. First we will need to create a JWTAuthenticationFilter class extending the GenericFilterBean class. Then we can add the filter to the HttpSecurity object\nhttp.[...].addFilterBefore(new JWTAuthenticationFilter(), UsernamePasswordAuthenticationFilter.class);\nFinally, as default users to start using the My Thai Star app we are going to define two profiles using the inMemoryAuthentication of the Spring Security framework. In the configure(AuthenticationManagerBuilder auth) method we will create:\nuser: waiter\npassword: waiter\nrole: Waiter\nuser: user0\npassword: password\nrole: Customer\nauth.inMemoryAuthentication().withUser(&quot;waiter&quot;).password(&quot;waiter&quot;).roles(&quot;Waiter&quot;).and().withUser(&quot;user0&quot;).password(&quot;password&quot;).roles(&quot;Customer&quot;);\nToken set up\nFollowing the official documentation the implementation details for the MyThaiStar&#x2019;s jwt will be:\nSecret: Used as part of the signature of the token, acting as a private key. For the showcase purposes we will use simply &quot;ThisIsASecret&quot;.\nToken Prefix schema: Bearer. The token will look like Bearer &lt;token&gt;\nHeader: Authorization. The response header where the token will be included. Also, in the requests, when checking the token it will be expected to be in the same header.\nThe Authorization header should be part of the Access-Control-Expose-Headers header to allow clients access to the Authorization header content (the token);\nThe claims are the content of the payload of the token. The claims are statements about the user, so we will include the user info in this section.\nsubject: &quot;sub&quot;. The username.\nissuer: &quot;iss&quot;. Who creates the token. We could use the url of our service but, as this is a showcase app, we simply will use &quot;MyThaiStarApp&quot;\nexpiration date: &quot;exp&quot;. Defines when the token expires.\ncreation date: &quot;iat&quot;. Defines when the token has been created.\nscope: &quot;scope&quot;. Array of strings to store the user roles.\nSignature Algorithm: To encrypt the token we will use the default algorithm HS512.\nAn example of a token claims before encryption would be:\n{sub=waiter, scope=[ROLE_Waiter], iss=MyThaiStarApp, exp=1496920280, iat=1496916680}\nCurrent User request\nTo provide to the client with the current user data our application should expose a service to return the user details. In Devon4j applications the /general/service/impl/rest/SecurityRestServiceImpl.java class is ready to do that.\n@Path(&quot;/security/v1&quot;)\n@Named(&quot;SecurityRestService&quot;)\npublic class SecurityRestServiceImpl {\n@Produces(MediaType.APPLICATION_JSON)\n@GET\n@Path(&quot;/currentuser/&quot;)\npublic UserDetailsClientTo getCurrentUserDetails(@Context HttpServletRequest request) {\n}\n}\nwe only will need to implement the getCurrentUserDetails method.\nAuthorization\nWe need to secure three services, that only should be accessible for users with role Waiter:\n(POST) /mythaistar/services/rest/bookingmanagement/v1/booking/search.\n(POST) /mythaistar/services/rest/ordermanagement/v1/order/search.\n(POST) /mythaistar/services/rest/ordermanagement/v1/order/filter.\nAs part of the token we are providing the user Role. So, when validating the token, we can obtain that same information and build a UsernamePasswordAuthenticationToken with username and the roles as collection of Granted Authorities.\nDoing so, afterwards, in the implementation class of the logic layer we can set up the related methods with the java security &apos;@RolesAllowed&apos; annotation to block the access to the resource to users that does not match the expected roles.\n@RolesAllowed(Roles.WAITER)\npublic PaginatedListTo&lt;BookingEto&gt; findBookings(BookingSearchCriteriaTo criteria) {\nreturn findBookings(criteria);\n}\n"},{"id":1075,"path":"../website/pages/docs/master-my-thai-star.asciidoc_technical-design.html#net-design.asciidoc","type":"docs","title":".NET design","body":"86.2.2. .NET design\nTODO\n"},{"id":1076,"path":"../website/pages/docs/master-my-thai-star.asciidoc_technical-design.html#nodejs-design.asciidoc","type":"docs","title":"Node.js design (deprecated)","body":"86.2.3. Node.js design (deprecated)\nIntroduction\nThe Node.js backend for My Thai Star application is going to be based on:\nExpress.js as the web application framework\nOASP4Fn as data access layer framework\nDynamoDB as NoSQL Database\nTo know more details about the above technologies please visit the following documentation:\nExpress.js\nOASP4Fn\nDynamoDB\nBasic architecture details\nThis structure can be shown in the following example image:\npublic - All files which be exposed on the server directly\nsrc\ndatabase folder - Folder with scripts to create/delete/seed the database\nmodel - Folder with all data model\nroutes - Folder with all Express.js routers\nutils - Folder with all utils like classes and functions\napp.ts - File with Express.js declaration\nconfig.ts - File with server configs\nlogic.ts - File with the business logic\ntest - Folder with all tests\nLayers\nService Layer: this layer will expose the REST api to exchange information with the client applications.\nLogic Layer: the layer in charge of hosting the business logic of the application.\nData Access Layer: the layer to communicate with the data base.\nService layer\nThe services layer will be solved using REST services with Express.js\nTo give service to the defined User Stories we will need to implement the following services:\nprovide all available dishes.\nsave a booking.\nsave an order.\nprovide a list of bookings (only for waiters) and allow filtering.\nprovide a list of orders (only for waiters) and allow filtering.\nlogin service (see the Security section).\nprovide the current user data (see the Security section)\nIn order to be compatible with the other backend implementations, we must follow the naming conventions proposed for Devon4j applications. We will define the following end points for the listed services.\n(POST) /mythaistar/services/rest/dishmanagement/v1/dish/search.\n(POST) /mythaistar/services/rest/bookingmanagement/v1/booking.\n(POST) /mythaistar/services/rest/ordermanagement/v1/order.\n(POST) /mythaistar/services/rest/bookingmanagement/v1/booking/search.\n(POST) /mythaistar/services/rest/ordermanagement/v1/order/search.\n(POST) /mythaistar/services/rest/ordermanagement/v1/order/filter (to filter with fields that does not belong to the Order entity).\n(POST) /mythaistar/login.\n(GET) /mythaistar/services/rest/security/v1/currentuser/.\nYou can find all the details for the services implementation in the Swagger definition included in the My Thai Star project on Github.\nTo treat these services separately, the following routers were created:\nbookingmanagement: will answer all requests with the prefix /mythaistar/services/rest/bookingmanagement/v1\ndishmanagement: will answer all requests with the prefix /mythaistar/services/rest/dishmanagement/v1\nordermanagement: will answer all requests with the prefix /mythaistar/services/rest/ordermanagement/v1\nThese routers will define the behavior for each service and use the logical layer.\nAn example of service definition:\nrouter.post(&apos;/booking/search&apos;, (req: types.CustomRequest, res: Response) =&gt; {\ntry {\n// body content must be SearchCriteria\nif (!types.isSearchCriteria(req.body)) {\nthrow {code: 400, message: &apos;No booking token given&apos; };\n}\n// use the searchBooking method defined at business logic\nbusiness.searchBooking(req.body, (err: types.Error | null, bookingEntity: types.PaginatedList) =&gt; {\nif (err) {\nres.status(err.code || 500).json(err.message);\n} else {\nres.json(bookingEntity);\n}\n});\n} catch (err) {\nres.status(err.code || 500).json({ message: err.message });\n}\n});\nLogic layer and Data access layer\nIn the logic layer we will locate all the business logic of the application. It will be located in the file logic.ts. If in this layer we need to get access to the data, we make use of data access layer directly, in this case using OASP4fn with the DynamoDB adapter.\nExample:\nexport async function cancelOrder(orderId: string, callback: (err: types.Error | null) =&gt; void) {\nlet order: dbtypes.Order;\ntry {\n// Data access\norder = await oasp4fn.table(&apos;Order&apos;, orderId).promise() as dbtypes.Order;\n[...]\n}\nWe could define the data access layer separately, but oasp4fn allows us to do this in a simple and clear way. So, we decided to not separate the access layer to the logic business.\nSecurity with Json Web Token\nFor the Authentication and Authorization the app will implement the json web token protocol.\nJwt basics\nRefer to Jwt basiscs for more information.\nJwt implementation details\nThe Json Web Token pattern will be implemented based on the JSON web token library available on npm.\nAuthentication\nBased on the JSON web token approach, we will implement a class Authentication to define the security entry point and filters. Also, as My Thai Star is a mainly public application, we will define here the resources that won&#x2019;t be secured.\nList of unsecured resources:\n/services/rest/dishmanagement/**: to allow anonymous users to see the dishes info in the menu section.\n/services/rest/ordermanagement/v1/order: to allow anonymous users to save an order. They will need a booking token but they won&#x2019;t be authenticated to do this task.\n/services/rest/bookingmanagement/v1/booking: to allow anonymous users to create a booking. Only a booking token is necessary to accomplish this task.\n/services/rest/bookingmanagement/v1/booking/cancel/**: to allow cancelling a booking from an email. Only the booking token is needed.\n/services/rest/bookingmanagement/v1/invitedguest/accept/**: to allow guests to accept an invite. Only a guest token is needed.\n/services/rest/bookingmanagement/v1/invitedguest/decline/**: to allow guests to reject an invite. Only a guest token is needed.\nTo configure the login we will create an instance of Authentication in the app file and then we will use the method auth for handle the requests to the /login endpoint.\napp.post(&apos;/mythaistar/login&apos;, auth.auth);\nTo verify the presence of the Authorization token in the headers, we will register in the express the Authentication.registerAuthentication middleware. This middleware will check if the token is correct, if so, it will place the user in the request and continue to process it. If the token is not correct it will continue processing the request normally.\napp.use(auth.registerAuthentication);\nFinally, we have two default users created in the database:\nuser: waiter\npassword: waiter\nrole: WAITER\nuser: user0\npassword: password\nrole: CUSTOMER\nToken set up\nFollowing the official documentation the implementation details for the MyThaiStar&#x2019;s jwt will be:\nSecret: Used as part of the signature of the token, acting as a private key. It can be modified at config.ts file.\nToken Prefix schema: Bearer. The token will look like Bearer &lt;token&gt;\nHeader: Authorization. The response header where the token will be included. Also, in the requests, when checking the token it will be expected to be in the same header.\nThe Authorization header should be part of the Access-Control-Expose-Headers header to allow clients access to the Authorization header content (the token);\nSignature Algorithm: To encrypt the token we will use the default algorithm HS512.\nCurrent User request\nTo provide to the client with the current user data our application should expose a service to return the user details. In this case the Authentication has a method called getCurrentUser which will return the user data. We only need register it at express.\napp.get(&apos;/mythaistar/services/rest/security/v1/currentuser&apos;, auth.getCurrentUser);\nAuthorization\nWe need to secure three services, that only should be accessible for users with role Waiter:\n(POST) /mythaistar/services/rest/bookingmanagement/v1/booking/search.\n(POST) /mythaistar/services/rest/ordermanagement/v1/order/search.\n(POST) /mythaistar/services/rest/ordermanagement/v1/order/filter.\nTo ensure this, the Authorization class has the securizedEndpoint method that guarantees access based on the role. This method can be used as middleware in secure services. As the role is included in the token, once validated we will have this information in the request and the middleware can guarantee access or return a 403 error.\napp.use(&apos;/mythaistar/services/rest/ordermanagement/v1/order/filter&apos;, auth.securizedEndpoint(&apos;WAITER&apos;));\napp.use(&apos;/mythaistar/services/rest/ordermanagement/v1/order/search&apos;, auth.securizedEndpoint(&apos;WAITER&apos;));\napp.use(&apos;/mythaistar/services/rest/bookingmanagement/v1/booking/search&apos;, auth.securizedEndpoint(&apos;WAITER&apos;));\n"},{"id":1077,"path":"../website/pages/docs/master-my-thai-star.asciidoc_technical-design.html#serverless-design.asciidoc","type":"docs","title":"Serverless design (deprecated)","body":"86.2.4. Serverless design (deprecated)\nIntroduction\nThe Node.js backend for My Thai Star application is going to be based on:\nServerless as serverless framework\nOASP4Fn as data access layer framework\nDynamoDB as NoSQL Database\nTo know more details about the above technologies please visit the following documentation:\nServerless\nOASP4Fn\nDynamoDB\nBasic architecture details\nThis structure can be shown in the following example image:\nhandlers - All function handlers following oasp4fn structure\nsrc\nmodel - Folder with all data model\nutils - Folder with all utils like classes and functions\nconfig.ts - File with server configs\nlogic.ts - File with the business logic\ntest - Folder with all tests\nLayers\nService Layer: this layer will expose the REST api to exchange information with the client applications.\nLogic Layer: the layer in charge of hosting the business logic of the application.\nData Access Layer: the layer to communicate with the data base.\nService layer\nThe services layer will be solved using REST services with Serverless\nTo give service to the defined User Stories we will need to implement the following services:\nprovide all available dishes.\nsave a booking.\nsave an order.\nprovide a list of bookings (only for waiters) and allow filtering.\nprovide a list of orders (only for waiters) and allow filtering.\nlogin service (see the Security section).\nprovide the current user data (see the Security section)\nIn order to be compatible with the other backend implementations, we must follow the naming conventions proposed for Devon4j applications. We will define the following end points for the listed services.\n(POST) /mythaistar/services/rest/dishmanagement/v1/dish/search.\n(POST) /mythaistar/services/rest/bookingmanagement/v1/booking.\n(POST) /mythaistar/services/rest/ordermanagement/v1/order.\n(POST) /mythaistar/services/rest/bookingmanagement/v1/booking/search.\n(POST) /mythaistar/services/rest/ordermanagement/v1/order/search.\n(POST) /mythaistar/services/rest/ordermanagement/v1/order/filter (to filter with fields that does not belong to the Order entity).\n(POST) /mythaistar/login.\n(GET) /mythaistar/services/rest/security/v1/currentuser/.\nYou can find all the details for the services implementation in the Swagger definition included in the My Thai Star project on Github.\nTo treat these http services, we must define the handlers following the oasp4fn convention:\n(handlers/Http/POST/dish-search-handler) /mythaistar/services/rest/dishmanagement/v1/dish/search.\n(handlers/Http/POST/booking-handler) /mythaistar/services/rest/bookingmanagement/v1/booking.\n(handlers/Http/POST/order-handler) /mythaistar/services/rest/ordermanagement/v1/order.\n(handlers/Http/POST/booking-search-handler) /mythaistar/services/rest/bookingmanagement/v1/booking/search.\n(handlers/Http/POST/order-search-handler) /mythaistar/services/rest/ordermanagement/v1/order/search.\n(handlers/Http/POST/order-filter-handler) /mythaistar/services/rest/ordermanagement/v1/order/filter (to filter with fields that does not belong to the Order entity).\n(handlers/Http/POST/login-handler) /mythaistar/login.\n(handlers/Http/GET/current-user-handler) /mythaistar/services/rest/security/v1/currentuser/.\nThese handlers will define the behavior for each service and use the logical layer.\nAn example of handler definition:\noasp4fn.config({ path: &apos;/mythaistar/services/rest/bookingmanagement/v1/booking/search&apos; });\nexport async function bookingSearch(event: HttpEvent, context: Context, callback: Function) {\ntry {\nconst search = &lt;types.SearchCriteria&gt;event.body;\nconst authToken = event.headers.Authorization;\n// falta lo que viene siendo comprobar el token y eso\nauth.decode(authToken, (err, decoded) =&gt; {\nif (err || decoded.role !== &apos;WAITER&apos;) {\nthrow { code: 403, message: &apos;Forbidden&apos;};\n}\n// body content must be SearchCriteria\nif (!types.isSearchCriteria(search)) {\nthrow { code: 400, message: &apos;No booking token given&apos; };\n}\nbusiness.searchBooking(search, (err: types.Error | null, bookingEntity: types.PaginatedList) =&gt; {\nif (err) {\ncallback(new Error(`[${err.code || 500}] ${err.message}`));\n} else {\ncallback(null, bookingEntity);\n}\n});\n});\n} catch (err) {\ncallback(new Error(`[${err.code || 500}] ${err.message}`));\n}\n}\nThe default integration for a handler is lambda. See oasp documentation for more information about default values and how to change it.\nNote\nIf you change the integration to lambda-proxy, you must take care that in this case the data will not be parsed. You must do JSON.parse explicitly\nAfter defining all the handlers, we must execute the fun command, which will generate the files serverless.yml and webpack.config.js.\nLogic layer and Data access layer\nSee in nodejs section\nSecurity with Json Web Token\nFor the Authentication and Authorization the app will implement the json web token protocol.\nJwt basics\nRefer to Jwt basiscs for more information.\nJwt implementation details\nThe Json Web Token pattern will be implemented based on the JSON web token library available on npm.\nAuthentication\nBased on the JSON web token approach, we will implement two methods in order to verify and user + generate the token and decode the token + return the user data. Also, as My Thai Star is a mainly public application, we will define here the resources that won&#x2019;t be secured.\nList of unsecured resources:\n/services/rest/dishmanagement/**: to allow anonymous users to see the dishes info in the menu section.\n/services/rest/ordermanagement/v1/order: to allow anonymous users to save an order. They will need a booking token but they won&#x2019;t be authenticated to do this task.\n/services/rest/bookingmanagement/v1/booking: to allow anonymous users to create a booking. Only a booking token is necessary to accomplish this task.\n/services/rest/bookingmanagement/v1/booking/cancel/**: to allow cancelling a booking from an email. Only the booking token is needed.\n/services/rest/bookingmanagement/v1/invitedguest/accept/**: to allow guests to accept an invite. Only a guest token is needed.\n/services/rest/bookingmanagement/v1/invitedguest/decline/**: to allow guests to reject an invite. Only a guest token is needed.\nTo configure the login we will create a handler called login and then we will use the method code to verify the user and generate the token.\napp.post(oasp4fn.config({ integration: &apos;lambda-proxy&apos;, path: &apos;/mythaistar/login&apos; });\nexport async function login(event: HttpEvent, context: Context, callback: Function) {\n.\n.\n.\n.\n}\nWe have two default users created in the database:\nuser: waiter\npassword: waiter\nrole: WAITER\nuser: user0\npassword: password\nrole: CUSTOMER\nToken set up\nSee in nodejs section\nCurrent User request\nTo provide the client with the current user data our application should expose a service to return the user details. In order to do this, we must define a handler called current-user-handler. This handler must decode the Authorization token and return the user data.\noasp4fn.config({\npath: &apos;/mythaistar/services/rest/security/v1/currentuser&apos;,\n});\nexport async function currentUser(event: HttpEvent, context: Context, callback: Function) {\nlet authToken = event.headers.Authorization;\ntry {\nauth.decode(authToken, (err: any, decoded?: any) =&gt; {\nif (err) {\ncallback(new Error(`[403] Forbidden`));\n} else {\ncallback(null, decoded);\n}\n});\n} catch (err) {\ncallback(new Error(`[${err.code || 500}] ${err.message}`));\n}\n}\nAuthorization\nWe need to secure three services, that only should be accessible for users with role Waiter:\n(POST) /mythaistar/services/rest/bookingmanagement/v1/booking/search.\n(POST) /mythaistar/services/rest/ordermanagement/v1/order/search.\n(POST) /mythaistar/services/rest/ordermanagement/v1/order/filter.\nTo ensure this, we must decode the Authorization token and check the result. As the role is included in the token, once validated we will have this information and can guarantee access or return a 403 error.\noasp4fn.config({ path: &apos;/mythaistar/services/rest/bookingmanagement/v1/booking/search&apos; });\nexport async function bookingSearch(event: HttpEvent, context: Context, callback: Function) {\nconst authToken = event.headers.Authorization;\nauth.decode(authToken, (err, decoded) =&gt; {\ntry {\nif (err || decoded.role !== &apos;WAITER&apos;) {\nthrow { code: 403, message: &apos;Forbidden&apos; };\n}\n[...]\n} catch (err) {\ncallback(new Error(`[${err.code || 500}] ${err.message}`));\n}\n});\n}\n"},{"id":1078,"path":"../website/pages/docs/master-my-thai-star.asciidoc_technical-design.html#graphql-design.asciidoc","type":"docs","title":"GraphQL design","body":"86.2.5. GraphQL design\nTODO\n"},{"id":1079,"path":"../website/pages/docs/master-my-thai-star.asciidoc_technical-design.html#master-my-thai-star.asciidoc_client-side","type":"docs","title":"Client Side","body":"86.3. Client Side\n"},{"id":1080,"path":"../website/pages/docs/master-my-thai-star.asciidoc_technical-design.html#angular-design.asciidoc","type":"docs","title":"Angular design","body":"86.3.1. Angular design\nIntroduction\nMyThaiStar client side has been built using latest frameworks, component libraries and designs:\nAngular 4 as main front-end Framework. https://angular.io/\nAngular/CLI 1.0.5 as Angular tool helper. https://github.com/angular/angular-cli\nCovalent Teradata 1.0.0-beta4 as Angular native component library based on Material Design. https://teradata.github.io/covalent/#/\nAngular/Material2 1.0.0-beta5 used by Covalent Teradata. https://github.com/angular/material2\nNote: this dependencies are evolving at this moment and if it is possible, we are updating it on the project.\nBasic project structure\nThe project is using the basic project seed that Angular/CLI provides with &#x201C;ng new &lt;project name&gt;&#x201D;. Then the app folder has been organized as Angular recommends and goes as follows:\napp\ncomponents\nsub-components\nshared\ncomponent files\nmain app component\nassets folder\nenvironments folder\nrest of angular files\nThis structure can be shown in the following example image:\nMain Views and components\nList of components that serve as a main view to navigate or components developed to make atomically a group of functionalities which given their nature, can be highly reusable through the app.\nNote: no-name-route corresponds to whatever URL the user introduced and does not exist, it redirects to HomeComponent.\nPublic area\nAppComponent\nContains the components that are on top of all views, including:\nOrder sidenav\nSidenav where selected orders are displayed with their total price and some comments.\nNavigation sidenav (only for mobile)\nThis sidenav proposal is to let user navigate through the app when the screen is too small to show the navigation buttons on the header.\nHeader\nIt contains the title, and some other basic functions regarding open and close sidenavs.\nFooter (only for desktop)\nAt the end of the page that shows only when open on desktop.\nHomeComponent\nMain view that shows up when the app initializes.\nMenuComponent\nView where the users can view, filter and select the dishes (with their extras) they want to order it contains a component to each menu entry:\nMenu-card\nThis component composes all the data of a dish in a card. Component made to display indeterminate number of dishes easily.\nBookTableComponent\nView to make book a table in a given data with a given number of assistants or create a reservation with a number of invitations via email.\nBook-table-dialog\nDialog which opens as a result of fulfilling the booking form, it displays all the data of the booking attempt, if everything is correct, the user can send the information or cancel if something is wrong.\nInvitation-dialog\nDialog which opens as a result of fulfilling the invitation form, it displays all the data of the booking with friends attempt, if everything is correct, the user can send the information or cancel if something is wrong.\nUserArea\nGroup of dialogs with the proposal of giving some functionalities to the user, as login, register, change password or connect with Twitter.\nLogin-dialog\nDialog with a tab to navigate between login and register.\nPassword-dialog\nFunctionality reserved to already logged users, in this dialog the user can change freely their password.\nTwitter-dialog\nDialog designed specifically to connect your user account with Twitter.\nWaiter cockpit area\nRestricted area to workers of the restaurant, here we can see all information about booked tables with the selected orders and the reservations with all the guests and their acceptance or decline of the event.\nOrderCockpitComponent\nData table with all the booked tables and a filter to search them, to show more info about that table you can click on it and open a dialog.\nOrder-dialog\nComplete display of data regarding the selected table and its orders.\nReservationCockpitComponent\nData table with all the reservations and a filter to search them, to show more info about that table you can click on it and open a dialog.\nReservation-dialog\nComplete display of data regarding the selected table and its guests.\nEmail Management\nAs the application send emails to both guests and hosts, we choose an approach based on URL&#x2019;s where the email contain a button with an URL to a service in the app and a token, front-end read that token and depending on the URL, will redirect to one service or another. For example:\nhttp://localhost:4200/booking/cancel/CB_20170605_8fb5bc4c84a1c5049da1f6beb1968afc\nThis URL will tell the app that is a cancellation of a booking with the token CB_20170605_8fb5bc4c84a1c5049da1f6beb1968afc. The app will process this information, send it to back-end with the correct headers, show the confirmation of the event and redirect to home page.\nThe main cases at the moment are:\nAccept Invite\nA guest accept an invitation sent by a host. It will receive another email to decline if it change its mind later on.\nReject Invite\nA guest decline the invitation.\nCancel Reservation\nA host cancel the reservation, everybody that has accepted or not already answered will receive an email notifying this event is canceled. Also all the orders related to this reservations will be removed.\nCancel Orders\nWhen you have a reservation, you will be assigned to a token, with that token you can save your order in the restaurant. When sent, you will receive an email confirming the order and the possibility to remove it.\nServices and directives\nServices are where all the main logic between components of that view should be. This includes calling a remote server, composing objects, calculate prices, etc.\nDirectives are a single functionality that are related to a component.\nAs it can be seen in the basic structure, every view that has a minimum of logic or need to call a server has its own service located in the shared folder.\nAlso, services and directives can be created to compose a reusable piece of code that will be reused in some parts of the code:\nPrice-calculator-service\nThis service located in the shared folder of sidenav contains the basic logic to calculate the price of a single order (with all the possibilities) and to calculate the price of a full list of orders for a table. As this is used in the sidenav and in the waiter cockpit, it has been exported as a service to be imported where needed and easily testable.\nAuthentication\nAuthentication services serves as a validator of roles and login and, at the same time, stores the basic data regarding security and authentication.\nMain task of this services is to provide visibility at app level of the current user information:\nCheck if the user is logged or not.\nCheck the permissions of the current user.\nStore the username and the JWT token.\nSnackService\nService created to serve as a factory of Angular Material Snackbars, which are used commonly through the app. This service accepts some parameters to customize the snackBar and opens it with this parameters.\nWindowService\nFor responsiveness reasons, the dialogs have to accept a width parameter to adjust to screen width and this information is given by Window object, as it is a good practice to have it in an isolated service, which also calculates the width percentage to apply on the dialogs.\nEqual-validator-directive\nThis directive located in the shared folder of userArea is used in 2 fields to make sure they have the same value. This directive is used in confirm password fields in register and change password.\nMock Backend\nTo develop meanwhile a real back-end is being developed let us to make a more realistic application and to make easier the adaptation when the backend is able to be connected and called. Its structure is as following:\nContains the three main groups of functionalities in the application. Every group is composed by:\nAn interface with all the methods to implement.\nA service that implements that interface, the main task of this service is to choose between real backend and mock backend depending on an environment variable.\nMock backend service which implements all the methods declared in the interface using mock data stored in a local file and mainly uses Lodash to operate the arrays.\nReal backend service works as Mock backend but in this case the methods call for server rest services through http.\nBooking\nThe booking group of functionalities manages the calls to reserve a table with a given time and assistants or with guests, get reservations filtered, accept or decline invitations or cancel the reservation.\nOrders\nManagement of the orders, including saving, filtering and cancel an order.\nDishes\nThe dishes group of functionalities manages the calls to get and filter dishes.\nLogin\nLogin manages the userArea logic: login, register and change password.\nSecurity\nMy Thai Star security is composed by two main security services:\nAuth-guard\nFront-end security approach, this service implements an interface called CanActivate that comes from angular/router module. CanActivate interface forces you to implement a canActivate() function which returns a Boolean.\nThis service checks with the AuthService stored data if the user is logged and if he has enough permission to access the waiter cockpit. This prevents that a forbidden user could access to waiter cockpit just by editing the URL in the browser.\nJWT\nJSON Web Token consists of a token that is generated by the server when the user logs in. Once provided, the token has to be included in an Authentication header on every Http call to the rest service, otherwise the call will be forbidden.\nJWT also has an expiration date and a role checking, so if a user has not enough permissions or keeps logged for a long certain amount of time that exceeds this expiration date, the next time he calls for a service call, the server will return an error and forbid the call. You can log again to restore the token.\nHttpClient\nTo implement this Authorization header management, an HttpClient service has been implemented.\nThis services works as an envelope of Http, providing some more functionalities, likes a header management and an automatically management of a server token error in case the JWT has expired, corrupted or not permitted.\n"},{"id":1081,"path":"../website/pages/docs/master-my-thai-star.asciidoc_technical-design.html#xamarin-design.asciidoc","type":"docs","title":"Xamarin design","body":"86.3.2. Xamarin design\nTODO\n&#x2190;&#xA0;Previous:&#xA0;User Stories&#xA0;| &#x2191;&#xA0;Up:&#xA0;MyThaiStar&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Security&#xA0;&#x2192;\n"},{"id":1082,"path":"../website/pages/docs/master-my-thai-star.asciidoc_testing.html#master-my-thai-star.asciidoc_testing","type":"docs","title":"Testing","body":"88. Testing\n"},{"id":1083,"path":"../website/pages/docs/master-my-thai-star.asciidoc_testing.html#master-my-thai-star.asciidoc_server-side","type":"docs","title":"Server Side","body":"88.1. Server Side\n"},{"id":1084,"path":"../website/pages/docs/master-my-thai-star.asciidoc_testing.html#java-testing.asciidoc","type":"docs","title":"Java testing","body":"88.1.1. Java testing\nComponent testing\nWe are going to test our components as a unit using Spring Test and Devon4j-test modules.\nIn order to test a basic component of the app first we will create a test class in the src/test/java folder and inside the main package of the test module. We will name the class following the convention.\n[Component]Test\nThen, in the declaration of the test class, we will use the @SpringBootTest annotation to run the application context. In addition, we will extend the ComponentTest from Devon4j-test module to have access to the main functionalities of the module, see more details here.\nSpring Test allows us to use Dependency Injection so we can inject our component directly using the @Inject annotation.\nEach test will be represented by a method annotated with @Test. Inside the method we will test one functionality, evaluating the result thanks to the asserts provided by the ComponentTest class that we are extending.\nA simple test example\n@SpringBootTest(classes = SpringBootApp.class)\npublic class DishmanagementTest extends ComponentTest {\n@Inject\nprivate Dishmanagement dishmanagement;\n@Test\npublic void findAllDishes() {\nPaginatedListTo&lt;DishCto&gt; result = this.dishmanagement.findDishes();\nassertThat(result).isNotNull();\n}\n...\n}\nRunning the tests\nFrom Eclipse\nWe can run the test from within Eclipse with the contextual menu Run As &gt; JUnit Test. This functionality can be launched from method level, class level or even package level. The results will be shown in the JUnit tab.\nFrom command line using Maven\nWe can also run tests using Maven and the command line, using the command mvn test (or mvn clean test).\nC:\\MyThaiStar&gt;mvn clean test\nDoing this we will run all the tests of the project (recognized by the Test word at the end of the classes) and the results will be shown by sub-project.\n...\n[D: 2017-07-17 09:30:08,457] [P: INFO ] [C: ] [T: Thread-5] [L: org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean] - [M: Closing JPA EntityManagerFactory for persistence unit &apos;default&apos;]\nResults :\nTests run: 11, Failures: 0, Errors: 0, Skipped: 1\n...\n[INFO]\n[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ mtsj-server ---\n[INFO] No sources to compile\n[INFO]\n[INFO] --- maven-surefire-plugin:2.12.4:test (default-test) @ mtsj-server ---\n[INFO] No tests to run.\n[INFO] ------------------------------------------------------------------------\n[INFO] Reactor Summary:\n[INFO]\n[INFO] mtsj ............................................... SUCCESS [ 0.902 s]\n[INFO] mtsj-core .......................................... SUCCESS [02:30 min]\n[INFO] mtsj-server ........................................ SUCCESS [ 1.123 s]\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD SUCCESS\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time: 02:35 min\n[INFO] Finished at: 20XX-07-17T09:30:13+02:00\n[INFO] Final Memory: 39M/193M\n[INFO] ------------------------------------------------------------------------\n"},{"id":1085,"path":"../website/pages/docs/master-my-thai-star.asciidoc_testing.html#net-testing.asciidoc","type":"docs","title":".NET testing","body":"88.1.2. .NET testing\nTODO\n"},{"id":1086,"path":"../website/pages/docs/master-my-thai-star.asciidoc_testing.html#nodejs-testing.asciidoc","type":"docs","title":"Node.js testing","body":"88.1.3. Node.js testing\nTODO\n"},{"id":1087,"path":"../website/pages/docs/master-my-thai-star.asciidoc_testing.html#graphql-testing.asciidoc","type":"docs","title":"GraphQL testing","body":"88.1.4. GraphQL testing\nTODO\n"},{"id":1088,"path":"../website/pages/docs/master-my-thai-star.asciidoc_testing.html#master-my-thai-star.asciidoc_client-side","type":"docs","title":"Client Side","body":"88.2. Client Side\n"},{"id":1089,"path":"../website/pages/docs/master-my-thai-star.asciidoc_testing.html#angular-testing.asciidoc","type":"docs","title":"Angular testing","body":"88.2.1. Angular testing\nMyThaiStar testing is made using Angular default testing environment and syntax language: Karma and Jasmine\nTo test an element of the application, you indicate that tests are a special type of files with the extension .spec.ts, then, in MyThaiStar angular/CLI config you can notice that there is an array with only one entry, Karma, with at the same time has one entry to Karma.config.js.\nIn the configuration of Karma we indicate which syntax language we are going to use (currently Jasmine as said before) between some other configurations, it is remarkable the last one: browsers. By default, the only available browser is chrome, that is because Karma works opening a chrome view to run all the tests, in that same window, Karma shows the result or errors of the test run. But we can add some other browser to adjust to our necessities, for example, in some automatic processes that run from console, it is not an option to open a chrome window, in that case, MyThaiStar used PhantomJS and ChromeHeadless.\nTaking all of this into account, to run the test in MyThaiStar we need to move to project root folder and run this command : ng test --browser &lt;browser&gt;\nNote\nIf you run just ng test it will run the three browser options simultaneously, giving as a result three test runs and outputs, it can cause timeouts and unwanted behaviors, if you want a shortcut to run the test with chrome window you can just run yarn test so we really encourage to not use just ng test.\nHere we are going to see how Client side testing of MyThaiStar has been done.\nTesting Components\nAngular components were created using angular/CLI ng create component so they already come with an spec file to test them. The only thing left to do is to add the providers and imports needed in the component to work as the component itself, once this is done, the most basic test is to be sure that all the dependencies and the component itself can be correctly created.\nAs an example, this is the spec.ts of the menu view component:\nall the imports...\ndescribe(&apos;MenuComponent&apos;, () =&gt; {\nlet component: MenuComponent;\nlet fixture: ComponentFixture&lt;MenuComponent&gt;;\nbeforeEach(async(() =&gt; {\nTestBed.configureTestingModule({\ndeclarations: [ MenuComponent, MenuCardComponent ],\nproviders: [SidenavService, MenuService, SnackBarService],\nimports: [\nBrowserAnimationsModule,\nBackendModule.forRoot({environmentType: 0, restServiceRoot: &apos;v1&apos;}),\nCovalentModule,\n],\n})\n.compileComponents();\n}));\nbeforeEach(() =&gt; {\nfixture = TestBed.createComponent(MenuComponent);\ncomponent = fixture.componentInstance;\nfixture.detectChanges();\n});\nit(&apos;should create&apos;, () =&gt; {\nexpect(component).toBeTruthy();\n});\n});\nFirst we declare the component to be tested and a Fixture object, then, we configure the testingModule right in the same way we could configure the MenuModule with the difference here that tests always have to use the mockBackend because we do not want to really depend on a server to test our components.\nOnce configured the test module, we have to prepare the context of the test, in this case we create the component, that is exactly what is going on in the beforeEach() function.\nFinally, we are ready to use the component and it&#x2019;s fixture to check if the component has bee correctly created.\nAt this moment this is the case for most of the components, in the future, some work would be applied on this matter to have a full testing experience in MyThaiStar components.\nDialog components\nDialog components are in a special category because they can not be tested normally. In the way Material implements the opening of dialogs, you have to create a component that will load into a dialog, to tell the module to load this components when needed, they have to be added into a special array category: EntryComponents. So, to test them, we need to import them in the test file as well.\nAlso, the testing code to open the component is a bit different too:\n...\nbeforeEach(() =&gt; {\ndialog = TestBed.get(MdDialog);\ncomponent = dialog.open(CommentDialogComponent).componentInstance;\n});\n...\nThat is right, the beforeEach() function is slightly different from the the example above, in this case we have to force to the test to know that the component is only displayed in a dialog, so we have to open a dialog with this component in order to access it.\nTesting Services\nAs well as components, services can be tested too, actually, they are even more necessary to be tested because they have inside more complex logic and data management.\nAs an example of testing services i am going to use a well done services, with a specific purpose and with its logic completely tested, the price-calculator service:\n...\ndescribe(&apos;PriceCalculatorService&apos;, () =&gt; {\nbeforeEach(() =&gt; {\nTestBed.configureTestingModule({\nproviders: [PriceCalculatorService],\n});\n});\nit(&apos;should be properly injected&apos;, inject([PriceCalculatorService], (service: PriceCalculatorService) =&gt; {\nexpect(service).toBeTruthy();\n}));\ndescribe(&apos;check getPrice method&apos;, () =&gt; {\nit(&apos;should calculate price for single order without extras&apos;, inject([PriceCalculatorService], (service: PriceCalculatorService) =&gt; {\nconst order: OrderView = {\ndish: {\nid: 0,\nprice: 12.50,\nname: &apos;Order without extras&apos;,\n},\norderLine: {\ncomment: &apos;&apos;,\namount: 1,\n},\nextras: [],\n};\nexpect(service.getPrice(order)).toEqual(order.dish.price);\n}));\n...\nIn services test, we have to inject the service in order to use it, then we can define some initializing contexts to test if the functions of the services returns the expected values, in the example we can see how an imaginary order is created and expected the function getPrice() to correctly calculate the price of that order.\nIn this same test file you can find some more test regarding all the possibilities of use in that services: orders with and without extras, single order, multiple orders and so on.\nSome services as well as the components have only tested that they are correctly created and they dependencies properly injected, in the future, will be full covering regarding this services test coverage.\nTesting in a CI environment\n"},{"id":1090,"path":"../website/pages/docs/master-my-thai-star.asciidoc_testing.html#xamarin-testing.asciidoc","type":"docs","title":"Xamarin testing","body":"88.2.2. Xamarin testing\nTODO\n"},{"id":1091,"path":"../website/pages/docs/master-my-thai-star.asciidoc_testing.html#master-my-thai-star.asciidoc_end-to-end","type":"docs","title":"End to end","body":"88.3. End to end\n"},{"id":1092,"path":"../website/pages/docs/master-my-thai-star.asciidoc_testing.html#mrchecker.asciidoc","type":"docs","title":"MrChecker E2E Testing","body":"88.3.1. MrChecker E2E Testing\nIntroduction\nMrChecker is a testing framework included in devonfw with several useful modules, from which we will focus on the Selenium Module, a module designed to make end-to-end testing easier to implement.\nHow to use it\nFirst of all download the repository.\nYou must run My Thai Star frontend and backend application and modify your url to the front in mrchecker/endtoend-test/src/resources/settings.properties\nNow you can run end to end test to check if the application works properly.\nTo run the e2e test you have two options:\nThe first option is using the command line in devonfw distribution\ncd mrchecker/endtoend-test/\nmvn test -Dtest=MyThaiStarTest -Dbrowser=Chrome\noptionally you can use it with a headless version or using another navigator:\n// chrome headless (without visual component)\nmvn test -Dtest=MyThaiStarTest -Dbrowser=ChromeHeadless\n// use firefox navigator\nmvn test -Dtest=MyThaiStarTest -Dbrowser=FireFox\nThe second is importing the project in devonfw Eclipse and running MyThaiStarTest.java as JUnit (right click, run as JUnit)\nThey can be executed one by one or all in one go, comment or uncomment @Test before those tests to enable or disable them.\nFor more information about how to use MrChecker and build your own end to end test read:\n* MrChecker documentation\n* MrChecker tutorial for My Thai Star\nEnd to end tests in My Thai Star\nWe have included a test suite with four tests to run in My Thai Star to verify everything works properly.\nThe included tests do the following:\nTest_loginAndLogOut: Log in and log out.\nTest_loginFake: Attempt to log in with a fake user.\nTest_bookTable: Log in and book a table, then login with a waiter and check if the table was successfully booked.\nTest_orderMenu: Log in and order food for a certain booked table.\nThese four tests can be found inside MyThaiStarTest.java located here.\n&#x2190;&#xA0;Previous:&#xA0;Security&#xA0;| &#x2191;&#xA0;Up:&#xA0;MyThaiStar&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;UI design&#xA0;&#x2192;\n"},{"id":1093,"path":"../website/pages/docs/master-my-thai-star.asciidoc_ui-design.html#master-my-thai-star.asciidoc_ui-design","type":"docs","title":"UI design","body":"89. UI design\n"},{"id":1094,"path":"../website/pages/docs/master-my-thai-star.asciidoc_ui-design.html#style-guide.asciidoc","type":"docs","title":"Style guide","body":"89.1. Style guide\n"},{"id":1095,"path":"../website/pages/docs/master-my-thai-star.asciidoc_ui-design.html#style-guide.asciidoc","type":"docs","title":"Low and high fidelity wireframes","body":"89.2. Low and high fidelity wireframes\nHistory of mockup designs for My Thai Star.\nMTS Wireframes Low Fidelity\nMTS Wireframes High Fidelity (Sprint 1)\nMTS Wireframes High Fidelity (Sprint 1) - Copy\nMTS Wireframes High Fidelity (Sprint 1) - Mobile\nMTS Wireframes High Fidelity (Sprint 2)\nMTS Wireframes High Fidelity (Sprint 2) - Modifications\n&#x2190;&#xA0;Previous:&#xA0;Testing&#xA0;| &#x2191;&#xA0;Up:&#xA0;MyThaiStar&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;CI/CD&#xA0;&#x2192;\n"},{"id":1096,"path":"../website/pages/docs/master-production-line.asciidoc.html#master-production-line.asciidoc","type":"docs","title":"X. Production Line Templates","body":"X. Production Line Templates\nThis repository contains a collection of templates that can be used inside a Production Line Jenkins to setup/configure and execute certain tasks.\nHow to add a Template to your PL instance\ndevonfw Technologies Templates\nUtility Templates\nMrChecker\nSamples\nTroubleshooting\n&#x2190;&#xA0;Previous:&#xA0;cicdgen Schematics&#xA0;| &#x2191;&#xA0;Up:&#xA0;devonfw guide&#xA0;| Next:&#xA0;How to add a Template to your PL instance&#xA0;&#x2192;\n"},{"id":1097,"path":"../website/pages/docs/master-production-line.asciidoc_devonfw-technologies-templates.html#master-production-line.asciidoc_devonfw-technologies-templates","type":"docs","title":"devonfw Technologies Templates","body":"65. devonfw Technologies Templates\n"},{"id":1098,"path":"../website/pages/docs/master-production-line.asciidoc_devonfw-technologies-templates.html#how-to-add-a-template.asciidoc","type":"docs","title":"How to add a Template to your PL instance","body":"65.1. How to add a Template to your PL instance\nGo to Jenkins.\nOn the upper left click on &quot;New Element&quot; to create a new Jenkins job.\nChose a name for the job such as &quot;MTS-template-seed-job&quot;. The job type has to be &quot;Pipeline&quot;. Click on ok.\nScroll down to the bottom of the job creation page where you will find the &quot;Pipeline&quot; section.\nSwitch to &quot;Pipeline script from SCM&quot;.\nSet &quot;SCM&quot; to &quot;Git&quot;.\nSet &quot;Repository URL&quot; to: https://github.com/devonfw/production-line.git\nCredentials can be left empty, because the repository is public.\nSet &quot;Script Path&quot; to the template that you want to use e.g. &quot;devon4j-mts/Jenkinsfile&quot;.\n"},{"id":1099,"path":"../website/pages/docs/master-production-line.asciidoc_devonfw-technologies-templates.html#devon4j-pl.asciidoc","type":"docs","title":"devon4j Template for Production Line","body":"65.2. devon4j Template for Production Line\n"},{"id":1100,"path":"../website/pages/docs/master-production-line.asciidoc_devonfw-technologies-templates.html#devon4j-pl.asciidoc_overview","type":"docs","title":"Overview","body":"65.2.1. Overview\nThis template will configure your PL instance to have a &apos;ready to use&apos; devon4j template. It can be used as a starting point for your Java projects.\nThis includes CICD files for a devonfw technology stack with configuration for:\ndocker or openshift deployment\npushing artifacts to nexus3\n"},{"id":1101,"path":"../website/pages/docs/master-production-line.asciidoc_devonfw-technologies-templates.html#devon4j-pl.asciidoc_prerequisites","type":"docs","title":"Prerequisites","body":"65.2.2. Prerequisites\nTo be able to run Jenkins devon4j job under ProductionLine you need to configure below settings in Jenkins and Gitlab\nJenkins\nExecute the initialize instance template\nIf you plan to deploy into OpenShift, you need to execute openshift-configuration template also.\nGitlab\nGenerate User Private Token\nGo to your Profile in Gitlab\nNext click on the pen icon\nOn the left menu choose Access Tokens and put token name and check fields like below\nClick &quot;Create personal access token&quot;, you should receive notification about created token and token string. Copy the token string.\nThe GitLab API user needs to have API access and the rights to create a new group. To set this permission follow the next steps:\nEnter the Admin control panel\nSelect &apos;Users&apos;\nSelect the user(s) in question and click &apos;Edit&apos;\nScroll down to &apos;Access&apos; and enable &apos;Can Create Group&apos;\n"},{"id":1102,"path":"../website/pages/docs/master-production-line.asciidoc_devonfw-technologies-templates.html#devon4j-pl.asciidoc_how-to-insert-the-template","type":"docs","title":"How to insert the Template","body":"65.2.3. How to insert the Template\nIn order to add the template, you can follow the guide.\n"},{"id":1103,"path":"../website/pages/docs/master-production-line.asciidoc_devonfw-technologies-templates.html#devon4j-pl.asciidoc_how-to-run-the-template","type":"docs","title":"How to run the Template","body":"65.2.4. How to run the Template\nBuild the job with parameters:\nPROJECT_NAME: The project name.\nPROJECT_SUFFIX: The project name suffix. As your project can have multiple assets (backend, frontend, middleware&#x2026;&#x200B;), you can define a suffix in order to identify each one with a different name\nDB_TYPE: The type of the database. Possible values: h2|postgresql|mysql|mariadb|oracle|hana|db2\nGROUP_ID: The group id of the project.\nGITLAB_USER_PRIVATE_TOKEN: Private Token of a Production Line Gitlab User that can be used to create repositories. Created as prerequisite, you only need to add it as credential with GitLab API token Kind.\nGITLAB_CREATE_GROUP_NAME: Name of the GitLab group. The repository will be create inside this group.\nGITLAB_CREATE_PROJECT_DESCRIPTION: Description of the repository.\nDEPLOY: Choose the environment where you want to deploy. The deployment could be none, docker or openshift. If docker or openshift were selected, extra parameters will be required in their dedicated steps:\nConfiguring DOCKER:\nDOCKER_URL: The remote docker daemon URL\nDOCKER_CERT: Credentials to access docker daemon. If the daemon is not secure, you can leave this empty.\nConfiguring Openshift:\nOC_NAME: Openshift cluster name. It was defined in the Openshift Configuration template\nDOCKER_REGISTRY_CREDENTIALS: Nexus docker registry user credentials. It was created in the initialize instance pipeline. The default username is nexus-api, the default password is the same as your service account.\nAfter executing this template, you will have:\nA new GitLab repository.\nThe repository group is the value passed in the GITLAB_CREATE_GROUP_NAME parameter.\nThe repository name is PROJECT_NAME-PROJECT_SUFFIX\nThe repository contains a clean devon4j project.\nThe repository contains a Jenkinsfile.\nThe repository has already setted the jenkins webhook.\nThe repository protects the branches master and release/* to only maintainers to push. Develop is the default branch.\nA new multibranch pipeline in jenkins inside the folder PROJECT_NAME with the name PROJECT_NAME-PROJECT_SUFFIX. As the webhook is already configured, it should be executed on every push to GitLab repository.\nIf you choose docker for deployment, your Jenkinsfile should contain two extra stages in order to build and deploy the docker image. Also, the repository should contain the Dockerfiles to create the docker images.\nIf you choose OpenShift for deployment, three new applications should be created in your OpenShift. Those applications represent three environments of your application: develop, uat and stage. Also, your Jenkinsfile should contain three extra stages in order to build and deploy the docker image and check that the pod is running without errors. Also, the repository should contain the Dockerfiles to create the docker images.\n"},{"id":1104,"path":"../website/pages/docs/master-production-line.asciidoc_devonfw-technologies-templates.html#devon4ng-pl.asciidoc","type":"docs","title":"devon4ng Template for Production Line","body":"65.3. devon4ng Template for Production Line\n"},{"id":1105,"path":"../website/pages/docs/master-production-line.asciidoc_devonfw-technologies-templates.html#devon4ng-pl.asciidoc_overview","type":"docs","title":"Overview","body":"65.3.1. Overview\nThis template will configure your PL instance to have a &apos;ready to use&apos; devon4ng template. It can be used as a starting point for your Angular projects.\nThis includes CICD files for a devonfw technology stack with configuration for:\nProductionLine instance\ndocker or openshift deployment\npushing artifacts to nexus3\n"},{"id":1106,"path":"../website/pages/docs/master-production-line.asciidoc_devonfw-technologies-templates.html#devon4ng-pl.asciidoc_prerequisites","type":"docs","title":"Prerequisites","body":"65.3.2. Prerequisites\nTo be able to run Jenkins Angular job under ProductionLine you need to configure below settings in Jenkins and Gitlab\nJenkins\nExecute the initialize instance template\nIf you plan to deploy into OpenShift, you need to execute openshift-configuration template also.\nGitlab\nGenerate User Private Token\nGo to your Profile in Gitlab\nNext click on the pen icon\nOn the left menu choose Access Tokens and put token name and check fields like below\nClick &quot;Create personal access token&quot;, you should receive notification about created token and token string. Copy the token string.\nThe GitLab API user needs to have API access and the rights to create a new group. To set this permission follow the next steps:\nEnter the Admin control panel\nSelect &apos;Users&apos;\nSelect the user(s) in question and click &apos;Edit&apos;\nScroll down to &apos;Access&apos; and un-tick &apos;Can Create Group&apos;\n"},{"id":1107,"path":"../website/pages/docs/master-production-line.asciidoc_devonfw-technologies-templates.html#devon4ng-pl.asciidoc_how-to-insert-the-template","type":"docs","title":"How to insert the Template","body":"65.3.3. How to insert the Template\nIn order to add the template, you can follow the guide.\n"},{"id":1108,"path":"../website/pages/docs/master-production-line.asciidoc_devonfw-technologies-templates.html#devon4ng-pl.asciidoc_how-to-run-the-template","type":"docs","title":"How to run the Template","body":"65.3.4. How to run the Template\nBuild the job with parameters:\nPROJECT_NAME: The project name.\nPROJECT_SUFFIX: The project name suffix. As your project can have multiple assets (backend, frontend, middleware&#x2026;&#x200B;), you can define a suffix in order to identify each one with a different name\nGROUP_ID: The group id of the project.\nGITLAB_USER_PRIVATE_TOKEN: Private Token of a Production Line Gitlab User that can be used to create repositories. Created as prerequisite, you only need to add it as credential with GitLab API token Kind.\nGITLAB_CREATE_GROUP_NAME: Name of the GitLab group. The repository will be create inside this group.\nGITLAB_CREATE_PROJECT_DESCRIPTION: Description of the repository.\nDEPLOY: Choose the environment where you want to deploy. The deployment could be none, docker or openshift. If docker or openshift were selected, extra parameters will be required in their dedicated steps:\nConfiguring DOCKER:\nDOCKER_URL: The remote docker daemon URL\nDOCKER_CERT: Credentials to access docker daemon. If the daemon is not secure, you can leave this empty.\nConfiguring Openshift:\nOC_NAME: Openshift cluster name. It was defined in the Openshift Configuration template\nDOCKER_REGISTRY_CREDENTIALS: Nexus docker registry user credentials. It was created in the initialize instance pipeline. The default username is nexus-api, the default password is the same as your service account.\nAfter executing this template, you will have:\nA new GitLab repository.\nThe repository group is the value passed in the GITLAB_CREATE_GROUP_NAME parameter.\nThe repository name is PROJECT_NAME-PROJECT_SUFFIX\nThe repository contains a clean devon4ng project.\nThe repository contains a Jenkinsfile.\nThe repository has already setted the jenkins webhook.\nThe repository protects the branches master and release/* to only maintainers to push. Develop is the default branch.\nA new multibranch pipeline in jenkins inside the folder PROJECT_NAME with the name PROJECT_NAME-PROJECT_SUFFIX. As the webhook is already configured, it should be executed on every push to GitLab repository.\nIf you choose docker for deployment, your Jenkinsfile should contain two extra stages in order to build and deploy the docker image. Also, the repository should contain the Dockerfiles to create the docker images.\nIf you choose OpenShift for deployment, three new applications should be created in your OpenShift. Those applications represent three environments of your application: develop, uat and stage. Also, your Jenkinsfile should contain three extra stages in order to build and deploy the docker image and check that the pod is running without errors. Also, the repository should contain the Dockerfiles to create the docker images.\nUnresolved directive in production-line.wiki/master-production-line.asciidoc - include::devon4net-pl.asciidoc[leveloffset=2]\n"},{"id":1109,"path":"../website/pages/docs/master-production-line.asciidoc_devonfw-technologies-templates.html#devon4node-pl.asciidoc","type":"docs","title":"devon4node Template for Production Line","body":"65.4. devon4node Template for Production Line\n"},{"id":1110,"path":"../website/pages/docs/master-production-line.asciidoc_devonfw-technologies-templates.html#devon4node-pl.asciidoc_overview","type":"docs","title":"Overview","body":"65.4.1. Overview\nThis template will configure your PL instance to have a &apos;ready to use&apos; devon4node template. It can be used as a starting point for your Node projects.\nThis includes CICD files for a devonfw technology stack with configuration for:\nProductionLine instance\ndocker or openshift deployment\npushing artifacts to nexus3\n"},{"id":1111,"path":"../website/pages/docs/master-production-line.asciidoc_devonfw-technologies-templates.html#devon4node-pl.asciidoc_prerequisites","type":"docs","title":"Prerequisites","body":"65.4.2. Prerequisites\nTo be able to run Jenkins Node job under ProductionLine you need to configure below settings in Jenkins and Gitlab\nJenkins\nExecute the initialize instance template\nIf you plan to deploy into OpenShift, you need to execute openshift-configuration template also.\nGitlab\nGenerate User Private Token\nGo to your Profile in Gitlab\nNext click on the pen icon\nOn the left menu choose Access Tokens and put token name and check fields like below\nClick &quot;Create personal access token&quot;, you should receive notification about created token and token string. Copy the token string.\nThe GitLab API user needs to have API access and the rights to create a new group. To set this permission follow the next steps:\nEnter the Admin control panel\nSelect &apos;Users&apos;\nSelect the user(s) in question and click &apos;Edit&apos;\nScroll down to &apos;Access&apos; and un-tick &apos;Can Create Group&apos;\n"},{"id":1112,"path":"../website/pages/docs/master-production-line.asciidoc_devonfw-technologies-templates.html#devon4node-pl.asciidoc_how-to-insert-the-template","type":"docs","title":"How to insert the Template","body":"65.4.3. How to insert the Template\nIn order to add the template, you can follow the guide.\n"},{"id":1113,"path":"../website/pages/docs/master-production-line.asciidoc_devonfw-technologies-templates.html#devon4node-pl.asciidoc_how-to-run-the-template","type":"docs","title":"How to run the Template","body":"65.4.4. How to run the Template\nBuild the job with parameters:\nPROJECT_NAME: The project name.\nPROJECT_SUFFIX: The project name suffix. As your project can have multiple assets (backend, frontend, middleware&#x2026;&#x200B;), you can define a suffix in order to identify each one with a different name\nGROUP_ID: The group id of the project.\nGITLAB_USER_PRIVATE_TOKEN: Private Token of a Production Line Gitlab User that can be used to create repositories. Created as prerequisite, you only need to add it as credential with GitLab API token Kind.\nGITLAB_CREATE_GROUP_NAME: Name of the GitLab group. The repository will be create inside this group.\nGITLAB_CREATE_PROJECT_DESCRIPTION: Description of the repository.\nDEPLOY: Choose the environment where you want to deploy. The deployment could be none, docker or openshift. If docker or openshift were selected, extra parameters will be required in their dedicated steps:\nConfiguring DOCKER:\nDOCKER_URL: The remote docker daemon URL\nDOCKER_CERT: Credentials to access docker daemon. If the daemon is not secure, you can leave this empty.\nConfiguring Openshift:\nOC_NAME: Openshift cluster name. It was defined in the Openshift Configuration template\nDOCKER_REGISTRY_CREDENTIALS: Nexus docker registry user credentials. It was created in the initialize instance pipeline. The default username is nexus-api, the default password is the same as your service account.\nAfter executing this template, you will have:\nA new GitLab repository.\nThe repository group is the value passed in the GITLAB_CREATE_GROUP_NAME parameter.\nThe repository name is PROJECT_NAME-PROJECT_SUFFIX\nThe repository contains a clean devon4node project.\nThe repository contains a Jenkinsfile.\nThe repository has already setted the jenkins webhook.\nThe repository protects the branches master and release/* to only maintainers to push. Develop is the default branch.\nA new multibranch pipeline in jenkins inside the folder PROJECT_NAME with the name PROJECT_NAME-PROJECT_SUFFIX. As the webhook is already configured, it should be executed on every push to GitLab repository.\nIf you choose docker for deployment, your Jenkinsfile should contain two extra stages in order to build and deploy the docker image. Also, the repository should contain the Dockerfiles to create the docker images.\nIf you choose OpenShift for deployment, three new applications should be created in your OpenShift. Those applications represent three environments of your application: develop, uat and stage. Also, your Jenkinsfile should contain three extra stages in order to build and deploy the docker image and check that the pod is running without errors. Also, the repository should contain the Dockerfiles to create the docker images.\n"},{"id":1114,"path":"../website/pages/docs/master-production-line.asciidoc_devonfw-technologies-templates.html#from-existing-devonfw.asciidoc","type":"docs","title":"From existing devonfw Template for Production Line","body":"65.5. From existing devonfw Template for Production Line\n"},{"id":1115,"path":"../website/pages/docs/master-production-line.asciidoc_devonfw-technologies-templates.html#from-existing-devonfw.asciidoc_overview","type":"docs","title":"Overview","body":"65.5.1. Overview\nFrom existing devonfw template is very similar to devon4j, devon4ng, devon4net and devon4node templates. The main difference is from existing devonfw template will no create a new devonfw project, it takes an existing project from GitLab and then add/create everything in order to apply a CICD strategy to your project.\n"},{"id":1116,"path":"../website/pages/docs/master-production-line.asciidoc_devonfw-technologies-templates.html#from-existing-devonfw.asciidoc_prerequisites","type":"docs","title":"Prerequisites","body":"65.5.2. Prerequisites\nTo be able to run Jenkins Node job under ProductionLine you need to configure below settings in Jenkins and Gitlab\nJenkins\nExecute the initialize instance template\nIf you plan to deploy into OpenShift, you need to execute openshift-configuration template also.\nGitlab\nCreate a project and upload your current code. In order to start a new project in your local machine, you can use the devonfw-ide. The project must be a devon4j, devon4ng, devon4net or devon4node project.\nGenerate User Private Token\nGo to your Profile in Gitlab\nNext click on the pen icon\nOn the left menu choose Access Tokens and put token name and check fields like below\nClick &quot;Create personal access token&quot;, you should receive notification about created token and token string. Copy the token string.\nThe GitLab API user needs to have API access and the rights to create a new group. To set this permission follow the next steps:\nEnter the Admin control panel\nSelect &apos;Users&apos;\nSelect the user(s) in question and click &apos;Edit&apos;\nScroll down to &apos;Access&apos; and un-tick &apos;Can Create Group&apos;\n"},{"id":1117,"path":"../website/pages/docs/master-production-line.asciidoc_devonfw-technologies-templates.html#from-existing-devonfw.asciidoc_how-to-insert-the-template","type":"docs","title":"How to insert the Template","body":"65.5.3. How to insert the Template\nIn order to add the template, you can follow the guide.\n"},{"id":1118,"path":"../website/pages/docs/master-production-line.asciidoc_devonfw-technologies-templates.html#from-existing-devonfw.asciidoc_how-to-run-the-template","type":"docs","title":"How to run the Template","body":"65.5.4. How to run the Template\nBuild the job with parameters:\nREPOSITORY_URL: The internal repository URL. Without protocol. Example: gitlab-core:80/gitlab/mygroup/myproject-frontend.\nGIT_BRANCH: The branch where you want to apply the CICD changes.\nMERGE_STRATEGY: Choose the merge strategy for cicdgen. For more information see the CICDGEN merge documentation page\nGITLAB_USER_PRIVATE_TOKEN: Private Token of a Production Line Gitlab User that can be used to create/update repositories. The token proprietary user must have admin rights in the repository. Created as prerequisite, you only need to add it as credential with GitLab API token Kind.\nDEPLOY: Choose the environment where you want to deploy. The deployment could be none, docker or openshift. If docker or openshift were selected, extra parameters will be required in their dedicated steps:\nConfiguring DOCKER:\nDOCKER_URL: The remote docker daemon URL\nDOCKER_CERT: Credentials to access docker daemon. If the daemon is not secure, you can leave this empty.\nConfiguring Openshift:\nOC_NAME: Openshift cluster name. It was defined in the Openshift Configuration template\nDOCKER_REGISTRY_CREDENTIALS: Nexus docker registry user credentials. It was created in the initialize instance pipeline. The default username is nexus-api, the default password is the same as your service account.\nAfter executing this template, you will have:\nYour GitLab project updated.\nAdded a Jenkinsfile with all CICD stages.\nThe repository is updated in order to have the jenkins webhook.\nA new multibranch pipeline in jenkins inside the folder PROJECT_NAME with the name PROJECT_NAME-PROJECT_SUFFIX. As the webhook is already configured, it should be executed on every push to GitLab repository.\nIf you choose docker for deployment, your Jenkinsfile should contain two extra stages in order to build and deploy the docker image. Also, the repository should contain the Dockerfiles to create the docker images.\nIf you choose OpenShift for deployment, three new applications should be created in your OpenShift. Those applications represent three environments of your application: develop, uat and stage. Also, your Jenkinsfile should contain three extra stages in order to build and deploy the docker image and check that the pod is running without errors. Also, the repository should contain the Dockerfiles to create the docker images.\n&#x2190;&#xA0;Previous:&#xA0;How to add a Template to your PL instance&#xA0;| &#x2191;&#xA0;Up:&#xA0;Production Line Templates&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Utility Templates&#xA0;&#x2192;\n"},{"id":1119,"path":"../website/pages/docs/master-production-line.asciidoc_how-to-add-a-template-to-your-pl-instance.html#master-production-line.asciidoc_how-to-add-a-template-to-your-pl-instance","type":"tutorial","title":"How to add a Template to your PL instance","body":"64. How to add a Template to your PL instance\nGo to Jenkins.\nOn the upper left click on &quot;New Element&quot; to create a new Jenkins job.\nSelect a name for the job such as &quot;MTS-template-seed-job&quot;. The job type has to be &quot;Pipeline&quot;. Click on ok.\nScroll down to the bottom of the job creation page where you will find the &quot;Pipeline&quot; section.\nSwitch to &quot;Pipeline script from SCM&quot;.\nSet &quot;SCM&quot; to &quot;Git&quot;.\nSet &quot;Repository URL&quot; to: https://github.com/devonfw/production-line.git\nCredentials can be left empty, because the repository is public.\nSet &quot;Script Path&quot; to the template that you want to use e.g. &quot;devon4j-mts/Jenkinsfile&quot;.\n&#x2191;&#xA0;Up:&#xA0;Production Line Templates&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;devonfw Technologies Templates&#xA0;&#x2192;\n"},{"id":1120,"path":"../website/pages/docs/master-production-line.asciidoc_mrchecker.html#master-production-line.asciidoc_mrchecker","type":"docs","title":"MrChecker","body":"67. MrChecker\n"},{"id":1121,"path":"../website/pages/docs/master-production-line.asciidoc_mrchecker.html#mrchecker.asciidoc","type":"docs","title":"MrChecker under ProductionLine","body":"67.1. MrChecker under ProductionLine\n"},{"id":1122,"path":"../website/pages/docs/master-production-line.asciidoc_mrchecker.html#mrchecker.asciidoc_introduction","type":"docs","title":"Introduction","body":"67.1.1. Introduction\nMrChecker is end to end automation test framework written in Java. It has been released\nby devonfw but it is not supported by the devonfw core team.\nThis framework consist of eight test modules:\nCore test module\nSelenium test module\nWebAPI test module\nSecurity test module\nDataBase test module\nStandalone test module\nDevOps module\n"},{"id":1123,"path":"../website/pages/docs/master-production-line.asciidoc_mrchecker.html#mrchecker.asciidoc_prerequisites","type":"docs","title":"Prerequisites","body":"67.1.2. Prerequisites\nTo be able to run Jenkins MrChecker job under ProductionLine you need to configure below settings in Jenkins and Gitlab\nJenkins\nAdd Jenkins Shared Library using documentation https://github.com/devonfw/production-line-shared-lib\nInstall required plugins:\nHTTP Request Plugin\nAllure Jenkins Plugin\nIn Jenkins Global Tool Configuration configure Allure Commandline and Maven like\nGitlab\nGenerate User Private Token\nGo to your Profile in Gitlab\nNext click on the pen icon\nOn the left menu choose Access Tokens and put token name and check fields like below\nClick &quot;Create personal access token&quot;, you should receive notification about created token and token string. Copy the token string.\nThe GitLab API user needs to have API access and the rights to create a new group. To set this permission follow the next steps:\nEnter the Admin control panel\nSelect &apos;Users&apos;\nSelect the user(s) in question and click &apos;Edit&apos;\nScroll down to &apos;Access&apos; and un-tick &apos;Can Create Group&apos;\n"},{"id":1124,"path":"../website/pages/docs/master-production-line.asciidoc_mrchecker.html#mrchecker.asciidoc_how-to-insert-the-template","type":"docs","title":"How to insert the Template","body":"67.1.3. How to insert the Template\nCreate new Jenkins Pipeline Job\nIn job configuration check &quot;This project is parametrized&quot;, choose &quot;String parameter and provide\nName: GITLAB_USER_PRIVATE_TOKEN\nDefault Value: &lt;GITLAB_TOKEN_STRING_YOU_JUST_CREATED&gt;\nAdd the template\nThe guide on how to add a template to your Jenkins can be found in the root directory of the template repository: https://github.com/devonfw/production-line.git\nSave job configuration\n"},{"id":1125,"path":"../website/pages/docs/master-production-line.asciidoc_mrchecker.html#mrchecker.asciidoc_how-to-run-the-template","type":"docs","title":"How to run the Template","body":"67.1.4. How to run the Template\nBuild the job\nAfter job ends with success wait few seconds for repository import to Gitlab\nAs output of the build new Jenkins Pipline job is created with name &quot;MrChecker_Example_Tests&quot; also new repository &quot;Mrchecker&quot; will be created in Gitlab\nBuild &quot;MrChecker_Example_Tests&quot; job\n"},{"id":1126,"path":"../website/pages/docs/master-production-line.asciidoc_mrchecker.html#mrchecker.asciidoc_expected-result","type":"docs","title":"Expected Result","body":"67.1.5. Expected Result\nAs output of this job Allure Report will be generated\n"},{"id":1127,"path":"../website/pages/docs/master-production-line.asciidoc_mrchecker.html#mrchecker.asciidoc_summary","type":"docs","title":"Summary","body":"67.1.6. Summary\nUsing this documentation you should be able to run MrChercker test framework on ProductionLine.\nMrChecker offers two projects to your disposal:\nFirst project &quot;mrchecker-app-under-test/pipelines/CI/Jenkinsfile_ProductionLine.groovy&quot; has all tests included in the project and is the default project used in &quot;MrChecker_Example_Tests&quot; job.\nSecond project &quot;mrchecker-app-under-testboilerplate/pipelines/CI/Jenkinsfile_ProductionLine.groovy&quot; here tests are not included, therefore if you choose to run &quot;MrChecker_Example_Tests&quot; job Allure report will be not generated.\nTo change the project change script path at the bottom of the &quot;MrChecker_Example_Tests&quot; job.\n&#x2190;&#xA0;Previous:&#xA0;Utility Templates&#xA0;| &#x2191;&#xA0;Up:&#xA0;Production Line Templates&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Samples&#xA0;&#x2192;\n"},{"id":1128,"path":"../website/pages/docs/master-production-line.asciidoc_samples.html#master-production-line.asciidoc_samples","type":"docs","title":"Samples","body":"68. Samples\n"},{"id":1129,"path":"../website/pages/docs/master-production-line.asciidoc_samples.html#devon4j-mts.asciidoc","type":"docs","title":"devon4j My-Thai-Star Sample Application Template for Production Line","body":"68.1. devon4j My-Thai-Star Sample Application Template for Production Line\n"},{"id":1130,"path":"../website/pages/docs/master-production-line.asciidoc_samples.html#devon4j-mts.asciidoc_introduction","type":"docs","title":"Introduction","body":"68.1.1. Introduction\nPlease read all of the following sections carefully.\n"},{"id":1131,"path":"../website/pages/docs/master-production-line.asciidoc_samples.html#devon4j-mts.asciidoc_overview","type":"docs","title":"Overview","body":"68.1.2. Overview\nThis template will configure your PL instance to have a &apos;ready to use&apos; My-Thai-Star devonfw application. It is only an example. In order to start a new project, please use the other templates. This includes:\nCloning the official My-Thai-Star (https://github.com/devonfw/my-thai-star) repository into your GitLab, which allows you to do customizations on your own.\nAdding a build job for the Angular front-end, including a SonarQube analysis and a delivery to Nexus as zip and docker image.\nAdding a build job for the Java back-end, including a SonarQube analysis and a deployment to Nexus as zip and docker image.\nAdding a deployment job for the Angular front-end\nAdding a deployment job for the Java back-end\nAdding a deployment job for the reverse proxy. Please see My Thai Star deployment documentation\nEspecially the build and delpoyment jobs require several additional Jenkins plugins, which are not part of the PL by default. The Template will also take care of those installations.\nAll build and deployment jobs are taken from the official My-Thai-Star (https://github.com/devonfw/my-thai-star) repository. The created build and deployment jobs inside Jenkins will use the Jenkinsfiles from the cloned repo in Gitlab. These are currently the following Jenkinsfiles:\nJenkins Jobs\nTable 47. Jenkins Jobs\nJenkins job name\nPath to Jenkinsfile in repo\nDescription\nMyThaiStar_FRONTEND_BUILD\njenkins/angular/cicd/Jenkinsfile\nBuilds and tests the Angular frontend. Pushes artifacts to Nexus.\nMyThaiStar_SERVER_BUILD\njenkins/java/cicd/Jenkinsfile\nBuilds and tests the Java backend. Pushes artifacts to Nexus.\nMyThaiStar_FRONTEND_DEPLOY\njenkins/angular/deployment/Jenkinsfile\nFrontend deployment job. Downloads the docker images from Nexus3 and starts a new container usign that image.\nMyThaiStar_SERVER_DEPLOY\njenkins/java/deployment/Jenkinsfile\nBackend deployment job. Downloads the docker images from Nexus3 and starts a new container usign that image.\nMyThaiStar_REVERSE-PROXY_DEPLOY\njenkins/deployment/Jenkinsfile\nReverse proxy deployment job. Downloads the docker images from Nexus3 and starts a new container usign that image. With this job you can also build the reverse proxy image.\n"},{"id":1132,"path":"../website/pages/docs/master-production-line.asciidoc_samples.html#devon4j-mts.asciidoc_how-to-report-issues","type":"docs","title":"How to report Issues","body":"68.1.3. How to report Issues\nThis template is independent from PL and devonfw releases and is also not really connected to one of the projects. Therefore issues that occur during the template setup or execution should be tracked in the issue section of this GitHub project.\n"},{"id":1133,"path":"../website/pages/docs/master-production-line.asciidoc_samples.html#devon4j-mts.asciidoc_how-to-contribute","type":"docs","title":"How to contribute","body":"68.1.4. How to contribute\nIn case you see improvements we would love to see a Pull Request.\n"},{"id":1134,"path":"../website/pages/docs/master-production-line.asciidoc_samples.html#devon4j-mts.asciidoc_prerequisities-before-running-the-template","type":"docs","title":"Prerequisities before running the template","body":"68.1.5. Prerequisities before running the template\nProduction Line Components\nTo use the template you need to make sure that your PL has the following components installed:\nJenkins (required to run the template and to execute the build/deployment Jobs)\nSonarQube (required for a static code analysis)\nGitLab (required as a repostiory)\nNexus3 (required to store the build artifacts)\nTip\nAdditional components can be ordered from the ProductionLine service team.\nTechnical User Setup\nIn order to configure the services, we need technical users for the following components:\nGitlab\nNexus3\nSonarQube\nThe following sections describe how to configure the components to enable technical users and tokens.\nManual configuration\nIn order to configure the Production Line components manually you can follow this guide\nAutomatic configuration\nIn order to configure the Production Line components automatically you can follow this guide\nThere is one thing that initialize-template can not do automatically: the gitlab token creation.\nThe creation of the GitLab Group and Project will require a private GitLab token which has to be created manually. The token can be obtained like this:\nGo to your Profile in Gitlab\nNext click on the pen icon\nOn the left menu choose Access Tokens and put token name and check fields like below\nClick &quot;Create personal access token&quot;, you should receive notification about created token and token string. Copy the token string.\nImportant\nThe GitLab API user needs to have API access and the rights to create a new group. To set this permission follow the next steps:\nEnter the Admin control panel\nSelect &apos;Users&apos;\nSelect the user(s) in question and click &apos;Edit&apos;\nScroll down to &apos;Access&apos; and un-tick &apos;Can Create Group&apos;\nBuild/Deployment Requirements\nThe My Thai Star CICD pipelines will create a docker image and then the deployment pipelines will use it in order to deploy the application. As Production Line do not include a docker daemon, you need an additional server to do it. Those server needs:\nDocker-CE has to be installed\nDocker daemon exposed\n"},{"id":1135,"path":"../website/pages/docs/master-production-line.asciidoc_samples.html#devon4j-mts.asciidoc_how-to-run-it","type":"docs","title":"How to run it","body":"68.1.6. How to run it\nWarning\nIf Jenkins needs to install plugins, a restart will be performed.\nSo please make sure, that nothing important is running.\nImportant\nWe have job-parameters inside the template Jenkinsfile that will only be active if Jenkins has run the job at least once!\nSetup template job in Jenkins\nThe guide on how to add a template to your Jenkins can be found in the root directory of the template repository: https://github.com/devonfw/production-line.git\nExecute the Jenkins job in your Jenkins\nGo to the Jenkins job.\nExecute job.\nIt will try to configure and setup the PL components such as Jenkins/Gitlab and Nexus.\nImportant\nIf a restart was needed, you need to trigger the job again!\nThe job should now show the required parameters, you only need to change the GITLAB PRIVATE TOKEN that you should have generated in the prerequisite section\nWhen everything is &quot;green&quot; the template is done and you can have a look in the created &quot;MTS&quot; folder in Jenkins.\nImportant\nIt will take a few minutes to clone the official MTS repository to the internal Gitlab. So you need to wait before executing the build jobs at the frist time.\nBuild Jobs\nYou can now execute the build for the frontend and also the backend. They do not require any parameters to run. The expected result is, that both jobs can run without any errors. They will build, test and deploy the artifacts to Nexus3.\nDeployment Jobs\nAll deployment jobs have several parameters configured in their Jenkinsfile. Unfortunately, Jenkins does not pick them up immediatly, so you need to execute the job once, by pressing the &quot;Build now&quot; button.\nThe run should fail quite fast and once you refresh the page, the &quot;Build now&quot; button should have changed to &quot;Build with Parameters&quot;. If you now click on the button you should see the parameters below:\nYou need to set the following parameters in order to get it running:\nTable 48. Required Parameters\nParameter\nDescription\nregistryUrl\nThe docker registry URL where image is stored.\nregistryCredentialsId\nThe nexus credentials to access to the docker registry.\nVERSION\nThe version of the image that was built in the build jobs. For example &quot;1.12.3-SNAPSHOT&quot;.\ndockerNetwork\nThe docker network where the container will be deployed.\nAlso, the reverse proxy deployment has two more parameters:\nTable 49. Reverse Proxy extra parameters\nParameter\nDescription\nbuildReverseProxy\nIf true, it will build a new reverse proxy docker image and then deploy that image.\nport\nThe port where the application will be listening. It&#x2019;s a host port, not a container port.\nNote\nYou can deploy multiple versions of My Thai Star in the same machine by changing the docker network in all deployments and the port in the reverse proxy deployment.\nImportant\nYou must choose the same docker network for all deployments\nImportant\nYou need to deploy the angular and java applications before the reverse proxy. Also, the first you need to check the buildReverseProxy parameter in order to create the reverse proxy image and then deploy the container.\n&#x2190;&#xA0;Previous:&#xA0;MrChecker&#xA0;| &#x2191;&#xA0;Up:&#xA0;Production Line Templates&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Troubleshooting&#xA0;&#x2192;\n"},{"id":1136,"path":"../website/pages/docs/master-production-line.asciidoc_troubleshooting.html#master-production-line.asciidoc_troubleshooting","type":"docs","title":"Troubleshooting","body":"69. Troubleshooting\n"},{"id":1137,"path":"../website/pages/docs/master-production-line.asciidoc_troubleshooting.html#troubleshoot.asciidoc","type":"docs","title":"Troubleshootibng","body":"69.1. Troubleshootibng\n"},{"id":1138,"path":"../website/pages/docs/master-production-line.asciidoc_troubleshooting.html#troubleshoot.asciidoc_introduction","type":"docs","title":"Introduction","body":"69.1.1. Introduction\nIn this section you can find the solution of the most common errors using the templates.\n"},{"id":1139,"path":"../website/pages/docs/master-production-line.asciidoc_troubleshooting.html#troubleshoot.asciidoc_template-startup-failed","type":"docs","title":"Template startup failed","body":"69.1.2. Template startup failed\nSometimes, when you execute any template you will see this an error like:\norg.codehaus.groovy.control.MultipleCompilationErrorsException: startup failed:\n/home/pl/jobs/devon4j-mts_PL_Template/builds/8/libs/ProductionLineTemplateLib/src/com/capgemini/productionline/configuration/JenkinsConfiguration.groovy: 38: unable to resolve class ru.yandex.qatools.allure.jenkins.tools.AllureCommandlineInstaller\n@ line 38, column 1.\nimport ru.yandex.qatools.allure.jenkins.tools.AllureCommandlineInstaller\nIn most of our templates we use the Production Line Shared Lib. In order to work, the Shared Lib needs some plugins installed in your Jenkins, so to solve this error you need to install those plugins manually using the Manage Plugins.\nIn this specific case the problem is the Allure plugin is not installed. Just install it, restart Jenkins and execute again the template.\n"},{"id":1140,"path":"../website/pages/docs/master-production-line.asciidoc_troubleshooting.html#troubleshoot.asciidoc_build-now-instead-build-with-parameters","type":"docs","title":"Build Now instead Build with Parameters","body":"69.1.3. Build Now instead Build with Parameters\nSometimes, when you go to execute a template, mostly the first time, the Build Now button is available instead Build with Parameters buttom. The root cause of this problem is the parameters are defined in the Jenkinsfile and, as you never execute it before, Jenkins do not have those Jenkinsfile yet. For this reason it does not knows the parameters required.\nTo solve this problem, you only need to press the Build Now button. Then, the execution will start and fail. It&#x2019;s not a problem as you do not enter any parameter. Now you only need to reload the page and the Build with Parameters button will be available.\n"},{"id":1141,"path":"../website/pages/docs/master-production-line.asciidoc_troubleshooting.html#troubleshoot.asciidoc_error-at-install-plugins-stage","type":"docs","title":"Error at Install plugins stage","body":"69.1.4. Error at Install plugins stage\nIn some templates you can see the Install plugins stage. In this stage some plugins required for the template will be installed. In order to properly load the plugins, Jekins needs to be restarted, for that reason the pipeline fails on that stage. It is not a bug or problem, so do not worry about that. You only need to wait until Jenkins is restarted and execute the template again.\n&#x2190;&#xA0;Previous:&#xA0;Samples&#xA0;| &#x2191;&#xA0;Up:&#xA0;Production Line Templates&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;CobiGen&#x2009;&#x2014;&#x2009;Code-based incremental Generator&#xA0;&#x2192;\n"},{"id":1142,"path":"../website/pages/docs/master-production-line.asciidoc_utility-templates.html#master-production-line.asciidoc_utility-templates","type":"docs","title":"Utility Templates","body":"66. Utility Templates\n"},{"id":1143,"path":"../website/pages/docs/master-production-line.asciidoc_utility-templates.html#initialize-instance.asciidoc","type":"docs","title":"Initialize Instance Template for Production Line","body":"66.1. Initialize Instance Template for Production Line\n"},{"id":1144,"path":"../website/pages/docs/master-production-line.asciidoc_utility-templates.html#initialize-instance.asciidoc_introduction","type":"docs","title":"Introduction","body":"66.1.1. Introduction\nProduction Line Templates allows you to create/configure certain task. In order to work properly, Production Line Templates needs some previous configurations. You can do it manually or executing the Initialize Instance Template.\n"},{"id":1145,"path":"../website/pages/docs/master-production-line.asciidoc_utility-templates.html#initialize-instance.asciidoc_prerequisites","type":"docs","title":"Prerequisites","body":"66.1.2. Prerequisites\nIn order to be able to start this template, you need:\nThe Production Line Shared Lib added in Jenkins\nThe following plugins:\nCustom Tools Plugin\nHTTP Request Plugin\nJob DSL Plugin\nSonarQube plugin\nPipeline Maven Plugin\nNodeJS Plugin\nA service account added in the LAM\nProduction Line provides by default the Shared Lib and the plugins, so no actions are required. The only thing that you need to do manually is the creation of the service account.\nIn order to create the service account you need:\nOpen the LAM\nPress the New User button\nEnter the required parameters\nChange to Unix tab and enter the required parameters\nThe user name will be used later in order to login. As this user will do some configuration changes, its primary group must be admins.\nSet a password for the user.\nPress the Save button\n"},{"id":1146,"path":"../website/pages/docs/master-production-line.asciidoc_utility-templates.html#initialize-instance.asciidoc_template","type":"docs","title":"Template","body":"66.1.3. Template\nIn order to execute this template, you need to add it into Jenkins manually. In order to do that, you can follow this guide\nParameters\nThe required parameters are:\nsvcaccount: The service account created as prerequisite. It must be added as a Jenkins credential.\ninstallDeploymentPlugins: With this parameter you can install extra plugins into Jenkins. Also, you can add extra template utils.\nExecution\nPress the Build with Parameters button\nInsert the parameters.\nIf the service account is not added as credential, please add a new entry.\nPress the Build button.\nWait until the pipeline ends.\nWarning\nif any plugin is installed, Jenkins will be restarted and the pipeline will fail. You need to execute it again with the same parameters.\nThe result\nInstall plugins stage\nIn this stage the following plugins will be installed:\nSSH Credentials Plugin\nCustom Tools Plugin\nHTTP Request Plugin\nJob DSL Plugin\nSonarQube plugin\nAnsible Plugin\nPipeline Maven Plugin\nNodeJS Plugin\nGitLab Plugin\nOWASP Dependency-Check Plugin\nIf installDeploymentPlugins is Docker or Docker+Openshift, extra plugins will be installed:\nDocker Plugin\nDocker build step plugin\nDocker Pipeline Plugin\nJClouds Plugin\nIf installDeploymentPlugins is Openshift or Docker+Openshift, extra plugins will be installed:\nOpenShift Client Plugin\nConfigure SonarQube stage\nThis stage is the responsible of configure the Jenkins-SonarQube integration. It will:\nGenerate a SonarQube API token for the user Admin\nRegister the token in Jenkins as credential with the id sonar-token\nAdd the SonarQube server in Jenkins &#x2192; Manage Jenkins &#x2192; Configure System &#x2192; SonarQube servers. The values used are:\nName: SonarQube\nServer URL: http://sonarqube-core:9000/sonarqube (default Production Line SonarQube URL)\nServer authentication token: sonar-token (generated in the previous step)\nAdd a webhook in SonarQube:\nName: jenkins\nURL: http://jenkins-core:8080/jenkins/sonarqube-webhook/\nInstall the following SonarQube plugins:\njava\njavascript\ntypescript\ncsharp\nweb\ncssfamily\njacoco\ncheckstyle\ncobertura\nsmells\nfindbugs\nscmgit\nansible\nsonar-dependency-check-plugin\nRestart the SonarQube server in order to enable the plugins installed.\nCreate UTIL templates stage\nSome templates needs that Jenkins has installed some plugins. If the plugins are not installed, the template will fail. In order to prevent this behaviour, we use the initialize-instance to install all plugins required in order templates. Then, we create another templates that will use the plugins installed by initialize-instance. In this stage we create some template utils to configure Jenkins after all required plugins are installed. Those templates are:\nInstall_SonarQube_Plugin\nIf installDeploymentPlugins is Docker or Docker+Openshift: Docker_Configuration\nIf installDeploymentPlugins is Openshift or Docker+Openshift: Openshift_Configuration\nConfigure Nexus 3 stage\nThis stage will configure the Production Line Nexus3\nEnable anonymous access\nAdd a internal user to download/upload docker images\nusername: nexus-api\npassword: The same as the service account created in LAM\nCreate the maven repositories: maven-central, maven-snapshots, maven-release, maven-plugin\nCreate the docker repository\nCreate the npmjs repositories: npmjs, npm-registry, npm\nCreate in Jenkins a new credential with the id nexus-api with the username and password created in nexus3\nConfigure Maven File stage\nThis stage adds the nexus3 credentials creadted in the previous stage to the maven global configuration file with the id pl-nexus\nNow, you are able to execute other templates adding them manually or using the Production Line Market Place.\n"},{"id":1147,"path":"../website/pages/docs/master-production-line.asciidoc_utility-templates.html#install-sonar-plugin.asciidoc","type":"docs","title":"Install SonarQube Plugin","body":"66.2. Install SonarQube Plugin\n"},{"id":1148,"path":"../website/pages/docs/master-production-line.asciidoc_utility-templates.html#install-sonar-plugin.asciidoc_introduction","type":"docs","title":"Introduction","body":"66.2.1. Introduction\nSonarQube can extends its behaviour by adding plugins. Some on them can be installed by using the SonarQube Marketplace, others can be installed by copying the .jar into the SonarQube plugins folder.\nOverview\nThis template will help you to install SonarQube plugins by copying the .jar into the SonarQube plugins folder. As you do not have access to the Production Line volumes, it will help you when you want to install a plugin that is not installed in the SonarQube Marketplace.\nIt will:\nDownload the .jar file from a provided URL.\nCopy the .jar file to the plugins folder.\nRestart the SonarQube server in order to enable the plugin.\nNote\nthis template only works in a Production Line instance.\n"},{"id":1149,"path":"../website/pages/docs/master-production-line.asciidoc_utility-templates.html#install-sonar-plugin.asciidoc_template","type":"docs","title":"Template","body":"66.2.2. Template\nThis template will be automatically created in your jenkins after executing the Initialize_Instance template inside the UTILS folder with the name Install_SonarQube_Plugin.\nFor manual creation see: How to add a Template\nImportant\nThis template needs the devonfw Production Line Shared Lib\nParameters\nThe only parameter required is the plugin download URL.\nExecution\nPress the Build with Parameters button\nInsert plugin the download url. Example: https://github.com/dependency-check/dependency-check-sonar-plugin/releases/download/1.2.6/sonar-dependency-check-plugin-1.2.6.jar\nPress the Build button.\nWait until the pipeline ends.\nAfter the execution, when the SonarQube is restarted, you can check that your plugin is installed visiting the Marketplace.\n"},{"id":1150,"path":"../website/pages/docs/master-production-line.asciidoc_utility-templates.html#docker-configuration.asciidoc","type":"docs","title":"Docker Configuration","body":"66.3. Docker Configuration\n"},{"id":1151,"path":"../website/pages/docs/master-production-line.asciidoc_utility-templates.html#docker-configuration.asciidoc_introduction","type":"docs","title":"Introduction","body":"66.3.1. Introduction\nDocker is the most popular container technology. It allows you to build your application in an image and then deploy it into a container.\nOverview\nThis template allow you to configure Jenkins in order to work with docker.\nIt will:\nAdd docker client as custom tool.\nConfigure docker to work with an external docker dameon.\n"},{"id":1152,"path":"../website/pages/docs/master-production-line.asciidoc_utility-templates.html#docker-configuration.asciidoc_prerequisites","type":"docs","title":"Prerequisites","body":"66.3.2. Prerequisites\nIn order to execute this template, you need the following plugins installed in your Jenkins:\nDocker Plugin\nDocker build step plugin\nDocker Pipeline\nJClouds Plugin\nImportant\nThe initialize instance template will install all plugins if you select &apos;Docker&apos; or &apos;Docker+Openshift&apos; in the installDeploymentPlugins parameter\n"},{"id":1153,"path":"../website/pages/docs/master-production-line.asciidoc_utility-templates.html#docker-configuration.asciidoc_template","type":"docs","title":"Template","body":"66.3.3. Template\nThis template will be automatically created in your jenkins after executing the Initialize_Instance template inside the UTILS folder with the name Docker_Configuration.\nFor manual creation see: How to add a Template\nImportant\nThis template needs the devonfw Production Line Shared Lib\nParameters\nThe only parameter required is remote docker daemon URL. Example: tcp://127.0.0.1:2367\nImportant\nYou need to expose the docker daemon manually in your machine. Here you can find how to do it\nWarning\nThis configuration requires that the docker daemon has no security. It&#x2019;s prepared for development environments, for production environments please add security to your docker daemon.\nExecution\nPress the Build with Parameters button\nInsert remote docker daemon URL.\nPress the Build button.\nWait until the pipeline ends.\nThen, you can see that the docker is configured and the remote docker daemon environment variable is set:\nThe environment variable is setted globally, if you want to use another remote docker daemon for a specific build, you can override the DOCKER_HOST environment variable in your job.\nIf the DOCKER_HOST is already setted globally, when you execute again this template the value will not be changed. You need to change the value manually at: Jenkins &#x2192; Manage Jenkins &#x2192; Configure System &#x2192; Global properties\n"},{"id":1154,"path":"../website/pages/docs/master-production-line.asciidoc_utility-templates.html#openshift-configuration.asciidoc","type":"docs","title":"Docker Configuration","body":"66.4. Docker Configuration\n"},{"id":1155,"path":"../website/pages/docs/master-production-line.asciidoc_utility-templates.html#openshift-configuration.asciidoc_introduction","type":"docs","title":"Introduction","body":"66.4.1. Introduction\nOpenShift is a docker container orchestrator built on top Kubernetes.\nOverview\nThis template allow you to configure Jenkins in order to work with OpenShift.\nIt will:\nAdd OpenShift client as custom tool.\nConfigure an OpenShift cluster to work with.\n"},{"id":1156,"path":"../website/pages/docs/master-production-line.asciidoc_utility-templates.html#openshift-configuration.asciidoc_prerequisites","type":"docs","title":"Prerequisites","body":"66.4.2. Prerequisites\nIn order to execute this template, you need the following plugins installed in your Jenkins:\nOpenShift Client Plugin\nNote\nThe initialize instance template will install all plugins if you select Openshift or Docker+Openshift in the installDeploymentPlugins parameter\n"},{"id":1157,"path":"../website/pages/docs/master-production-line.asciidoc_utility-templates.html#openshift-configuration.asciidoc_template","type":"docs","title":"Template","body":"66.4.3. Template\nThis template will be automatically created in your jenkins after executing the Initialize_Instance template inside the UTILS folder with the name Openshift_Configuration.\nFor manual creation see: How to add a Template\nImportant\nThis template needs the devonfw Production Line Shared Lib\nParameters\nThe required parameters are:\nocName: The name of the OpenShift connection. You can define multiple OpenShift connections by changing the name.\nocUrl: The OpenShift URL.\nocProject: The OpenShift Project.\nocToken: The OpenShift token. In order to have a long-term token, this token should be a service account token.\nExecution\nPress the Build with Parameters button\nInsert the parameters.\nIf the OpenShift token is not added as credential, please add a new entry.\nPress the Build button.\nWait until the pipeline ends.\nWarning\nIf a cluster already exists with the provided name, it will not modify anything.\nYou can add more clusters by executing the template again or in Jenkins &#x2192; Manage Jenkins &#x2192; Configure System\n&#x2190;&#xA0;Previous:&#xA0;devonfw Technologies Templates&#xA0;| &#x2191;&#xA0;Up:&#xA0;Production Line Templates&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;MrChecker&#xA0;&#x2192;\n"},{"id":1158,"path":"../website/pages/docs/master-release-notes.asciidoc.html#master-release-notes.asciidoc","type":"docs","title":"XVII. Release Notes","body":"XVII. Release Notes\ndevonfw Release notes 2021.04\ndevonfw Release notes 2020.12\ndevonfw Release notes 2020.08\ndevonfw Release notes 2020.04\ndevonfw Release notes 3.2 &#x201C;Homer&#x201D;\ndevonfw Release notes 3.1 &#x201C;Goku&#x201D;\ndevonfw Release notes 3.0 &#x201C;Fry&#x201D;\ndevonfw Release notes 2.4 &#x201C;EVE&#x201D;\ndevonfw Release notes 2.3 &quot;Dash&quot;\ndevonfw Release notes 2.2 &quot;Courage&quot;\nRelease notes devonfw 2.1.1 &quot;Balu&quot;\n&#x2190;&#xA0;Previous:&#xA0;OSS Compliance&#xA0;| &#x2191;&#xA0;Up:&#xA0;devonfw guide&#xA0;| Next:&#xA0;devonfw Release notes 2021.04&#xA0;&#x2192;\n"},{"id":1159,"path":"../website/pages/docs/master-solicitor.asciidoc.html#master-solicitor.asciidoc","type":"docs","title":"XV. Solicitor User Guide","body":"XV. Solicitor User Guide\nSPDX-License-Identifier: Apache-2.0\nIntroduction\nArchitecture\nUsage\nReading License Information with Readers\nWorking with Decision Tables\nStandard Business Rules\nReporting / Creating output documents\nResolving of License URLs\nFeature Deprecation\nAppendix A: Default Base Configuration\nAppendix B: Built in Default Properties\nAppendix C: Extending Solicitor\nAppendix D: Release Notes\n&#x2190;&#xA0;Previous:&#xA0;Settings&#xA0;| &#x2191;&#xA0;Up:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Introduction&#xA0;&#x2192;\n"},{"id":1160,"path":"../website/pages/docs/master-solicitor.asciidoc_architecture.html#master-solicitor.asciidoc_architecture","type":"docs","title":"Architecture","body":"98. Architecture\nThe following picture show a business oriented view of Solicitor.\nRaw data about the components and attached licenses within an application is gathered by scanning with technology and build chain specific tools. This happens outside Solicitor.\nThe import step reads this data and transforms it into a common technology independent internal format.\nIn the normalization step the license information is completed and unified.\nInformation not contained in the raw data is added.\nWhere possible the applicable licenses are expressed by SPDX-IDs.\nMany open source compontents are available via multi licensing models.\nWithin qualification the finally applicable licenses are selected.\nIn the legal assessment the compliance of applicable licenses will be checked based on generic rules defined in company wide policies and possibly project specific project specific extensions.\nDefining those rules is considered as &quot;legal advice&quot; and possibly needs to be done by lawyers which are authorized to do so.\nFor this step Solicitor only provides a framework / tool to support the process here but does not deliver any predefined rules.\nThe final export step produces documents based on the internal data model. This might be the list of licenses to be forwarded to the customer or a license compliance report. Data might also be fed into other systems.\nA more technical oriented view of Solicitor is given below.\nThere are three major technical components: The reader and writer components are performing import and export of data. The business logic - doing normalization, qualification and legal assessment is done by a rule engine. Rules are mainly defined via decision tables. Solicitor comes with a starting set of rules for normalization and qualification but these rulesets need to be extended within the projects. Rules for legal evaluation need to be completely defined by the user.\nSolicitor is working without additional persisted data: When being executed it generates the output direcly from the read input data after processing the business rules.\n"},{"id":1161,"path":"../website/pages/docs/master-solicitor.asciidoc_architecture.html#master-solicitor.asciidoc_data-model","type":"docs","title":"Data Model","body":"98.1. Data Model\nThe internal business data model consists of 6 entities:\nModelRoot: root object of the business data model which holds metadata about the data processing\nEngagement: the masterdata of the overall project\nApplication: a deliverable within the Engagement\nApplicationComponent: component within an Application\nRawLicense: License info attached to an ApplicationComponent as it is read from the input data\nNormalizedLicense: License info attached to an ApplicationComponent processed by the business rules\n"},{"id":1162,"path":"../website/pages/docs/master-solicitor.asciidoc_architecture.html#master-solicitor.asciidoc_modelroot","type":"docs","title":"ModelRoot","body":"98.1.1. ModelRoot\nProperty\nType\nDescription\nmodelVersion\nint\nversion number of the data model\nexecutionTime\nString\ntimestamp when the data was processed\nsolicitorVersion\nString\nSolicitor version which processed the model\nsolicitorGitHash\nString\nbuildnumber / GitHash of the Solicitor build\nsolicitorBuilddate\nString\nbuild date of the Solicitor build\nextensionArtifactId\nString\nartifactId of the active Solicitor Extension (&quot;NONE&quot; if no extension)\nextensionVersion\nString\nVersion of the active Extension (or &quot;NONE&quot;)\nextensionGitHash\nString\nBuildnumber / GitHash of the Extension (or &quot;NONE&quot;)\n"},{"id":1163,"path":"../website/pages/docs/master-solicitor.asciidoc_architecture.html#master-solicitor.asciidoc_engagement","type":"docs","title":"Engagement","body":"98.1.2. Engagement\nProperty\nType\nDescription\nengagementName\nString\nthe engagement name\nengagementType\nEngagementType\nthe engagement type; possible values: INTERN, EXTERN\nclientName\nString\nname of the client\ngoToMarketModel\nGoToMarketModel\nthe go-to-market-model; possible values: LICENSE\ncontractAllowsOss\nboolean\ndoes the contract explicitely allow OSS?\nossPolicyFollowed\nboolean\nis the companies OSS policy followed?\ncustomerProvidesOss\nboolean\ndoes the customer provide the OSS?\n"},{"id":1164,"path":"../website/pages/docs/master-solicitor.asciidoc_architecture.html#master-solicitor.asciidoc_application","type":"docs","title":"Application","body":"98.1.3. Application\nProperty\nType\nDescription\napplicationName\nString\nthe name of the application / deliverable\nreleaseId\nString\nversion identifier of the application\nreleaseDate\nSting\nrelease data of the application\nsourceRepo\nString\nURL of the source repo of the application (should be an URL)\nprogrammingEcosystem\nString\nprogramming ecosystem (e.g. Java8; Android/Java, iOS / Objective C)\n"},{"id":1165,"path":"../website/pages/docs/master-solicitor.asciidoc_architecture.html#master-solicitor.asciidoc_applicationcomponent","type":"docs","title":"ApplicationComponent","body":"98.1.4. ApplicationComponent\nProperty\nType\nDescription\nusagePattern\nUsagePattern\npossible values: DYNAMIC_LINKING, STATIC_LINKING, STANDALONE_PRODUCT\nossModified\nboolean\nis the OSS modified?\nossHomepage\nString\nURL of the OSS homepage\ngroupId\nString\ncomponent identifier: maven group\nartifactId\nString\ncomponent identifier: maven artifactId\nversion\nString\ncomponent identifier: Version\nrepoType\nString\ncomponent identifier: RepoType\n"},{"id":1166,"path":"../website/pages/docs/master-solicitor.asciidoc_architecture.html#master-solicitor.asciidoc_rawlicense","type":"docs","title":"RawLicense","body":"98.1.5. RawLicense\nProperty\nType\nDescription\ndeclaredLicense\nString\nname of the declared license\nlicenseUrl\nString\nURL of the declared license\ntrace\nString\ndetail info of history of this data record\nspecialHandling\nboolean\n(for controlling rule processing)\n"},{"id":1167,"path":"../website/pages/docs/master-solicitor.asciidoc_architecture.html#master-solicitor.asciidoc_normalizedlicense","type":"docs","title":"NormalizedLicense","body":"98.1.6. NormalizedLicense\nProperty\nType\nDescription\ndeclaredLicense\nString\nname of the declared license (copied from RawLicense)\nlicenseUrl\nString\nURL of the declared license (copied from RawLicense\ndeclaredLicenseContent\nString\nresolved content of licenseUrl\nnormalizedLicenseType\nString\ntype of the license, see License types\nnormalizedLicense\nString\nname of the license in normalized form (SPDX-Id) or special &quot;pseudo license id&quot;, see Pseudo License Ids\nnormalizedLicenseUrl\nString\nURL pointing to a normalized form of the license\nnormalizedLicenseType\nString\ntype of the license, see License types\neffectiveNormalizedLicenseType\nString\ntype of the effective license, see License types\neffectiveNormalizedLicense\nString\neffective normalized license (SPDX-Id) or &quot;pseudo license id&quot;; this is the information after selecting the right license in case of multi licensing or any license override due to a component being redistributed under a different license\neffectiveNormalizedLicenseUrl\nString\nURL pointing to the effective normalized license\neffectiveNormalizedLicenseContent\nString\nresolved content of effectiveNormalizedLicenseUrl\nlegalPreApproved\nString\nindicates whether the license is pre approved based on company standard policy\ncopyLeft\nString\nindicates the type of copyleft of the license\nlicenseCompliance\nString\nindicates if the license is compliant according to the default company policy\nlicenseRefUrl\nString\nURL to the reference license information (TBD)\nlicenseRefContent\nString\nresolved content of licenseRefUrl\nincludeLicense\nString\ndoes the license require to include the license text ?\nincludeSource\nString\ndoes the license require to deliver source code of OSS component ?\nreviewedForRelease\nString\nfor which release was the legal evaluation done?\ncomments\nString\ncomments on the component/license (mainly as input to legal)\nlegalApproved\nString\nindicates whether this usage is legally approved\nlegalComments\nString\ncomments from legal, possibly indicating additional conditions to be fulfilled\ntrace\nString\ndetail info of history of this data record (rule executions)\nFor the mechanism how Solicitor resolves the content of URLs and how the result\nmight be influenced see Resolving of License URLs\nLicense types\nDefines the type of license\nOSS-SPDX - An OSS license which has a corresponding SPDX-Id\nOSS-OTHER - An OSS license which has no SPDX-Id\nCOMMERCIAL - Commercial (non OSS) license; this might also include code which is owned by the project\nUNKNOWN- License is unknown\nIGNORED- license will be ignored (non selected license in multi licensing case; only to be used as &quot;Effective Normalized License Type&quot;)\nPseudo License Ids\nA &quot;normalized&quot; license id might be either a SPDX-Id or a &quot;pseudo license id&quot; which is used to indicate a specific situation. The following pseudo license ids are used:\nOSS specific - a nonstandard OSS license which could not be mapped to a SPDX-Id\nPublicDomain - any form of public domain which is not represented by an explicit SPDX-Id\nIgnored - license will be ignored (non selected license in multi licensing case; only to be used as &quot;Effective Normalized License&quot;)\nNonOSS - commercial license, not OSS\n&#x2190;&#xA0;Previous:&#xA0;Introduction&#xA0;| &#x2191;&#xA0;Up:&#xA0;Solicitor User Guide&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Usage&#xA0;&#x2192;\n"},{"id":1168,"path":"../website/pages/docs/master-solicitor.asciidoc_built-in-default-properties.html#master-solicitor.asciidoc_built-in-default-properties","type":"docs","title":"Appendix B: Built in Default Properties","body":"Appendix B: Built in Default Properties\nThe following lists the default settings of technical properties as given by the built in application.properties file.\nIf required these values might be overridden on the command line when starting Solicitor:\njava -Dpropertyname1=value1 -Dpropertyname2=value2 -jar solicitor.jar &lt;any other arguments&gt;\nListing 133. application.properties\nUnresolved directive in solicitor.wiki/master-solicitor.asciidoc - include::../src/main/resources/application.properties.asciidoc[]\n&#x2190;&#xA0;Previous:&#xA0;Default Base Configuration&#xA0;| &#x2191;&#xA0;Up:&#xA0;Solicitor User Guide&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Extending Solicitor&#xA0;&#x2192;\n"},{"id":1169,"path":"../website/pages/docs/master-solicitor.asciidoc_default-base-configuration.html#master-solicitor.asciidoc_default-base-configuration","type":"docs","title":"Appendix A: Default Base Configuration","body":"Appendix A: Default Base Configuration\nThe builtin default base configuration contains settings for the rules and writers section\nof the Solicitor configuration file which will be used if the project specific config file omits those sections.\nListing 132. Default Configuration\nUnresolved directive in solicitor.wiki/master-solicitor.asciidoc - include::../src/main/resources/com/devonfw/tools/solicitor/config/solicitor_base.cfg.asciidoc[lines=23..169]\n&#x2190;&#xA0;Previous:&#xA0;Feature Deprecation&#xA0;| &#x2191;&#xA0;Up:&#xA0;Solicitor User Guide&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Built in Default Properties&#xA0;&#x2192;\n"},{"id":1170,"path":"../website/pages/docs/master-solicitor.asciidoc_extending-solicitor.html#master-solicitor.asciidoc_extending-solicitor","type":"docs","title":"Appendix C: Extending Solicitor","body":"Appendix C: Extending Solicitor\nSolicitor comes with a sample rule data set and sample reporting templates. In general it will\nbe required to correct, supplement and extend this data sets and templates. This can be done straightforward\nby creating copies of the appropriate resources (rule data XLS and template files), adopting them and furtheron referencing those copies instead of the original resources from the project configuration file.\nEven though this approach is possible it will result in hard to maintain configurations,\nespecially in the case of multiple projects using Solicitor in parallel.\nTo support such scenarios Solicitor provides an easy extension mechanism which allows\nto package all those customized configurations into a single archive and reference it from the\ncommand line when starting Solicitor.\nThis facilitates configuration management, distribution and deployment of such extensions.\n"},{"id":1171,"path":"../website/pages/docs/master-solicitor.asciidoc_extending-solicitor.html#master-solicitor.asciidoc_format-of-the-extension-file","type":"docs","title":"C.1. Format of the extension file","body":"C.1. Format of the extension file\nThe extensions might be provided as JAR file or even as a simple ZIP file. There is only\none mandatory file which contains (at least metadata) about the extension and which needs\nto be included in this archive in the root folder.\nListing 134. application-extension.properties\nUnresolved directive in solicitor.wiki/master-solicitor.asciidoc - include::../src/main/resources/samples/application-extension.properties.asciidoc[]\nThis file is included via the standard Spring Boot profile mechanism. Besides containing\nnaming and version info on the extension this file might override any\nproperty values defined within Solicitor.\nAny other resources (like rule data or templates) which need to be part of the Extension\ncan be included in the archive as well - either in the root directory or any subdirectories.\nIf the extension is active those resources will be available on the classpath like any\nresources included in the Solicitor jar.\nOverriding / redefining the default base configuration within the Extension enables to\nupdate all rule data and templates without the need to touch the projects configuration\nfile.\n"},{"id":1172,"path":"../website/pages/docs/master-solicitor.asciidoc_extending-solicitor.html#master-solicitor.asciidoc_activating-the-extension","type":"docs","title":"C.2. Activating the Extension","body":"C.2. Activating the Extension\nThe Extension will be activated by referencing it as follows when starting Solicitor:\njava -Dloader.path=path/to/the/extension.zip -jar solicitor.jar &lt;any other arguments&gt;\n&#x2190;&#xA0;Previous:&#xA0;Built in Default Properties&#xA0;| &#x2191;&#xA0;Up:&#xA0;Solicitor User Guide&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Release Notes&#xA0;&#x2192;\n"},{"id":1173,"path":"../website/pages/docs/master-solicitor.asciidoc_feature-deprecation.html#master-solicitor.asciidoc_feature-deprecation","type":"docs","title":"Feature Deprecation","body":"105. Feature Deprecation\nWithin the lifecycle of the Solicitor development features might be discontinued due\nto various reasons. In case that such discontinuation is expected to break existing projects\na two stage deprecation mechanism is used:\nStage 1: Usage of a deprecated feature will produce a warning only giving details on\nwhat needs to be changed.\nStage 2: When a deprecated feature is used Solicitor by default will terminate with an error\nmessage giving information about the deprecation.\nBy setting the property solicitor.deprecated-features-allowed to true\n(e.g. via the command line, see Configuration of Technical Properties), even in second stage\nthe feature will still be available and only a warning will be logged. The project setup should in any\ncase ASAP be changed to no longer use the feature as it might soon be removed without further\nnotice.\nImportant\nEnabling the use of deprecated feature via the above property should only be\na temporary workaround and not a standard setting.\nNote\nIf usage of a feature should be discontinued immediately (e.g. because it might lead to\nwrong/misleading output) the first stage of deprecation will be skipped.\n"},{"id":1174,"path":"../website/pages/docs/master-solicitor.asciidoc_feature-deprecation.html#master-solicitor.asciidoc_list-of-deprecated-features","type":"docs","title":"List of Deprecated Features","body":"105.1. List of Deprecated Features\nThe following features are deprecated via the above mechanism:\nReader of type &quot;gradle&quot; (use Reader of type &quot;gradle2&quot; instead); Stage 2 from Version 1.0.5 on; see https://github.com/devonfw/solicitor/issues/58\nReader of type &quot;npm&quot; (use type &quot;npm-license-crawler-csv&quot; instead); Stage 1 from Version 1.0.8 on; see https://github.com/devonfw/solicitor/issues/62\n&#x2190;&#xA0;Previous:&#xA0;Resolving of License URLs&#xA0;| &#x2191;&#xA0;Up:&#xA0;Solicitor User Guide&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Default Base Configuration&#xA0;&#x2192;\n"},{"id":1175,"path":"../website/pages/docs/master-solicitor.asciidoc_introduction.html#master-solicitor.asciidoc_introduction","type":"docs","title":"Introduction","body":"97. Introduction\nTodays software projects often make use of large amounts of Open Source software. Being\ncompliant with the license obligations of the used software components is a prerequisite for every such project. This results in different requirements that the project might need to fulfill. Those requirements can be grouped into two main categories:\nThings that need to be done to actually fulfill license obligations\nThings that need to be done to monitor / report fulfillment of license obligations\nMost of the above activities share common points:\nThe need to have an inventory of used (open source) components and their licenses\nSome rule based evaluation and reporting based on this inventory\nWhile working on these easy looking tasks, they might get complex due to various aspects:\nThe number of open source components might be quite large (&gt;&gt; 100 for a typical webapplication based on state of the art programming frameworks)\nAgile development and rapid changes of used components result in frequent changes of the inventory\nOpen Source usage scenarios and license obligations might be OK in one context (e.g. in the relation between a software developer and his client) but might be completely inacceptable in another context (e.g. when the client distributes the same software to end customers)\nLegal interpretation of license conditions often differ from organisation to organisation and result in different compliance rules to be respected.\nLicense information for components is often not available in a standardized form which would allow automatic processing\nTools for supporting the license management processes are often specific to a technology or build tool and do not support all aspects of OSS license management.\nOf course there are specific commercial tool suites which address the IP rights and license domain. But due to high complexity and license costs those tools are out of reach for most projects - at least for permanent use.\nSolicitor tries to address some of the issues hightlighted above. In its initial version it is a tool for programmatically executing a process which was originally defined as an Excel-supported manual process.\nWhen running Solicitor three subsequent processing steps are executed:\nCreating an initial component and license inventory based on technology specific input files\nRule based normalization and evaluation of licenses\nGeneration of output documents\nWarning\nSolicitor comes with a set of sample rules for the normalization and evaluation of licenses.\nEven though these included rules are not &quot;intentionally wrong&quot; they are only samples and you should never rely on these builtin rules without checking and possibly modifying their content and consulting your lawyer.\nSolicitor is a tool for technically supporting the management of OSS licenses within your project.\nSolicitor neither gives legal advice nor is a replacement for a lawyer.\n"},{"id":1176,"path":"../website/pages/docs/master-solicitor.asciidoc_introduction.html#master-solicitor.asciidoc_licensing-of-solicitor","type":"docs","title":"Licensing of Solicitor","body":"97.1. Licensing of Solicitor\nThe Solicitor code and accompanying resources (including this userguide) as stored in the GIT Repository https://github.com/devonfw/solicitor are licensed as Open Source under Apache 2 license (https://www.apache.org/licenses/LICENSE-2.0).\nImportant\nSpecifically observe the &quot;Disclaimer of Warranty&quot; and &quot;Limitation of Liability&quot; which are part of the license.\nImportant\nThe executable JAR file which is created by the Maven based build process includes numerous other Open Source components which are subject to different Open Source licenses. Any distribution of the Solicitor executable JAR file needs to comply with the license conditions of all those components.\nIf you are running Solicitor from the executable JAR you might use the -eug option to store detailed license information as file solicitor_licenseinfo.html in your current working directory (together with a copy of this user guide).\n&#x2191;&#xA0;Up:&#xA0;Solicitor User Guide&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Architecture&#xA0;&#x2192;\n"},{"id":1177,"path":"../website/pages/docs/master-solicitor.asciidoc_reading-license-information-with-readers.html#master-solicitor.asciidoc_reading-license-information-with-readers","type":"docs","title":"Reading License Information with Readers","body":"100. Reading License Information with Readers\nDifferent Readers are available to import raw component / license information for different\ntechnologies. This chapter describes how to setup the different build / dependency management systems to create the required input and how to configure the corresponding reader.\n"},{"id":1178,"path":"../website/pages/docs/master-solicitor.asciidoc_reading-license-information-with-readers.html#master-solicitor.asciidoc_maven","type":"docs","title":"Maven","body":"100.1. Maven\nFor the export of the licenses from a maven based project the license-maven-plugin is used, which can directly be called without the need to change anything in the pom.xml.\nTo generate the input file required for Solicitor the License Plugin needs to be executed with the following command:\nmvn org.codehaus.mojo:license-maven-plugin:1.14:aggregate-download-licenses -Dlicense.excludedScopes=test,provided\nThe generated output file named licenses.xml (in the directory specified in the\nplugin config) should look like the following:\nUnresolved directive in solicitor.wiki/master-solicitor.asciidoc - include::licenses.xml.asciidoc[]\nIn Solicitor the data is read with the following reader config:\n&quot;readers&quot; : [ {\n&quot;type&quot; : &quot;maven&quot;,\n&quot;source&quot; : &quot;file:target/generated-resouces/licenses.xml&quot;,\n&quot;usagePattern&quot; : &quot;DYNAMIC_LINKING&quot;\n} ]\n(the above assumes that Solicitor is executed in the maven projects main directory)\n"},{"id":1179,"path":"../website/pages/docs/master-solicitor.asciidoc_reading-license-information-with-readers.html#master-solicitor.asciidoc_csv","type":"docs","title":"CSV","body":"100.2. CSV\nThe CSV input is normally manually generated and should look like this (The csv File is &quot;;&quot; separated):\nUnresolved directive in solicitor.wiki/master-solicitor.asciidoc - include::csvlicenses.csv.asciidoc[]\nIn Solicitor the data is read with the following part of the config\n&quot;readers&quot; : [ {\n&quot;type&quot; : &quot;csv&quot;,\n&quot;source&quot; : &quot;file:path/to/the/file.csv&quot;,\n&quot;usagePattern&quot; : &quot;DYNAMIC_LINKING&quot;\n} ]\nThe following 5 columns need to be contained:\ngroupId\nartifactId\nversion\nlicense name\nlicense URL\nIn case that a component has multiple licenses attached, there needs to be a separate\nline in the file for each license.\n"},{"id":1180,"path":"../website/pages/docs/master-solicitor.asciidoc_reading-license-information-with-readers.html#master-solicitor.asciidoc_npm","type":"docs","title":"NPM","body":"100.3. NPM\nFor NPM based projects either the NPM License Crawler (https://www.npmjs.com/package/npm-license-crawler) or the NPM License Checker (https://www.npmjs.com/package/license-checker) might be used. The NPM License Crawler can process several node packages in one run.\n"},{"id":1181,"path":"../website/pages/docs/master-solicitor.asciidoc_reading-license-information-with-readers.html#master-solicitor.asciidoc_npm-license-crawler","type":"docs","title":"NPM License Crawler","body":"100.3.1. NPM License Crawler\nTo install the NPM License Crawler the following command needs to be executed.\nnpm i npm-license-crawler -g\nTo get the licenses, the crawler needs to be executed like the following example\nnpm-license-crawler --dependencies --csv licenses.csv\nThe export should look like the following (The csv file is &quot;,&quot; separated)\nUnresolved directive in solicitor.wiki/master-solicitor.asciidoc - include::licenses.csv.asciidoc[]\nSource: https://www.npmjs.com/package/npm-license-crawler\nIn Solicitor the data is read with the following part of the config\n&quot;readers&quot; : [ {\n&quot;type&quot; : &quot;npm-license-crawler-csv&quot;,\n&quot;source&quot; : &quot;file:path/to/licenses.csv&quot;,\n&quot;usagePattern&quot; : &quot;DYNAMIC_LINKING&quot;,\n&quot;repoType&quot; : &quot;npm&quot;\n} ]\n"},{"id":1182,"path":"../website/pages/docs/master-solicitor.asciidoc_reading-license-information-with-readers.html#master-solicitor.asciidoc_npm-license-checker","type":"docs","title":"NPM License Checker","body":"100.3.2. NPM License Checker\nTo install the NPM License Checker the following command needs to be executed.\nnpm i license-checker -g\nTo get the licenses, the checker needs to be executed like the following example (we require JSON output here)\nlicense-checker --json &gt; /path/to/licenses.json\nThe export should look like the following\nUnresolved directive in solicitor.wiki/master-solicitor.asciidoc - include::licensesNpmLicenseChecker.json.asciidoc[]\nSource: https://www.npmjs.com/package/license-checker\nIn Solicitor the data is read with the following part of the config\n&quot;readers&quot; : [ {\n&quot;type&quot; : &quot;npm-license-checker&quot;,\n&quot;source&quot; : &quot;file:path/to/licenses.json&quot;,\n&quot;usagePattern&quot; : &quot;DYNAMIC_LINKING&quot;,\n&quot;repoType&quot; : &quot;npm&quot;\n} ]\n"},{"id":1183,"path":"../website/pages/docs/master-solicitor.asciidoc_reading-license-information-with-readers.html#master-solicitor.asciidoc_gradle-windows","type":"docs","title":"Gradle (Windows)","body":"100.4. Gradle (Windows)\nFor the export of the licenses from a Gradle based project the Gradle License Plugin is used.\nTo install the plugin some changes need to be done in build.gradle, like following example\nbuildscript {\nrepositories {\nmaven { url &apos;https://oss.jfrog.org/artifactory/oss-snapshot-local/&apos; }\n}\ndependencies {\nclasspath &apos;com.jaredsburrows:gradle-license-plugin:0.8.5-SNAPSHOT&apos;\n}\n}\napply plugin: &apos;java-library&apos;\napply plugin: &apos;com.jaredsburrows.license&apos;\nAfterwards execute the following command in the console:\nFor Windows (Java Application)\ngradlew licenseReport\nThe Export should look like this:\nUnresolved directive in solicitor.wiki/master-solicitor.asciidoc - include::licenses.json.asciidoc[]\nSource: https://github.com/jaredsburrows/gradle-license-plugin\nIn Solicitor the data is read with the following part of the config\n&quot;readers&quot; : [ {\n&quot;type&quot; : &quot;gradle2&quot;,\n&quot;source&quot; : &quot;file:path/to/licenses.json&quot;,\n&quot;usagePattern&quot; : &quot;DYNAMIC_LINKING&quot;\n} ]\nNote\nThe former reader of type gradle is deprecated and should no longer be used. See List of Deprecated Features.\n"},{"id":1184,"path":"../website/pages/docs/master-solicitor.asciidoc_reading-license-information-with-readers.html#master-solicitor.asciidoc_gradle-android","type":"docs","title":"Gradle (Android)","body":"100.5. Gradle (Android)\nFor the Export of the the Licenses from a Gradle based Android Projects the Gradle License Plugin is used.\nTo install the Plugin some changes need to be done in the build.gradle of the Project, like following example\nbuildscript {\nrepositories {\njcenter()\n}\ndependencies {\nclasspath &apos;com.jaredsburrows:gradle-license-plugin:0.8.5&apos;\n}\n}\nAlso there is a change in the build.gradle of the App. Add the line in the second line\napply plugin: &apos;com.android.application&apos;\nAfterwards execute the following command in the Terminal of Android studio:\nFor Windows(Android Application)\ngradlew licenseDebugReport\nThe Export is in the following folder\n$Projectfolder\\app\\build\\reports\\licenses\nIt should look like this:\nUnresolved directive in solicitor.wiki/master-solicitor.asciidoc - include::licenseDebugReport.json.asciidoc[]\nSource: https://github.com/jaredsburrows/gradle-license-plugin\nIn Solicitor the Data is read with the following part of the config\n&quot;readers&quot; : [ {\n&quot;type&quot; : &quot;gradle2&quot;,\n&quot;source&quot; : &quot;file:$/input/licenses.json&quot;,\n&quot;usagePattern&quot; : &quot;DYNAMIC_LINKING&quot;\n} ]\nNote\nThe former reader of type gradle is deprecated and should no longer be used. See List of Deprecated Features.\n&#x2190;&#xA0;Previous:&#xA0;Usage&#xA0;| &#x2191;&#xA0;Up:&#xA0;Solicitor User Guide&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Working with Decision Tables&#xA0;&#x2192;\n"},{"id":1185,"path":"../website/pages/docs/master-solicitor.asciidoc_release-notes.html#master-solicitor.asciidoc_release-notes","type":"docs","title":"Appendix D: Release Notes","body":"Appendix D: Release Notes\nChanges in 1.3.0\nChanges in 1.2.0\nAdded some license name mapping rules in LicenseNameMappingSample.xls\nhttps://github.com/devonfw/solicitor/issues/71:\nNew &quot;Quality Report&quot; which might be helpful in validating the outcome of the Solicitor run.\nCurrently this report contains a list of all application components which have more than one effective license attached.\nThis might be helpful for spotting cases where appropriate rules for selecting the applicable license in case of dual-/multilicensing is missing.\nChanges in 1.1.1\nCorrected order of license name mapping which prevented Unlicense, The W3C License, WTFPL, Zlib and\nZope Public License 2.1 to be mapped.\nChanges in 1.1.0\nhttps://github.com/devonfw/solicitor/issues/67: Inclusion of detailed license information for the\ndependencies included in the executable JAR. Use the &apos;-eug&apos; command line option to store this file\n(together with a copy of the user guide) in the current work directory.\nAdditional rules for license name mappings in decision table LicenseNameMappingSample.xls.\nhttps://github.com/devonfw/solicitor/pull/61: Solicitor can now run with Java 8 or Java 11.\nChanges in 1.0.8\nhttps://github.com/devonfw/solicitor/issues/62: New Reader of type npm-license-checker\nfor reading component/license data collected by NPM License Checker (https://www.npmjs.com/package/license-checker).\nThe type of the existing Reader for reading CSV data from the NPM License Crawler has been changed from npm\nto npm-license-crawler-csv. (npm is still available but deprecated.) Projects should adopt their Reader\nconfiguration and replace type npm by npm-license-crawler-csv.\nChanges in 1.0.7\nhttps://github.com/devonfw/solicitor/issues/56: Enable continuing analysis in\nmultiapplication projects even is some license files are unavailable.\nDescribed simplified usage of license-maven-plugin without need to change pom.xml. (Documentation only)\nEnsure consistent sorting even in case that multiple &quot;Ignored&quot; licenses exist for a component\n&#x2190;&#xA0;Previous:&#xA0;Extending Solicitor&#xA0;| &#x2191;&#xA0;Up:&#xA0;Solicitor User Guide&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Contributing&#xA0;&#x2192;\n"},{"id":1186,"path":"../website/pages/docs/master-solicitor.asciidoc_reporting--creating-output-documents.html#master-solicitor.asciidoc_reporting--creating-output-documents","type":"docs","title":"Reporting / Creating output documents","body":"103. Reporting / Creating output documents\nAfter applying the business rules the resulting data can can be used to create reports and\nother output documents.\nCreating such reports consists of three steps:\ntransform and filter the model data by using an embedded SQL database\ndetermining difference to previously stored model (optional)\nTemplate based reporting via\nVelocity templates (for textual output like e.g. HTML)\nExcel templates\n"},{"id":1187,"path":"../website/pages/docs/master-solicitor.asciidoc_reporting--creating-output-documents.html#master-solicitor.asciidoc_sql-transformation-and-filtering","type":"docs","title":"SQL transformation and filtering","body":"103.1. SQL transformation and filtering\n"},{"id":1188,"path":"../website/pages/docs/master-solicitor.asciidoc_reporting--creating-output-documents.html#master-solicitor.asciidoc_database-structure","type":"docs","title":"Database structure","body":"103.1.1. Database structure\nAfter the business rules have been processed (or a Solicitor data model has been loaded via\ncommand line option -l) the model data is stored in a dynamically created internal SQL database.\nFor each type of model object a separate table is created. The tablename is the name of model object type written in uppercase characters. (E.g. type NormalizedLicense stored in table NORMALIZEDLICENSE)\nAll properties of the model objects are stored as strings in fields named like the properties within the database table. Field names are case sensitive (see note below for handling this in SQL statements).\nAn additional primary key is defined for each table, named ID_&lt;TABLENAME&gt;.\nFor all model elements that belong to some parent in the object hierarchy (i.e. all objects except ModelRoot) a foreign key field is added named PARENT_&lt;TABLENAME&gt; which contains the unique key of the corresponding parent\n"},{"id":1189,"path":"../website/pages/docs/master-solicitor.asciidoc_reporting--creating-output-documents.html#master-solicitor.asciidoc_sql-queries-for-filtering-and-transformation","type":"docs","title":"SQL queries for filtering and transformation","body":"103.1.2. SQL queries for filtering and transformation\nEach Writer configuration (see Writers / Reporting) includes a section which references SQL select statements that are applied on the database data. The result of the SQL select statements is made accessible for the subsequent processing of the Writer via the dataTable name given in the configuration.\n"},{"id":1190,"path":"../website/pages/docs/master-solicitor.asciidoc_reporting--creating-output-documents.html#master-solicitor.asciidoc_postprocessing-of-data-selected-from-the-database-tables","type":"docs","title":"Postprocessing of data selected from the database tables","body":"103.1.3. Postprocessing of data selected from the database tables\nBefore the result of the SQL select statement is handed over to the Writer the following postprocessing\nis done:\na rowCount column is added to the result which gives the position of the entry in the result set (starting with 1).\nColumns named ID_&lt;TABLENAME&gt; are replaced with columns named OBJ_&lt;TABLENAME&gt;. The fields of those columns are filled with the corresponding original model objects (java objects).\nWarning\nThe result table column OBJ_&lt;TABLENAME&gt; gives access to the native Solicitor data model (java objects), e.g. in the Velocity writer. As this breaks the decoupling done via the SQL database using this feature is explicitely discouraged. It should only be used with high caution and in exceptional situations. The feature might be discontinued in future versions without prior notice.\n"},{"id":1191,"path":"../website/pages/docs/master-solicitor.asciidoc_reporting--creating-output-documents.html#master-solicitor.asciidoc_determining-difference-to-previously-stored-model","type":"docs","title":"Determining difference to previously stored model","body":"103.2. Determining difference to previously stored model\nWhen using the command line option -d Solicitor can determine difference information between two different data models (e.g. the difference between the licenses of the current release and a former release.) The difference is calculated on the result of the above described SQL statements:\nFirst the internal reporting database is created for the current data model and all defined SQL statements are executed\nThen the internal database is recreated for the &quot;old&quot; data model and all defined SQL stements are executed again\nFinally for each defined result table the difference between the current result and the &quot;old&quot; result\nis calculated\nTo correctly correlate corresponding rows of the two different versions of table data it is necessary to define explicit correlation keys for each table in the SQL select statement.\nIt is possible to define up to 10 correlation keys named CORR_KEY_X with X in the range from 0 to 9. CORR_KEY_0 has highest priority, CORR_KEY_9 has lowest priority.\nThe correlation algorithm will first try to match rows using CORR_KEY_0. It will then attempt to correlate unmatched rows using CORR_KEY_1 e.t.c.. Correlation will stop, when\nall correlations keys CORR_KEY_0 to CORR_KEY_9 have been processed OR\nthe required correlation key column does not exist in the SQL select result OR\nthere are no unmatched &quot;new&quot; rows OR\nthere are no unmatched &quot;old&quot; rows\nThe result of the correlation / difference calulation is stored in the reporting table data structure. For each row the status is accessible if\nThe row is &quot;new&quot; (did not exist in the old data)\nThe row is unchanged (no changes in the field values representing the properties of the Solicitor data model)\nThe row is changed (at least one field corresponding to the Solicitor data model changed)\nFor each field of &quot;changed&quot; or &quot;unchanged&quot; rows the following status is available:\nField is &quot;changed&quot;\nField is &quot;unchanged&quot;\nFor each field of such rows it is furtheron possible to access the new and the old field value.\n"},{"id":1192,"path":"../website/pages/docs/master-solicitor.asciidoc_reporting--creating-output-documents.html#master-solicitor.asciidoc_sample-sql-statement","type":"docs","title":"Sample SQL statement","body":"103.3. Sample SQL statement\nThe following shows a sample SQL statement showing some join over multiple tables and the use of\ncorrelations keys.\nUnresolved directive in solicitor.wiki/master-solicitor.asciidoc - include::../src/main/resources/com/devonfw/tools/solicitor/sql/allden_normalizedlicenses.sql.asciidoc[]\nNote\nAbove example also shows how the case sensitive column names have to be handled within the SQL\n"},{"id":1193,"path":"../website/pages/docs/master-solicitor.asciidoc_reporting--creating-output-documents.html#master-solicitor.asciidoc_writers","type":"docs","title":"Writers","body":"103.4. Writers\nThe above dscribed SQL processing is identical for all Writers. Writers only differ in the\nway how the output document is created based on a template and the reporting table data\nobtained by the SQL transformation.\n"},{"id":1194,"path":"../website/pages/docs/master-solicitor.asciidoc_reporting--creating-output-documents.html#master-solicitor.asciidoc_velocity-writer","type":"docs","title":"Velocity Writer","body":"103.4.1. Velocity Writer\nThe Velocity Writer uses the Apache Velocity Templating Engine\nto create text based reports. The reporting data tables created by the SQL transformation are\ndirectly put to the into Velocity Context.\nFor further information see the\nVelocity Documentation\nThe Solicitor JavaDoc (which also includes datails on how to access the diff information for rows and fields of reporting data tables)\nThe samples included in Solicitor\n"},{"id":1195,"path":"../website/pages/docs/master-solicitor.asciidoc_reporting--creating-output-documents.html#master-solicitor.asciidoc_excel-writer","type":"docs","title":"Excel Writer","body":"103.4.2. Excel Writer\nUsing Placeholders in Excel Spreadsheets\nWithin Excel spreadsheet templates there are two kinds of placeholders / markers possible, which control the processing:\nIterator Control\nThe templating logic searches within the XLSX workbook for fields containing the names of the\nreporting data tables as defined in the Writer configuration like e.g.:\n#ENGAGEMENT#\n#LICENSE#\nWhenever such a string is found in a cell this indicates that this row is a template row. For each entry in the respective resporting data table a copy of this row is created and the attribute replacement will be done with the data from that reporting table. (The pattern #&#x2026;&#x200B;# will be removed when copying.)\nAttribute replacement\nWithin each row which was copied in the previous step the templating logic searches for the string pattern $someAttributeName$ where someAttributeName corresponds to the column names of the reporting table. Any such occurence is replaced with the corresponding data value.\nRepresentation of Diff Information\nIn case that a difference processing (new vs. old model data) was done this will be represented\nas follows when using the XLS templating:\nFor rows that are &quot;new&quot; (so no corresponding old row available) an Excel note indicating that this row is new will be attached to the field that contained the #&#x2026;&#x200B;# placeholder.\nFields in non-new rows that have changed their value will be marked with an Excel note indicating the old value.\n&#x2190;&#xA0;Previous:&#xA0;Standard Business Rules&#xA0;| &#x2191;&#xA0;Up:&#xA0;Solicitor User Guide&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Resolving of License URLs&#xA0;&#x2192;\n"},{"id":1196,"path":"../website/pages/docs/master-solicitor.asciidoc_resolving-of-license-urls.html#master-solicitor.asciidoc_resolving-of-license-urls","type":"docs","title":"Resolving of License URLs","body":"104. Resolving of License URLs\nResolving of the content of license texts which are referenced by the URLs given in NormalizedLicense is done in the following way:\nIf the content is found as a resource in the classpath under licenses this will be taken. (The Solicitor application might include a set of often used license texts and thus it is not necessary to fetch those via the net.) If the classpath does not contain the content of the URL the next step is taken.\nIf the content is found as a file in subdirectory licenses of the current working directory this is taken. If no such file exists the content is fetched via the net. The result will be written to the file directory, so any content will only be fetched once. (The user might alter the files in that directory to change/correct its content.) A file of length zero indicates that no content could be fetched.\n"},{"id":1197,"path":"../website/pages/docs/master-solicitor.asciidoc_resolving-of-license-urls.html#master-solicitor.asciidoc_encoding-of-urls","type":"docs","title":"Encoding of URLs","body":"104.1. Encoding of URLs\nWhen creating the resource or filename for given URLs in the above steps the following encoding scheme will be applied to ensure that always a valid name can be created:\nAll &quot;non-word&quot; characters (i.e. characters outside the set [a-zA-Z_0-9]) are replaced by underscores (&#x201C;_&#x201D;).\n&#x2190;&#xA0;Previous:&#xA0;master-solicitor.asciidoc_reporting&amp;&#xA0;| &#x2191;&#xA0;Up:&#xA0;Solicitor User Guide&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Feature Deprecation&#xA0;&#x2192;\n"},{"id":1198,"path":"../website/pages/docs/master-solicitor.asciidoc_standard-business-rules.html#master-solicitor.asciidoc_standard-business-rules","type":"docs","title":"Standard Business Rules","body":"102. Standard Business Rules\nThe processing of business rules is organized in different phases. Each phase might consist of multiple decision tables to be processed in order.\n"},{"id":1199,"path":"../website/pages/docs/master-solicitor.asciidoc_standard-business-rules.html#master-solicitor.asciidoc_phase-1-determining-assigned-licenses","type":"docs","title":"Phase 1: Determining assigned Licenses","body":"102.1. Phase 1: Determining assigned Licenses\nIn this phase the license data imported via the readers is cleaned and normalized. At the end of this phase the internal data model should clearly represent all components and their assigned licenses in normalized form.\nThe phase itself consists of two decision tables / rule groups:\n"},{"id":1200,"path":"../website/pages/docs/master-solicitor.asciidoc_standard-business-rules.html#master-solicitor.asciidoc_decision-table-explicitely-setting-licenses","type":"docs","title":"Decision Table: Explicitely setting Licenses","body":"102.1.1. Decision Table: Explicitely setting Licenses\nWith this decision table is is possible to explicitely assign NormalizedLicenses to components. This will be used if the imported RawLicense data is either incomplete or incorrect. Items which have been processed by rules of this group will not be reprocessed by the next rule group.\nLHS conditions:\nEngagement.clientName\nEngagement.engagementName\nApplication.applicationName\nApplicationComponent.groupId [magic]\nApplicationCompomnent.artifactId [magic]\nApplicationComponent.version [magic]\nRawLicense.declaredLicense [magic]\nRawLicense.url [magic]\nRHS result:\nNormalizedLicense.normalizedLicenseType\nNormalizedLicense.normalizedLicense\nNormalizedLicense.normalizedLicenseUrl\nNormalizedLicense.comment\n[magic]: On these fields the Extended comparison syntax might be used\nAll RawLicenses which are in scope of fired rules will be marked so that they do not get reprocessed by the following decision table.\n"},{"id":1201,"path":"../website/pages/docs/master-solicitor.asciidoc_standard-business-rules.html#master-solicitor.asciidoc_decision-table-detecting-licenses-from-imported-data","type":"docs","title":"Decision Table: Detecting Licenses from Imported Data","body":"102.1.2. Decision Table: Detecting Licenses from Imported Data\nWith this decision table the license info from the RawLicense is mapped to the NormalizedLicense. This is based on the name and/or URL of the license as imported via the readers.\nLHS conditions:\nRawLicense.declaredLicense [magic]\nRawLicense.url [magic]\nRHS result:\nNormalizedLicense.normalizedLicenseType\nNormalizedLicense.normalizedLicense\n[magic]: On these fields the Extended comparison syntax might be used\n"},{"id":1202,"path":"../website/pages/docs/master-solicitor.asciidoc_standard-business-rules.html#master-solicitor.asciidoc_phase-2-selecting-applicable-licenses","type":"docs","title":"Phase 2: Selecting applicable Licenses","body":"102.2. Phase 2: Selecting applicable Licenses\nWithin this phase the actually applicable licenses will be selected for each component.\nThis phase consists of two decision tables.\n"},{"id":1203,"path":"../website/pages/docs/master-solicitor.asciidoc_standard-business-rules.html#master-solicitor.asciidoc_choosing-specific-license-in-case-of-multi-licensing","type":"docs","title":"Choosing specific License in case of Multi-Licensing","body":"102.2.1. Choosing specific License in case of Multi-Licensing\nThis group of rules has the speciality that it might match to a group of NormalizedLicenses associated to an ApplicationComponent. In case that multiple licenses are associated to an ApplicationComponent one of them might be selected as &quot;effective&quot; license and the others might be marked as Ignored.\nLHS conditions:\nApplicationComponent.groupId [magic]\nApplicationComponent.artifactId [magic]\nApplicationComponent.version [magic]\nNormalizedLicense.normalizedLicense (licenseToTake; mandatory)\nNormalizedLicense.normalizedLicense (licenseToIgnore1; mandatory)\nNormalizedLicense.normalizedLicense (licenseToIgnore2; optional)\nNormalizedLicense.normalizedLicense (licenseToIgnore3; optional)\nRHS result\nlicense matching &quot;licenseToTake&quot; will get this value assigned to effectiveNormalizedLicense\nlicenses matching &quot;licenseToIgnoreN&quot; will get IGNORED assigned to effectiveNormalizedLicenseType Ignored assigned to effectiveNormalizedLicense\n[magic]: On these fields the Extended comparison syntax might be used\nIt is important to note that the rules only match, if all licenses given in the conditions actually exist and are assigned to the same ApplicationComponent.\n"},{"id":1204,"path":"../website/pages/docs/master-solicitor.asciidoc_standard-business-rules.html#master-solicitor.asciidoc_selecting--overriding-applicable-license","type":"docs","title":"Selecting / Overriding applicable License","body":"102.2.2. Selecting / Overriding applicable License\nThe second decision table in this group is used to define the effectiveNormalizedLicense (if not already handled by the decision table before).\nLHS conditions:\nApplicationComponent.groupId [magic]\nApplicationComponent.artifactId [magic]\nApplicationComponent.version [magic]\nNormalizedLicense.normalizedLicenseType\nNormalizedLicense.normalizedLicense\nRHS result:\nNormalizedLicense.effectiveNormalizedLicenseType (if empty in the decision table then the value of normalizedLicenseType will be taken)\nNormalizedLicense.effectiveNormalizedLicense (if empty in the decision table then the value of normalizedLicense will be taken)\nNormalizedLicense.effectiveNormalizedLicenseUrl (if empty in the decision table then the value of normalizedLicenseUrl will be taken)\n[magic]: On these fields the Extended comparison syntax might be used\n"},{"id":1205,"path":"../website/pages/docs/master-solicitor.asciidoc_standard-business-rules.html#master-solicitor.asciidoc_phase-3-legal-evaluation","type":"docs","title":"Phase 3: Legal evaluation","body":"102.3. Phase 3: Legal evaluation\nThe third phase ist the legal evaluation of the licenses and the check, whether OSS usage is according to defined legal policies. Again this phase comprises two decision tables.\n"},{"id":1206,"path":"../website/pages/docs/master-solicitor.asciidoc_standard-business-rules.html#master-solicitor.asciidoc_pre-evaluation-based-on-common-rules","type":"docs","title":"Pre-Evaluation based on common rules","body":"102.3.1. Pre-Evaluation based on common rules\nWithin the pre evaluation the license info is checked against standard OSS usage policies. This roughly qualifies the usage and might already determine licenses which are OK in any case or which need to be further evaluated. Furtheron they qualify whether the license text or source code needs to be included in the distribution. The rules in this decision table are only based on the effectiveNormalizedLicense and do not consider any project, application of component information.\nLHS condition:\nNormalizedLicense.effectiveNormalizedLicenseType\nNormalizedLicense.effectiveNormalizedLicense\nRHS result:\nNormalizedLicense.legalPreApproved\nNormalizedLicense.copyLeft\nNormalizedLicense.licenseCompliance\nNormalizedLicense.licenseRefUrl\nNormalizedLicense.includeLicense\nNormalizedLicense.includeSource\n"},{"id":1207,"path":"../website/pages/docs/master-solicitor.asciidoc_standard-business-rules.html#master-solicitor.asciidoc_final-evaluation","type":"docs","title":"Final evaluation","body":"102.3.2. Final evaluation\nThe decision table for final legal evaluation defines all rules which are needed\nto create the result of the legal evaluation. Rules here might be general for all projects or even very specific to a project if the rule can not be applied to other projects.\nLHS condition:\nEngagement.clientName\nEngagement.engagementName\nEngagement.customerProvidesOss\nApplication.applicationName\nApplicationComponent.groupId [magic]\nApplicationComponent.artifactId [magic]\nApplicationComponent.version [magic]\nApplicationComponent.usagePattern\nApplicationComponent.ossModified\nNormalizedLicense.effectiveNormalizedLicenseType\nNormalizedLicense.effectiveNormalizedLicense\nRHS result:\nNormalizedLicense.legalApproved\nNormalizedLicense.legalComments\n[magic]: On these fields the Extended comparison syntax might be used\n"},{"id":1208,"path":"../website/pages/docs/master-solicitor.asciidoc_standard-business-rules.html#master-solicitor.asciidoc_amending-the-builtin-decision-tables-with-own-rules","type":"docs","title":"Amending the builtin decision tables with own rules","body":"102.4. Amending the builtin decision tables with own rules\nThe standard process as described before consists of 6 decision tables / rule\ngroups to be processed in sequence. When using the builtin default base configuration all those decision tables use the internal sample data / rules as contained in Solicitor.\nTo use your own rule data there are three approaches:\nInclude your own rules section in the project configuration file (so not inheriting from the builtin base configuration file) and reference your own decision tables there.\nCreate your own &quot;Solicitor Extension&quot; which might completely redefine/replace the buitin Solicitor setup including all decision tables and the base configuration file. See Extending Solicitor for details.\nMake use of the optional project specific decision tables which are defined in the default base configuration: For every builtin decision table there is an optional external decision table (expected in the filesystem) which will be checked for existence. If such external decision table exists it will be processed first - before processing the builtin decision table. Thus is it possible to amend / override the builtin rules by project specific rules. When you create the starter configuration of your project as described in Starting a new project, those project specific decision tables are automatically created.\n&#x2190;&#xA0;Previous:&#xA0;Working with Decision Tables&#xA0;| &#x2191;&#xA0;Up:&#xA0;Solicitor User Guide&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;master-solicitor.asciidoc_reporting&amp;&#xA0;&#x2192;\n"},{"id":1209,"path":"../website/pages/docs/master-solicitor.asciidoc_usage.html#master-solicitor.asciidoc_usage","type":"docs","title":"Usage","body":"99. Usage\n"},{"id":1210,"path":"../website/pages/docs/master-solicitor.asciidoc_usage.html#master-solicitor.asciidoc_executing-solicitor","type":"docs","title":"Executing Solicitor","body":"99.1. Executing Solicitor\nSolicitor is a standalone Java (Spring Boot) application. Prerequisite for running it is an existing Java 8 or 11 runtime environment. If you do not yet have a the Solicitor executable JAR (solicitor.jar) you need to build it as given on the project GitHub homepage https://github.com/devonfw/solicitor .\nSolicitor is executed with the following command:\njava -jar solicitor.jar -c &lt;configfile&gt;\nwhere &lt;configfile&gt; is to be replaced by the location of the Project Configuration File.\nTo get a first idea on what Solicitor does you might call\njava -jar solicitor.jar -c classpath:samples/solicitor_sample.cfg\nThis executes Solicitor with default configuration on it own list of internal components and produces sample output.\nTo get an overview of the available command line options use\njava -jar solicitor.jar -h\nAdressing of resources\nFor unique adressing of resources to be read (configuration files, input data, rule templates and decision tables) Solicitor makes use of the Spring ResourceLoader functionality, see https://docs.spring.io/spring-framework/docs/current/spring-framework-reference/core.html#resources-resourceloader . This allows to load from the classpath, the filesystem or even via http get.\nIf you want to reference a file in the filesystem you need to write it as follows: file:path/to/file.txt\nNote that this only applies to resources being read. Output files are adressed without that prefix.\n"},{"id":1211,"path":"../website/pages/docs/master-solicitor.asciidoc_usage.html#master-solicitor.asciidoc_project-configuration-file","type":"docs","title":"Project Configuration File","body":"99.2. Project Configuration File\nThe project configuration of Solicitor is done via a configuration file in\nJSON format. This configuration file defines the engagements and applications master data, configures the readers for importing component and license information, references the business rules to be applied and defines the exports to be done.\nThe config file has the following skeleton:\n{\n&quot;version&quot; : 1,\n&quot;comment&quot; : &quot;Sample Solicitor configuration file&quot;,\n&quot;engagementName&quot; : &quot;DevonFW&quot;, (1)\n.\n.\n.\n&quot;applications&quot; : [ ... ], (2)\n&quot;rules&quot; : [ ... ], (3)\n&quot;writers&quot; : [ ... ] (4)\n}\nThe leading data defines the engagement master data, see Header and Engagement Master Data\napplications defines the applications within the engagement and configures the readers to import the component/license information, see Applications\nrules references the rules to apply to the imported data, see Business Rules\nwriters configures how the processed data should be exported, see Writers / Reporting\nNote\nThe following section describes all sections of the Solicitor configuration file format. Often the configuration of writers and especially rules will be identical for projects. To facilitate the project specific configuration setup Solicitor internally provides a base configuration which contains reasonable defaults for the rules and writers section. If the project specific configuration file omits the rules and/or writers sections then the corresponding settings from the base configuration will be taken. For details see Default Base Configuration.\nWarning\nIf locations of files are specified within the configuration files as relative\npathnames then this is always evaluated relative to the current working directory (which\nmight differ from the location of the configuration file). If some file location\nshould be given relative to the location of the configuration file this might be done\nusing the special placeholder ${cfgdir} as described in the following.\n"},{"id":1212,"path":"../website/pages/docs/master-solicitor.asciidoc_usage.html#master-solicitor.asciidoc_placeholders-within-the-configuration-file","type":"docs","title":"Placeholders within the configuration file","body":"99.2.1. Placeholders within the configuration file\nWithin certain parts of the configuration file (path and filenames) special placeholders might be used to parameterize the configuration. These areas are explicitely marked in the following\ndescription.\nThese placeholders are available:\n${project} - A simplified project name (taking the engagement name,\nremoving all non-word characters and converting to lowercase).\n${cfgdir} - If the config file was loaded from the filesystem this denotes the directory where the config file resides, . otherwise. This can be used to reference locations relative to the location of the config file.\n"},{"id":1213,"path":"../website/pages/docs/master-solicitor.asciidoc_usage.html#master-solicitor.asciidoc_header-and-engagement-master-data","type":"docs","title":"Header and Engagement Master Data","body":"99.2.2. Header and Engagement Master Data\nThe leading section of the config file defines some metadata and the engagement master data.\n&quot;version&quot; : 1, (1)\n&quot;comment&quot; : &quot;Sample Solicitor configuration file&quot;, (2)\n&quot;engagementName&quot; : &quot;DevonFW&quot;, (3)\n&quot;engagementType&quot; : &quot;INTERN&quot;, (4)\n&quot;clientName&quot; : &quot;none&quot;, (5)\n&quot;goToMarketModel&quot; : &quot;LICENSE&quot;, (6)\n&quot;contractAllowsOss&quot; : true, (7)\n&quot;ossPolicyFollowed&quot; : true, (8)\n&quot;customerProvidesOss&quot; : false, (9)\nversion of the config file format (currently needs to be 1)\nis a free text comment (no further function at the moment)\nthe engagement name (any string)\nthe engagement type; possible values: INTERN, EXTERN\nname of the client (any string)\nthe go-to-market-model; possible values: LICENSE\ndoes the contract explicitely allow OSS? (boolean)\nis the companies OSS policy followed? (boolean)\ndoes the customer provide the OSS? (boolean)\n"},{"id":1214,"path":"../website/pages/docs/master-solicitor.asciidoc_usage.html#master-solicitor.asciidoc_applications","type":"docs","title":"Applications","body":"99.2.3. Applications\nWithin this section the different applications (=deliverables) of the engagement are defined. Furtheron for each application at least one reader needs to be defined which imports the component and license information.\n&quot;applications&quot; : [ {\n&quot;name&quot; : &quot;Devon4J&quot;, (1)\n&quot;releaseId&quot; : &quot;3.1.0-SNAPSHOT&quot;, (2)\n&quot;sourceRepo&quot; : &quot;https://github.com/devonfw/devon4j.git&quot;, (3)\n&quot;programmingEcosystem&quot; : &quot;Java8&quot;, (4)\n&quot;readers&quot; : [ { (5)\n&quot;type&quot; : &quot;maven&quot;, (6)\n&quot;source&quot; : &quot;classpath:samples/licenses_devon4j.xml&quot;, (7) (10)\n&quot;usagePattern&quot; : &quot;DYNAMIC_LINKING&quot;, (8)\n&quot;repoType&quot; : &quot;maven&quot; (9)\n} ]\n} ],\nThe name of the application / deliverable (any string)\nVersion identifier of the application (any string)\nURL of the source repo of the application (string; should be an URL)\nprogramming ecosystem (any string; e.g. Java8; Android/Java, iOS / Objective C)\nmultiple readers might be defined per application\nthe type of reader; for possible values see Reading License Information with Readers\nlocation of the source file to read (ResourceLoader-URL)\nusage pattern; possible values: DYNAMIC_LINKING, STATIC_LINKING, STANDALONE_PRODUCT\nrepoType: Repository to download the sources from: currently possible values: maven, npm; if omitted then &quot;maven&quot; will be taken as default\nplaceholder patterns might be used here\nThe different readers are described in chapter Reading License Information with Readers\n"},{"id":1215,"path":"../website/pages/docs/master-solicitor.asciidoc_usage.html#master-solicitor.asciidoc_business-rules","type":"docs","title":"Business Rules","body":"99.2.4. Business Rules\nBusiness rules are executed within a Drools rule engine. They are defined as a sequence of rule templates and corresponding XLS files which together represent decision tables.\n&quot;rules&quot; : [ {\n&quot;type&quot; : &quot;dt&quot;, (1)\n&quot;optional&quot; : false, (2)\n&quot;ruleSource&quot; : &quot;classpath:samples/LicenseAssignmentSample.xls&quot;, (3) (7)\n&quot;templateSource&quot; : &quot;classpath:com/.../rules/rule_templates/LicenseAssignment.drt&quot;, (4) (7)\n&quot;ruleGroup&quot; : &quot;LicenseAssignment&quot;, (5)\n&quot;description&quot; : &quot;setting license in case that no one was detected&quot; (6)\n},\n.\n.\n.\n,{\n&quot;type&quot; : &quot;dt&quot;,\n&quot;optional&quot; : false,\n&quot;ruleSource&quot; : &quot;classpath:samples/LegalEvaluationSample.xls&quot;,\n&quot;templateSource&quot; : &quot;classpath:com/.../rules/rule_templates/LegalEvaluation.drt&quot;,\n&quot;ruleGroup&quot; : &quot;LegalEvaluation&quot;,\n&quot;decription&quot; : &quot;final legal evaluation based on the rules defined by legal&quot;\n} ],\ntype of the rule; only possible value: dt which stands for &quot;decision table&quot;\nif set to true the processing of this group of rules will be skipped if the XLS with table\ndata (given by ruleSource) does not exist; if set to false a missing XLS table will result\nin program termination\nlocation of the tabular decision table data\nlocation of the drools rule template to be used to define the rules together with the decision table data\nid of the group of rules; used to reference it e.g. when doing logging\nsome textual description of the rule group\nplaceholder patterns might be used here\nWhen running, Solicitor will execute the rules of each rule group separately and in the order\ngiven by the configuration. Only if there are no more rules to fire in a group Solicitor will\nmove to the next rule group and start firing those rules.\nNormally a project will only customize (part of) the data of the decision tables and thus will only change the ruleSource and the data in the XLS. All other configuration (the different templates and processing order) is part of the Solicitor application itself and should not be changed by end users.\nSee Working with Decision Tables and Standard Business Rules for further information on the business rules.\n"},{"id":1216,"path":"../website/pages/docs/master-solicitor.asciidoc_usage.html#master-solicitor.asciidoc_writers--reporting","type":"docs","title":"Writers / Reporting","body":"99.2.5. Writers / Reporting\nThe writer configuration defines how the processed data will be exported and/or reported.\n&quot;writers&quot; : [ {\n&quot;type&quot; : &quot;xls&quot;, (1)\n&quot;templateSource&quot; : &quot;classpath:samples/Solicitor_Output_Template_Sample.xlsx&quot;, (2) (6)\n&quot;target&quot; : &quot;OSS-Inventory-DevonFW.xlsx&quot;, (3) (6)\n&quot;description&quot; : &quot;The XLS OSS-Inventory document&quot;, (4)\n&quot;dataTables&quot; : { (5)\n&quot;ENGAGEMENT&quot; : &quot;classpath:com/devonfw/tools/solicitor/sql/allden_engagements.sql&quot;,\n&quot;LICENSE&quot; : &quot;classpath:com/devonfw/tools/solicitor/sql/allden_normalizedlicenses.sql&quot;\n}\n} ]\ntype of writer to be selected; possible values: xls, velo\npath to the template to be used\nlocation of the output file\nsome textual description\nreference to SQL statements used to transform the internal data model to data tables used for reporting\nplaceholder patterns might be used here\nFor details on the writer configuration see Reporting / Creating output documents.\n"},{"id":1217,"path":"../website/pages/docs/master-solicitor.asciidoc_usage.html#master-solicitor.asciidoc_starting-a-new-project","type":"docs","title":"Starting a new project","body":"99.3. Starting a new project\nTo simplify setting up a new project Solicitor provides an option to create a project starter configuration in a given directory.\njava -jar solicitor.jar -wiz some/directory/path\nBesides the necessary configuration file this includes also empty XLS files for defining project\nspecific rules which amend the builtin rules. Furtheron a sample license.xml file is provided to\ndirectly enable execution of solicitor and check functionality.\nThis configuration then serves as starting point for project specific configuration.\n"},{"id":1218,"path":"../website/pages/docs/master-solicitor.asciidoc_usage.html#master-solicitor.asciidoc_exporting-the-builtin-configuration","type":"docs","title":"Exporting the Builtin Configuration","body":"99.4. Exporting the Builtin Configuration\nWhen working with Solicitor it might be necessary to get access to the builtin base configuration, e.g. for reviewing the builtin sample rules or using builtin reporting templates as starting point for the creation of own templates.\nThe command\njava -jar solicitor.jar -ec some/directory/path\nwill export all internal configuration to the given directory. This includes:\nThe base configuration file, which defines standard settings inherited by the Project Configuration File\nThe Drools Rule Templates\nThe builtin decision tables which are referenced in the base configuration, see Standard Business Rules\nThe SQL statements which are used for SQL transformation and filtering\nThe referenced templates for the Velocity Writer and Excel Writer\n"},{"id":1219,"path":"../website/pages/docs/master-solicitor.asciidoc_usage.html#master-solicitor.asciidoc_configuration-of-technical-properties","type":"docs","title":"Configuration of Technical Properties","body":"99.5. Configuration of Technical Properties\nBesides the project configuration done via the above described file there are a set of technical settings in Solicitor which are done via properties. Solicitor is implemented as a Spring Boot Application and makes use\nof the standard configuration mechanism provided by the Spring Boot Platform which provides several ways to define/override properties.\nThe default property values are given in Built in Default Properties.\nIn case that a property shall be overridden when executing Solicitor this can easiest be done via the command line when executing\nSolicitor:\njava -Dsome.property.name1=value -Dsome.property.name2=another_value -jar solicitor.jar &lt;any other arguments&gt;\n&#x2190;&#xA0;Previous:&#xA0;Architecture&#xA0;| &#x2191;&#xA0;Up:&#xA0;Solicitor User Guide&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Reading License Information with Readers&#xA0;&#x2192;\n"},{"id":1220,"path":"../website/pages/docs/master-solicitor.asciidoc_working-with-decision-tables.html#master-solicitor.asciidoc_working-with-decision-tables","type":"docs","title":"Working with Decision Tables","body":"101. Working with Decision Tables\nSolicitor uses the Drools rule engine to execute business rules. Business rules are\ndefined as &quot;extended&quot; decision tables. Each such decision table consists of two artifacts:\nA rule template file in specific drools template format\nAn Excel (XLSX) table which defines the decision table data\nWhen processing, Solicitor will internally use the rule template to create one or multiple rules for every record found in the Excel sheet. The following points are important here:\nRule templates:\nRule templates should be regarded as part of the Solicitor implementation and should not be changed on an engagement level.\nExcel decision table data\nThe Excel tables might be extended or changed on a per project level.\nThe rules defined by the tabular data will have decreasing &quot;salience&quot; (priority) from top to bottom\nIn general multiple rules defined within a table might fire for the same data to be processed; the definition of the rules within the rule template will normally ensure that once a rule from the decision table was processed no other rule from that table will be processed for the same data\nThe excel tables contain header information in the first row which is only there for documentation purposes; the first row is completely ignored when creating rules from the xls\nThe rows starting from the second row contain decision table data\nThe first &quot;empty&quot; row (which does not contain data in any of the defined columns) ends the decision table\nDecision tables might use multiple condition columns which define the data that a rule matches. Often such conditions are optional: If left free in the Excel table the condition will be omitted from the rule conditions. This allows to define very specific rules (which only fire on exact data patterns) or quite general rules which get activated on large groups of data. Defining general rules further down in the table (with lower salience/priority) ensures that more specific rules get fired earlier. This even allows to define a default rule at the end of the table which gets fired if no other rule could be applied.\nrule groups: Business rules are executed within groups. All rules resulting from a single decision table are assigned to the same rule group. The order of execution of the rule groups\nis defined by the sequence of declaration in the config file. Processing of the current group will\nbe finished when there are no more rules to fire in that group. Processing of the next group will then start. Rule groups which have been finished processing will not be resumed even if rules within that group might have been activated again due to changes of the facts.\n"},{"id":1221,"path":"../website/pages/docs/master-solicitor.asciidoc_working-with-decision-tables.html#master-solicitor.asciidoc_extended-comparison-syntax","type":"docs","title":"Extended comparison syntax","body":"101.1. Extended comparison syntax\nBy default any condtions given in the fields of decision tables are simple textual comparisons: The condition\nis true if the property of the model is identical to the given value in the XLS sheet.\nDepending on the configuration of the rule templates for some fields, an extended syntax might be available. For those fields the following syntax applies:\nIf the given value of the XLS field starts with the prefix NOT: then the outcome of the remaining condition is logically negated, i.e. this field condition is true if the rest of the condition is NOT fulfilled.\nA prefix of REGEX: indicates that the remainder of the field defines a Java Regular Expression. For the condition to become true the whole property needs to match the given regular expression.\nThe prefix RANGE: indicates that the remainder of the field defines\na Maven Version Range. Using this makes only sense on the artifact version property.\nIf no such prefix is detected, then the behavior is identical to the normal (verbatim) comparison logic\nFields which are subject to this extended syntax are marked explicitly in the following section.\n&#x2190;&#xA0;Previous:&#xA0;Reading License Information with Readers&#xA0;| &#x2191;&#xA0;Up:&#xA0;Solicitor User Guide&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Standard Business Rules&#xA0;&#x2192;\n"},{"id":1222,"path":"../website/pages/docs/oss-compliance.asciidoc.html#oss-compliance.asciidoc","type":"docs","title":"OSS Compliance","body":"108. OSS Compliance\nThis chapter helps you to gain transparency on OSS usage and reach OSS compliance in your project.\n"},{"id":1223,"path":"../website/pages/docs/oss-compliance.asciidoc.html#oss-compliance.asciidoc_preface","type":"docs","title":"Preface","body":"108.1. Preface\ndevonfw, as most Java software, makes strong use of Open Source Software (OSS). It is using about 150 OSS products on the server only and on the client even more. Using a platform like devonfw to develop your own custom solution requires handling contained OSS correctly, i.e acting OSS-compliant.\nPlease read the Open Source policy of your company first, e.g. the Capgemini OSS Policy which contains a short, comprehensive and well written explanation on relevant OSS-knowledge. Make sure you:\nunderstand the copyleft effect and its effect in commercial projects\nunderstand the 3 license categories: &quot;permissive&quot;, &quot;weak copyleft&quot; and &quot;strong copyleft&quot;\nknow prominent license types as e.g. &quot;Apache-2.0&quot; or GPL-3.0&quot; and what copyleft-category they are in\nare aware that some OSS offer dual/multi-licenses\nUnderstand that OSS libraries often come with sub-dependencies of other OSS carrying licenses themselves\nTo define sufficient OSS compliance measures, contact your IP officer or legal team as early as possible, especially if you develop software for clients.\n"},{"id":1224,"path":"../website/pages/docs/oss-compliance.asciidoc.html#oss-compliance.asciidoc_obligations-when-using-oss","type":"docs","title":"Obligations when using OSS","body":"108.2. Obligations when using OSS\nIf you create a custom solution containing OSS, this in legal sense is a &quot;derived&quot; work. If you distribute your derived work to your business client or any other legal entity in binary packaged form, the license obligations of contained OSS get into effect. Ignoring these leads to a license infringement which can create high damage.\nTo carefully handle these obligations you must:\nmaintain an OSS inventory (to gain transparency on OSS usage and used licenses)\ncheck license conformity depending on usage/distribution in a commercial scenario\ncheck license compatibility between used OSS-licenses\nfulfill obligations defined by the OSS-licenses\nObligations need to be checked per license. Frequent obligations are:\ndeliver the license terms of all used versions of the OSS licenses\nnot to change any copyright statements or warranty exclusions contained in the used OSS components\ndeliver the source code of the OSS components (e.g. on a data carrier)\nwhen modifying OSS, track any source code modification (including date and name of the employee/company)\ndisplay OSS license notice in a user frontend (if any)\nother obligations depending on individual license\n"},{"id":1225,"path":"../website/pages/docs/oss-compliance.asciidoc.html#oss-compliance.asciidoc_automate-oss-handling","type":"docs","title":"Automate OSS handling","body":"108.3. Automate OSS handling\nCarefully judging the OSS usage in your project is a MANUAL activity! However, collecting OSS information and fulfilling license obligations should be automated as much as possible. A prominent professional tool to automate OSS compliance is the commercial software &quot;Black Duck&quot;. Unfortunately it is rather expensive - either purchased or used as SaaS.\nThe most recommended lightweight tooling is a combination of Maven plugins. We will mainly use the Mojo Maven License Plugin.\n"},{"id":1226,"path":"../website/pages/docs/oss-compliance.asciidoc.html#oss-compliance.asciidoc_configure-the-mojo-maven-license-plugin","type":"docs","title":"Configure the Mojo Maven License Plugin","body":"108.4. Configure the Mojo Maven License Plugin\nYou can use it from command line but this will limit the ability to sustainably configure it (shown later).\nTherefore we add it permanently as a build-plugin to the project parent-pom like this (already contained in OASP-parent-pom):\n&lt;plugin&gt;\n&lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt;\n&lt;artifactId&gt;license-maven-plugin&lt;/artifactId&gt;\n&lt;version&gt;1.14&lt;/version&gt;\n&lt;configuration&gt;\n&lt;outputDirectory&gt;${project.build.directory}/generated-resources&lt;/outputDirectory&gt;\n&lt;sortArtifactByName&gt;true&lt;/sortArtifactByName&gt;\n&lt;includeTransitiveDependencies&gt;true&lt;/includeTransitiveDependencies&gt;\n&lt;!-- the &quot;missing file&quot; declares licenses for dependencies that could not be detected automatically --&gt;\n&lt;useMissingFile&gt;true&lt;/useMissingFile&gt;\n&lt;!-- find the &quot;missing files&quot; in all child-projects at the following location --&gt;\n&lt;missingFile&gt;src/license/THIRD-PARTY.properties&lt;/missingFile&gt;\n&lt;!-- if the &quot;missing files&quot; are not yet existing in child-projects they will be created automatically --&gt;\n&lt;failOnMissing&gt;false&lt;/failOnMissing&gt;\n&lt;overrideFile&gt;src/license/override-THIRD-PARTY.properties&lt;/overrideFile&gt;\n&lt;!-- harmonize different ways of writing license names --&gt;\n&lt;licenseMerges&gt;\n&lt;licenseMerge&gt;Apache-2.0|Apache 2.0&lt;/licenseMerge&gt;\n&lt;licenseMerge&gt;Apache-2.0|Apache License, Version 2.0&lt;/licenseMerge&gt;\n&lt;licenseMerge&gt;Apache-2.0|Apache Software License, Version 2.0&lt;/licenseMerge&gt;\n&lt;licenseMerge&gt;Apache-2.0|The Apache Software License, Version 2.0&lt;/licenseMerge&gt;\n&lt;/licenseMerges&gt;\n&lt;encoding&gt;utf-8&lt;/encoding&gt;\n&lt;/configuration&gt;\n&lt;/plugin&gt;\nIn the config above there are several settings that help to permanently improve the result of an automated OSS scan. We explain these now.\n"},{"id":1227,"path":"../website/pages/docs/oss-compliance.asciidoc.html#oss-compliance.asciidoc_declare-additional-licenses","type":"docs","title":"Declare additional licenses","body":"108.4.1. Declare additional licenses\nSometimes the licenses of used OSS cannot be resolved automatically. That is not the mistake of the maven-license-tool, but the mistake of the OSS author who didn&#x2019;t make the respective license-information properly available.\nDeclare additional licenses in a &quot;missing file&quot; within each maven-subproject: /src/license/THIRD-PARTY.properties.\n# Generated by org.codehaus.mojo.license.AddThirdPartyMojo\n#-------------------------------------------------------------------------------\n# Already used licenses in project :\n# - ASF 2.0\n# - Apache 2\n...\n#-------------------------------------------------------------------------------\n# Please fill the missing licenses for dependencies :\n...\ndom4j--dom4j--1.6.1=BSD 3-Clause\njavax.servlet--jstl--1.2=CDDL\n...\nIn case the use of &quot;missing files&quot; is activated, but the THIRD-PARTY.properties-file is not yet existing, the first run of an &quot;aggregate-add-third-party&quot; goal (see below) will fail. Luckily the license-plugin just helped us and created the properties-files automatically (in each maven-subproject) and prefilled it with:\na list of all detected licenses within the maven project\nall OSS libraries where a license could not be detected automatically.\nYou now need to fill in missing license information and rerun the plugin.\n"},{"id":1228,"path":"../website/pages/docs/oss-compliance.asciidoc.html#oss-compliance.asciidoc_redefine-wrongly-detected-licenses","type":"docs","title":"Redefine wrongly detected licenses","body":"108.4.2. Redefine wrongly detected licenses\nIn case automatically detected licenses proof to be wrong by closer investigation, this wrong detection can be overwritten. Add a configuration to declare alternative licenses within each maven-subproject: /src/license/override-THIRD-PARTY.properties\ncom.sun.mail--javax.mail--1.5.6=Common Development and Distribution License 1.1\nThis can be also be useful for OSS that provides a multi-license to make a decision which license to actually choose .\n"},{"id":1229,"path":"../website/pages/docs/oss-compliance.asciidoc.html#oss-compliance.asciidoc_merge-licenses","type":"docs","title":"Merge licenses","body":"108.4.3. Merge licenses\nYou will see that many prominent licenses come in all sorts of notations, e.g. Apache-2.0 as: &quot;Apache 2&quot; or &quot;ASL-2.0&quot; or &quot;The Apache License, Version 2.0&quot;. The Mojo Maven License Plugin allows to harmonize different forms of a license-naming like this:\n&lt;!-- harmonize different ways of writing license names --&gt;\n&lt;licenseMerges&gt;\n&lt;licenseMerge&gt;Apache-2.0|Apache 2.0&lt;/licenseMerge&gt;\n&lt;licenseMerge&gt;Apache-2.0|Apache License, Version 2.0&lt;/licenseMerge&gt;\n&lt;licenseMerge&gt;Apache-2.0|Apache Software License, Version 2.0&lt;/licenseMerge&gt;\n&lt;licenseMerge&gt;Apache-2.0|The Apache Software License, Version 2.0&lt;/licenseMerge&gt;\n&lt;/licenseMerges&gt;\nLicense-names will be harmonized in the OSS report to one common term. We propose to harmonize to short-license-IDs defined by the SPDX standard.\n"},{"id":1230,"path":"../website/pages/docs/oss-compliance.asciidoc.html#oss-compliance.asciidoc_retrieve-licenses-list","type":"docs","title":"Retrieve licenses list","body":"108.5. Retrieve licenses list\nFor a quick initial judgement of OSS license situation run the following maven command from command line:\n$ mvn license:license-list\nYou receive the summary list of all used OSS licenses on the cmd-out.\n"},{"id":1231,"path":"../website/pages/docs/oss-compliance.asciidoc.html#oss-compliance.asciidoc_create-an-oss-inventory","type":"docs","title":"Create an OSS inventory","body":"108.6. Create an OSS inventory\nTo create an OSS inventory means to report on the overall bill of material of used OSS and corresponding licenses.\nWithin the parent project, run the following maven goal from command line.\n$ mvn license:aggregate-download-licenses -Dlicense.excludedScopes=test,provided\nRunning the aggregate-download-licenses goal creates two results.\na license.xml that contains all used OSS dependencies (even sub-dependencies) with respective license information\nputs all used OSS-license-texts as html files into folder target/generated resources\nCarefully validate and judge the outcome of the license list. It is recommended to copy the license.xml to the project documentation and hand it over to your client. You may also import it into a spreadsheet to get a better overview.\n"},{"id":1232,"path":"../website/pages/docs/oss-compliance.asciidoc.html#oss-compliance.asciidoc_create-a-third-party-file","type":"docs","title":"Create a THIRD PARTY file","body":"108.7. Create a THIRD PARTY file\nWithin Java software it is a common practice to add a &quot;THIRD-PARTY&quot; text file to the distribution. Contained is a summary-list of all used OSS and respective licenses. This can also be achieved with the Mojo Maven License Plugin.\nWithin the parent project, run the following maven goal from command line.\n$ mvn license:aggregate-add-third-party -Dlicense.excludedScopes=test,provided\nFind the THIRD-PARTY.txt in the folder: target\\generated-resources. The goal aggregate-add-third-party also profits from configuration as outlined above.\n"},{"id":1233,"path":"../website/pages/docs/oss-compliance.asciidoc.html#oss-compliance.asciidoc_download-and-package-oss-sourcecode","type":"docs","title":"Download and package OSS SourceCode","body":"108.8. Download and package OSS SourceCode\nSome OSS licenses require handing over the OSS source code which is packaged with your custom software to the client the solution is distributed to. It is a good practice to hand over the source code of all used OSS to your client. Collecting all source code can be accomplished by another Maven plugin: Apache Maven Dependency Plugin.\nIt downloads all OSS Source Jars into the folder: \\target\\sources across the parent and all child maven projects.\nYou configure the plugin like this:\n&lt;plugin&gt;\n&lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\n&lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt;\n&lt;version&gt;3.0.2&lt;/version&gt;\n&lt;configuration&gt;\n&lt;classifier&gt;sources&lt;/classifier&gt;\n&lt;failOnMissingClassifierArtifact&gt;false&lt;/failOnMissingClassifierArtifact&gt;\n&lt;outputDirectory&gt;${project.build.directory}/sources&lt;/outputDirectory&gt;\n&lt;/configuration&gt;\n&lt;executions&gt;\n&lt;execution&gt;\n&lt;id&gt;src-dependencies&lt;/id&gt;\n&lt;phase&gt;package&lt;/phase&gt;\n&lt;goals&gt;\n&lt;!-- use unpack-dependencies instead if you want to explode the sources --&gt;\n&lt;goal&gt;copy-dependencies&lt;/goal&gt;\n&lt;/goals&gt;\n&lt;/execution&gt;\n&lt;/executions&gt;\n&lt;/plugin&gt;\nYou run the plugin from command line like this:\n$ mvn dependency:copy-dependencies -Dclassifier=sources\nThe plugin provides another goal that also unzips the jars, which is not recommended, since contents get mixed up.\nDeliver the OSS source jars to your client with the release of your custom solution. This has been done physically - e.g. on DVD.\n"},{"id":1234,"path":"../website/pages/docs/oss-compliance.asciidoc.html#oss-compliance.asciidoc_handle-oss-within-ci-process","type":"docs","title":"Handle OSS within CI-process","body":"108.9. Handle OSS within CI-process\nTo automate OSS handling in the regular build-process (which is not recommended to start with) you may declare the following executions and goals in your maven-configuration:\n&lt;plugin&gt;\n...\n&lt;executions&gt;\n&lt;execution&gt;\n&lt;id&gt;aggregate-add-third-party&lt;/id&gt;\n&lt;phase&gt;generate-resources&lt;/phase&gt;\n&lt;goals&gt;\n&lt;goal&gt;aggregate-add-third-party&lt;/goal&gt;\n&lt;/goals&gt;\n&lt;/execution&gt;\n&lt;execution&gt;\n&lt;id&gt;aggregate-download-licenses&lt;/id&gt;\n&lt;phase&gt;generate-resources&lt;/phase&gt;\n&lt;goals&gt;\n&lt;goal&gt;aggregate-download-licenses&lt;/goal&gt;\n&lt;/goals&gt;\n&lt;/execution&gt;\n&lt;/executions&gt;\n&lt;/plugin&gt;\nNote that the build may fail in case the OSS information was not complete. Check the build-output to understand and resolve the issue - like e.g. add missing license information in the &quot;missing file&quot;.\n&#x2190;&#xA0;Previous:&#xA0;Contributor Covenant Code of Conduct&#xA0;| &#x2191;&#xA0;Up:&#xA0;Contributing&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Release Notes&#xA0;&#x2192;\n"},{"id":1235,"path":"../website/pages/docs/release-notes-version-2.1.asciidoc.html#release-notes-version-2.1.asciidoc","type":"releasenote","title":"Release notes devonfw 2.1.1 &quot;Balu&quot;","body":"119. Release notes devonfw 2.1.1 &quot;Balu&quot;\n"},{"id":1236,"path":"../website/pages/docs/release-notes-version-2.1.asciidoc.html#release-notes-version-2.1.asciidoc_version-2.1.2-oasp4j-updates--some-new-features","type":"releasenote","title":"Version 2.1.2: OASP4J updates &amp; some new features","body":"119.1. Version 2.1.2: OASP4J updates &amp; some new features\nWe&#x2019;ve released the latest update release of devonfw in the Balu series: version 2.1.2. The next major release, code named Courage, will be released approximately the end of June. This current release contains the following items:\n"},{"id":1237,"path":"../website/pages/docs/release-notes-version-2.1.asciidoc.html#release-notes-version-2.1.asciidoc_oasp4j-2.3.0-release","type":"releasenote","title":"OASP4j 2.3.0 Release","body":"119.1.1. OASP4j 2.3.0 Release\nFriday the 12th of May 2017 OASP4J version 2.3.0 was released. Major features added are :\nDatabase Integration with PostGres, MSSQL Server, MariaDB\nAdded docs folder for gh pages and added oomph setups\nRefactored Code\nRefactored Test Infrastructure\nAdded Documentation on debugging tests\nAdded Two Batch Job tests in the restaurant sample\nBugfix: Fixed the error received when the Spring Boot Application from sample application that is created from maven archetype is launched\nBugfix: Fix for 404 error received when clicked on the link &apos;1. Table&apos; in index.html of the sample application created from maven archetype\nMore details on features added can be found at https://github.com/oasp/oasp4j/milestone/23?closed=1 .\nThe OASP4j wiki and other documents are updated for release 2.3.0.\n"},{"id":1238,"path":"../website/pages/docs/release-notes-version-2.1.asciidoc.html#release-notes-version-2.1.asciidoc_cobigen-enhancements","type":"releasenote","title":"CobiGen Enhancements","body":"119.1.2. CobiGen Enhancements\nPrevious versions of CobiGen are able to generate code for REST services only. Now it is possible to generate the code for SOAP services as well. There are two use cases available in CobiGen:\nSOAP without nested data\nSOAP nested data\nThe &quot;nested data&quot; use case is when there are 3 or more entities which are interrelated with each other. CobiGen will generate code which will return the nested data. Currently CobiGen services return ETO classes, CobiGen has been enhanced as to return CTO classes (ETO + relationship).\nApart from the SOAP code generation, the capability to express nested relationships have been added to the existing ReST code generator as well.\nSee: https://github.com/devonfw/devon-guide/wiki/cookbook-cobigen-advanced-use-cases-soap-and-nested-data\n"},{"id":1239,"path":"../website/pages/docs/release-notes-version-2.1.asciidoc.html#release-notes-version-2.1.asciidoc_micro-services-module-spring-cloudnetflix-oss","type":"releasenote","title":"Micro services module (Spring Cloud/Netflix OSS)","body":"119.1.3. Micro services module (Spring Cloud/Netflix OSS)\nTo make it easier for devonfw users to design and develop applications based on microservices, this release provides a series of archetypes and resources based on Spring Cloud Netflix to automate the creation and configuration of microservices.\nNew documentation ind de devonfw Guide contains all the details to start creating microservices with devonfw\n"},{"id":1240,"path":"../website/pages/docs/release-notes-version-2.1.asciidoc.html#release-notes-version-2.1.asciidoc_spring-integration-module","type":"releasenote","title":"Spring Integration Module","body":"119.1.4. Spring Integration Module\nBased on the Java Message Service (JMS) and Spring Integration, the devonfw Integration module provides a communication system (sender/subscriber) out-of-the-box with simple channels (only to send and read messages), request and reply channels (to send messages and responses) and request &amp; reply asynchronously channels. You can find more details about the implementation in the devonfw guide.\n"},{"id":1241,"path":"../website/pages/docs/release-notes-version-2.1.asciidoc.html#release-notes-version-2.1.asciidoc_websphere--wildfly-deployment-documentation","type":"releasenote","title":"WebSphere &amp; Wildfly deployment documentation","body":"119.1.5. WebSphere &amp; Wildfly deployment documentation\nThe new version of devonfw contains more elaborate and updated documentation about deployment on WebSpere and Wildfly.\n"},{"id":1242,"path":"../website/pages/docs/release-notes-version-2.1.asciidoc.html#release-notes-version-2.1.asciidoc_version-2.1.1-updates","type":"releasenote","title":"Version 2.1.1 Updates, fixes &amp; some new features","body":"119.2. Version 2.1.1 Updates, fixes &amp; some new features\n"},{"id":1243,"path":"../website/pages/docs/release-notes-version-2.1.asciidoc.html#release-notes-version-2.1.asciidoc_cobigen-code-generator-fixes","type":"releasenote","title":"CobiGen code-generator fixes","body":"119.2.1. CobiGen code-generator fixes\nThe CobiGen incremental code generator released in the previous version contained a regression which has now been fixed. Generating services in Batch mode whereby a package can be given as an input, using all Entities contained in that package, works again as expected.\nFor more information see: The CobiGen documentation and the corresponding change in the devonfw Guide\n"},{"id":1244,"path":"../website/pages/docs/release-notes-version-2.1.asciidoc.html#release-notes-version-2.1.asciidoc_devcon-enhancements","type":"releasenote","title":"Devcon enhancements","body":"119.2.2. Devcon enhancements\nIn this new release we have added devcon to the devonfw distribution itself so one can directly use devcon from the console.bat or ps-console.bat windows. It is therefore no longer necessary to independently install devcon. However, as devcon is useful outside of the devonfw distribution, this remains a viable option.\n"},{"id":1245,"path":"../website/pages/docs/release-notes-version-2.1.asciidoc.html#release-notes-version-2.1.asciidoc_devon4sencha","type":"releasenote","title":"Devon4Sencha","body":"119.2.3. Devon4Sencha\nin Devon4Sencha there are changes in the sample application. It now complies fully with the architecture which is known as &quot;universal app&quot;, so now it has screens custom tailored for desktop and mobile devices. All the basic logic remains the same for both versions. (The StarterTemplate is still only for creating a desktop app. This will be tackled in the next release.)\n"},{"id":1246,"path":"../website/pages/docs/release-notes-version-2.1.asciidoc.html#release-notes-version-2.1.asciidoc_new-winauth-modules","type":"releasenote","title":"New Winauth modules","body":"119.2.4. New Winauth modules\nThe original winauth module that, in previous Devon versions, implemented the Active Directory authentication and the Single Sign-on authentication now has been divided in two independent modules. The Active Directory authentication now is included in the new Winauth-ad module whereas the Single Sign-on implementation is included in a separate module called Winauth-sso.\nAlso some improvements have been added to Winauth-sso module to ease the way in which the module can be injected.\nFor more information about the update see: The Sencha docs within the devonfw Guide\n"},{"id":1247,"path":"../website/pages/docs/release-notes-version-2.1.asciidoc.html#release-notes-version-2.1.asciidoc_general-updates","type":"releasenote","title":"General updates","body":"119.2.5. General updates\nThere are a series of updates to the devonfw documentation, principally the devonfw Guide. Further more, from this release on, you can find the devonfw guide in the doc folder of the distribution.\nFurthermore, the OASP4J and devonfw source-code in the &quot;examples&quot; workspace, have been updated to the latest version.\n"},{"id":1248,"path":"../website/pages/docs/release-notes-version-2.1.asciidoc.html#release-notes-version-2.1.asciidoc_version-2.1-new-features","type":"releasenote","title":"Version 2.1 New features, improvements and updates","body":"119.3. Version 2.1 New features, improvements and updates\n"},{"id":1249,"path":"../website/pages/docs/release-notes-version-2.1.asciidoc.html#release-notes-version-2.1.asciidoc_introduction","type":"releasenote","title":"Introduction","body":"119.3.1. Introduction\nWe are proud to present the new release of devonfw, version &quot;2.1&quot; which we&#x2019;ve baptized &quot;Balu&quot;. A major focus for this release is developer productivity. So that explains the name, as Balu is not just big, friendly and cuddly but also was very happy to let Mowgli do the work for him.\n"},{"id":1250,"path":"../website/pages/docs/release-notes-version-2.1.asciidoc.html#release-notes-version-2.1.asciidoc_cobigen-code-generator-ui-code-generation-and-more","type":"releasenote","title":"Cobigen code-generator UI code generation and more","body":"119.3.2. Cobigen code-generator UI code generation and more\nThe Cobigen incremental code generator which is part of devonfw has been significantly improved. Based on a single data schema it can generate the JPA/Hibernate code for the whole service layer (from data-access code to web services) for all CRUD operations. When generating code, Cobigen is able to detect and leave untouched any code which developers have added manually.\nIn the new release it supports Spring Data for data access and it is now capable of generating the whole User Interface as well: data-grids and individual rows/records with support for filters, pagination etc. That is to say: Cobigen can now generate automatically all the code from the server-side database access layer all the way up to the UI &quot;screens&quot; in the web browser.\nCurrently we support Sencha Ext JS with support for Angular 2 coming soon. The code generated by Cobigen can be opened and used by Sencha Architect, the visual design tool, which enables the programmer to extend and enhance the generated UI non-programmatically. When Cobigen regenerates the code, even those additions are left intact. All these features combined allow for an iterative, incremental way of development which can be up to an order of an magnitude more productive than &quot;programming manual&quot;\nCobigen can now also be used for code-generation within the context of an engagement. It is easily extensible and the process of how to extend it for your own project is well documented. This becomes already worthwhile (&quot;delivers ROI&quot;) when having 5+ identical elements within the project.\nFor more information see: The Cobigen documentation and the corresponding changer in the devonfw Guide and\n"},{"id":1251,"path":"../website/pages/docs/release-notes-version-2.1.asciidoc.html#release-notes-version-2.1.asciidoc_angular-2","type":"releasenote","title":"Angular 2","body":"119.3.3. Angular 2\nWith the official release of Angular 2 and TypeScript 2, we&#x2019;re slowly but steadily moving to embrace these important new players in the web development scene. We keep supporting the Angular 1 based OASP4js framework and are planning a migration of this framework to Angular 2 in the near future. For &quot;Balu&quot; we&#x2019;ve have decided to integrate &quot;vanilla&quot; Angular 2.\nWe have migrated the Restaurant Sample application to serve as a, documented and supported, blueprint for Angular 2 applications. Furthermore, we support three &quot;kickstarter&quot; projects which help engagement getting started with Angular2 - either using Bootstrap or Google&#xB4;s Material Design - or, alternatively, Ionic 2 (the mobile framework on top of Angular 2). For more information see: Angular 2 Kickstarter and Ionic 2 Kickstarter\n"},{"id":1252,"path":"../website/pages/docs/release-notes-version-2.1.asciidoc.html#release-notes-version-2.1.asciidoc_oasp4j-2.2.0-release","type":"releasenote","title":"OASP4J 2.2.0 Release","body":"119.3.4. OASP4J 2.2.0 Release\nA new release of OASP4J, version 2.2.0, is included in this release of devonfw. This release mainly focuses on server side of oasp. i.e oasp4j.\nMajor features added are :\nUpgrade to Spring Boot 1.3.8.RELEASE\nUpgrade to Apache CXF 3.1.8\nDatabase Integration with Oracle 11g\nAdded Servlet for HTTP-Debugging\nRefactored code and improved JavaDoc\nBugfix: mvn spring-boot:run executes successfully for oasp4j application created using oasp4j template\nAdded subsystem tests of SalesmanagementRestService and several other tests\nAdded Tests to test java packages conformance to OASP conventions\nMore details on features added can be found at https://github.com/oasp/oasp4j/milestone/19?closed=1(here). The OASP4j wiki and other documents are updated for release 2.2.0.\n"},{"id":1253,"path":"../website/pages/docs/release-notes-version-2.1.asciidoc.html#release-notes-version-2.1.asciidoc_devon4sencha","type":"releasenote","title":"Devon4Sencha","body":"119.3.5. Devon4Sencha\nDevon4Sencha is an alternative view layer for web applications developed with devonfw. It is based on Sencha Ext JS. As it requires a license for commercial applications it is not provided as Open Source and is considered to be part of the IP of Capgemini.\nThese libraries provide support for creating SPA (Single Page Applications) with a very rich set of components for both desktop and mobile. In the new version we extend this functionality to support for &quot;Universal Apps&quot;, the Sencha specific term for true multi-device applications which make it possible to develop a single application for desktop, tablet as well as mobile devices. In the latest version Devon4Sencha has been upgraded to support Ext JS 6.2 and we now support the usage of Cobigen as well as Sencha Architect as extra option to improve developer productivity.\nFor more information about the update see: The Sencha docs within the devonfw Guide\n"},{"id":1254,"path":"../website/pages/docs/release-notes-version-2.1.asciidoc.html#release-notes-version-2.1.asciidoc_devcon-enhancements","type":"releasenote","title":"Devcon enhancements","body":"119.3.6. Devcon enhancements\nThe Devon Console, Devcon, is a cross-platform command line tool running on the JVM that provides many automated tasks around the full life-cycle of Devon applications, from installing the basic working environment and generating a new project, to running a test server and deploying an application to production. It can be used by the engagements to integrate with their proprietary tool chain.\nIn this new release we have added an optional graphical user interface (with integrated help) which makes using Devcon even easier to use. Another new feature is that it is now possible to easily extend it with commands just by adding your own or project specific Javascript files. This makes it an attractive option for project task automation. You can find more information in the Devcon Command Developers Guide\n"},{"id":1255,"path":"../website/pages/docs/release-notes-version-2.1.asciidoc.html#release-notes-version-2.1.asciidoc_ready-for-the-cloud","type":"releasenote","title":"Ready for the Cloud","body":"119.3.7. Ready for the Cloud\ndevonfw is in active use in the Cloud, with projects running on IBM Bluemix and on Amazon AWS. The focus is very much to keep Cloud-specific functionality decoupled from the devonfw core. The engagement can choose between - and easily configure the use of - either CloudFoundry or Spring Cloud (alternatively, you can run devonfw in Docker containers in the Cloud as well. See elsewhere in the release notes). For more information\nabout how to configure devonfw for use in the cloud see: devonfw on Docker and devonfw in IBM Bluemix\n"},{"id":1256,"path":"../website/pages/docs/release-notes-version-2.1.asciidoc.html#release-notes-version-2.1.asciidoc_spring-data","type":"releasenote","title":"Spring Data","body":"119.3.8. Spring Data\nThe java server stack within devonfw, OASP4J, is build on a very solid DDD architecture which uses JPA for its data access layer. We now offer integration of Spring Data as an alternative or to be used in conjunction with JPA. Spring Data offers significant advantages over JPA through its query mechanism which allows the developer to specify complex queries in an easy way. Overall working with Spring Data should be quite more productive compared with JPA for the average or junior developer. And extra advantage is that Spring Data also allows - and comes with support for - the usage of NoSQL databases like MongoDB, Cassandra, DynamoDB etc. THis becomes especially critical in the Cloud where NoSQL databases typically offer better scalability than relational databases.\nFor more information see: Integrating Spring Data in OASP4J\n"},{"id":1257,"path":"../website/pages/docs/release-notes-version-2.1.asciidoc.html#release-notes-version-2.1.asciidoc_videos-content-in-the-devonfw-guide","type":"releasenote","title":"Videos content in the devonfw Guide","body":"119.3.9. Videos content in the devonfw Guide\nThe devonfw Guide is the single, authoritative tutorial and reference (&quot;cookbook&quot;) for all things devonfw, targeted at the general developer working with the platform (there is another document for Architects). It is clear and concise but because of the large scope and wide reach of devonfw, it comes with a hefty 370+ pages. For the impatient - and sometimes images do indeed say more than words - we&#x2019;ve added 17 videos to the Guide which significantly speed up getting started with the diverse aspects of devonfw.\nFor more information see: Video releases on TeamForge\n"},{"id":1258,"path":"../website/pages/docs/release-notes-version-2.1.asciidoc.html#release-notes-version-2.1.asciidoc_containerisation-with-docker-and-the-production-line","type":"releasenote","title":"Containerisation with Docker and the Production Line","body":"119.3.10. Containerisation with Docker and the Production Line\nDocker (see: https://www.docker.com/) containers wrap a piece of software in a complete filesystem that contains everything needed to run: code, runtime, system tools, system libraries &#x2013; anything that can be installed on a server. Docker containers resemble virtual machines but are far more resource efficient. Because of this, Docker and related technologies like Kubernetes are taking the Enterprise and Cloud by storm. We have certified and documented the usage of devonfw on Docker so we can now firmly state that &quot;devonfw is Docker&quot; ready. All the more so as the iCSD Production Line is now supporting devonfw as well. The Production Line is a Docker based set of methods and tools that make possible to develop custom software to our customers on time and with the expected quality. By having first-class support for devonfw on the Production Line, iCSD has got an unified, integral solution which covers all the phases involved on the application development cycle from requirements to testing and hand-off to the client.\nSee: devonfw on Docker and devonfw on the Production Line\n"},{"id":1259,"path":"../website/pages/docs/release-notes-version-2.1.asciidoc.html#release-notes-version-2.1.asciidoc_eclipse-neon","type":"releasenote","title":"Eclipse Neon","body":"119.3.11. Eclipse Neon\ndevonfw comes with its own pre configured and enhanced Eclipse based IDE: the Open Source &quot;OASP IDE&quot; and &quot;devonfw Distr&quot; which falls under Capgemini IP. We&#x2019;ve updated both versions to the latest stable version of Eclipse, Neon. From Balu onwards we support the IDE on Linux as well and we offer downloadable versions for both Windows and Linux.\nSee: The Devon IDE\n"},{"id":1260,"path":"../website/pages/docs/release-notes-version-2.1.asciidoc.html#release-notes-version-2.1.asciidoc_default-java-8-with-java-7-compatibility","type":"releasenote","title":"Default Java 8 with Java 7 compatibility","body":"119.3.12. Default Java 8 with Java 7 compatibility\nFrom version 2.1. &quot;Balu&quot; onwards, devonfw is using by default Java 8 for both the tool-chain as well as the integrated development environments. However, both the framework as well as the IDE and tool-set remain fully backward compatible with Java 7. We have added documentation to help configuring aspects of the framework to use Java 7 or to upgrade existing projects to Java 8. See: Compatibility guide for Java7, Java8 and Tomcat7, Tomcat8\n"},{"id":1261,"path":"../website/pages/docs/release-notes-version-2.1.asciidoc.html#release-notes-version-2.1.asciidoc_full-linux-support","type":"releasenote","title":"Full Linux support","body":"119.3.13. Full Linux support\nIn order to fully support the move towards the Cloud, from version 2.1. &quot;Balu&quot; onwards, devonfw is fully supported on Linux. Linux is the de-facto standard for most Cloud providers. We currently only offer first-class support for Ubuntu 16.04 LTS onward but most aspects of devonfw should run without problems on other and older distributions as well.\n"},{"id":1262,"path":"../website/pages/docs/release-notes-version-2.1.asciidoc.html#release-notes-version-2.1.asciidoc_initial-atom-support","type":"releasenote","title":"Initial ATOM support","body":"119.3.14. Initial ATOM support\nAtom is a text editor that&#x2019;s modern, approachable, yet hackable to the core - a tool you can customize to do anything but also use productively without ever touching a config file. It is turning into a standard for modern web development. In devonfw 2.1 &quot;Balu&quot; we provide a script which installs automatically the most recent version of Atom in the devonfw distribution with a pre-configured set of essential plugins. See: OASP/devonfw Atom editor (&quot;IDE&quot;) settings &amp; packages\n"},{"id":1263,"path":"../website/pages/docs/release-notes-version-2.1.asciidoc.html#release-notes-version-2.1.asciidoc_database-support","type":"releasenote","title":"Database support","body":"119.3.15. Database support\nThrough JPA (and now Spring Data as well) devonfw supports many databases. In Balu we&#x2019;ve extended this support to prepared configuration, extensive documentations and supporting examples for all major &quot;Enterprise&quot; DB servers. So it becomes even easier for engagements to start using these standard database options. Currently we provide this extended support for Oracle, Microsoft SQL Server, MySQL and PostgreSQL.\nFor more information see: OASP Database Migration Guide\n"},{"id":1264,"path":"../website/pages/docs/release-notes-version-2.1.asciidoc.html#release-notes-version-2.1.asciidoc_file-upload-and-download","type":"releasenote","title":"File upload and download","body":"119.3.16. File upload and download\nFile up and download was supported in previous version of the framework, but as these operations are common but complex, we&#x2019;ve extended the base functionality and improved the available documentation so it becomes substantially easier to offer both File up- as well as download in devonfw based applications. See: devonfw Guide Cookbook: File Upload and Download\n"},{"id":1265,"path":"../website/pages/docs/release-notes-version-2.1.asciidoc.html#release-notes-version-2.1.asciidoc_internationalisation-i18n-improvements","type":"releasenote","title":"Internationalisation (I18N) improvements","body":"119.3.17. Internationalisation (I18N) improvements\nLikewise, existing basic Internationalisation (I18N) support has been significantly enhanced through an new devonfw module and extended to support Ext JS and Angular 2 apps as well. This means that both server as well as client side applications can be made easily to support multiple languages (&quot;locales&quot;), using industry standard tools and without touching programming code (essential when working with teams of translators). For more information see: The I18N (Internationalization) module and Client GUI Sencha i18n\n"},{"id":1266,"path":"../website/pages/docs/release-notes-version-2.1.asciidoc.html#release-notes-version-2.1.asciidoc_asynchronous-http-support","type":"releasenote","title":"Asynchronous HTTP support","body":"119.3.18. Asynchronous HTTP support\nAsynchronous HTTP is an important feature allowing so-called &quot;long polling&quot; HTTP Requests (for streaming applications, for example) or with requests sending large amounts of data. By making HTTP Requests asynchronous, devonfw server instances can better support these types of use-cases while offering far better performance. Documentation about how to include the new devonfw module implementing this feature can be found at: The devonfw async module\n"},{"id":1267,"path":"../website/pages/docs/release-notes-version-2.1.asciidoc.html#release-notes-version-2.1.asciidoc_security-and-license-guarantees","type":"releasenote","title":"Security and License guarantees","body":"119.3.19. Security and License guarantees\nIn devonfw security comes first. The components of the framework are designed and implemented according to the recommendations and guidelines as specified by OWASP in order to confront the top 10 security vulnerabilities.\nFrom version 2.1 &quot;Balu&quot; onward we certify that devonfw has been scanned by software from &quot;Black Duck&quot;. This verifies that devonfw is based on 100% Open Source Software (non Copyleft) and demonstrates that at moment of release there are no known, critical security flaws. Less critical issues are clearly documented.\n"},{"id":1268,"path":"../website/pages/docs/release-notes-version-2.1.asciidoc.html#release-notes-version-2.1.asciidoc_documentation-improvements","type":"releasenote","title":"Documentation improvements","body":"119.3.20. Documentation improvements\nApart from the previously mentioned additions and improvements to diverse aspects of the devonfw documentation, principally the devonfw Guide, there are a number of other important changes. We&#x2019;ve incorporated the Devon Modules Developer&#xB4;s Guide which describes how to extend devonfw with its Spring-based module system. Furthermore we&#x2019;ve significantly improved the Guide to the usage of web services. We&#x2019;ve included a Compatibility Guide which details a series of considerations related with different version of the framework as well as Java 7 vs 8. And finally, we&#x2019;ve extended the F.A.Q. to provide the users with direct answers to common, Frequently Asked Questions.\n"},{"id":1269,"path":"../website/pages/docs/release-notes-version-2.1.asciidoc.html#release-notes-version-2.1.asciidoc_contributors","type":"releasenote","title":"Contributors","body":"119.3.21. Contributors\nMany thanks to adrianbielewicz, aferre777, amarinso, arenstedt, azzigeorge, cbeldacap, cmammado, crisjdiaz, csiwiak, Dalgar, drhoet, Drophoff, dumbNickname, EastWindShak, fawinter, fbougeno, fkreis, GawandeKunal, henning-cg, hennk, hohwille, ivanderk, jarek-jpa, jart, jensbartelheimer, jhcore, jkokoszk, julianmetzler, kalmuczakm, kiran-vadla, kowalj, lgoerlach, ManjiriBirajdar, MarcoRose, maybeec, mmatczak, nelooo, oelsabba, pablo-parra, patrhel, pawelkorzeniowski, PriyankaBelorkar, RobertoGM, sekaiser, sesslinger, SimonHuber, sjimenez77, sobkowiak, sroeger, ssarmokadam, subashbasnet, szendo, tbialecki, thoptr, tsowada, znazir and anyone who we may have forgotten to add!\n&#x2190;&#xA0;Previous:&#xA0;devonfw Release notes 2.2 &quot;Courage&quot;&#xA0;| &#x2191;&#xA0;Up:&#xA0;Release Notes&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide\n"},{"id":1270,"path":"../website/pages/docs/release-notes-version-2.2.asciidoc.html#release-notes-version-2.2.asciidoc","type":"releasenote","title":"devonfw Release notes 2.2 &quot;Courage&quot;","body":"118. devonfw Release notes 2.2 &quot;Courage&quot;\n"},{"id":1271,"path":"../website/pages/docs/release-notes-version-2.2.asciidoc.html#release-notes-version-2.2.asciidoc_production-line-integration","type":"releasenote","title":"Production Line Integration","body":"118.1. Production Line Integration\ndevonfw is now fully supported on the Production Line v1.3 and the coming v2.0. Besides that, we now &quot;eat our own dogfood&quot; as the whole devonfw project, all &quot;buildable assets&quot;, now run on the Production Line.\n"},{"id":1272,"path":"../website/pages/docs/release-notes-version-2.2.asciidoc.html#release-notes-version-2.2.asciidoc_oasp4js-2.0","type":"releasenote","title":"OASP4js 2.0","body":"118.2. OASP4js 2.0\nThe main focus of the Courage release is the renewed introduction of &quot;OASP for JavaScript&quot;, or OASP4js. This new version is a completely new implementation based on Angular (version 4). This new &quot;stack&quot; comes with:\nNew application templates for Angular 4 application (as well as Ionic 3)\nA new reference application\nA new tutorial (and Architecture Guide following soon)\nComponent Gallery\nNew CobiGen templates for generation of both Angular 4 and Ionic 3 UI components (&quot;screens&quot;)\nIntegration of Covalent and Bootstrap offering a large number of components\nmy-thai-star, a showcase and reference implementation in Angular of a real, responsive usable app using recommended architecture and patterns\nA new Tutorial using my-thai-star as a starting point\nSee:\nhttps://github.com/oasp/oasp4js-application-template\nhttps://github.com/oasp/oasp4js-angular-catalog\nhttps://github.com/oasp/my-thai-star/tree/develop/angular\n"},{"id":1273,"path":"../website/pages/docs/release-notes-version-2.2.asciidoc.html#release-notes-version-2.2.asciidoc_a-new-oasp-portal","type":"releasenote","title":"A new OASP Portal","body":"118.3. A new OASP Portal\nAs part of the new framework(s) we have also done a complete redesign of the OASP Portal website at http://oasp.io/ which should make all things related with OASP more accessible and easier to find.\n"},{"id":1274,"path":"../website/pages/docs/release-notes-version-2.2.asciidoc.html#release-notes-version-2.2.asciidoc_new-cobigen","type":"releasenote","title":"New Cobigen","body":"118.4. New Cobigen\nMajor changes in this release:\nSupport for multi-module projects\nClient UI Generation:\nNew Angular 4 templates based on the latest - angular project seed\nBasic Typescript Merger\nBasic Angular Template Merger\nJSON Merger\nRefactored oasp4j templates to make use of Java template logic feature\nBugfixes:\nFixed merging of nested Java annotations including array values\nmore minor issues\nUnder the hood:\nLarge refactoring steps towards language agnostic templates formatting sensitive placeholder descriptions automatically formatting camelCase to TrainCase to snake-case, etc.\nEasy setup of CobiGen IDE to enable fluent contribution\nCI integration improved to integrate with GitHub for more valuable feedback\nSee: https://github.com/devonfw/cobigen/releases\n"},{"id":1275,"path":"../website/pages/docs/release-notes-version-2.2.asciidoc.html#release-notes-version-2.2.asciidoc_mythaistar-new-restaurant-example","type":"releasenote","title":"MyThaiStar: New Restaurant Example, reference implementation &amp; Methodology showcase","body":"118.5. MyThaiStar: New Restaurant Example, reference implementation &amp; Methodology showcase\nA major part of the new devonfw release is the incorporation of a new application, &quot;my-thai-star&quot; which among others:\nserve as an example of how to make a &quot;real&quot; devonfw application (i.e. the application could be used for real)\nServes as an attractive showcase\nServes as a reference application of devonfw patterns and practices as well as the standard example in the new devonfw tutorial\nhighlights modern security option like JWT Integration\nThe application is accompanied by a substantial new documentation asset, the devonfw methodology, which described in detail the whole lifecycle of the development of a devonfw application, from requirements gathering to technical design. Officially my-that-star is still considered to be an incubator as especially this last part is still not as mature as it could be. But the example application and tutorial are 100% complete and functional and form a marked improvement over the &quot;old&quot; restaurant example app. My-Thai-star will become the standard example app from devonfw 3.0 onwards.\nSee: https://github.com/oasp/my-thai-star\nhttps://github.com/oasp/my-thai-star/wiki\n"},{"id":1276,"path":"../website/pages/docs/release-notes-version-2.2.asciidoc.html#release-notes-version-2.2.asciidoc_the-new-oasp-tutorial","type":"releasenote","title":"The new OASP Tutorial","body":"118.6. The new OASP Tutorial\nThe OASP Tutorial is a new part of the combined OASP / devonfw documentation which changes the focus of how people can get started with the platform\nThere are tutorials for OASP4j, OASP4js (Angular), OASP4fn and more to come. My-Thai-Star is used throughout the tutorial series to demonstrate the basic principles, architecture, and good practices of the different OASP &quot;stacks&quot;. There is an elaborated exercise where the readers get to write their own application &quot;JumpTheQueue&quot;.\nWe hope that the new tutorial offers a better, more efficient way for people to get started with devonfw. Answering especially the question: how to make a devonfw application.\nOasp4j tutorial: https://github.com/oasp/oasp-tutorial-sources/wiki/OASP4jGettingStartedHome\nOasp4js tutorial: https://github.com/oasp/oasp-tutorial-sources/wiki/OASP4jsGettingStartedHome\nOasp4fn tutorial: https://github.com/oasp/oasp-tutorial-sources/wiki/OASP4FnGettingStartedHome\n"},{"id":1277,"path":"../website/pages/docs/release-notes-version-2.2.asciidoc.html#release-notes-version-2.2.asciidoc_oasp4j-2.4.0","type":"releasenote","title":"OASP4j 2.4.0","body":"118.7. OASP4j 2.4.0\n&quot;OASP for Java&quot; or OASP4j now includes updated versions of the latest stable versions of Spring Boot and the Spring Framework and all related dependencies. This allows guaranteed, stable, execution of any devonfw 2.X application on the latest versions of the Industry Standard Spring stack.\nAnother important new feature is a new testing architecture/infrastructure. All database options are updated to the latest versions as well as guaranteed to function on all Application Servers which should cause less friction and configuration time when starting a new OASP4j project.\nDetails:\nSpring Boot Upgrade to 1.5.3\nUpdated all underlying dependencies\nSpring version is 4.3.8\nExclude Third Party Libraries that are not needed from sample restaurant application\nBugfix:Fixed the &apos;WhiteLabel&apos; error received when tried to login to the sample restaurant application that is deployed onto external Tomcat\nBugfix:Removed the API api.org.apache.catalina.filters.SetCharacterEncodingFilter and used spring framework&#x2019;s API org.springframework.web.filter.CharacterEncodingFilter instead\nBugfix:Fixed the error &quot;class file for javax.interceptor.InterceptorBinding not found&quot; received when executing the command &apos;mvn site&apos; when trying to generate javadoc using Maven javadoc plugin\nRemoved the deprecated API io.oasp.module.web.common.base.PropertiesWebApplicationContextInitializer\nDocumentation of the usage of UserDetailsService of Spring Security\nSee: https://github.com/oasp/oasp4j\nWiki: https://github.com/oasp/oasp4j/wiki\n"},{"id":1278,"path":"../website/pages/docs/release-notes-version-2.2.asciidoc.html#release-notes-version-2.2.asciidoc_microservices-netflix","type":"releasenote","title":"Microservices Netflix","body":"118.8. Microservices Netflix\ndevonfw now includes a microservices implementation based on Spring Cloud Netflix. It provides a Netflix OSS integrations for Spring Boot apps through auto-configuration and binding to the Spring Environment. It offers microservices archetypes and a complete user guide with all the details to start creating microservices with devonfw.\nSee: https://github.com/devonfw-forge/devon-guide/wiki/devon-microservices\n"},{"id":1279,"path":"../website/pages/docs/release-notes-version-2.2.asciidoc.html#release-notes-version-2.2.asciidoc_devonfw-distribution-based-on-eclipse-oomph","type":"releasenote","title":"devonfw distribution based on Eclipse OOMPH","body":"118.9. devonfw distribution based on Eclipse OOMPH\nThe new Eclipse devonfw distribution is now based on Eclipse OOMPH, which allows us, an any engagement, to create and manage the distribution more effectively by formalizing the setup instructions so they can be performed automatically (due to a blocking issue postponed to devonfw 2.2.1 which will be released a few weeks after 2.2.0)\n"},{"id":1280,"path":"../website/pages/docs/release-notes-version-2.2.asciidoc.html#release-notes-version-2.2.asciidoc_visual-studio-code--atom","type":"releasenote","title":"Visual Studio Code / Atom","body":"118.10. Visual Studio Code / Atom\nThe devonfw distro now contains Visual Studio Code alongside Eclipse in order to provide a default, state of the art, environment for web based development.\nSee: https://github.com/oasp/oasp-vscode-ide\n"},{"id":1281,"path":"../website/pages/docs/release-notes-version-2.2.asciidoc.html#release-notes-version-2.2.asciidoc_more-i18n-options","type":"releasenote","title":"More I18N options","body":"118.11. More I18N options\nThe platform now contains more documentation and a conversion utility which makes it easier to share i18n resource files between the different frameworks.\nSee: https://github.com/devonfw/devon/wiki/cookbook-i18n-resource-converter\n"},{"id":1282,"path":"../website/pages/docs/release-notes-version-2.2.asciidoc.html#release-notes-version-2.2.asciidoc_spring-integration-as-devonfw-module","type":"releasenote","title":"Spring Integration as devonfw Module","body":"118.12. Spring Integration as devonfw Module\nThis release includes a new module based on the Java Message Service (JMS) and Spring Integration which provides a communication system (sender/subscriber) out-of-the-box with simple channels (only to send and read messages), request and reply channels (to send messages and responses) and request &amp; reply asynchronously channels.\nSee: https://github.com/devonfw/devon/wiki/cookbook-integration-module\n"},{"id":1283,"path":"../website/pages/docs/release-notes-version-2.2.asciidoc.html#release-notes-version-2.2.asciidoc_devonfw-harvest-contributions","type":"releasenote","title":"devonfw Harvest contributions","body":"118.13. devonfw Harvest contributions\ndevonfw contains a whole series of new components obtained through the Harvesting process. Examples are :\nNew backend IP module Compose for Redis: management component for cloud environments. Redis is an open-source, blazingly fast, key/value low maintenance store. Compose&#x2019;s platform gives you a configuration pre-tuned for high availability and locked down with additional security features. The component will manage the service connection and the main methods to manage the key/values on the storage. The library used is &quot;lettuce&quot;.\nSencha component for extending GMapPanel with the following functionality :\nMarkers management\nGoogle Maps options management\nGeoposition management\nSearch address and coordinates management\nMap events management\nMap life cycle and behavior management\nSencha responsive Footer that moves from horizontal to vertical layout depending on the screen resolution or the device type. It is a simple functionality but we consider it very useful and reusable.\nSee: https://github.com/devonfw/devon/wiki/cookbook-compose-for-redis-module\n"},{"id":1284,"path":"../website/pages/docs/release-notes-version-2.2.asciidoc.html#release-notes-version-2.2.asciidoc_more-deployment-options-to-jee-application-servers-and-dockercloudfoundry","type":"releasenote","title":"More Deployment options to JEE Application Servers and Docker/CloudFoundry","body":"118.14. More Deployment options to JEE Application Servers and Docker/CloudFoundry\nThe platform now fully supports deployment on the latest version of Weblogic, WebSphere, Wildfly (JBoss) as well as Docker and Cloud Foundry.\nSee: https://github.com/devonfw/devon/wiki/Deployment-on-WebLogic\nhttps://github.com/devonfw/devon/wiki/cookbook-Deployment-on-WebSphere\nhttps://github.com/devonfw/devon/wiki/cookbook-Deployment-on-Wildfly\n"},{"id":1285,"path":"../website/pages/docs/release-notes-version-2.2.asciidoc.html#release-notes-version-2.2.asciidoc_devcon-on-linux","type":"releasenote","title":"Devcon on Linux","body":"118.15. Devcon on Linux\nDevcon is now fully supported on Linux which, together with the devonfw distro running on Linux, makes devonfw fully multi-platform and Cloud compatible (as Linux is the default OS in the Cloud!)\nSee: https://github.com/devonfw/devcon/releases\n"},{"id":1286,"path":"../website/pages/docs/release-notes-version-2.2.asciidoc.html#release-notes-version-2.2.asciidoc_new-oasp-incubators","type":"releasenote","title":"New OASP Incubators","body":"118.16. New OASP Incubators\nFrom different Business Units (countries) have contributed &quot;incubator&quot; frameworks:\nOASP4NET (Stack based on .NET Core / .NET &quot;Classic&quot; (4.6))\nOASP4X (Stack based on Xamarin)\nOASP4Fn (Stack based on Node-js/Serverless): https://github.com/oasp/oasp4fn\nAn &quot;incubator&quot; status means that the frameworks are production ready, all are actually already used in production, but are still not fully compliant with the OASP definition of a &quot;Minimally Viable Product&quot;.\nDuring this summer the OASP4NET and OASP4X repos will be properly installed. In the mean time, if you want to have access to the source code, please contact the devonfw Core Team.\n&#x2190;&#xA0;Previous:&#xA0;devonfw Release notes 2.3 &quot;Dash&quot;&#xA0;| &#x2191;&#xA0;Up:&#xA0;Release Notes&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;Release notes devonfw 2.1.1 &quot;Balu&quot;&#xA0;&#x2192;\n"},{"id":1287,"path":"../website/pages/docs/release-notes-version-2.3.asciidoc.html#release-notes-version-2.3.asciidoc","type":"releasenote","title":"devonfw Release notes 2.3 &quot;Dash&quot;","body":"117. devonfw Release notes 2.3 &quot;Dash&quot;\n"},{"id":1288,"path":"../website/pages/docs/release-notes-version-2.3.asciidoc.html#release-notes-version-2.3.asciidoc_release-improving--strengthening-the-platform","type":"releasenote","title":"Release: improving &amp; strengthening the Platform","body":"117.1. Release: improving &amp; strengthening the Platform\nWe are proud to announce the immediate release of devonfw version 2.3 (code named &#x201C;Dash&#x201D; during development). This release comes with a bit of a delay as we decided to wait for the publication of OASP4j 2.5. &#x201C;Dash&#x201D; contains a slew of new features but in essence it is already driven by what we expect to be the core focus of 2018: strengthening the platform and improving quality.\nAfter one year and a half of rapid expansion, we expect the next release(s) of the devonfw 2.x series to be fully focused on deepening the platform rather than expanding it. That is to say: we should work on improving existing features rather than adding new ones and strengthen the qualitative aspects of the software development life cycle, i.e. testing, infrastructure (CI, provisioning) etc.\n&#x201C;Dash&#x201D; already is very much an example of this. This release contains the Allure Test Framework as an incubator. This is an automated testing framework for functional testing of web applications. Another incubator is the devonfw Shop Floor which intended to be a compilation of DevOps experiences from the devonfw perspective. And based on this devonfw has been OpenShift Primed (&#x201C;certified&#x201D;) by Red Hat.\nThere is a whole range of new features and improvements which can be seen in that light. OASP4j 2.5 changes and improves the package structure of the core Java framework. The My Thai Star sample app has now been fully integrated in the different frameworks and the devonfw Guide has once again been significantly expanded and improved.\n"},{"id":1289,"path":"../website/pages/docs/release-notes-version-2.3.asciidoc.html#release-notes-version-2.3.asciidoc_an-industrialized-platform-for-the-adcenter","type":"releasenote","title":"An industrialized platform for the ADcenter","body":"117.2. An industrialized platform for the ADcenter\nAlthough less visible to the overall devonfw community, an important driving force was (meaning that lots of work has been done in the context of) the creation of the ADcenter concept towards the end of 2017. Based on a radical transformation of on/near/offshore software delivery, the focus of the ADcenters is to deliver agile &amp; accelerated &#x201C;Rightshore&#x201D; services with an emphasis on:\nDelivering Business Value and optimized User Experience\nInnovative software development with state of the art technology\nHighly automated devops; resulting in lower costs &amp; shorter time-to-market\nThe first two ADcenters, in Valencia (Spain) and Bangalore (India), are already servicing clients all over Europe - Germany, France, Switzerland and the Netherlands - while ADcenter aligned production teams are currently working for Capgemini UK as well (through Spain).Through the ADcenter, Capgemini establishes industrialized innovation; designed for &amp; with the user. The availability of platforms for industrialized software delivery like devonfw and the Production Line has allowed us to train and make available over a 150 people in very short time.\nThe creation of the ADcenter is such a short time is visible proof that we&#xB4;re getting closer to a situation where devonfw and Production Line are turning into the default development platform for APPS2, thereby standardizing all aspects of the software development life cycle: from training and design, architecture, devops and development, all the way up to QA and deployment.\n"},{"id":1290,"path":"../website/pages/docs/release-notes-version-2.3.asciidoc.html#release-notes-version-2.3.asciidoc_changes-and-new-features","type":"releasenote","title":"Changes and new features","body":"117.3. Changes and new features\n"},{"id":1291,"path":"../website/pages/docs/release-notes-version-2.3.asciidoc.html#release-notes-version-2.3.asciidoc_devonfw-dist","type":"releasenote","title":"devonfw dist","body":"117.3.1. devonfw dist\nThe devonfw dist, or distribution, i.e. the central zip file which contains the main working environment for the devonfw developer, has been significantly enhanced. New features include:\nEclipse Oxygen integrated\nCheckStyle Plugin installed and configured\nSonarLint Plugin installed and configured\nGit Plugin installed\nFindBugs replaced by SpotBugs and configured\nTomcat8 specific Oxygen configuration\nCobiGen Plugin installed\nOther Software\nCmder integrated (when console.bat launched)\nVisual Studio Code latest version included and pre-configured with https://github.com/devonfw/extension-pack-vscode\nAnt updated to latest.\nMaven updated to latest.\nJava updated to latest.\nNodejs LTS updated to latest.\n@angular/cli included.\nYarn package manager included.\nPython3 integrated\nSpyder3 IDE integrated in python3 installation\nOASP4JS-application-template for Angular5 at workspaces/examples\nDevon4sencha starter templates updated\n"},{"id":1292,"path":"../website/pages/docs/release-notes-version-2.3.asciidoc.html#release-notes-version-2.3.asciidoc_oasp4j-2.5","type":"releasenote","title":"OASP4j 2.5","body":"117.3.2. OASP4j 2.5\nSupport for JAX-RS &amp; JAX-WS clients\nWith the aim to enhance the ease in consuming RESTful and SOAP web services, JAX-RS and JAX-WS clients have been introduced. They enable developers to concisely and efficiently implement portable client-side solutions that leverage existing and well-established client-side HTTP connector implementations. Furthermore, the getting started time for consuming web services has been considerably reduced with the default configuration out-of-the-box which can be tweaked as per individual project requirements.\nSee: https://github.com/oasp/oasp4j/issues/358\nSeparate security logs for OASP4J log component\nBased on OWASP(Open Web Application Security Project), OASP4J aims to give developers more control and flexibility with the logging of security events and tracking of forensic information. Furthermore, it helps classifying the information in log messages and applying masking when necessary. It provides powerful security features while based on set of logging APIs developers are already familiar with over a decade of their experience with Log4J and its successors.\nSee: https://github.com/oasp/oasp4j/issues/569\nSupport for Microservices\nIntegration of an OASP4J application to a Microservices environment can now be leveraged with this release of OASP4J. Introduction of service clients for RESTful and SOAP web services based on Java EE give developers agility and ease to access microservices in the Devon framework. It significantly cuts down the efforts on part of developers around boilerplate code and stresses more focus on the business code improving overall efficiency and quality of deliverables.\nSee: https://github.com/oasp/oasp4j/pull/589/commits\n"},{"id":1293,"path":"../website/pages/docs/release-notes-version-2.3.asciidoc.html#release-notes-version-2.3.asciidoc_cobigen","type":"releasenote","title":"Cobigen","body":"117.3.3. Cobigen\nA new version of Cobigen has been included. New features include:\nSwagger/Yaml Plugin for CobiGen. CobiGen is able to read a swagger definition file that follows the OpenAPI 3.0 spec and generate code. A preliminary release was already included in 2.2.1 but the current version is much more mature and stable. See: https://github.com/devonfw/cobigen/wiki/howto_openapi_generation\nIntegration of CobiGen into Maven build process. This already existed but has been improved. It consists mainly of documentation + better log output and bug fixes. See: https://github.com/devonfw/cobigen/wiki/cobigen-maven_configuration\nCobiGen Ionic CRUD App generation based on https://github.com/oasp/oasp4js-ionic-application-template\nCobigen_Templates project and docs updated\nBugfixes and Hardening\n"},{"id":1294,"path":"../website/pages/docs/release-notes-version-2.3.asciidoc.html#release-notes-version-2.3.asciidoc_my-thai-star-sample-application","type":"releasenote","title":"My Thai Star Sample Application","body":"117.3.4. My Thai Star Sample Application\nFrom this release on the My Thai Star application has been fully integrated in the different frameworks in the platform. Further more, a more modularized approach has been followed in the current release of My Thai star application to decouple client from implementation details. Which provides better encapsulation of code and dependency management for API and implementation classes. This has been achieved with creation of a new &#x201C;API&#x201D; module that contain interfaces for REST services and corresponding Request/Response objects. With existing &#x201C;Core&#x201D; module being dependent on &#x201C;API&#x201D; module. To read further you can follow the link https://github.com/oasp/my-thai-star/wiki/java-design#basic-architecture-details\nFurthermore: an email and Twitter micro service were integrated in my-thai-star. This is just for demonstration purposes. A full micro service framework is already part of oasp4j 2.5.0\n"},{"id":1295,"path":"../website/pages/docs/release-notes-version-2.3.asciidoc.html#release-notes-version-2.3.asciidoc_documentation-refactoring","type":"releasenote","title":"Documentation refactoring","body":"117.3.5. Documentation refactoring\nThe complete devonfw guide is restructured and refactored. Getting started guides are added for easy start with devonfw.Integration of the new Tutorial with the existing devonfw Guide whereby existing chapters of the previous tutorial were converted to Cookbook chapters. Asciidoctor is used for devonfw guide PDF generation.\nSee: https://github.com/devonfw/devon-guide/wiki\n"},{"id":1296,"path":"../website/pages/docs/release-notes-version-2.3.asciidoc.html#release-notes-version-2.3.asciidoc_oasp4js","type":"releasenote","title":"OASP4JS","body":"117.3.6. OASP4JS\nThe following changes have been incorporated in OASP4JS:\nAngular CLI 1.6.0,\nAngular 5.1,\nAngular Material 5 and Covalent 1.0.0 RC1,\nPWA enabled,\nCore and Shared Modules included to follow the recommended Angular projects structure,\nYarn and NPM compliant since both lock files are included in order to get a stable installation.\n"},{"id":1297,"path":"../website/pages/docs/release-notes-version-2.3.asciidoc.html#release-notes-version-2.3.asciidoc_admin-interface-for-oasp4j-apps","type":"releasenote","title":"Admin interface for oasp4j apps","body":"117.3.7. Admin interface for oasp4j apps\nThe new version includes an Integration of an admin interface for oasp4j apps (Spring Boot). This module is based on CodeCentric&#xB4;s Spring Boot Admin (https://github.com/codecentric/spring-boot-admin). See: https://github.com/devonfw/devon-guide/wiki/Spring-boot-admin-Integration-with-devon4j\n"},{"id":1298,"path":"../website/pages/docs/release-notes-version-2.3.asciidoc.html#release-notes-version-2.3.asciidoc_devcon","type":"releasenote","title":"Devcon","body":"117.3.8. Devcon\nA new version of Devcon has been released. Fixes and new features include:\nRenaming of system Commands.\nNew menu has been added - &#x201C;other modules&#x201D;, if menus are more than 10, other modules will display some menus.\nA progress bar has been added for installing the distribution\n"},{"id":1299,"path":"../website/pages/docs/release-notes-version-2.3.asciidoc.html#release-notes-version-2.3.asciidoc_devonfw-modules","type":"releasenote","title":"devonfw Modules","body":"117.3.9. devonfw Modules\nExisting devonfw modules can now be accessed with the help of starters following namespace devonfw-&lt;module_name&gt;-starter. Starters available for modules:\nReporting module\nWinAuth AD Module\nWinAuth SSO Module\nI18n Module\nAsync Module\nIntegration Module\nMicroservice Module\nCompose for Redis Module\nSee: https://github.com/devonfw/devon/wiki#ip-modules\n"},{"id":1300,"path":"../website/pages/docs/release-notes-version-2.3.asciidoc.html#release-notes-version-2.3.asciidoc_devonfw-shop-floor","type":"releasenote","title":"devonfw Shop Floor","body":"117.3.10. devonfw Shop Floor\nThis incubator is intended to be a compilation of DevOps experiences from the devonfw perspective. &#x201C;How we use our devonfw projects in DevOps environments&#x201D;. Integration with the Production Line, creation and service integration of a Docker-based CI environment and deploying devonfw applications in an OpenShift Origin cluster using devonfw templates.\nSee: https://github.com/devonfw/devonfw-shop-floor\n"},{"id":1301,"path":"../website/pages/docs/release-notes-version-2.3.asciidoc.html#release-notes-version-2.3.asciidoc_devonfw-testing","type":"releasenote","title":"devonfw-testing","body":"117.3.11. devonfw-testing\nThe Allure Test Framework is an automated testing framework for functional testing of web applications and in coming future native mobile apps, web services and databases. All modules have tangible examples of how to build resilient integration test cases based on delivered functions.\nExamples available under embedded project &#x201C;Allure-App-Under-Test&#x201D; and in project wiki: https://github.com/devonfw/devonfw-testing/wiki\nHow to install: https://github.com/devonfw/devonfw-testing/wiki/How-to-install\nRelease Notes:\nCore Module &#x2013; ver.4.12.0.3:\nTest report with logs and/or screenshots\nTest groups/tags\nData Driven (inside test case, external file)\nTest case parallel execution\nRun on independent Operating System (Java)\nExternalize test environment (DEV, QA, PROD)\nUI Selenium module &#x2013; ver. 3.4.0.3:\nMalleable resolution ( Remote Web Design, Mobile browsers)\nSupport for many browsers( Internet Explorer, Edge, Chrome, Firefox, Safari)\nUser friendly actions ( elementCheckBox, elementDropdown, etc. )\nUbiquese test execution (locally, against Selenium Grid through Jenkins)\nPage Object Model architecture\nSelenium WebDriver library ver. 3.4.0\nSee: https://github.com/devonfw/devonfw-testing/wiki\n"},{"id":1302,"path":"../website/pages/docs/release-notes-version-2.3.asciidoc.html#release-notes-version-2.3.asciidoc_dot.net-framework-incubators","type":"releasenote","title":"DOT.NET Framework incubators","body":"117.3.12. DOT.NET Framework incubators\nThe .NET Core and Xamarin frameworks are still under development by a workgroup from The Netherlands, Spain, Poland, Italy, Norway and Germany. The 1.0 release is expected to be coming soon but the current incubator frameworks are already being used in several engagements. Some features to highlight are:\nFull .NET implementation with multi-platform support\nDetailed documentation for developers\nDocker ready\nWeb API server side template :\nSwagger auto-generation\nJWT security\nEntity Framework Support\nAdvanced log features\nXamarin Templates based on Excalibur framework\nMy Thai Star implementation:\nBackend (.NET Core)\nFrontEnd (Xamarin)\n"},{"id":1303,"path":"../website/pages/docs/release-notes-version-2.3.asciidoc.html#release-notes-version-2.3.asciidoc_devonfw-has-been-primed-by-red-hat-for-openshift","type":"releasenote","title":"devonfw has been Primed by Red Hat for OpenShift","body":"117.3.13. devonfw has been Primed by Red Hat for OpenShift\nOpenShift is a supported distribution of Kubernetes from Red Hat for container-based software deployment and management. It is using Docker containers and DevOps tools for accelerated application development. Using OpenShift allows Capgemini to avoid Cloud Vendor lock-in. OpenShift provides devonfw with a state of the art CI/CD environment (devonfw Shop Floor), providing devonfw with a platform for the whole development life cycle: from development to staging / deploy.\nSee https://hub.openshift.com/primed/120-capgemini and https://github.com/oasp/s2i\n"},{"id":1304,"path":"../website/pages/docs/release-notes-version-2.3.asciidoc.html#release-notes-version-2.3.asciidoc_harvested-components-and-modules","type":"releasenote","title":"Harvested components and modules","body":"117.3.14. Harvested components and modules\nThe devonfw Harvesting process continues to add valuable components and modules to the devonfw platform. The last months the following elements were contributed:\nService Client support (for Micro service Projects).\nThis client is for consuming microservices from other application.This solution is already very flexible and customizable.As of now,this is suitable for small and simple project where two or three microservices are invoked. Donated by J&#xF6;rg Hohwiller. See: https://github.com/devonfw/devon-microservices\nJHipster devonfw code generation\nThis component was donated by the ADcenter in Valencia. It was made in order to comply with strong requirements (especially from the French BU) to use jHipster for code generation.\nJHipster is a code generator based on Yeoman generators. Its default generator generator-jhipster generates a specific JHipster structure. The purpose of generator-jhipster-DevonModule is to generate the structure and files of a typical OASP4j project. It is therefore equivalent to the standard OASP4j application template based CobiGen code generation.\nSee: https://github.com/devonfw/devon-guide/wiki/cookbook-devon-jhipster-module\nSimple Jenkins task status dashboard\nThis component has been donated by, has been harvested from system in use by, Capgemini Valencia. This dashboard, apart from an optional gamification element, allows the display of multiple Jenkins instances. See: https://github.com/oasp/jenkins_view\n"},{"id":1305,"path":"../website/pages/docs/release-notes-version-2.3.asciidoc.html#release-notes-version-2.3.asciidoc_and-lots-more","type":"releasenote","title":"And lots more, among others:","body":"117.3.15. And lots more, among others:\nOASP4J/devonfw docker based build IN a docker process. See: https://github.com/devonfw/devon-guide/wiki/Dockerfile-for-the-maven-based-spring.io-projects\nCI test boot archetype. This is for unit testing.This will create a sample project and add sample web service to it. A Jenkins job will start oasp4j server and will call web service. See: https://github.com/devonfw/devonfw-shop-floor/tree/master/testing/Oasp4jTestingScripts\nCI test Angular starterTemplate. Testing automation for Angular applications (My Thai Star) in Continuous Integration environments by using Headless browsers and creating Node.js scripts. See: https://github.com/oasp/my-thai-star/blob/develop/angular/package.json#L8-L12 and https://github.com/oasp/my-thai-star/blob/develop/angular/karma.conf.js\n&#x2190;&#xA0;Previous:&#xA0;devonfw Release notes 2.4 &#x201C;EVE&#x201D;&#xA0;| &#x2191;&#xA0;Up:&#xA0;Release Notes&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;devonfw Release notes 2.2 &quot;Courage&quot;&#xA0;&#x2192;\n"},{"id":1306,"path":"../website/pages/docs/release-notes-version-2.4.asciidoc.html#release-notes-version-2.4.asciidoc","type":"releasenote","title":"devonfw Release notes 2.4 &#x201C;EVE&#x201D;","body":"116. devonfw Release notes 2.4 &#x201C;EVE&#x201D;\n"},{"id":1307,"path":"../website/pages/docs/release-notes-version-2.4.asciidoc.html#release-notes-version-2.4.asciidoc_introduction","type":"releasenote","title":"Introduction","body":"116.1. Introduction\nWe are proud to announce the immediate release of devonfw version 2.4 (code named &#x201C;EVE&#x201D; during development). This version is the first one that fully embraces Open Source, including components like the documentation assets and CobiGen. Most of the IP (Intellectual Property or proprietary) part of devonfw are now published under the Apache License version 2.0 (with the documentation under the Creative Commons License (Attribution-NoDerivatives)). This includes the GitHub repositories where all the code and documentation is located. All of these repositories are now open for public viewing as well.\n&#x201C;EVE&#x201D; contains a slew of new features but in essence it is already driven by what we expect to be the core focus of 2018: strengthening the platform and improving quality.\nThis release is also fully focused on deepening the platform rather than expanding it. That is to say: we have worked on improving existing features rather than adding new ones and strengthen the qualitative aspects of the software development life cycle, i.e. security, testing, infrastructure (CI, provisioning) etc.\n&#x201C;EVE&#x201D; already is very much an example of this. This release contains the Allure Test Framework (included as an incubator in version 2.3) update called MrChecker Test Framework. MrChecker is an automated testing framework for functional testing of web applications, API web services, Service Virtualization, Security and in coming future native mobile apps, and databases. All modules have tangible examples of how to build resilient integration test cases based on delivered functions.\nAnother incubator being updated is the devonfw Shop Floor which intended to be a compilation of DevOps experiences from the devonfw perspective. A new part of the release is the new Solution Guide for Application Security based on the state of the art in OWASP based application security.\nThere is a whole range of new features and improvements which can be seen in that light. OASP4j 2.6 changes and improves the package structure of the core Java framework. The My Thai Star sample app has now been upgraded to Angular 6, lots of bugs have been fixed and the devonfw Guide has once again been improved.\nLast but not least, this release contains the formal publication of the devonfw Methodology or The Accelerated Solution Design - an Industry Standards based solution design and specification (documentation) methodology for Agile (and less-than-agile) projects.\n"},{"id":1308,"path":"../website/pages/docs/release-notes-version-2.4.asciidoc.html#release-notes-version-2.4.asciidoc_changes-and-new-features","type":"releasenote","title":"Changes and new features","body":"116.2. Changes and new features\n"},{"id":1309,"path":"../website/pages/docs/release-notes-version-2.4.asciidoc.html#release-notes-version-2.4.asciidoc_devonfw-2.4-is-open-source","type":"releasenote","title":"devonfw 2.4 is Open Source","body":"116.2.1. devonfw 2.4 is Open Source\nThis version is the first release of devonfw that fully embraces Open Source, including components like the documentation assets and CobiGen. This is done in response to intensive market pressure and demands from the MU&#xB4;s (Public Sector France, Netherlands)\nMost of the IP (Intellectual Property or proprietary) part of devonfw are now published under the Apache License version 2.0 (with the documentation under the Creative Commons License (Attribution-NoDerivatives)).\nSo you can now use the devonfw distribution (the &quot;zip&quot; file), CobiGen, the devonfw modules and all other components without any worry to expose the client unwittingly to Capgemini IP.\nNote: there are still some components which are IP and are not published under an OSS license. The class room trainings, the Sencha components and some CobiGen templates. But these are not includes in the distribution nor documentation and are now completely maintained separately.\n"},{"id":1310,"path":"../website/pages/docs/release-notes-version-2.4.asciidoc.html#release-notes-version-2.4.asciidoc_devonfw-dist","type":"releasenote","title":"devonfw dist","body":"116.2.2. devonfw dist\nEclipse Oxygen integrated\nCheckStyle Plugin updated.\nSonarLint Plugin updated.\nGit Plugin updated.\nFindBugs Plugin updated.\nCobiGen plugin updated.\nOther Software\nVisual Studio Code latest version included and pre-configured with https://github.com/oasp/oasp-vscode-ide\nAnt updated to latest.\nMaven updated to latest.\nJava updated to latest.\nNodejs LTS updated to latest.\n@angular/cli included.\nYarn package manager updated.\nPython3 updated.\nSpyder3 IDE integrated in python3 installation updated.\nOASP4JS-application-template for Angular 6 at workspaces/examples\n"},{"id":1311,"path":"../website/pages/docs/release-notes-version-2.4.asciidoc.html#release-notes-version-2.4.asciidoc_my-thai-star-sample-application","type":"releasenote","title":"My Thai Star Sample Application","body":"116.2.3. My Thai Star Sample Application\nThe new release of My Thai Star has focused on the following improvements:\nRelease 1.6.0.\nTravis CI integration with Docker. Now we get a valuable feedback of the current status and when collaborators make pull requests.\nDocker compose deployment.\nOASP4J:\nFlyway upgrade from 3.2.1 to 4.2.0\nBug fixes.\nOASP4JS:\nClient OASP4JS updated to Angular 6.\nFrontend translated into 9 languages.\nImproved mobile and tablet views.\nRouting fade animations.\nCompodoc included to generate dynamically frontend documentation.\n"},{"id":1312,"path":"../website/pages/docs/release-notes-version-2.4.asciidoc.html#release-notes-version-2.4.asciidoc_documentation-updates","type":"releasenote","title":"Documentation updates","body":"116.2.4. Documentation updates\nThe following contents in the devonfw guide have been updated:\ndevonfw OSS modules documentation.\nCreating a new OASP4J application.\nHow to update Angular CLI in devonfw.\nInclude Angular i18n.\nApart from this the documentation has been reviewed and some typos and errors have been fixed.\nThe current development of the guide has been moved to https://github.com/oasp-forge/devon-guide/wiki in order to be available as the rest of OSS assets.\n"},{"id":1313,"path":"../website/pages/docs/release-notes-version-2.4.asciidoc.html#release-notes-version-2.4.asciidoc_oasp4j","type":"releasenote","title":"OASP4J","body":"116.2.5. OASP4J\nThe following changes have been incorporated in OASP4J:\nIntegrate batch with archetype.\nApplication module structure and dependencies improved.\nIssues with Application Template fixed.\nSolved issue where Eclipse maven template oasp4j-template-server version 2.4.0 produced pom with missing dependency spring-boot-starter-jdbc.\nSolved datasource issue with project archetype 2.4.0.\nDecouple archetype from sample (restaurant).\nUpgrade to Flyway 4.\nFix for issue with Java 1.8 and QueryDSL #599.\n"},{"id":1314,"path":"../website/pages/docs/release-notes-version-2.4.asciidoc.html#release-notes-version-2.4.asciidoc_oasp4js","type":"releasenote","title":"OASP4JS","body":"116.2.6. OASP4JS\nThe following changes have been incorporated in OASP4JS:\nFirst version of the new client application architecture guide https://github.com/oasp-forge/oasp4js-wiki/wiki\nAngular CLI 6,\nAngular 6,\nAngular Material 6 and Covalent 2.0.0-beta.1,\nIonic 3.20.0,\nCordova 8.0.0,\nOASP4JS Angular application template updated to Angular 6 with visual improvements and bugfixes https://github.com/oasp/oasp4js-application-template\nOASP4JS Ionic application template updated and improved https://github.com/oasp/oasp4js-ionic-application-template\nPWA enabled.\n"},{"id":1315,"path":"../website/pages/docs/release-notes-version-2.4.asciidoc.html#release-notes-version-2.4.asciidoc_appsec-quick-solution-guide","type":"releasenote","title":"AppSec Quick Solution Guide","body":"116.2.7. AppSec Quick Solution Guide\nThis release incorporates a new Solution Guide for Application Security based on the state of the art in OWASP based application security. The purpose of this guide is to offer quick solutions for common application security issues for all applications based on devonfw. It&#x2019;s often the case that we need our systems to comply to certain sets of security requirements and standards. Each of these requirements needs to be understood, addressed and converted to code or project activity. We want this guide to prevent the wheel from being reinvented over and over again and to give clear hints and solutions to common security problems.\nThe wiki can be accessed here: https://github.com/devonfw/devonfw-security/wiki\nThe PDF can be accessed here: https://github.com/devonfw/devonfw-security\n"},{"id":1316,"path":"../website/pages/docs/release-notes-version-2.4.asciidoc.html#release-notes-version-2.4.asciidoc_cobigen","type":"releasenote","title":"CobiGen","body":"116.2.8. CobiGen\nCobiGen_Templates project and docs updated.\nCobiGen Angular 6 generation improved based on the updated application template\nCobiGen Ionic CRUD App generation based on Ionic application template. Although a first version was already implemented, it has been deeply improved:\nChanged the code structure to comply with Ionic standards.\nAdded pagination.\nPull-to-refresh, swipe and attributes header implemented.\nCode documented and JSDoc enabled (similar to Javadoc)\nCobiGen TSPlugin Interface Merge support.\nCobiGen XML plugin comes out with new cool features:\nEnabled the use of XPath within variable assignment. You can now retrieve almost any data from an XML file and store it on a variable for further processing on the templates. Documented here.\nAble to generate multiple output files per XML input file.\nGenerating code from UML diagrams. XMI files (standard XML for UML) can be now read and processed. This means that you can develop templates and generate code from an XMI like class diagrams.\nCobiGen OpenAPI plugin released with multiple bug-fixes and other functionalities like:\nAssigning global and local variables is now possible. Therefore you can set any string for further processing on the templates. For instance, changing the root package name of the generated files. Documented here.\nEnabled having a class with more than one relationship to another class (more than one property of the same type).\nCobiGen Text merger plugin has been extended and now it is able to merge text blocks. This means, for example, that the generation and merging of AsciiDoc documentation is possible. Documented here.\n"},{"id":1317,"path":"../website/pages/docs/release-notes-version-2.4.asciidoc.html#release-notes-version-2.4.asciidoc_devcon","type":"releasenote","title":"Devcon","body":"116.2.9. Devcon\nA new version of Devcon has been released. Fixes and new features include:\nNow Devcon is OSS, with public repository at https://github.com/devonfw/devcon\nUpdated to match current OASP4J\nUpdate to download Linux distribution.\nCustom modules creation improvements.\nBugfixes.\n"},{"id":1318,"path":"../website/pages/docs/release-notes-version-2.4.asciidoc.html#release-notes-version-2.4.asciidoc_devonfw-oss-modules","type":"releasenote","title":"devonfw OSS Modules","body":"116.2.10. devonfw OSS Modules\nExisting devonfw IP modules have been moved to OSS.\nThey can now be accessed in any OASP4J project as optional dependencies from Maven Central.\nThe repository now has public access https://github.com/devonfw/devon\nStarters available for modules:\nReporting module\nWinAuth AD Module\nWinAuth SSO Module\nI18n Module\nAsync Module\nIntegration Module\nMicroservice Module\nCompose for Redis Module\nSee: https://github.com/devonfw/devon/wiki#devonfw-modules\n"},{"id":1319,"path":"../website/pages/docs/release-notes-version-2.4.asciidoc.html#release-notes-version-2.4.asciidoc_devonfw-shop-floor","type":"releasenote","title":"devonfw Shop Floor","body":"116.2.11. devonfw Shop Floor\ndevonfw Shop Floor 4 Docker\nDocker-based CICD environment\ndocker-compose.yml (installation file)\ndsf4docker.sh (installation script)\nService Integration (documentation in Wiki)\ndevonfw projects build and deployment with Docker\nDockerfiles (multi-stage building)\nBuild artifact (NodeJS for Angular and Maven for Java)\nDeploy built artifact (NGINX for Angular and Tomcat for Java)\nNGINX Reverse-Proxy to redirect traffic between both Angular client and Java server containers.\ndevonfw Shop Floor 4 OpenShift\ndevonfw projects deployment in OpenShift cluster\ns2i images\nOpenShift templates\nVideo showcase (OpenShift Origin 3.6)\nThis incubator is intended to be a compilation of DevOps experiences from the devonfw perspective. &#x201C;How we use our devonfw projects in DevOps environments&#x201D;. Integration with the Production Line, creation and service integration of a Docker-based CI environment and deploying devonfw applications in an OpenShift Origin cluster using devonfw templates.\nSee: https://github.com/devonfw/devonfw-shop-floor\n"},{"id":1320,"path":"../website/pages/docs/release-notes-version-2.4.asciidoc.html#release-notes-version-2.4.asciidoc_devonfw-testing","type":"releasenote","title":"devonfw Testing","body":"116.2.12. devonfw Testing\nThe MrChecker Test Framework is an automated testing framework for functional testing of web applications, API web services, Service Virtualization, Security and in coming future native mobile apps, and databases. All modules have tangible examples of how to build resilient integration test cases based on delivered functions.\nExamples available under embedded project &#x201C;MrChecker-App-Under-Test&#x201D; and in project wiki: https://github.com/devonfw/devonfw-testing/wiki\nHow to install:\nWiki : https://github.com/devonfw/devonfw-testing/wiki/How-to-install\nRelease Note:\nmodule core - 4.12.0.8:\nfixes on getting Environment values\ntop notch example how to keep vulnerable data in repo , like passwords\nmodule selenium - 3.8.1.8:\nbrowser driver auto downloader\nlist of out off the box examples to use in any web page\nmodule webAPI - ver. 1.0.2 :\napi service virtualization with REST and SOAP examples\napi service virtualization with dynamic arguments\nREST working test examples with page object model\nmodule security - 1.0.1 (security tests against My Thai Start)\nmodule DevOps :\ndockerfile for Test environment execution\nCI + CD as Jenkinsfile code\n"},{"id":1321,"path":"../website/pages/docs/release-notes-version-2.4.asciidoc.html#release-notes-version-2.4.asciidoc_devonfw-methodology-accelerated-solution-design","type":"releasenote","title":"devonfw methodology: Accelerated Solution Design","body":"116.2.13. devonfw methodology: Accelerated Solution Design\nOne of the prime challenges in Distributed Agile Delivery is the maintenance of a common understanding and unity of intent among all participants in the process of creating a product. That is: how can you guarantee that different parties in the client, different providers, all in different locations and time zones during a particular period of time actually understand the requirements of the client, the proposed solution space and the state of implementation.\nWe offer the Accelerated Solution Design as a possible answer to these challenges. The ASD is carefully designed to be a practical guideline that fosters and ensures the collaboration and communication among all team members.\nThe Accelerated Solution Design is:\nA practical guideline rather than a &#x201C;methodology&#x201D;\nBased on industry standards rather than proprietary methods\nConsisting of an evolving, &#x201C;living&#x201D;, document set rather than a static, fixed document\nEncapsulating the business requirements, functional definitions as well as Architecture design\nBased on the intersection of Lean, Agile, DDD and User Story Mapping\nAnd further it is based on the essential belief or paradigm that ASD should be:\nFocused on the design (definition) of the &#x201C;externally observable behavior of a system&#x201D;\nPromoting communication and collaboration between team members\nGuided by prototypes\nFor more on the devonfw Methodology / ASD, see:\nhttps://github.com/devonfw/devon-methodology/blob/master/design-guidelines/Accelerated_Solution_Design.adoc\n&#x2190;&#xA0;Previous:&#xA0;devonfw Release notes 3.0 &#x201C;Fry&#x201D;&#xA0;| &#x2191;&#xA0;Up:&#xA0;Release Notes&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;devonfw Release notes 2.3 &quot;Dash&quot;&#xA0;&#x2192;\n"},{"id":1322,"path":"../website/pages/docs/release-notes-version-2020.04.asciidoc.html#release-notes-version-2020.04.asciidoc","type":"releasenote","title":"devonfw Release notes 2020.04","body":"112. devonfw Release notes 2020.04\n"},{"id":1323,"path":"../website/pages/docs/release-notes-version-2020.04.asciidoc.html#release-notes-version-2020.04.asciidoc_introduction","type":"releasenote","title":"Introduction","body":"112.1. Introduction\nWe are proud to announce the immediate release of devonfw version 2020.04. This version is the first one with the new versioning that will make easier to the community to identify when it was released since we use the year and month as many other software distributions.\nThis release includes lots of bug fixes and many version updates, but it is very important to highlight the following improvements:\nNew devonfw IDE auto-configure project feature.\nImproved devonfw IDE plugin configuration.\nNew devon4j kafka module.\nNew devon4j JWT module.\nNew devon4j authorization of batches feature.\nDozer replaced with Orika in devon4j.\nSupport for composite keys in devon4j and CobiGen.\nMultiple enhancements for project specific plugin development and usage of project specific template sets in CobiGen.\nAbility to adapt your own templates by making use of CobiGen CLI.\nBetter responsiveness in eclipse and bugfixes in all assets in CobiGen.\ndevon4ng updated to Angular 9, NgRx 9 and Ionic 5, including documentation, samples and templates.\nYarn 2 support in devon4ng.\ndevon4node updated to NestJS 7 (packages, samples and documentation)\ndevon4node TSLint replaced with ESLint.\n@devon4node/config package added.\ndevon4net updated to latest .NET Core 3.1.3 LTS version.\nUpdate of the Production Line templates for devonfw projects in devonfw shop floor.\nNew merge feature included in the devonfw shop floor cicdgen tool.\nUpdated sonar-devon4j-plugin:\nImproved coloring and other visual cues to our rule descriptions to highlight good and bad code examples.\nImproved the locations of issues thrown on method- and class-level.\nPlease check the detailed list below.\nThis would have not been possible without the commitment and hard work of the devonfw core team, German, Indian and ADCenter Valencia colleagues and collaborators as, among many others, the Production Line team.\n"},{"id":1324,"path":"../website/pages/docs/release-notes-version-2020.04.asciidoc.html#release-notes-version-2020.04.asciidoc_devonfw-ide","type":"releasenote","title":"devonfw IDE","body":"112.2. devonfw IDE\nThe consolidated list of features for this devonfw IDE release is as it follows.\n"},{"id":1325,"path":"../website/pages/docs/release-notes-version-2020.04.asciidoc.html#release-notes-version-2020.04.asciidoc_2020.04.001","type":"releasenote","title":"2020.04.001","body":"112.2.1. 2020.04.001\nStarting with this release we have changed the versioning schema in devonfw to yyyy.mm.NNN where yyyy.mm is the date of the planned milestone release and NNN is a running number increased with every bug- or security-fix update.\n#394 variable from devon.properties not set if not terminated with newline\n#399 launching of Intellij fails with No such file or directory error.\n#371 Eclipse plugin installation broke\n#390 maven get/set-version buggy\n#397 migration support for devon4j 2020.04.001\n#400 allow custom args for release\nThe full list of changes for this release can be found in milestone 2020.04.001.\n"},{"id":1326,"path":"../website/pages/docs/release-notes-version-2020.04.asciidoc.html#release-notes-version-2020.04.asciidoc_3.3.1","type":"releasenote","title":"3.3.1","body":"112.2.2. 3.3.1\nNew release with bugfixes and new ide plugin feature:\n#343: Setup can&#x2019;t find Bash nor Git\n#369: Fix flattening of POMs\n#386: Feature/clone recursive\n#379: Use own extensions folder in devonfw-ide\n#381: Add ability to configure VS Code plugins via settings\n#376: Improve Eclipse plugin configuration\n#373: Fix project import on windows\n#374: Rework build on import\nThe full list of changes for this release can be found in milestone 3.3.1.\n"},{"id":1327,"path":"../website/pages/docs/release-notes-version-2020.04.asciidoc.html#release-notes-version-2020.04.asciidoc_3.3.0","type":"releasenote","title":"3.3.0","body":"112.2.3. 3.3.0\nNew release with bugfixes and new project import feature:\n#343: Detect non-admin GitForWindows and Cygwin\n#175: Ability to clone projects and import into Eclipse automatically\n#346: devon eclipse add-plugin parameters swapped\n#363: devon ide update does not pull latest project settings\n#366: update java versions to latest fix releases\nThe full list of changes for this release can be found in milestone 3.3.0.\n"},{"id":1328,"path":"../website/pages/docs/release-notes-version-2020.04.asciidoc.html#release-notes-version-2020.04.asciidoc_devon4j","type":"releasenote","title":"devon4j","body":"112.3. devon4j\nThe consolidated list of features for this devon4j release is as it follows.\n"},{"id":1329,"path":"../website/pages/docs/release-notes-version-2020.04.asciidoc.html#release-notes-version-2020.04.asciidoc_2020.04.001","type":"releasenote","title":"2020.04.001","body":"112.3.1. 2020.04.001\nStarting with this release we have changed the versioning schema in devonfw to yyyy.mm.NNN where yyyy.mm is the date of the planned milestone release and NNN is a running number increased with every bug- or security-fix update.\nThe following changes have been incorporated in devon4j:\n#233: Various version updates\n#241: Add module to support JWT and parts of OAuth\n#147: Switch from dozer to orika\n#180: Cleanup archtype\n#240: Add unreferenced guides\n#202: Architecture documentation needs update for components\n#145: Add a microservices article in the documentation\n#198: Deploy SNAPSHOTs to OSSRH in travis CI\n#90: Authorization of batches\n#221: Wrote monitoring guide\n#213: Document logging of custom field in json\n#138: Remove deprecated RevisionMetadata[Type]\n#211: Archetype: security config broken\n#109: LoginController not following devon4j to use JAX-RS but uses spring-webmvc instead\n#52: Improve configuration\n#39: Ability to log custom fields via SLF4J\n#204: Slf4j version\n#190: Rework of spring-batch integration\n#210: Rework documentation for blob support\n#191: Rework of devon4j-batch module\n#209: Include performance info in separate fields\n#207: Use more specific exception for not found entity\n#208: Remove unnecesary clone\n#116: Bug in JSON Mapping for ZonedDateTime\n#184: Fixed BOMs so devon4j and archetype can be used again\n#183: Error in executing the project created with devon4j\n#177: Switch to new maven-parent\n169: Provide a reason, why unchecked exceptions are used in devon4j\nDocumentation is available at devon4j guide 2020.04.001.\nThe full list of changes for this release can be found in milestone devon4j 2020.04.001.\n"},{"id":1330,"path":"../website/pages/docs/release-notes-version-2020.04.asciidoc.html#release-notes-version-2020.04.asciidoc_devon4ng","type":"releasenote","title":"devon4ng","body":"112.4. devon4ng\nThe consolidated list of features for this devon4ng release is as it follows.\n"},{"id":1331,"path":"../website/pages/docs/release-notes-version-2020.04.asciidoc.html#release-notes-version-2020.04.asciidoc_2020.04.001","type":"releasenote","title":"2020.04.001","body":"112.4.1. 2020.04.001\nStarting with this release we have changed the versioning schema in devonfw to yyyy.mm.NNN where yyyy.mm is the date of the planned milestone release and NNN is a running number increased with every bug- or security-fix update.\n#111: Yarn 2 support included\n#96: devon4ng upgrade to Angular 9\nTemplates and samples updated to Angular 9, NgRx 9 and Ionic 5.\nNew internationalization module.\nDocumentation updates and improvements.\n#95: Added token management info in documentation\n"},{"id":1332,"path":"../website/pages/docs/release-notes-version-2020.04.asciidoc.html#release-notes-version-2020.04.asciidoc_devon4net","type":"releasenote","title":"devon4net","body":"112.5. devon4net\nThe consolidated list of features for this devon4net release is as it follows:\nUpdated to latest .NET Core 3.1.3 LTS version\nDependency Injection Autoregistration for services and repositories\nAdded multiple role managing claims in JWT\nAdded custom headers to circuit breaker\nReviewed default log configuration\nAdded support to order query results from database via lambda expression\nUpdated template and nuget packages\n"},{"id":1333,"path":"../website/pages/docs/release-notes-version-2020.04.asciidoc.html#release-notes-version-2020.04.asciidoc_devon4node","type":"releasenote","title":"devon4node","body":"112.6. devon4node\nThe consolidated list of features for this devon4node release is as it follows:\nUpgrade to NestJS 7 (packages, samples and documentation)\nTSLint replaced with ESLint\nAdd lerna to project to manage all the packages\nAdd @devon4node/config package\nAdd new schematics: Repository\nImprove WinstonLogger\nImprove documentation\nUpdate dependencies to latest versions\n"},{"id":1334,"path":"../website/pages/docs/release-notes-version-2020.04.asciidoc.html#release-notes-version-2020.04.asciidoc_cobigen","type":"releasenote","title":"CobiGen","body":"112.7. CobiGen\nNew release with updates and bugfixes:\ndevonfw templates:\n#1063: Upgrade devon4ng Ionic template to latest version\n#1065: devon4ng templates for devon4node\n#1128: update java templates for composite keys\n#1130: Update template for devon4ng application template\n#1131: Update template for devon4ng NgRx template\n#1149: .NET templates\n#1146: Dev ionic template update bug fix\nTypeScript plugin:\n#1126: OpenApi parse/merge issues (ionic List templates)\nEclipse plugin:\n#412: Write UI Test for HealthCheck use\n#867: Cobigen processbar\n#1069: #953 dot path\n#1099: NPE on HealthCheck\n#1100: 1099 NPE on health check\n#1101: #867 fix import of core and api\n#1102: eclipse_plugin doesn&#x2019;t accept folders as input\n#1134: (Eclipse-Plugin) Resolve Template utility classes from core\n#1142: #1102 accept all kinds of input\nCobiGen core:\n#429: Reference external template files\n#1143: Abort generation if external trigger does not match\n#1125: Generation of templates from external increments does not work\n#747: Variable assignment for external increments throws exception\n#1133: Bugfix/1125 generation of templates from external increments does not work\n#1127: #1119 added new TemplatesUtilsClassesUtil class to core\n#953: NPE bug if foldername contains a dot\n#1067: Feature/158 lat variables syntax\nCobiGen CLI:\n#1111: Infinity loop in mmm-code (MavenDependencyCollector.collectWithReactor)\n#1113: cobigen-cli does not seem to properly resolve classes from dependencies\n#1120: Feature #1108 custom templates folder\n#1115: Fixing CLI bugs related to dependencies and custom templates jar\n#1108: CobiGen CLI: Allow easy use of user&#x2019;s templates\n#1110: FileSystemNotFoundException blocking cobigen-cli\n#1138: #1108 dev cli feature custom templates folder\n#1136: (Cobigen-CLI) Resolve Template utility classes from core\n"},{"id":1335,"path":"../website/pages/docs/release-notes-version-2020.04.asciidoc.html#release-notes-version-2020.04.asciidoc_devonfw-shop-floor","type":"releasenote","title":"devonfw-shop-floor","body":"112.8. devonfw-shop-floor\nAdd documentation for deploy jenkins slaves\nImprove documentation\nAdd devon4net Openshift template\nAdd nginx docker image for devon4ng\nAdd Openshift provisioning\nProduction Line:\nUpdated MTS template: add step for dependency check and change the deployment method\nAdd template utils: initialize instance, openshift configuration, docker configuration and install sonar plugin\nAdd devon4net template\nAdd from existing template\nImprove documentation\nRefactor the documentation in order to follow the devonfw wiki workflow\nUpdate devon4j, devon4ng, devon4net and devon4node in order to be able to choose the deployment method: none, docker or openshift.\nUpdate the tools version in order to use the latest.\nProduction Line Shared Lib\nAdd more fuctionality to the existing classes.\nAdd classes: DependencyCheckConfiguration, DockerConfiguration and OpenshiftConfiguration\nCICDGEN\nAdd devon4net support\nUpdate tools versions in Jenkinsfiles to align with Production Line templates\nAdd merge strategies: error, keep, override, combine\nAdd lerna to the project\nMinor improvements in the code\nAdd GitHub actions workflow to validate the new changes\nImprove documentation\nBreaking changes:\nRemove the following parameters: plurl, ocurl\nAdd the following parameters: dockerurl, dockercertid, registryurl, ocname and merge\n"},{"id":1336,"path":"../website/pages/docs/release-notes-version-2020.04.asciidoc.html#release-notes-version-2020.04.asciidoc_sonar-devon4j-plugin","type":"releasenote","title":"Sonar devon4j plugin","body":"112.9. Sonar devon4j plugin\nThe consolidated list of features for this Sonar devon4j plugin release is as it follows.\n"},{"id":1337,"path":"../website/pages/docs/release-notes-version-2020.04.asciidoc.html#release-notes-version-2020.04.asciidoc_2020.04.001","type":"releasenote","title":"2020.04.001","body":"112.9.1. 2020.04.001\nThis is the first version using our new versioning scheme. Here, the following issues were resolved:\n#60: Fixed a bug in the naming check for Use-Case implementation classes\n#67: Fixed a bug where the whole body of a method or a class was marked as the issue location. Now only the method / class headers will be highlighted.\n#68: Made our rule descriptions more accessible by using better readable colors as well as alternative visual cues\n#71: Fixed a bug where a NPE could be thrown\n#74: Fixed a bug where a method always returned null\nUnrelated to any specific issues, there was some refactoring and cleaning up done with the following two PRs:\nPR #66: Refactored the prefixes of our rule names from &apos;Devon&apos; to &apos;devonfw&apos;\nPR #65: Sorted security-related test files into their own package\nChanges for this release can be found in milestone 2020.04.001.\n"},{"id":1338,"path":"../website/pages/docs/release-notes-version-2020.04.asciidoc.html#release-notes-version-2020.04.asciidoc_my-thai-star","type":"releasenote","title":"My Thai Star","body":"112.10. My Thai Star\nAs always, our reference application, My Thai Star, contains some interesting improvements that come from the new features and bug fixes from the other assets. The list is as it follows:\ndevon4j - Java\nImplement example batches with modified devon-batch\nUpgrade spring boot version to 2.2.6 and devon4j 2020.004.001\nMigrate from dozer to orika\ndevon4ng - Angular\nMove configuration to NgRx store\ndevonfw shop floor - Jenkins\nUpdate tools versions in order to align with Production Line templates\nAdd dependency check step (using dependency checker and yarn audit)\nSend dependency checker reports to SonarQube\nChanged deployment pipelines. Now pipelines are able to deploy docker containers using docker directly. No more ssh connections to execute commands in a remote machine are required.\nUpdate documentation in order to reflect all changes\ndevon4nde - Node.js\nUpgrade to NestJS 7\nAdd custom repositories\nAdd exceptions and exception filters\nAdd tests (missing in the previous version)\nSplit logic into use cases in order to make the test process easier\nMinor patches and improvemets\nDocumentation updated in order to reflect the new implementation\n&#x2190;&#xA0;Previous:&#xA0;devonfw Release notes 2020.08&#xA0;| &#x2191;&#xA0;Up:&#xA0;Release Notes&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;devonfw Release notes 3.2 &#x201C;Homer&#x201D;&#xA0;&#x2192;\n"},{"id":1339,"path":"../website/pages/docs/release-notes-version-2020.08.asciidoc.html#release-notes-version-2020.08.asciidoc","type":"releasenote","title":"devonfw Release notes 2020.08","body":"111. devonfw Release notes 2020.08\n"},{"id":1340,"path":"../website/pages/docs/release-notes-version-2020.08.asciidoc.html#release-notes-version-2020.08.asciidoc_introduction","type":"releasenote","title":"Introduction","body":"111.1. Introduction\nWe are proud to announce the release of devonfw version 2020.08.\nThis release includes lots of addition of new features, updates and bug fixes but it is very important to highlight the following improvements:\n"},{"id":1341,"path":"../website/pages/docs/release-notes-version-2020.08.asciidoc.html#release-notes-version-2020.08.asciidoc_devonfw-ide","type":"releasenote","title":"devonfw IDE","body":"111.2. devonfw IDE\nThe consolidated list of features for this devonfw IDE release is as it follows.\n"},{"id":1342,"path":"../website/pages/docs/release-notes-version-2020.08.asciidoc.html#release-notes-version-2020.08.asciidoc_2020.08.001","type":"releasenote","title":"2020.08.001","body":"111.2.1. 2020.08.001\nUpdate with the following bugfixes and improvements:\n#454: update to eclipse 2020.06\n#442: update nodejs and vscode\n#432: vsCode settings are not updated\n#446: intellij: doConfigureEclipse: command not found\n#440: Software update may lead to inconsistent state due to windows file locks\n#427: release: keep leading zeros\n#450: update settings\n#431: devon build command not working correct for yarn or npm\n#449: update to devon4j 2020.08.001\nThe full list of changes for this release can be found in milestone 2020.08.001.\n"},{"id":1343,"path":"../website/pages/docs/release-notes-version-2020.08.asciidoc.html#release-notes-version-2020.08.asciidoc_2020.04.004","type":"releasenote","title":"2020.04.004","body":"111.2.2. 2020.04.004\nMinor update with the following bugfixes and improvements:\n#433: Windows: devon command line sets wrong environment variables (with tilde symbol)\n#435: fix variable resolution on bash\nThe full list of changes for this release can be found in milestone 2020.04.004.\n"},{"id":1344,"path":"../website/pages/docs/release-notes-version-2020.08.asciidoc.html#release-notes-version-2020.08.asciidoc_2020.04.003","type":"releasenote","title":"2020.04.003","body":"111.2.3. 2020.04.003\nMinor update with the following bugfixes and improvements:\n#395: variable from devon.properites unset if value is in double quotes\n#429: Added script to create a meta file in the users directory after setup\nThe full list of changes for this release can be found in milestone 2020.04.003.\n"},{"id":1345,"path":"../website/pages/docs/release-notes-version-2020.08.asciidoc.html#release-notes-version-2020.08.asciidoc_2020.04.002","type":"releasenote","title":"2020.04.002","body":"111.2.4. 2020.04.002\nMinor update with the following bugfixes and improvements:\n#418: Make projects optional\n#421: update devon4j to 2020.04.002\n#413: Update Eclipse to 2020-03\n#424: Strange errors on windows if devon.properties contains mixed line endings\n#399: launching of Intellij fails with No such file or directory error.\n#410: fix jsonmerge for boolean and null values\nThe full list of changes for this release can be found in milestone 2020.04.002.\n"},{"id":1346,"path":"../website/pages/docs/release-notes-version-2020.08.asciidoc.html#release-notes-version-2020.08.asciidoc_devon4j","type":"releasenote","title":"devon4j","body":"111.3. devon4j\nThe consolidated list of features for this devon4j release is as it follows.\n"},{"id":1347,"path":"../website/pages/docs/release-notes-version-2020.08.asciidoc.html#release-notes-version-2020.08.asciidoc_2020.08.001","type":"releasenote","title":"2020.08.001","body":"111.3.1. 2020.08.001\nNew release of devon4j with async REST service client support and other improvements:\n#279: support for async service clients\n#277: Update Security-Guide to recent OWASP Top (2017)\n#281: cleanup documentation\nDocumentation is available at devon4j guide 2020.08.001.\nThe full list of changes for this release can be found in milestone devon4j 2020.08.001.\n"},{"id":1348,"path":"../website/pages/docs/release-notes-version-2020.08.asciidoc.html#release-notes-version-2020.08.asciidoc_2020.04.002","type":"releasenote","title":"2020.04.002","body":"111.3.2. 2020.04.002\nMinor update of devon4j with the following bugfixes and small improvements:\n#261: JUnit4 backward compatibility\n#267: Fix JWT permission expansion\n#254: JWT Authentication support for devon4j-kafka\n#258: archetype is still lacking a .gitignore\n#273: Update libs\n#271: Do not enable resource filtering by default\n#255: Kafka: Support different retry configuration for different topics\nDocumentation is available at devon4j guide 2020.04.002.\nThe full list of changes for this release can be found in milestone devon4j 2020.04.002.\n"},{"id":1349,"path":"../website/pages/docs/release-notes-version-2020.08.asciidoc.html#release-notes-version-2020.08.asciidoc_devon4ng","type":"releasenote","title":"devon4ng","body":"111.4. devon4ng\nThis release is focused mainly on the Angular 10 upgrade:\n#176: Template submodules updated to Angular 10 and NgRx 10.\n#167, #168, #174 and #175: Updated electron (sample and documentation).\n#166: Update error handler.\n#165: Cypress sample.\n#164: Update to Angular 10 (samples and documentation).\n"},{"id":1350,"path":"../website/pages/docs/release-notes-version-2020.08.asciidoc.html#release-notes-version-2020.08.asciidoc_devon4node","type":"releasenote","title":"devon4node","body":"111.5. devon4node\nNew devon4node version is published, the changes are:\nUpdated dependencies.\nSolved bug when you introduce a name with dashes in new command.\nAdd more options to the non-interactive new command.\n"},{"id":1351,"path":"../website/pages/docs/release-notes-version-2020.08.asciidoc.html#release-notes-version-2020.08.asciidoc_cobigen","type":"releasenote","title":"CobiGen","body":"111.6. CobiGen\nCobiGen version numbers have been consolidated to now represent plug-in compatibility in the major release number (7.x.x).\n"},{"id":1352,"path":"../website/pages/docs/release-notes-version-2020.08.asciidoc.html#release-notes-version-2020.08.asciidoc_cli","type":"releasenote","title":"CLI","body":"111.6.1. CLI\nCLI increments can be referenced by name and description.\nAbility to configure logging.\nFixed error on code formatting.\nImproved Performance by lazy plug-in loading.\nPossibility to prefer custom plug-ins over CobiGen ones.\nFixed bug, which broke whole CobiGen execution in case a custom CobiGen Plug-in was throwing an arbitrary exception.\n"},{"id":1353,"path":"../website/pages/docs/release-notes-version-2020.08.asciidoc.html#release-notes-version-2020.08.asciidoc_eclipse","type":"releasenote","title":"Eclipse","body":"111.6.2. Eclipse\nImproved Performance by lazy plug-in loading.\nPossibility to prefer custom plug-ins over CobiGen ones.\nFixed bug, which broke whole CobiGen execution in case a custom CobiGen Plug-in was throwing an arbitrary exception.\n"},{"id":1354,"path":"../website/pages/docs/release-notes-version-2020.08.asciidoc.html#release-notes-version-2020.08.asciidoc_maven","type":"releasenote","title":"Maven","body":"111.6.3. Maven\nFixed bug to properly load template util classes.\nImproved Performance by lazy plug-in loading.\nPossibility to prefer custom plug-ins over CobiGen ones.\nFixed bug, which broke whole CobiGen execution in case a custom CobiGen Plug-in was throwing an arbitrary exception.\n"},{"id":1355,"path":"../website/pages/docs/release-notes-version-2020.08.asciidoc.html#release-notes-version-2020.08.asciidoc_xml-plug-in","type":"releasenote","title":"XML Plug-in","body":"111.6.4. XML Plug-in\nAdded ability to provide custom merge schemas as part of the template folder.\nAdded further merge strategies for merging including XML validation.\n"},{"id":1356,"path":"../website/pages/docs/release-notes-version-2020.08.asciidoc.html#release-notes-version-2020.08.asciidoc_java-plug-in","type":"releasenote","title":"Java Plug-in","body":"111.6.5. Java Plug-in\nFixed NPE for annotated constructors.\nFixed line separator handling to now prefer the file&#x2019;s one instead of the system ones.\nFixed unwanted new lines in constructors after merging.\nFixed annotation formatting after merge.\n"},{"id":1357,"path":"../website/pages/docs/release-notes-version-2020.08.asciidoc.html#release-notes-version-2020.08.asciidoc_typescript-plug-in","type":"releasenote","title":"TypeScript Plug-in","body":"111.6.6. TypeScript Plug-in\nFixed issue on automatic update of the ts-merger bundle.\n"},{"id":1358,"path":"../website/pages/docs/release-notes-version-2020.08.asciidoc.html#release-notes-version-2020.08.asciidoc_sonar-devon4j-plugin","type":"releasenote","title":"Sonar devon4j plugin","body":"111.7. Sonar devon4j plugin\nThe consolidated list of features for this Sonar devon4j plugin release is as it follows.\nWith this release, we added our own quality profile:\n#16: Install devon4j quality profile\nChanges for this release can be found in milestone 2020.08.001\n"},{"id":1359,"path":"../website/pages/docs/release-notes-version-2020.08.asciidoc.html#release-notes-version-2020.08.asciidoc_my-thai-star-with-microservices-and-istio-service-mesh-implementation","type":"releasenote","title":"My Thai Star with Microservices and ISTIO Service Mesh Implementation","body":"111.8. My Thai Star with Microservices and ISTIO Service Mesh Implementation\nAs always, our reference application, My Thai Star now has been implemented with Microservices and ISTIO Service Mesh features:\ndevon4j - Java\nMy Thai Star now has a sample version on Microservices architecture.\nThe github repository for the microservices version of My Thai Star is hosted at My Thai Star with Microservices\nMy Thai Star Microservices now has a multi stage docker build which generates the respective docker images for all the My Thai Star services.\nMy Thai Star microservices has the Kubernetes artifacts available to be able to deploy into Kubernetes pods.\nMy Thai Star microservices has ISTIO the service mesh implementation.\nCheck out the guides to implement or configure ISTIO features such as Traffic Routing, Network Resiliency features(RequestRouting, RequestTimeouts, Fault Injection, Circuit Breaker), Canary Deployments.\n&#x2190;&#xA0;Previous:&#xA0;devonfw Release notes 2020.12&#xA0;| &#x2191;&#xA0;Up:&#xA0;Release Notes&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;devonfw Release notes 2020.04&#xA0;&#x2192;\n"},{"id":1360,"path":"../website/pages/docs/release-notes-version-2020.12.asciidoc.html#release-notes-version-2020.12.asciidoc","type":"releasenote","title":"devonfw Release notes 2020.12","body":"110. devonfw Release notes 2020.12\n"},{"id":1361,"path":"../website/pages/docs/release-notes-version-2020.12.asciidoc.html#release-notes-version-2020.12.asciidoc_introduction","type":"releasenote","title":"Introduction","body":"110.1. Introduction\nWe are proud to announce the release of devonfw version 2020.12.\nThis release includes lots of addition of new features, updates and bug fixes but it is very important to highlight the following improvements:\n"},{"id":1362,"path":"../website/pages/docs/release-notes-version-2020.12.asciidoc.html#release-notes-version-2020.12.asciidoc_devonfw-ide","type":"releasenote","title":"devonfw IDE","body":"110.2. devonfw IDE\nThe consolidated list of features for this devonfw IDE release is as it follows.\n"},{"id":1363,"path":"../website/pages/docs/release-notes-version-2020.12.asciidoc.html#release-notes-version-2020.12.asciidoc_2020.12.001","type":"releasenote","title":"2020.12.001","body":"110.2.1. 2020.12.001\nUpdate with the following bugfixes and improvements:\n#495: Documentation corrections\n#491: Consider lombok support\n#489: Update node to v12.19.0 and VS Code to 1.50.1\n#470: reverse merge of workspace settings not sorting properties anymore\n#483: Error during installation when npm is already installed\n#415: documentation to customize settings\n#479: Error for vscode plugin installation\n#471: Preconfigure Project Explorer with Hierarchical Project Presentation\nThe full list of changes for this release can be found in milestone 2020.12.001.\n"},{"id":1364,"path":"../website/pages/docs/release-notes-version-2020.12.asciidoc.html#release-notes-version-2020.12.asciidoc_2020.08.001","type":"releasenote","title":"2020.08.001","body":"110.2.2. 2020.08.001\nUpdate with the following bugfixes and improvements:\n#454: update to eclipse 2020.06\n#442: update nodejs and vscode\n#432: vsCode settings are not updated\n#446: intellij: doConfigureEclipse: command not found\n#440: Software update may lead to inconsistent state due to windows file locks\n#427: release: keep leading zeros\n#450: update settings\n#431: devon build command not working correct for yarn or npm\n#449: update to devon4j 2020.08.001\nThe full list of changes for this release can be found in milestone 2020.08.001.\n"},{"id":1365,"path":"../website/pages/docs/release-notes-version-2020.12.asciidoc.html#release-notes-version-2020.12.asciidoc_2020.04.004","type":"releasenote","title":"2020.04.004","body":"110.2.3. 2020.04.004\nMinor update with the following bugfixes and improvements:\n#433: Windows: devon command line sets wrong environment variables (with tilde symbol)\n#435: fix variable resolution on bash\nThe full list of changes for this release can be found in milestone 2020.04.004.\n"},{"id":1366,"path":"../website/pages/docs/release-notes-version-2020.12.asciidoc.html#release-notes-version-2020.12.asciidoc_2020.04.003","type":"releasenote","title":"2020.04.003","body":"110.2.4. 2020.04.003\nMinor update with the following bugfixes and improvements:\n#395: variable from devon.properites unset if value is in double quotes\n#429: Added script to create a meta file in the users directory after setup\nThe full list of changes for this release can be found in milestone 2020.04.003.\n"},{"id":1367,"path":"../website/pages/docs/release-notes-version-2020.12.asciidoc.html#release-notes-version-2020.12.asciidoc_2020.04.002","type":"releasenote","title":"2020.04.002","body":"110.2.5. 2020.04.002\nMinor update with the following bugfixes and improvements:\n#418: Make projects optional\n#421: update devon4j to 2020.04.002\n#413: Update Eclipse to 2020-03\n#424: Strange errors on windows if devon.properties contains mixed line endings\n#399: launching of Intellij fails with No such file or directory error.\n#410: fix jsonmerge for boolean and null values\nThe full list of changes for this release can be found in milestone 2020.04.002.\n"},{"id":1368,"path":"../website/pages/docs/release-notes-version-2020.12.asciidoc.html#release-notes-version-2020.12.asciidoc_devon4j","type":"releasenote","title":"devon4j","body":"110.3. devon4j\nThe consolidated list of features for this devon4j release is as it follows.\n"},{"id":1369,"path":"../website/pages/docs/release-notes-version-2020.12.asciidoc.html#release-notes-version-2020.12.asciidoc_2020.12.001","type":"releasenote","title":"2020.12.001","body":"110.3.1. 2020.12.001\nNew release of devon4j with pluggable web security (CSRF starter) and CompletableFuture support for async REST service client as well as other improvements:\n#283: Support for CompletableFuture in async service client\n#307: Fix CSRF protection support\n#287: spring-boot update to 2.3.3\n#288: Update jackson to 2.11.2\n#293: Update owasp-dependency-check plugin version to 5.3.2\n#302: added guide for project/app structure\n#315: devon4j documentation correction\n#306: improve documentation to launch app\nDocumentation is available at devon4j guide 2020.12.001.\nThe full list of changes for this release can be found in milestone devon4j 2020.12.001.\n"},{"id":1370,"path":"../website/pages/docs/release-notes-version-2020.12.asciidoc.html#release-notes-version-2020.12.asciidoc_2020.08.001","type":"releasenote","title":"2020.08.001","body":"110.3.2. 2020.08.001\nNew release of devon4j with async REST service client support and other improvements:\n#279: support for async service clients\n#277: Update Security-Guide to recent OWASP Top (2017)\n#281: cleanup documentation\nDocumentation is available at devon4j guide 2020.08.001.\nThe full list of changes for this release can be found in milestone devon4j 2020.08.001.\n"},{"id":1371,"path":"../website/pages/docs/release-notes-version-2020.12.asciidoc.html#release-notes-version-2020.12.asciidoc_2020.04.002","type":"releasenote","title":"2020.04.002","body":"110.3.3. 2020.04.002\nMinor update of devon4j with the following bugfixes and small improvements:\n#261: JUnit4 backward compatibility\n#267: Fix JWT permission expansion\n#254: JWT Authentication support for devon4j-kafka\n#258: archetype is still lacking a .gitignore\n#273: Update libs\n#271: Do not enable resource filtering by default\n#255: Kafka: Support different retry configuration for different topics\nDocumentation is available at devon4j guide 2020.04.002.\nThe full list of changes for this release can be found in milestone devon4j 2020.04.002.\n"},{"id":1372,"path":"../website/pages/docs/release-notes-version-2020.12.asciidoc.html#release-notes-version-2020.12.asciidoc_devon4node","type":"releasenote","title":"devon4node","body":"110.4. devon4node\nNew devon4node version is published, the changes are:\nOn this release we have deprecated devon4node cli, now we use nest cli, and we have added a GraphQL sample.\n#375: GraphQL Sample.\n#257: D4N cli remove\n"},{"id":1373,"path":"../website/pages/docs/release-notes-version-2020.12.asciidoc.html#release-notes-version-2020.12.asciidoc_cobigen","type":"releasenote","title":"CobiGen","body":"110.5. CobiGen\nVarious bugfixes were made as well as consolidating behavior of eclipse vs maven vs cli by properly sharing more code across the different clients.\nAlso properly takes into account a files line delimiter instead of defaulting to those of the host system.\nCobiGen CLI v7.1.0\nCobiGen Maven Plug-in v7.1.0\nCobiGen Eclipse Plug-in v7.1.0\n"},{"id":1374,"path":"../website/pages/docs/release-notes-version-2020.12.asciidoc.html#release-notes-version-2020.12.asciidoc_templates","type":"releasenote","title":"Templates","body":"110.5.1. Templates\nRemoved environment.ts from the crud_angular_client_app/CRUD devon4ng Angular App increment since Cobigen did not make any changes in it\nRemoved cross referencing between template increments since there is currently no useful use case for it and it leads to a few problems\nv2020.12.001\n"},{"id":1375,"path":"../website/pages/docs/release-notes-version-2020.12.asciidoc.html#release-notes-version-2020.12.asciidoc_java-plug-in","type":"releasenote","title":"Java Plug-in","body":"110.5.2. Java Plug-in\nNow properly merges using the input files line delimiters instead of defaulting to those of the host system.\nv7.1.0\n"},{"id":1376,"path":"../website/pages/docs/release-notes-version-2020.12.asciidoc.html#release-notes-version-2020.12.asciidoc_typescript-plug-in","type":"releasenote","title":"TypeScript Plug-in","body":"110.5.3. TypeScript Plug-in\nFixed NPE Added the option to read a path from an object input\nv7.1.0\n"},{"id":1377,"path":"../website/pages/docs/release-notes-version-2020.12.asciidoc.html#release-notes-version-2020.12.asciidoc_property-plug-in","type":"releasenote","title":"Property Plug-in","body":"110.5.4. Property Plug-in\nNow properly merges using the input files line delimiters instead of defaulting to those of the host system.\nv7.1.0\n"},{"id":1378,"path":"../website/pages/docs/release-notes-version-2020.12.asciidoc.html#release-notes-version-2020.12.asciidoc_openapi-plug-in","type":"releasenote","title":"OpenAPI Plug-in","body":"110.5.5. OpenAPI Plug-in\nFixed an issue where nullable enums lead to errors\n7.1.0\n"},{"id":1379,"path":"../website/pages/docs/release-notes-version-2020.12.asciidoc.html#release-notes-version-2020.12.asciidoc_textmerger","type":"releasenote","title":"Textmerger","body":"110.5.6. Textmerger\nNow properly merges using the input files line delimiters instead of defaulting to those of the host system.\nv7.1.0\nv7.1.1\n"},{"id":1380,"path":"../website/pages/docs/release-notes-version-2020.12.asciidoc.html#release-notes-version-2020.12.asciidoc_sonar-devon4j-plugin","type":"releasenote","title":"Sonar devon4j plugin","body":"110.6. Sonar devon4j plugin\nWith this release, we made the package structure configurable and did some other improvements and fixes:\n#117: Rule from checkstyle plugin could not be instantiated in our quality profile\n#118: NPE during project analysis\n#97: Custom configuration for architecture\n#92: Display warnings on the &apos;devonfw&apos; config page in the &apos;Administration&apos; section of SonarQube\n#95: Add 3rd Party rule to avoid Immutable annotation from wrong package\n#94: Add 3rd Party rule to avoid legacy date types\n#93: Improve devonfw Java quality profile\n#114: Deleted unused architecture config from SonarQube settings to avoid confusion\nChanges for this release can be found in milestone 2020.12.001 and\nmilestone 2020.12.002\n"},{"id":1381,"path":"../website/pages/docs/release-notes-version-2020.12.asciidoc.html#release-notes-version-2020.12.asciidoc_devon4net","type":"releasenote","title":"devon4net","body":"110.7. devon4net\nThe consolidated list of features for devon4net is as follows:\nLiteDb: - Support for LiteDB - Provided basic repository for CRUD operations.\nRabbitMq: - Use of EasyQNet library to perform CQRS main functions between different microservices - Send commands / Subscribe queues with one C# sentence - Events management: Handled received commands to subscribed messages - Automatic messaging backup when sent and handled (Internal database via LiteDB and database backup via Entity Framework)\nMediatR: - Use of MediatR library to perform CQRS main functions in memory - Send commands / Subscribe queues with one C# sentence - Events management: Handled received commands to subscribed messages - Automatic messaging backup when sent and handled (Internal database via LiteDB and database backup via Entity Framework)\nSmaxHcm: - Component to manage Microfocus SMAX for cloud infrastructure services management\nCyberArk: - Manage safe credentials with CyberArk\nAnsibleTower: - Ansible automates the cloud infrastructure. devon4net integrates with Ansible Tower via API consumption endpoints\ngRPC+Protobuf: - Added Client + Server basic templates sample gRPC with Google&#x2019;s Protobuf protocol using devon4net\nKafka: - Added Apache Kafka support for deliver/consume messages and create/delete topics as well\nAWS support\nAWS Template to create serverless applications with auto generation of an APIGateway using AWS base template\nAWS template to create pure Lambda functions and manage SQS Events, SNS Events, Generic Events, CloudWatch, S3 Management, AWS Secrets management as a configuration provider in .NET life cycle\nAWS CDK integration component to create/manage AWS infrastructures (Infra As Code): Database, Database cluster, VPC, Secrets, S3 buckets, Roles&#x2026;\nMinor performance and stability improvements such Entity framework migration integration\nUpdated to the latest .net Core 3.1 TLS\n"},{"id":1382,"path":"../website/pages/docs/release-notes-version-2020.12.asciidoc.html#release-notes-version-2020.12.asciidoc_dashboard-beta-version","type":"releasenote","title":"dashboard (beta version)","body":"110.8. dashboard (beta version)\nWe are adding dashboard beta version as part of this release. Dashboard is a tool that allows you to create and manage devonfw projects.It makes it easy to onboard a new person with devonfw.\nDashboard list all ide available on user system or if no ide is availble it will provide option to download latest version of ide.\nProject creation and management: Project page list all projects created by user using dahboard. User will be able to create devon4j, devon4ng and devon4node projects using dashboard.\nSupport for Eclipse and VSCode IDE\nIntegrated devonfw-ide usage guide from the website\n"},{"id":1383,"path":"../website/pages/docs/release-notes-version-2020.12.asciidoc.html#release-notes-version-2020.12.asciidoc_solicitor","type":"releasenote","title":"Solicitor","body":"110.9. Solicitor\nSolicitor is a tool which helps managing Open Source Software used within projects. Below is consolidated feature list of solicitor:\nStandalone Command Line Java Tool\nImporters for component/license information from\nMaven\nGradle\nNPM\nCSV (e.g. for manual entry of data)\nRules processing (using Drools Rule Engine) controls the the different phases:\nNormalizing / Enhancing of license information\nHandling of multilicensing (including selection of applicable licenses) and re-licensing\nLegal evaluation\nRules to be defined as Decision Tables\nSample Decision Tables included\nAutomatic download and file based caching of license texts\nAllows manual editing / reformatting of license text\nOutput processing\nTemplate based text (Velocity) and XLS generation\nSQL based pre-processor (e.g. for filtering, aggregation)\nAudit log which documents all applied rules for every item might be included in report\n&quot;Diff Mode&quot; allows to mark data which has changed as compared to a previous run of Solicitor (in Velocity and XLS reporting)\nCustomization\nProject specific configuration (containing e.g. reporting templates, decision tables) allows to override/amend builtin configuration\nBuiltin configuration might be overridden/extended by configuration data contained in a single extension file (ZIP format)\nThis allows to safely provide organization specific rules and reporting templates to all projects of an organization (e.g. to reflect the specific OSS usage policy of the organization)\n"},{"id":1384,"path":"../website/pages/docs/release-notes-version-2020.12.asciidoc.html#release-notes-version-2020.12.asciidoc_mrchecker","type":"releasenote","title":"MrChecker","body":"110.10. MrChecker\nMrChecker Test Framework is an end to end test automation framework written in Java. It is an automated testing framework for functional testing of web applications, API web services, Service Virtualization, Security, native mobile apps and, in the near future, databases. All modules have tangible examples of how to build resilient integration test cases based on delivered functions. Below is consolidated list of updates in MrChecker:\nMigration of core module to junit5\nExtension of MrCheckers tests harness\nMigration of mrchecker-example-module to junit 5\nMigration guide https://devonfw.com/website/pages/docs/master-mrchecker.asciidoc_migration-from-junit4-to-junit5.html\nUpgrade to cucumber 6.7.0\nRelease of the 3.0.1 version to maven-central\n"},{"id":1385,"path":"../website/pages/docs/release-notes-version-2020.12.asciidoc.html#release-notes-version-2020.12.asciidoc_trainingstutorials","type":"releasenote","title":"Trainings/tutorials","body":"110.11. Trainings/tutorials\nKatakoda tutorials : https://katacoda.com/devonfw\nYoutube tutorials : https://www.youtube.com/channel/UCtb1p-24jus-QoXy49t9Xzg\n&#x2190;&#xA0;Previous:&#xA0;devonfw Release notes 2021.04&#xA0;| &#x2191;&#xA0;Up:&#xA0;Release Notes&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;devonfw Release notes 2020.08&#xA0;&#x2192;\n"},{"id":1386,"path":"../website/pages/docs/release-notes-version-2021.04.asciidoc.html#release-notes-version-2021.04.asciidoc","type":"releasenote","title":"devonfw Release notes 2021.04","body":"109. devonfw Release notes 2021.04\n"},{"id":1387,"path":"../website/pages/docs/release-notes-version-2021.04.asciidoc.html#release-notes-version-2021.04.asciidoc_introduction","type":"releasenote","title":"Introduction","body":"109.1. Introduction\nWe are proud to announce the release of devonfw version 2021.04.\nThis release includes lots of addition of new features, updates and bug fixes but it is very important to highlight the following improvements:\n"},{"id":1388,"path":"../website/pages/docs/release-notes-version-2021.04.asciidoc.html#release-notes-version-2021.04.asciidoc_devonfw-ide","type":"releasenote","title":"devonfw IDE","body":"109.2. devonfw IDE\nThe consolidated list of features for this devonfw IDE release is as it follows.\n"},{"id":1389,"path":"../website/pages/docs/release-notes-version-2021.04.asciidoc.html#release-notes-version-2021.04.asciidoc_2021.04.001","type":"releasenote","title":"2021.04.001","body":"109.2.1. 2021.04.001\nUpdate with the following bugfixes and improvements:\n#537: Update eclipse to 2021-03\n#287: Command autocompletion\n#536: Improve handling of aborted downloads\n#542: Support placeholders in settings.xml template\n#557: minimize setup by reducing DEVON_IDE_TOOLS\n#550: update maven to 3.8.1\n#545: update devon4j to 2021.04.002 and add migration\n#575: jasypt support for password encryption and decryption\n#546: Problems with tm-terminal Eclipse plugin\n#553: VSCode user-data-dir shall be part of workspace config\n#513: Configurable generation of IDE start scripts\nThe full list of changes for this release can be found in milestone 2021.04.001.\n"},{"id":1390,"path":"../website/pages/docs/release-notes-version-2021.04.asciidoc.html#release-notes-version-2021.04.asciidoc_devon4j","type":"releasenote","title":"devon4j","body":"109.3. devon4j\nThe consolidated list of features for this devon4j release is as it follows.\n"},{"id":1391,"path":"../website/pages/docs/release-notes-version-2021.04.asciidoc.html#release-notes-version-2021.04.asciidoc_2021.04.002","type":"releasenote","title":"2021.04.002","body":"109.4. 2021.04.002\nBugfix release of with the following stories:\n* #389: archetype build broken with ci-friendly-maven\n* #391: jasypt documentation improvements\n* #387: rebuild and updated diagram with drawio\nDocumentation is available at devon4j guide 2021.04.002.\nThe full list of changes for this release can be found in milestone devon4j 2020.04.002.\n"},{"id":1392,"path":"../website/pages/docs/release-notes-version-2021.04.asciidoc.html#release-notes-version-2021.04.asciidoc_2021.04.001","type":"releasenote","title":"2021.04.001","body":"109.4.1. 2021.04.001\nNew release of devon4j with fixes, updates and improvements:\n#370: Minor updates (spring-boot 2.4.4, jackson 2.12.2, CXF 3.4.3, etc.)\n#366: BaseTest.isInitialSetup() broken\n#85: ci-friendly-maven also for archetype\n#373: CORS starter not part of devon4j release\n#164: Flattened pom for core project invalid\n#323: Add spring integration test to archetype\n#351: improved error handling of service client\n#71: improve documentation for strong password encryption\n#354: JMS senders should not be part of data access layer, but logical layer\n#377: updated T-Architecture\n#294: integrate sonarcloud analysis into devon4j CI pipeline\nDocumentation is available at devon4j guide 2021.04.001.\nThe full list of changes for this release can be found in milestone devon4j 2020.04.001.\n"},{"id":1393,"path":"../website/pages/docs/release-notes-version-2021.04.asciidoc.html#release-notes-version-2021.04.asciidoc_devon4ng","type":"releasenote","title":"devon4ng","body":"109.5. devon4ng\nUpdated template and samples to Angular 11.\nUpdated guide of devon4ng.\n"},{"id":1394,"path":"../website/pages/docs/release-notes-version-2021.04.asciidoc.html#release-notes-version-2021.04.asciidoc_mrchecker","type":"releasenote","title":"MrChecker","body":"109.6. MrChecker\nMrChecker Test Framework is an end to end test automation framework written in Java. It is an automated testing framework for functional testing of web applications, API web services, Service Virtualization, Security, native mobile apps and, in the near future, databases. All modules have tangible examples of how to build resilient integration test cases based on delivered functions. Two new modules are added to MrChecker:\nDB Module - we have created a module intended to make testing efforts on DBs easier. It is founded on JPA in conjunction with Hibernate and therefore supports both high level, object based access to DB entities via the IDao interface and low level, native SQL commands via the EntityManager class .\nCLI Module - we have created a module intended to make testing command line applications like compilers or batches easier and faster. Huge success here is that, team using this solution was able to prepare a test suite, without app provided, basing only on documentation and using mocking technique.\n"},{"id":1395,"path":"../website/pages/docs/release-notes-version-2021.04.asciidoc.html#release-notes-version-2021.04.asciidoc_trainingstutorials","type":"releasenote","title":"Trainings/tutorials","body":"109.7. Trainings/tutorials\nKatakoda tutorials : https://katacoda.com/devonfw\nYoutube tutorials : https://www.youtube.com/channel/UCtb1p-24jus-QoXy49t9Xzg\n&#x2191;&#xA0;Up:&#xA0;Release Notes&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;devonfw Release notes 2020.12&#xA0;&#x2192;\n"},{"id":1396,"path":"../website/pages/docs/release-notes-version-3.0.asciidoc.html#release-notes-version-3.0.asciidoc","type":"releasenote","title":"devonfw Release notes 3.0 &#x201C;Fry&#x201D;","body":"115. devonfw Release notes 3.0 &#x201C;Fry&#x201D;\n"},{"id":1397,"path":"../website/pages/docs/release-notes-version-3.0.asciidoc.html#release-notes-version-3.0.asciidoc_introduction","type":"releasenote","title":"Introduction","body":"115.1. Introduction\nWe are proud to announce the immediate release of devonfw version 3.0 (code named &#x201C;Fry&#x201D; during development). This version is the consolidation of Open Source, focused on the major namespace change ever in the platform, removing the OASP references and adopting the new devonfw names for each technical stack or framework.\nThe new stack names are the following:\ndevon4j, former OASP4J, is the new name for Java.\ndevon4ng, former OASP4JS, is the new one for Angular.\ndevon4net, is the new .NET stack.\ndevon4X, is the new stack for Xamarin development.\ndevon4node, is the new devonfw incubator for node.js.\nThe new devon4j version was created directly from the latest oasp4j version (3.0.0). Hence it brings all the features and values that oasp4j offered. However, the namespace migration was used to do some housekeeping and remove deprecated code as well as reduce dependencies. Therefore your data-access layer will no longer have to depend on any third party except for devon4j as well as of course the JPA. We also have improved the application template that now comes with a modern JSON logging ready for docker and logstash based environments.\nTo help you upgrading we introduced a migration feature in devcon. This can automatically migrate your code from oasp4j (even older versions starting from 2.4.0) to the latest version of devon4j. There might be some small manual changes left to do but 90% of the migration will be done automatically for you.\nBesides, the first version of the devonfw plugin for SonarQube has been released. It extends SonarQube with the ability to validate your code according to the devon4j architecture. More details at https://github.com/devonfw/sonar-devon-plugin.\nThis is the first release that integrates the new devonfw .NET framework, called devon4net, and Xamarin for mobile native development, devon4X. devon4NET and devon4X are the Capgemini standard frameworks for .NET and Xamarin software development. With the two new family members devonfw provides guidance and acceleration for the major software development platforms in our industry. Their interoperability provides you the assurance your multichannel solution will be consistent across web and mobile channels.\n&#x201C;Fry&#x201D; release contains lots of improvements in our Mr.Checker E2E Testing Framework, including a complete E2E sample inside our reference application My Thai Star. Besides Mr.Checker, we include as an incubator Testar, a test tool (and framework) to test applications at the GUI level whose objective is to solve part of the maintenance problem affecting tests by automatically generating test cases based on a structure that is automatically derived from the GUI. Testar is not included to replace Mr.Checker but rather to provide development teams with a series of interesting options which go beyond what Mr.Checker already provides.\nApart from Mr.Checker, engagements can now use Testar as an extra option for testing. This is a tool that enables the automated system testing of desktop, web and mobile applications at the GUI level. Testar has been added as an incubator to the platform awaiting further development during 2019.\nThe new incubator for node.js, called devon4node, has been included and implemented in several internal projects. This incubator is based on the Nest framework https://www.nestjs.com/. Nest is a framework for building efficient, scalable Node.js server-side applications. It uses progressive JavaScript, is built with TypeScript (preserves compatibility with pure JavaScript) and combines elements of OOP (Object Oriented Programming), FP (Functional Programming), and FRP (Functional Reactive Programming). Under the hood, Nest makes use of Express, but also provides compatibility with a wide range of other libraries (e.g. Fastify). This allows for easy use of the myriad third-party plugins which are available.\nIn order to facilitate the utilization of Microsoft Visual Studio Code in devonfw, we have developed and included the new devonfw Platform Extension Pack with lots of features to develop and test applications with this IDE in languages and frameworks such as TypeScript, JavaScript, .NET, Java, Rust, C++ and many more. More information at https://marketplace.visualstudio.com/items?itemName=devonfw.devonfw-extension-pack. Also, you can contribute to this extension in this GitHub repository https://github.com/devonfw/devonfw-extension-pack-vscode.\nThere is a whole range of new features and improvements which can be seen in that light. The My Thai Star sample app has now been upgraded to devon4j and devon4ng, a new devon4node backend implementation has been included that is seamless interchangeable, an E2E MrChecker sample project, CICD and deployment scripts and lots of bugs have been fixed.\nLast but not least, the projects wikis and the devonfw Guide has once again been updated accordingly before the big refactor that will be addressed in the following release in 2019.\n"},{"id":1398,"path":"../website/pages/docs/release-notes-version-3.0.asciidoc.html#release-notes-version-3.0.asciidoc_changes-and-new-features","type":"releasenote","title":"Changes and new features","body":"115.2. Changes and new features\n"},{"id":1399,"path":"../website/pages/docs/release-notes-version-3.0.asciidoc.html#release-notes-version-3.0.asciidoc_devonfw-dist","type":"releasenote","title":"Devonfw dist","body":"115.2.1. Devonfw dist\nEclipse 2018.9 integrated\nCheckStyle Plugin updated.\nSonarLint Plugin updated.\nGit Plugin updated.\nFindBugs Plugin updated.\nCobiGen plugin updated.\nOther Software\nVisual Studio Code latest version included and pre-configured with the devonfw Platform Extension Pack.\nAnt updated to latest.\nMaven updated to latest.\nJava updated to latest.\nNodejs LTS updated to latest.\n@angular/cli included.\nYarn package manager updated.\nPython3 updated.\nSpyder3 IDE integrated in python3 installation updated.\ndevon4ng-application-template for Angular 7 at workspaces/examples\ndevon4ng-ionic-application-template for Ionic 3.20 at workspace/samples\n"},{"id":1400,"path":"../website/pages/docs/release-notes-version-3.0.asciidoc.html#release-notes-version-3.0.asciidoc_my-thai-star-sample-application","type":"releasenote","title":"My Thai Star Sample Application","body":"115.2.2. My Thai Star Sample Application\nThe new release of My Thai Star has focused on the following improvements:\nRelease 1.12.2.\ndevon4j:\ndevon4j 3.0.0 integrated.\nSpring Boot 2.0.4 integrated.\nSpring Data integration.\nNew pagination and search system.\nBug fixes.\ndevon4ng:\nClient devon4ng updated to Angular 7.\nAngular Material and Covalent UI frameworks updated.\nElectron framework integrated.\ndevon4node\nTypeScript 3.1.3.\nBased on Nest framework.\nAligned with devon4j.\nComplete backend implementation.\nTypeORM integrated with SQLite database configuration.\nWebpack bundler.\nNodemon runner.\nJest unit tests.\nMr.Checker\nExample cases for end-to-end test.\nProduction line configuration.\nCICD\nImproved integration with Production Line\nNew deployment from artifact\nNew CICD pipelines\nNew deployment pipelines\nAutomated creation of pipelines in Jenkins\n"},{"id":1401,"path":"../website/pages/docs/release-notes-version-3.0.asciidoc.html#release-notes-version-3.0.asciidoc_documentation-updates","type":"releasenote","title":"Documentation updates","body":"115.2.3. Documentation updates\nThe following contents in the devonfw guide have been updated:\nUpgrade of all the new devonfw named assets.\ndevon4j\ndevon4ng\nMr.Checker\nElectron integration cookbook.\nUpdated cookbook about Swagger.\nRemoved deprecated entries.\nApart from this the documentation has been reviewed and some typos and errors have been fixed.\nThe current development of the guide has been moved to https://github.com/devonfw-forge/devon-guide/wiki in order to be available as the rest of OSS assets.\n"},{"id":1402,"path":"../website/pages/docs/release-notes-version-3.0.asciidoc.html#release-notes-version-3.0.asciidoc_devon4j","type":"releasenote","title":"devon4j","body":"115.2.4. devon4j\nThe following changes have been incorporated in devon4j:\nSpring Boot 2.0.4 Integrated.\nSpring Data layer Integrated.\nDecouple mmm.util.*\nRemoved depreciated restaurant sample.\nUpdated Pagination support for Spring Data\nAdd support for hana as dbType.\nBugfixes.\n"},{"id":1403,"path":"../website/pages/docs/release-notes-version-3.0.asciidoc.html#release-notes-version-3.0.asciidoc_devon4ng","type":"releasenote","title":"devon4ng","body":"115.2.5. devon4ng\nThe following changes have been incorporated in devon4ng:\nNew client application architecture guide https://github.com/devonfw/devon4ng/wiki\nAngular CLI 7,\nAngular 7,\nAngular Material 7 and Covalent 2.0.0-beta.7,\nIonic 3.20.0,\nCordova 8.0.0,\ndevon4ng Angular application template updated to Angular 7 with visual improvements and bugfixes https://github.com/devonfw/devon4ng-application-template\ndevon4ng Ionic application template updated and improved https://github.com/devonfw/devon4ng-ionic-application-template\nPWA enabled.\nElectron integrated to run My Thai Star as a desktop application in Windows, Linux or macOS.\n"},{"id":1404,"path":"../website/pages/docs/release-notes-version-3.0.asciidoc.html#release-notes-version-3.0.asciidoc_devon4net","type":"releasenote","title":"devon4net","body":"115.2.6. devon4net\nSome of the highlights of devon4net 1.0 are:\nExternal configuration file for each environment.\n.NET Core 2.1.X working solution (Latest 2.1.402).\nPackages and solution templates published on nuget.org.\nFull components customization by config file.\nDocker ready (My Thai Star sample fully working on docker).\nPort specification by configuration.\nDependency injection by Microsoft .NET Core.\nAutomapper support.\nEntity framework ORM (Unit of work, async methods).\n.NET Standard library 2.0 ready.\nMulti-platform support: Windows, Linux, Mac.\nSamples: My Thai Star back-end, Google API integration, Azure login, AOP with Castle.\nDocumentation site.\nSPA page support.\nAnd included the following features:\nLogging:\nText File.\nSqlite database support.\nSerilog Seq Server support.\nGraylog integration ready through TCP/UDP/HTTP protocols.\nAPI Call params interception (simple and compose objects).\nAPI error exception management.\nSwagger:\nSwagger auto generating client from comments and annotations on controller classes.\nFull swagger client customization (Version, Title, Description, Terms, License, Json endpoint definition).\nJWT:\nIssuer, audience, token expiration customization by external file configuration.\nToken generation via certificate.\nMVC inherited classes to access JWT user properties.\nAPI method security access based on JWT Claims.\nCORS:\nSimple CORS definition ready.\nMultiple CORS domain origin definition with specific headers and verbs.\nHeaders:\nAutomatic header injection with middleware.\nSupported header definitions: AccessControlExposeHeader, StrictTransportSecurityHeader, XFrameOptionsHeader, XssProtectionHeader, XContentTypeOptionsHeader, ContentSecurityPolicyHeader, PermittedCrossDomainPoliciesHeader, ReferrerPolicyHeader.\nReporting server:\nPartial implementation of reporting server based on My-FyiReporting (now runs on linux container).\nTesting:\nIntegration test template with sqlite support.\nUnit test template.\nMoq, xunit frameworks integrated.\n"},{"id":1405,"path":"../website/pages/docs/release-notes-version-3.0.asciidoc.html#release-notes-version-3.0.asciidoc_devon4x","type":"releasenote","title":"devon4X","body":"115.2.7. devon4X\nSome of the highlights of the new devonfw Xamarin framework are:\nBased on Excalibur framework by Hans Harts (https://github.com/Xciles/Excalibur).\nUpdated to latest MVVMCross 6 version.\nMy Thai Star Excalibur forms sample.\nXamarin Forms template available on nuget.org.\n"},{"id":1406,"path":"../website/pages/docs/release-notes-version-3.0.asciidoc.html#release-notes-version-3.0.asciidoc_appsec-quick-solution-guide","type":"releasenote","title":"AppSec Quick Solution Guide","body":"115.2.8. AppSec Quick Solution Guide\nThis release incorporates a new Solution Guide for Application Security based on the state of the art in OWASP based application security. The purpose of this guide is to offer quick solutions for common application security issues for all applications based on devonfw. It&#x2019;s often the case that we need our systems to comply to certain sets of security requirements and standards. Each of these requirements needs to be understood, addressed and converted to code or project activity. We want this guide to prevent the wheel from being reinvented over and over again and to give clear hints and solutions to common security problems.\nThe wiki can be accessed here: https://github.com/devonfw/devonfw-security/wiki\nThe PDF can be accessed here: https://github.com/devonfw/devonfw-security\n"},{"id":1407,"path":"../website/pages/docs/release-notes-version-3.0.asciidoc.html#release-notes-version-3.0.asciidoc_cobigen","type":"releasenote","title":"CobiGen","body":"115.2.9. CobiGen\nCobiGen core new features:\nCobiGen_Templates will not need to be imported into the workspace anymore. However, If you want to adapt them, you can still click on a button that automatically imports them for you.\nCobiGen_Templates can be updated by one-click whenever the user wants to have the latest version.\nAdded the possibility to reference external increments on configuration level. This is used for reducing the number of duplicated templates.\nCobiGen_Templates project and docs updated:\nSpring standard has been followed better than ever.\nInterface templates get automatically relocated to the api project. Needed for following the new devon4j standard.\nCobiGen Angular:\nAngular 7 generation improved based on the updated application template.\nPagination changed to fit Spring standard.\nCobiGen Ionic: Pagination changed to fit Spring standard.\nCobiGen OpenAPI plugin released with multiple bug-fixes and other functionalities like:\nResponse and parameter types are parsed properly when they are a reference to an entity.\nParameters defined on the body of a request are being read correctly.\n"},{"id":1408,"path":"../website/pages/docs/release-notes-version-3.0.asciidoc.html#release-notes-version-3.0.asciidoc_devcon","type":"releasenote","title":"Devcon","body":"115.2.10. Devcon\nA new version of Devcon has been released. Fixes and new features include:\nUpdated to match current devon4j\nUpdate to download Linux distribution.\nCustom modules creation improvements.\nCode Migration feature added\nBugfixes.\n"},{"id":1409,"path":"../website/pages/docs/release-notes-version-3.0.asciidoc.html#release-notes-version-3.0.asciidoc_devonfw-oss-modules","type":"releasenote","title":"Devonfw OSS Modules","body":"115.2.11. Devonfw OSS Modules\nModules upgraded to be used in new devon4j projects:\nReporting module\nWinAuth AD Module\nWinAuth SSO Module\nI18n Module\nAsync Module\nIntegration Module\nMicroservice Module\nCompose for Redis Module\nSee: https://github.com/devonfw/devon/wiki#devonfw-modules\n"},{"id":1410,"path":"../website/pages/docs/release-notes-version-3.0.asciidoc.html#release-notes-version-3.0.asciidoc_devonfw-testing","type":"releasenote","title":"Devonfw Testing","body":"115.2.12. Devonfw Testing\nMr.Checker\nThe Mr.Checker Test Framework is an automated testing framework for functional testing of web applications, API web services, Service Virtualization, Security and in coming future native mobile apps, and databases. All modules have tangible examples of how to build resilient integration test cases based on delivered functions. Mr.Checker updates and improvements:\nExamples available under embedded project &#x201C;MrChecker-App-Under-Test&#x201D; and in project wiki: https://github.com/devonfw/devonfw-testing/wiki\nHow to install:\nWiki : https://github.com/devonfw/devonfw-testing/wiki/How-to-install\nRelease Note:\nmodule selenium - 3.8.1.13:\nheadless browser\nenable browser options\nmodule DevOps :\nJenkinsfile align with ProductionLine\nTestar\nWe have added Test*, Testar, as an incubator to the available test tools within devonfw. This ground-breaking tool is being developed by the Technical University of Valencia (UPV). In 2019 Capgemini will co-develop Testar with the UPV.\nTestar is a tool that enables the automated system testing of desktop, web and mobile applications at the GUI level.\nWith Testar, you can start testing immediately. It automatically generates and executes test sequences based on a structure that is automatically derived from the UI through the accessibility API. Testar can detect the violation of general-purpose system requirements and you can use plugins to customize your tests.\nYou do not need test scripts and maintenance of it. The tests are random and are generated and executed automatically.\nIf you need to do directed tests you can create scripts to test specific requirements of your application.\nTestar is included in the devonfw distro or can be downloaded from https://testar.org/download/.\nThe Github repository can be found at o: https://github.com/TESTARtool/TESTAR.\n&#x2190;&#xA0;Previous:&#xA0;devonfw Release notes 3.1 &#x201C;Goku&#x201D;&#xA0;| &#x2191;&#xA0;Up:&#xA0;Release Notes&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;devonfw Release notes 2.4 &#x201C;EVE&#x201D;&#xA0;&#x2192;\n"},{"id":1411,"path":"../website/pages/docs/release-notes-version-3.1.asciidoc.html#release-notes-version-3.1.asciidoc","type":"releasenote","title":"devonfw Release notes 3.1 &#x201C;Goku&#x201D;","body":"114. devonfw Release notes 3.1 &#x201C;Goku&#x201D;\n"},{"id":1412,"path":"../website/pages/docs/release-notes-version-3.1.asciidoc.html#release-notes-version-3.1.asciidoc_introduction","type":"releasenote","title":"Introduction","body":"114.1. Introduction\nWe are proud to announce the immediate release of devonfw version 3.1 (code named &#x201C;Goku&#x201D; during development). This version is the first one that implements our new documentation workflow, that will allow users to get the updated documentation at any moment and not to wait for the next devonfw release.\nThis is now possible as we have established a new workflow and rules during development of our assets. The idea behind this is that all the repositories contain a documentation folder and, in any pull request, the developer must include the related documentation change. A new Travis CI configuration added to all these repositories will automatically take the changes and publish them in the wiki section of every repository and in the new devonfw-guide repository that consolidates all the changes from all the repositories. Another pipeline will take changes from this consolidated repository and generate dynamically the devonfw guide in PDF and in the next weeks in HTML for the new planned devonfw website. The following schema explains this process:\nThis release includes the very first version of the new CobiGen CLI. Now using commands, you will be able to generate code the same way as you do with Eclipse. This means that you can use CobiGen on other IDEs like Visual Studio Code or IntelliJ. Please take a look at https://github.com/devonfw/cobigen/wiki/howto_Cobigen-CLI-generation for more info.\nThe devonfw-shop-floor project has got a lot of updates in order to make even easier the creation of devonfw projects with CICD pipelines that run on the Production Line, deploy on Red Hat OpenShift Clusters and in general Docker environments. See the details below.\nThis release includes the very first version of our devonfw-ide tool that will allow users to automate devonfw setup and update the development environment. This tool will become the default devonfw setup tool in future releases. For more information please visit the repository https://github.com/devonfw/devon-ide.\nFollowing the same collaboration model we used in order to improve the integration of devonfw with Red Hat OpenShift and which allowed us to get the Red Hat Open Shift Primed certification, we have been working alongside with SAP HANA developers in order to support this database in the devon4j. This model was based on the contribution and review of pull requests in our reference application My Thai Star. In this case, SAP developers collaborated with us in the following two new use cases:\nPrediction of future demand\nGeospatial analysis and clustering of customers\nMore info at https://blogs.sap.com/2019/06/17/introducing-devonfw-support-for-sap-hana/.\nLast but not least the devonfw extension pack for VS Code has been improved with the latest extensions and helpers for this IDE. Among many others you can now use:\nRemote development on Docker containers and VMs https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.vscode-remote-extensionpack\nDependency Analysis for maven and npm https://marketplace.visualstudio.com/items?itemName=redhat.fabric8-analytics\nReact Native Tools https://marketplace.visualstudio.com/items?itemName=msjsdiag.vscode-react-native\nNgRx Snippets https://marketplace.visualstudio.com/itemdetails?itemName=hardikpthv.NgRxSnippets\nAlso it is worth the try of the updated support for Java and Spring Boot development in VS Code. Check it out for yourself!\nMore information at https://marketplace.visualstudio.com/items?itemName=devonfw.devonfw-extension-pack. Also, you can contribute to this extension in this GitHub repository https://github.com/devonfw/devonfw-extension-pack-vscode.\n"},{"id":1413,"path":"../website/pages/docs/release-notes-version-3.1.asciidoc.html#release-notes-version-3.1.asciidoc_changes-and-new-features","type":"releasenote","title":"Changes and new features","body":"114.2. Changes and new features\n"},{"id":1414,"path":"../website/pages/docs/release-notes-version-3.1.asciidoc.html#release-notes-version-3.1.asciidoc_devonfw-dist","type":"releasenote","title":"Devonfw dist","body":"114.2.1. Devonfw dist\nEclipse 2018.12 integrated\nCheckStyle Plugin updated.\nSonarLint Plugin updated.\nGit Plugin updated.\nFindBugs Plugin updated.\nCobiGen plugin updated.\nOther Software\nVisual Studio Code latest version included and pre-configured with the devonfw Platform Extension Pack.\nAnt updated to latest.\nMaven updated to latest.\nJava updated to latest.\nNodejs LTS updated to latest.\n@angular/cli included.\n@devonfw/cicdgen included.\nYarn package manager updated.\nPython3 updated.\nSpyder3 IDE integrated in python3 installation updated.\ndevon4ng-application-template for Angular 8 at workspaces/examples\ndevon4ng-ionic-application-template for Ionic 4 at workspace/samples\n"},{"id":1415,"path":"../website/pages/docs/release-notes-version-3.1.asciidoc.html#release-notes-version-3.1.asciidoc_my-thai-star-sample-application","type":"releasenote","title":"My Thai Star Sample Application","body":"114.2.2. My Thai Star Sample Application\nThe new release of My Thai Star has focused on the following improvements:\nRelease 3.1.0.\ndevon4j:\ndevon4j 3.1.0 integrated.\nSpring Boot 2.1.6 integrated.\nSAP 4/HANA prediction use case.\nBug fixes.\ndevon4ng:\nSAP 4/HANA prediction use case.\n2FA toggleable (two factor authentication).\nNgRx integration in process (PR #234).\ndevon4node\nTypeScript 3.1.3.\nBased on Nest framework.\nAligned with devon4j.\nComplete backend implementation.\nTypeORM integrated with SQLite database configuration.\nWebpack bundler.\nNodemon runner.\nJest unit tests.\nMr.Checker\nExample cases for end-to-end test.\nProduction line configuration.\nCICD\nImproved integration with Production Line\nNew Traefik load balancer and reverse proxy\nNew deployment from artifact\nNew CICD pipelines\nNew deployment pipelines\nAutomated creation of pipelines in Jenkins\n"},{"id":1416,"path":"../website/pages/docs/release-notes-version-3.1.asciidoc.html#release-notes-version-3.1.asciidoc_documentation-updates","type":"releasenote","title":"Documentation updates","body":"114.2.3. Documentation updates\nThis release addresses the new documentation workflow, being now possible to keep the documentation synced with any change. The new documentation includes the following contents:\nGetting started\nContribution guide\nDevcon\nRelease notes\ndevon4j documentation\ndevon4ng documentation\ndevon4net documentation\ndevonfw-shop-floor documentation\ncicdgen documentation\ndevonfw testing with MrChecker\nMy Thai Star documentation\n"},{"id":1417,"path":"../website/pages/docs/release-notes-version-3.1.asciidoc.html#release-notes-version-3.1.asciidoc_devon4j","type":"releasenote","title":"devon4j","body":"114.2.4. devon4j\nThe following changes have been incorporated in devon4j:\nAdded Support for Java8 up to Java11\nUpgrade to Spring Boot 2.1.6.\nUpgrade to Spring 5.1.8\nUpgrade to JPA 2.2\nUpgrade to Hibernate 5.3\nUpgrade to Dozer 6.4.1 (ATTENTION: Requires Migration, use devon-ide for automatic upgrade)\nMany improvements to documentation (added JDK guide, architecture-mapping, JMS, etc.)\nCompleted support (JSON, Beanmapping) for pagination, IdRef, and java.time\nAdded MasterCto\nFor all details see milestone.\n"},{"id":1418,"path":"../website/pages/docs/release-notes-version-3.1.asciidoc.html#release-notes-version-3.1.asciidoc_devon4ng","type":"releasenote","title":"devon4ng","body":"114.2.5. devon4ng\nThe following changes have been incorporated in devon4ng:\nAngular CLI 8,\nAngular 8,\nAngular Material 8,\nIonic 4,\nCapacitor 1.0 as Cordova replacement,\nNgRx 8 support for State Management,\ndevon4ng Angular application template updated to Angular 8 with visual improvements and bugfixes https://github.com/devonfw/devon4ng-application-template\ndevon4ng Ionic application template updated and improved https://github.com/devonfw/devon4ng-ionic-application-template\nNew devon4ng Angular application template with state management using Angular 8 and NgRx 8 https://github.com/devonfw/devon4ng-ngrx-template\nNew devon4ng library https://github.com/devonfw/devon4ng-library that includes the following libraries:\nCache Module for Angular 7+ projects.\nAuthorization Module for Angular 7+ projects.\nNew use cases with documentation and samples:\nWeb Components with Angular Elements\nInitial configuration with App Initializer pattern\nError Handling\nPWA with Angular and Ionic\nLazy Loading\nLibrary construction\nLayout with Angular Material\nTheming with Angular Material\n"},{"id":1419,"path":"../website/pages/docs/release-notes-version-3.1.asciidoc.html#release-notes-version-3.1.asciidoc_devon4net","type":"releasenote","title":"devon4net","body":"114.2.6. devon4net\nThe following changes have been incorporated in devon4net:\nNew circuit breaker component to communicate microservices via HTTP\nResolved the update packages issue\n"},{"id":1420,"path":"../website/pages/docs/release-notes-version-3.1.asciidoc.html#release-notes-version-3.1.asciidoc_appsec-quick-solution-guide","type":"releasenote","title":"AppSec Quick Solution Guide","body":"114.2.7. AppSec Quick Solution Guide\nThis release incorporates a new Solution Guide for Application Security based on the state of the art in OWASP based application security. The purpose of this guide is to offer quick solutions for common application security issues for all applications based on devonfw. It&#x2019;s often the case that we need our systems to comply to certain sets of security requirements and standards. Each of these requirements needs to be understood, addressed and converted to code or project activity. We want this guide to prevent the wheel from being reinvented over and over again and to give clear hints and solutions to common security problems.\nThe wiki can be accessed here: https://github.com/devonfw/devonfw-security/wiki\nThe PDF can be accessed here: https://github.com/devonfw/devonfw-security\n"},{"id":1421,"path":"../website/pages/docs/release-notes-version-3.1.asciidoc.html#release-notes-version-3.1.asciidoc_cobigen","type":"releasenote","title":"CobiGen","body":"114.2.8. CobiGen\nCobiGen core new features:\nCobiGen CLI: New command line interface for CobiGen. Using commands, you will be able to generate code the same way as you do with Eclipse. This means that you can use CobiGen on other IDEs like Visual Studio Code or IntelliJ. Please take a look into the documentation for more info.\nPerformance improves greatly in the CLI thanks to the lack of GUI.\nYou will be able to use path globs for selecting multiple input files.\nWe have implemented a search functionality so that you can easily search for increments or templates.\nFirst steps taken on CobiGen refactoring: With the new refactoring we will be able to decouple CobiGen completely from the target and input language. This will facilitate the creation of parsers and mergers for any language.\nNashornJS has been deprecated: It was used for executing JavaScript code inside JVM. With the refactoring, performance has improved on the TypeScript merger.\nImproving CobiGen templates:\nRemoved Covalent from Angular templates as it is not compatible with Angular 8.\nAdded devon4ng-NgRx templates that implement reactive state management. Note: The TypeScript merger is currently being improved in order to accept NgRx. The current templates are set as overridable by default.\nTest data builder templates now make use of Lambdas and Consumers.\nCTOs and ETOs increments have been correctly separated.\nTypeScript merger has been improved: Now it is possible to merge comments (like tsdoc) and enums.\nOpenAPI parsing extended to read enums. Also fixed some bugs when no properties were set or when URLs were too short.\nJava static and object initializers now get merged.\nFixed bugs when downloading and adapting templates.\n"},{"id":1422,"path":"../website/pages/docs/release-notes-version-3.1.asciidoc.html#release-notes-version-3.1.asciidoc_devcon","type":"releasenote","title":"Devcon","body":"114.2.9. Devcon\nA new version of Devcon has been released. Fixes and new features include:\nUpdated to match current devon4j\nUpdate to download Linux distribution.\nCustom modules creation improvements.\nCode Migration feature added.\nBugfixes.\n"},{"id":1423,"path":"../website/pages/docs/release-notes-version-3.1.asciidoc.html#release-notes-version-3.1.asciidoc_devonfw-oss-modules","type":"releasenote","title":"Devonfw OSS Modules","body":"114.2.10. Devonfw OSS Modules\nModules upgraded to be used in new devon4j projects:\nReporting module\nWinAuth AD Module\nWinAuth SSO Module\nI18n Module\nAsync Module\nIntegration Module\nMicroservice Module\nCompose for Redis Module\nSee: https://github.com/devonfw/devon/wiki#devonfw-modules\n"},{"id":1424,"path":"../website/pages/docs/release-notes-version-3.1.asciidoc.html#release-notes-version-3.1.asciidoc_devonfw-shop-floor","type":"releasenote","title":"devonfw shop floor","body":"114.2.11. devonfw shop floor\nIndustrialization oriented to configure the provisioning environment provided by Production Line and deploy applications on an OpenShift cluster.\nAdded Jenkinsfiles to configure automatically OpenShift environments to deploy devonfw applications.\nIndustrialization to start new projects and configure them with CICD.\nUpgrade the documentation with getting started guide to configure CICD in any devonfw project and deploy it.\nAdded new tool cicdgen to generate CICD code/files.\ncicdgen\ncicdgen is a devonfw tool to generate all code/files related to CICD in your project. It&#x2019;s based on angular schematics and it has its own CLI.\nMore information here.\nCICD configuration for devon4j, devon4ng and devon4node projects\nOption to deploy devonfw projects with Docker\nOption to deploy devonfw projects with OpenShift\n"},{"id":1425,"path":"../website/pages/docs/release-notes-version-3.1.asciidoc.html#release-notes-version-3.1.asciidoc_devonfw-testing","type":"releasenote","title":"Devonfw Testing","body":"114.2.12. Devonfw Testing\nMr.Checker\nThe Mr.Checker Test Framework is an automated testing framework for functional testing of web applications, API web services, Service Virtualization, Security and in coming future native mobile apps, and databases. All modules have tangible examples of how to build resilient integration test cases based on delivered functions. Mr.Checker updates and improvements:\nExamples available under embedded project &#x201C;MrChecker-App-Under-Test&#x201D; and in project wiki: https://github.com/devonfw/devonfw-testing/wiki\nHow to install:\nWiki : https://github.com/devonfw/devonfw-testing/wiki/How-to-install\nRelease Note:\nmodule selenium - 3.8.2.1:\npossibility to define version of driver in properties.file\nautomatic driver download if the version is not specified\npossibility to run with different browser options\nmodule webAPI &#x2013; 1.2.1:\npossibility to connect to the remote WireMock server\n&#x2190;&#xA0;Previous:&#xA0;devonfw Release notes 3.2 &#x201C;Homer&#x201D;&#xA0;| &#x2191;&#xA0;Up:&#xA0;Release Notes&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;devonfw Release notes 3.0 &#x201C;Fry&#x201D;&#xA0;&#x2192;\n"},{"id":1426,"path":"../website/pages/docs/release-notes-version-3.2.asciidoc.html#release-notes-version-3.2.asciidoc","type":"releasenote","title":"devonfw Release notes 3.2 &#x201C;Homer&#x201D;","body":"113. devonfw Release notes 3.2 &#x201C;Homer&#x201D;\n"},{"id":1427,"path":"../website/pages/docs/release-notes-version-3.2.asciidoc.html#release-notes-version-3.2.asciidoc_introduction","type":"releasenote","title":"Introduction","body":"113.1. Introduction\nWe are proud to announce the immediate release of devonfw version 3.2 (code named &#x201C;Homer&#x201D; during development). This version is the first one that contains the new devonfw IDE by default, so there is no need to download a huge ZIP with the whole distribution regardless of the use to which it will be put. The new devonfw IDE CLI will allow any user to setup a customized development environment completely configured with access to all the devonfw features, frameworks and tools. As we access to the official IDEs this is also the first version macOS compatible.\nThis release consolidates the documentation workflow adding the contents dynamically to the new devonfw website at the same time the PDF is generated. This have been achieved using a new GitHub action that takes the contents and builds the HTML files for the documentation section of the website. The documentation workflow proposed in the following picture is now complete:\nThis release also includes the first version of devon4node. We consider that node.js should be a first-class citizen inside the devonfw platform and for that reason we have included the latest development technologies for this ecosystem. The devon4node CLI, schematics and other tools will allow our users to create powerful node.js applications with the same philosophy you may find in the other languages and frameworks included. More information at its section below.\nThe new devon4net 3.2.0 version is also included in this release. Based on the .NET Core 3.0 and containing lots of new features gathered from important and recent projects, it represents a great improvement and an intermediate step to provide support for the incoming .NET Core 3.1 LTS. More information at its section below.\nThis release includes the final version of the new CobiGen CLI and completely integrated with the new devonfw IDE. Now using commands, you will be able to generate code the same way as you do with Eclipse. This means that you can use CobiGen on other IDEs like Visual Studio Code or IntelliJ. Besides the Update command has been implemented. Now you will be able to update easily all your CobiGen plug-ins and templates inside the CLI.\nOn the other hand, the refactoring process has been completely developed, improving the mergers and including input readers for any other languages and frameworks, allowing the creation of models to generate code from them. Last, but not least, this new version includes the new templates for devon4net, devon4ng and devon4j generation.\nAnd as always, My Thai Star has been updated to the latest versions of devon4j, devon4node and devon4net including completely State Management with NgRx in its devon4ng implementation upgrade.\nThis is the last release with the current semantic versioning number and without a fixed release calendar. From now on the new devonfw releases will happen in April, August and December and will be named YYYY.MM.NN, being the first release of the next year the 2020.04.00.\n"},{"id":1428,"path":"../website/pages/docs/release-notes-version-3.2.asciidoc.html#release-notes-version-3.2.asciidoc_changes-and-new-features","type":"releasenote","title":"Changes and new features","body":"113.2. Changes and new features\n"},{"id":1429,"path":"../website/pages/docs/release-notes-version-3.2.asciidoc.html#release-notes-version-3.2.asciidoc_devonfw-ide","type":"releasenote","title":"devonfw-ide","body":"113.2.1. devonfw-ide\nWe have entirely rewritten our automated solution for your local IDE (integrated desktop environment). The former oasp4j-ide and devonfw distributions with their extra-large gigabyte zip files are not entirely replaced with devonfw-ide. This new solution is provided as a small *.tar.gz file that is publicly available. It works on all platforms and has been tested on Windows, MacOS, and Linux. After extraction you only need to run a setup script. Here you provide a settings git URL for your customer project or simply hit return for testing or small projects. After reading and confirming the terms of use it will download all required tools in the proper versions for your operating system and configure them. Instead of various confusing scripts there is now only one CLI command devon for all use-cases what gives a much better user experience.\nTo get started go to the home page. There is even a migration-guide if you are currently used to the old approach and want to quickly jump into the new solution.\n"},{"id":1430,"path":"../website/pages/docs/release-notes-version-3.2.asciidoc.html#release-notes-version-3.2.asciidoc_my-thai-star-sample-application","type":"releasenote","title":"My Thai Star Sample Application","body":"113.2.2. My Thai Star Sample Application\nThe new release of My Thai Star has focused on the following improvements:\nRelease 3.2.0.\ndevon4j:\ndevon4j 3.2.0 integrated.\nSpring Boot 2.1.9 integrated.\nSAP 4/HANA prediction use case.\nBug fixes.\ndevon4ng:\nSAP 4/HANA prediction use case.\n2FA toggleable (two factor authentication).\nNgRx full integrated (PR #285).\ndevon4net\ndevon4net for dotnet core 3.0 updated\nUpdated the API contract compatible with the other stacks\nJWT implementation reviewed to increase security\nASP.NET user database dependencies removed\nHTTP2 support\nClearer CRUD pattern implementation\ndevon4node\nTypeScript 3.6.3.\nBased on Nest framework.\nConfiguration Module\nAdded cors and security headers\nAdded mailer module and email templates.\nBuilt in winston logger\nCustom ClassSerializerInterceptor\nMrChecker\nExample cases for end-to-end test.\nProduction line configuration.\nCICD\nImproved integration with Production Line\nNew Traefik load balancer and reverse proxy\nNew deployment from artifact\nNew CICD pipelines\nNew deployment pipelines\nAutomated creation of pipelines in Jenkins\n"},{"id":1431,"path":"../website/pages/docs/release-notes-version-3.2.asciidoc.html#release-notes-version-3.2.asciidoc_documentation-updates","type":"releasenote","title":"Documentation updates","body":"113.2.3. Documentation updates\nThis release addresses the new documentation workflow, being now possible to keep the documentation synced with any change. The new documentation includes the following contents:\nGetting started\ndevonfw ide\ndevon4j documentation\ndevon4ng documentation\ndevon4net documentation\ndevon4node documentation\nCobiGen documentation\ndevonfw-shop-floor documentation\ncicdgen documentation\ndevonfw testing with MrChecker\nMy Thai Star documentation\nContribution guide\nRelease notes\n"},{"id":1432,"path":"../website/pages/docs/release-notes-version-3.2.asciidoc.html#release-notes-version-3.2.asciidoc_devon4j","type":"releasenote","title":"devon4j","body":"113.2.4. devon4j\nThe following changes have been incorporated in devon4j:\nCompleted full support from Java8 to Java11\nSeveral security fixes\nUpgrade to Spring Boot 2.1.9\nUpgrade to Spring 5.1.8\nUpgrade to JUnit 5 (requires migration via devonfw-ide)\nImproved JPA support for IdRef\nImproved auditing metadata support\nMany improvements to documentation (added JDK guide, architecture-mapping, JMS, etc.)\nFor all details see milestone.\n"},{"id":1433,"path":"../website/pages/docs/release-notes-version-3.2.asciidoc.html#release-notes-version-3.2.asciidoc_devon4ng","type":"releasenote","title":"devon4ng","body":"113.2.5. devon4ng\nThe following changes have been incorporated in devon4ng:\nAngular CLI 8.3.1,\nAngular 8.2.11,\nAngular Material 8.2.3,\nIonic 4.11.1,\nCapacitor 1.2.1 as Cordova replacement,\nNgRx 8.3 support for State Management,\ndevon4ng Angular application template updated to Angular 8.2.11 with visual improvements and bugfixes https://github.com/devonfw/devon4ng-application-template\ndevon4ng Ionic application template updated to 4.11.1 and improved https://github.com/devonfw/devon4ng-ionic-application-template\nImproved devon4ng Angular application template with state management using Angular 8 and NgRx 8 https://github.com/devonfw/devon4ng-ngrx-template\nDocumentation and samples updated to latest versions:\nWeb Components with Angular Elements\nInitial configuration with App Initializer pattern\nError Handling\nPWA with Angular and Ionic\nLazy Loading\nLibrary construction\nLayout with Angular Material\nTheming with Angular Material\n"},{"id":1434,"path":"../website/pages/docs/release-notes-version-3.2.asciidoc.html#release-notes-version-3.2.asciidoc_devon4net","type":"releasenote","title":"devon4net","body":"113.2.6. devon4net\nThe following changes have been incorporated in devon4net:\nUpdated to latest .net core 3.0 version\nTemplate\nGlobal configuration automated. devon4net can be instantiated on any .net core application template with no effort\nAdded support for HTTP2\nNumber of libraries minimized\nArchitecture layer review. More clear and scalable\nAdded red button functionality (aka killswitch) to stop attending API request with custom error\nImproved API error management\nAdded support to only accept request from clients with a specific client certificate on Kestrel server. Special thanks to Bart Roozendaal (Capgemini NL)\nAll components use IOptions pattern to be set up properly\nSwagger generation compatible with OpenAPI v3\nModules\nThe devon4net netstandard libraries have been updated to netstandard 2.1\nJWT:\nAdded token encryption (token cannot be decrypted anymore by external parties). Now You can choose the encryption algorithm depending on your needs\nAdded support for secret key or certificate encryption\nAdded authorization for swagger portal\nCircuit breaker\nAdded support to bypass certificate validation\nAdded support to use a certificate for https communications using Microsoft&#x2019;s httpclient factory\nUnit of Work\nRepository classes unified and reviewed for increasing performance and reduce the consumed memory\nAdded support for different database servers: In memory, Cosmos, MySQL + MariaDB, Firebird, PostgreSQL, Oracle, SQLite, Access, MS Local.\n"},{"id":1435,"path":"../website/pages/docs/release-notes-version-3.2.asciidoc.html#release-notes-version-3.2.asciidoc_devon4node","type":"releasenote","title":"devon4node","body":"113.2.7. devon4node\nThe following changes have been incorporated in devon4node:\nTypeScript 3.6.3.\nBased on Nest framework.\nComplete backend implementation.\nNew devon4node CLI. It will provide you some commands\nnew: create a new devon4node interactively\ngenerate: generate code based on schematics\ndb: manage the database\nNew devon4node schematics\napplication: create a new devon4node application\nconfig-module: add a configuration module to the project\nmailer: install and configure the devon4node mailer module\ntypeorm: install TypeORM in the project\nauth-jwt: add users and auth-jwt modules to the project\nswagger: expose an endpoint with the auto-generated swagger\nsecurity: add cors and other security headers to the project.\ncrud: create all CRUD for an entity\nentity: create an entity\nNew mailer module\nNew common library\nBuild in winston logger\nCustom ClassSerializerInterceptor\nExtendable base entity\nNew application samples\n"},{"id":1436,"path":"../website/pages/docs/release-notes-version-3.2.asciidoc.html#release-notes-version-3.2.asciidoc_cobigen","type":"releasenote","title":"CobiGen","body":"113.2.8. CobiGen\nCobiGen core new features:\nCobiGen CLI: Update command implemented. Now you will be able to update easily all your CobiGen plug-ins and templates inside the CLI. Please take a look into the documentation for more info.\nCobiGen CLI is now JDK11 compatible.\nCobiGen CLI commandlet for devonfw-ide has been added. You can use it to setup easily your CLI and to run CobiGen related commands.\nAdded a version provider so that you will be able to know all the CobiGen plug-ins versions.\nAdded a process bar when the CLI is downloading the CobiGen plug-ins.\nCobiGen refactoring finished: With this refactoring we have been able to decouple CobiGen completely from the target and input language. This facilitates the creation of parsers and mergers for any language. For more information please take a look here.\nNew TypeScript input reader: We are now able to parse any TypeScript class and generate code using the parsed information. We currently use TypeORM entities as a base for generation.\nImproving CobiGen templates:\nUpdated devon4ng-NgRx templates to NgRx 8.\nGeneration of an Angular client using as input a TypeORM entity. This is possible thanks to the new TypeScript input reader.\n.Net templates have been upgraded to .Net Core 3.0\nCobiGen for Eclipse is now JDK11 compatible.\nFixed bugs when adapting templates and other bugs on the CobiGen core.\n"},{"id":1437,"path":"../website/pages/docs/release-notes-version-3.2.asciidoc.html#release-notes-version-3.2.asciidoc_devonfw-shop-floor","type":"releasenote","title":"devonfw shop floor","body":"113.2.9. devonfw shop floor\nAdded devon4ng OpenShift templates\nAdded devon4j OpenShift templates\nAdded devon4node OpenShift templates\nAdded more methods to link https://github.com/devonfw-forge/devon-production-line-shared-lib [devonfw Production Line shared library]\nUpdated link: devonfw Production Line templates\ncicdgen\nPatched minor bugs\n"},{"id":1438,"path":"../website/pages/docs/release-notes-version-3.2.asciidoc.html#release-notes-version-3.2.asciidoc_sonar-devon4j-plugin","type":"releasenote","title":"sonar-devon4j-plugin","body":"113.2.10. sonar-devon4j-plugin\nsonar-devon4j-plugin is a SonarQube plugin for architecture governance of devon4j applications. It verifies the architecture and conventions of devon4j, the Java stack of devonfw. The following changes have been incorporated:\n* Plugin was renamed from sonar-devon-plugin to sonar-devon4j-plugin\n* Rules/checks have been added to verify naming conventions\n* New rule for proper JPA datatype mapping\n* Proper tagging of rules as architecture-violation and not as bug, etc.\n* Several improvements have been made to prepare the plugin to enter the SonarQube marketplace, what will happen with the very next release.\n* Details can be found here: https://github.com/devonfw/sonar-devon4j-plugin/milestone/2?closed=1\n&#x2190;&#xA0;Previous:&#xA0;devonfw Release notes 2020.04&#xA0;| &#x2191;&#xA0;Up:&#xA0;Release Notes&#xA0;| &#x2302;&#xA0;Home:&#xA0;devonfw guide&#xA0;| Next:&#xA0;devonfw Release notes 3.1 &#x201C;Goku&#x201D;&#xA0;&#x2192;\n"},{"id":1439,"path":"../website/pages/explore/explore.html#/way-of-working","type":"explore","title":"Way of Working","body":""},{"id":1440,"path":"../website/pages/explore/explore.html#/way-of-working/working-method","type":"explore","title":"Working Method","body":""},{"id":1441,"path":"../website/pages/explore/explore.html#/way-of-working/working-method/agile","type":"explore","title":"Agile","body":""},{"id":1442,"path":"../website/pages/explore/explore.html#/way-of-working/working-method/agile/scrum","type":"explore","title":"Scrum","body":"Scrum as a process is completely valid to be applied. devonfw does not make any prescriptions in regards to the process."},{"id":1443,"path":"../website/pages/explore/explore.html#/way-of-working/working-method/agile/xp","type":"explore","title":"XP","body":"Generally devonfw and XP can be used together."},{"id":1444,"path":"../website/pages/explore/explore.html#/way-of-working/working-method/agile/kanban","type":"explore","title":"Kanban","body":"Kanban as a process is completely valid to be applied. devonfw does not make any prescriptions in regards to the process."},{"id":1445,"path":"../website/pages/explore/explore.html#/way-of-working/working-method/agile/accelerated-solution-design","type":"explore","title":"Accelerated Solution Design","body":""},{"id":1446,"path":"../website/pages/explore/explore.html#/way-of-working/working-method/agile/safe","type":"explore","title":"SAFe","body":"Generally devonfw and SAFe can be used together."},{"id":1447,"path":"../website/pages/explore/explore.html#/way-of-working/working-method/waterfall","type":"explore","title":"Waterfall","body":"Generally devonfw and waterfall can be used together."},{"id":1448,"path":"../website/pages/explore/explore.html#/way-of-working/working-method/testing-methodologies","type":"explore","title":"Testing Methodologies","body":""},{"id":1449,"path":"../website/pages/explore/explore.html#/way-of-working/working-method/testing-methodologies/tdd","type":"explore","title":"TDD","body":"Generally devonfw and TDD can be used together."},{"id":1450,"path":"../website/pages/explore/explore.html#/way-of-working/working-method/testing-methodologies/automation","type":"explore","title":"Automation","body":""},{"id":1451,"path":"../website/pages/explore/explore.html#/way-of-working/working-method/testing-methodologies/e2e","type":"explore","title":"E2E","body":""},{"id":1452,"path":"../website/pages/explore/explore.html#/way-of-working/community","type":"explore","title":"Community","body":""},{"id":1453,"path":"../website/pages/explore/explore.html#/way-of-working/community/contributions","type":"explore","title":"Contributions","body":""},{"id":1454,"path":"../website/pages/explore/explore.html#/way-of-working/community/contributions/github","type":"explore","title":"GitHub","body":""},{"id":1455,"path":"../website/pages/explore/explore.html#/way-of-working/community/collaboration","type":"explore","title":"Collaboration","body":""},{"id":1456,"path":"../website/pages/explore/explore.html#/way-of-working/community/collaboration/microsoft-teams","type":"explore","title":"Microsoft Teams","body":""},{"id":1457,"path":"../website/pages/explore/explore.html#/way-of-working/community/collaboration/devonfw-shop-floor","type":"explore","title":"devonfw-shop-floor","body":"devonfw shop floor is a platform to industrialize continuous delivery and continuous integration processes.devonfw shop floor is a set of documentation, tools and methodologies used to configure the provisioning, development and uat environments used in your projects. devonfw shop floor allows the administrators of those environments to apply CI/CD operations and enables automated application deployment.devonfw shop floor is mainly oriented to configure the provisioning environment provided by Production Line and deploy applications on an OpenShift cluster. In the cases where Production Line or OpenShift cluster are not available, there will be alternatives to achieve similar goals.The devonfw shop floor 4 OpenShift is a solution based on the experience of priming devonfw for OpenShift by RedHat."},{"id":1458,"path":"../website/pages/explore/explore.html#/way-of-working/community/feedback-channel","type":"explore","title":"Feedback Channel","body":""},{"id":1459,"path":"../website/pages/explore/explore.html#/way-of-working/community/feedback-channel/yammer","type":"explore","title":"Yammer","body":""},{"id":1460,"path":"../website/pages/explore/explore.html#/macro-architecture","type":"explore","title":"Macro Architecture","body":""},{"id":1461,"path":"../website/pages/explore/explore.html#/macro-architecture/general-architecture-paradigm","type":"explore","title":"General Architecture Paradigm","body":""},{"id":1462,"path":"../website/pages/explore/explore.html#/macro-architecture/general-architecture-paradigm/structured-system","type":"explore","title":"Structured System","body":""},{"id":1463,"path":"../website/pages/explore/explore.html#/macro-architecture/general-architecture-paradigm/structured-system/layers","type":"explore","title":"Layers","body":""},{"id":1464,"path":"../website/pages/explore/explore.html#/macro-architecture/communication-schemas-and-messaging","type":"explore","title":"Communication Schemas and Messaging","body":""},{"id":1465,"path":"../website/pages/explore/explore.html#/macro-architecture/communication-schemas-and-messaging/sync-standards-(rpc)","type":"explore","title":"Sync Standards (RPC)","body":""},{"id":1466,"path":"../website/pages/explore/explore.html#/macro-architecture/communication-schemas-and-messaging/sync-standards-(rpc)/rest","type":"explore","title":"REST","body":""},{"id":1467,"path":"../website/pages/explore/explore.html#/macro-architecture/communication-schemas-and-messaging/sync-standards-(rpc)/soap","type":"explore","title":"SOAP","body":""},{"id":1468,"path":"../website/pages/explore/explore.html#/macro-architecture/communication-schemas-and-messaging/async-messaging","type":"explore","title":"Async Messaging","body":""},{"id":1469,"path":"../website/pages/explore/explore.html#/macro-architecture/communication-schemas-and-messaging/async-messaging/kafka","type":"explore","title":"Kafka","body":""},{"id":1470,"path":"../website/pages/explore/explore.html#/macro-architecture/communication-schemas-and-messaging/async-middleware","type":"explore","title":"Async Middleware","body":""},{"id":1471,"path":"../website/pages/explore/explore.html#/macro-architecture/communication-schemas-and-messaging/versioning-of-apis","type":"explore","title":"Versioning of APIs","body":""},{"id":1472,"path":"../website/pages/explore/explore.html#/micro-architecture","type":"explore","title":"Micro Architecture","body":""},{"id":1473,"path":"../website/pages/explore/explore.html#/micro-architecture/architectural","type":"explore","title":"Architectural","body":""},{"id":1474,"path":"../website/pages/explore/explore.html#/micro-architecture/architectural/architectural-patterns","type":"explore","title":"Architectural Patters","body":""},{"id":1475,"path":"../website/pages/explore/explore.html#/micro-architecture/architectural/architectural-patterns/jee","type":"explore","title":"JEE","body":""},{"id":1476,"path":"../website/pages/explore/explore.html#/micro-architecture/architectural/databases","type":"explore","title":"Databases","body":""},{"id":1477,"path":"../website/pages/explore/explore.html#/micro-architecture/architectural/databases/central-database","type":"explore","title":"Central Database","body":""},{"id":1478,"path":"../website/pages/explore/explore.html#/micro-architecture/architectural/databases/relational-database","type":"explore","title":"Relational Database","body":""},{"id":1479,"path":"../website/pages/explore/explore.html#/micro-architecture/architectural/databases/relational-database/oracle","type":"explore","title":"Oracle","body":""},{"id":1480,"path":"../website/pages/explore/explore.html#/micro-architecture/technological","type":"explore","title":"Technological","body":""},{"id":1481,"path":"../website/pages/explore/explore.html#/micro-architecture/technological/database-technology-providers-products","type":"explore","title":"Database Technology/Providers/Products","body":""},{"id":1482,"path":"../website/pages/explore/explore.html#/micro-architecture/technological/database-technology-providers-products/entityframework","type":"explore","title":"EntityFramework","body":""},{"id":1483,"path":"../website/pages/explore/explore.html#/micro-architecture/technological/database-technology-providers-products/typeorm","type":"explore","title":"TypeORM","body":""},{"id":1484,"path":"../website/pages/explore/explore.html#/micro-architecture/technological/client-technology-frameworks","type":"explore","title":"Client Technology/Frameworks","body":""},{"id":1485,"path":"../website/pages/explore/explore.html#/micro-architecture/technological/client-technology-frameworks/angular","type":"explore","title":"Angular","body":"devonfw provides a solution to building applications which combine best-in-class frameworks and libraries as well as industry proven practices and code conventions. It massively speeds up development, reduces risks and helps you to deliver better results.This document contains links to devon4ng, the Angular stack of devonfw."},{"id":1486,"path":"../website/pages/explore/explore.html#/micro-architecture/technological/server-technology-frameworks","type":"explore","title":"Server Technology/Frameworks","body":""},{"id":1487,"path":"../website/pages/explore/explore.html#/micro-architecture/technological/server-technology-frameworks/iis","type":"explore","title":"IIS","body":""},{"id":1488,"path":"../website/pages/explore/explore.html#/micro-architecture/technological/server-technology-frameworks/spring-boot","type":"explore","title":"spring-boot","body":""},{"id":1489,"path":"../website/pages/explore/explore.html#/micro-architecture/technological/server-technology-frameworks/net-core","type":"explore","title":".NET Core","body":""},{"id":1490,"path":"../website/pages/explore/explore.html#/micro-architecture/technological/server-technology-frameworks/nestjs","type":"explore","title":"NestJS","body":""},{"id":1491,"path":"../website/pages/explore/explore.html#/micro-architecture/technological/server-technology-frameworks/nodejs","type":"explore","title":"Node.js","body":"devon4node is the NodeJS stack of devonfw. It allows you to build business applications (backends) using NodeJS technology in standardized way based on established best-practices.devon4node is based on NestJS. Nest (NestJS) is a framework for building efficient, scalable Node.js server-side applications. It uses progressive TypeScript and combines elements of OOP (Object Oriented Programming), FP (Functional Programming), and FRP (Functional Reactive Programming)."},{"id":1492,"path":"../website/pages/explore/explore.html#/micro-architecture/technological/testing","type":"explore","title":"Testing","body":""},{"id":1493,"path":"../website/pages/explore/explore.html#/micro-architecture/technological/testing/unittesting","type":"explore","title":"UnitTesting","body":""},{"id":1494,"path":"../website/pages/explore/explore.html#/micro-architecture/technological/testing/mr-checker","type":"explore","title":"Mr Checker","body":""},{"id":1495,"path":"../website/pages/explore/explore.html#/micro-architecture/technological/programming-concepts","type":"explore","title":"Programming Concepts","body":""},{"id":1496,"path":"../website/pages/explore/explore.html#/micro-architecture/technological/programming-concepts/dependency-injection","type":"explore","title":"Dependency Injection","body":""},{"id":1497,"path":"../website/pages/explore/explore.html#/micro-architecture/technological/programming-language","type":"explore","title":"Programming Language","body":""},{"id":1498,"path":"../website/pages/explore/explore.html#/micro-architecture/technological/programming-language/java","type":"explore","title":"Java","body":"devonfw provides a solution to building applications which combine best-in-class frameworks and libraries as well as industry proven practices and code conventions. It massively speeds up development, reduces risks and helps you to deliver better results.This document contains links to devon4j, the Java stack of devonfw."},{"id":1499,"path":"../website/pages/explore/explore.html#/micro-architecture/technological/programming-language/net","type":"explore","title":".NET","body":"devonfw provides a solution to building applications which combine best-in-class frameworks and libraries as well as industry proven practices and code conventions. It massively speeds up development, reduces risks and helps you to deliver better results.This document links to devon4net, the .NET stack of devonfw."},{"id":1500,"path":"../website/pages/explore/explore.html#/micro-architecture/technological/programming-language/javascript","type":"explore","title":"JavaScript","body":""},{"id":1501,"path":"../website/pages/explore/explore.html#/operational-architecture","type":"explore","title":"Operational Architecture","body":""},{"id":1502,"path":"../website/pages/explore/explore.html#/operational-architecture/ci-cd-pipeline-products-integrations-concepts","type":"explore","title":"CI CD Pipeline","body":""},{"id":1503,"path":"../website/pages/explore/explore.html#/operational-architecture/ci-cd-pipeline-products-integrations-concepts/jenkins","type":"explore","title":"Jenkins","body":"Continuous integration and continuous delivery environment. Jenkins is used to build and test your applications to assure their quality."},{"id":1504,"path":"../website/pages/explore/explore.html#/operational-architecture/ci-cd-pipeline-products-integrations-concepts/ci-cd","type":"explore","title":"CI/CD","body":"cicdgen is a devonfw tool for generate all code/files related to CICD. It will include/modify into your project all files that the project needs run a Jenkins cicd pipeline, to create a docker image based on your project, etc. Its based on angular schematics, so you can add it as a dependency into your project and generate the code using ng generate. In addition, it has its own CLI for those projects that are not angular based."},{"id":1505,"path":"../website/pages/explore/explore.html#/operational-architecture/management-distribution","type":"explore","title":"Management/Distribution","body":""},{"id":1506,"path":"../website/pages/explore/explore.html#/operational-architecture/management-distribution/docker","type":"explore","title":"Docker","body":""},{"id":1507,"path":"../website/pages/explore/explore.html#/operational-architecture/management-distribution/kubernetes","type":"explore","title":"Kubernetes","body":""},{"id":1508,"path":"../website/pages/explore/explore.html#/operational-architecture/management-distribution/openshift","type":"explore","title":"OpenShift","body":""},{"id":1509,"path":"../website/pages/explore/explore.html#/operational-architecture/monitoring-logging","type":"explore","title":"Monitoring/Logging","body":""},{"id":1510,"path":"../website/pages/explore/explore.html#/operational-architecture/monitoring-logging/graylog","type":"explore","title":"Graylog","body":""},{"id":1511,"path":"../website/pages/explore/explore.html#/operational-architecture/security-compliance","type":"explore","title":"Security/Compliance","body":""},{"id":1512,"path":"../website/pages/explore/explore.html#/operational-architecture/security-compliance/sonarqube","type":"explore","title":"SonarQube","body":""},{"id":1513,"path":"../website/pages/explore/explore.html#/accelerators","type":"explore","title":"Accelerators","body":""},{"id":1514,"path":"../website/pages/explore/explore.html#/accelerators/cobigen","type":"explore","title":"CobiGen","body":"CobiGen is a generic incremental generator for end to end code generation tasks, mostly used in Java projects. Due to a template-based approach, CobiGen generates any set of text-based documents and document fragments."},{"id":1515,"path":"../website/pages/explore/explore.html#/accelerators/ide","type":"explore","title":"devonfw IDE","body":"The devon-ide is a fantastic tool to automatically download, install, setup and update the IDE (integrated development environment) of your software development projects."},{"id":1516,"path":"../website/pages/explore/explore.html#/accelerators/solicitor","type":"explore","title":"Solicitor","body":"Solicitor is an open source tool for analyzing licenses of all maven dependencies or npm dependencies and automatically generates proper output in an excel file for further manual processing or an html document for reporting."},{"id":1517,"path":"../website/pages/explore/explore.html#/samples","type":"explore","title":"Samples","body":""},{"id":1518,"path":"../website/pages/explore/explore.html#/samples/jump-the-queue","type":"explore","title":"Jump the Queue","body":""},{"id":1519,"path":"../website/pages/explore/explore.html#/samples/my-thai-star","type":"explore","title":"My-Thai-Star","body":""},{"id":1520,"path":"https://www.katacoda.com/devonfw/scenarios/JumpTheQueue","type":"tutorial","title":"Jump start an end-to-end devonfw sample application.","body":"Jump start an end-to-end devonfw sample application.\r\n\n\n\nThe definition of each step of this tutorial can be found at https://github.com/devonfw-tutorials/tutorials/tree/main/JumpTheQueue. \n\nFeel free to report any errors to us or fix them yourself. Errors can be reported by creating an issue in the https://github.com/devonfw-tutorials/tutorials/issues[tutorials repository]. To fix the error fork the repository and create a pull request. Errors in the wiki can be reported and fixed in the https://github.com/devonfw-tutorials/tutorial-compiler[Tutorial-compiler repository].\nYou can find a description of what to look for when creating a pull request at the devonfw contribution guide: https://devonfw.com/website/pages/community/community.html#community.asciidoc_contributing-to-devonfw. If you want to create a tutorial you can start with the https://katacoda.com/devonfw/scenarios/create-your-own-tutorial[katacoda tutorial] and read the description for creating your own tutorials: https://github.com/devonfw-tutorials/tutorials/wiki/Development.\n\nJump The Queue is a small application based on the devonfw framework, which you can create yourself by following our simple step-by-step tutorial. By doing so, you will learn about the app development workflow and gain insight into the design of a professional business information system.\n\n\n#\n## Prerequisites\n\n* User should have Java, Angular development experience\n\n\n#\n## Learning goals\n\n* After completing this tutorial, you will have learned about a devonfw sample application Jump-The-Queue and its architecture. \n\nMore information about Jump The Queue on https://github.com/devonfw/jump-the-queue\n"},{"id":1521,"path":"https://www.katacoda.com/devonfw/scenarios/create-your-own-tutorial","type":"tutorial","title":"Create your own tutorial","body":"Create your own tutorial\r\nIn this scenario, you will learn how to create your own tutorial using the tutorial compiler.\n\n## Prerequisites\n* GitHub account\n\n## Learning goals\n* You will learn how to set up the environment and get an introduction to the syntax for writing your own tutorial.\n\nYou can find the documentation of the tutorial compiler here:\n\nhttps://github.com/devonfw-forge/tutorial-compiler/wiki\n\n\n\nThe definition of each step of this tutorial can be found at https://github.com/devonfw-tutorials/tutorials/tree/main/create-your-own-tutorial. \n\nFeel free to report any errors to us or fix them yourself. Errors can be reported by creating an issue in the https://github.com/devonfw-tutorials/tutorials/issues[tutorials repository]. To fix the error fork the repository and create a pull request. Errors in the wiki can be reported and fixed in the https://github.com/devonfw-tutorials/tutorial-compiler[Tutorial-compiler repository].\nYou can find a description of what to look for when creating a pull request at the devonfw contribution guide: https://devonfw.com/website/pages/community/community.html#community.asciidoc_contributing-to-devonfw. If you want to create a tutorial you can start with the https://katacoda.com/devonfw/scenarios/create-your-own-tutorial[katacoda tutorial] and read the description for creating your own tutorials: https://github.com/devonfw-tutorials/tutorials/wiki/Development.\n\n"},{"id":1522,"path":"https://www.katacoda.com/devonfw/scenarios/devon4j-app","type":"tutorial","title":"Generate your Java application with devon4j","body":"Generate your Java application with devon4j\r\ndevon4j is the Java stack of devonfw. It allows you to build business applications (backends) using Java technology in a highly efficient and standardized way based on established best-practices.\n\n## Prerequisites\n* User should have Java development experience\n\n## Learning goals\nAfter completing this scenario, you will have learned how to generate Java application using devon4j.\n\nMore information about devon4j on https://devonfw.com/website/pages/docs/devon4j.asciidoc.html\n\n\n\n\nThe definition of each step of this tutorial can be found at https://github.com/devonfw-tutorials/tutorials/tree/main/devon4j-app. \n\nFeel free to report any errors to us or fix them yourself. Errors can be reported by creating an issue in the https://github.com/devonfw-tutorials/tutorials/issues[tutorials repository]. To fix the error fork the repository and create a pull request. Errors in the wiki can be reported and fixed in the https://github.com/devonfw-tutorials/tutorial-compiler[Tutorial-compiler repository].\nYou can find a description of what to look for when creating a pull request at the devonfw contribution guide: https://devonfw.com/website/pages/community/community.html#community.asciidoc_contributing-to-devonfw. If you want to create a tutorial you can start with the https://katacoda.com/devonfw/scenarios/create-your-own-tutorial[katacoda tutorial] and read the description for creating your own tutorials: https://github.com/devonfw-tutorials/tutorials/wiki/Development.\n\n"},{"id":1523,"path":"https://www.katacoda.com/devonfw/scenarios/devon4j-architecture","type":"tutorial","title":"devon4j architecture in practice","body":"devon4j architecture in practice\r\n## Prerequisites\n\nJava programming knowledge\n\n## Learning goals\n\nThis tutorial aims to explain concepts and principles of devon4j architecture with help of an sample application named JumpTheQueue. Below are the steps we will go through to understand it clearly.\n\n* Clone JumpTheQueue repository\n* Understand devon4j application structure \n* Understand Key and architectural principles followed by devon4j\n* Understand devon4j application architecture\n\nBy end of this tutorial you will have detailed understanding of principles followed by devon4j application as well as its structure and architecture. \n\n\n\n\nThe definition of each step of this tutorial can be found at https://github.com/devonfw-tutorials/tutorials/tree/main/devon4j-architecture. \n\nFeel free to report any errors to us or fix them yourself. Errors can be reported by creating an issue in the https://github.com/devonfw-tutorials/tutorials/issues[tutorials repository]. To fix the error fork the repository and create a pull request. Errors in the wiki can be reported and fixed in the https://github.com/devonfw-tutorials/tutorial-compiler[Tutorial-compiler repository].\nYou can find a description of what to look for when creating a pull request at the devonfw contribution guide: https://devonfw.com/website/pages/community/community.html#community.asciidoc_contributing-to-devonfw. If you want to create a tutorial you can start with the https://katacoda.com/devonfw/scenarios/create-your-own-tutorial[katacoda tutorial] and read the description for creating your own tutorials: https://github.com/devonfw-tutorials/tutorials/wiki/Development.\n\n"},{"id":1524,"path":"https://www.katacoda.com/devonfw/scenarios/devon4j-http-rest-client","type":"tutorial","title":"Develop a devon4j CXF REST Client using Synchronous call","body":"Develop a devon4j CXF REST Client using Synchronous call\r\n\n\n\nThe definition of each step of this tutorial can be found at https://github.com/devonfw-tutorials/tutorials/tree/main/devon4j-http-rest-client. \n\nFeel free to report any errors to us or fix them yourself. Errors can be reported by creating an issue in the https://github.com/devonfw-tutorials/tutorials/issues[tutorials repository]. To fix the error fork the repository and create a pull request. Errors in the wiki can be reported and fixed in the https://github.com/devonfw-tutorials/tutorial-compiler[Tutorial-compiler repository].\nYou can find a description of what to look for when creating a pull request at the devonfw contribution guide: https://devonfw.com/website/pages/community/community.html#community.asciidoc_contributing-to-devonfw. If you want to create a tutorial you can start with the https://katacoda.com/devonfw/scenarios/create-your-own-tutorial[katacoda tutorial] and read the description for creating your own tutorials: https://github.com/devonfw-tutorials/tutorials/wiki/Development.\n\nREST (REpresentational State Transfer) is an inter-operable protocol for services that is more lightweight than SOAP. We give best practices that lead to simple, easy and pragmatic &#34;HTTP APIs&#34;.\r\n\r\n\n## Prerequisites\r\n\n* User should have development experience in JAVA.\r\n\n* Basic knowledge of REST.\r\n\r\n\n## Learning Goal\r\nHere in this tutorial you will learn the following things:\r\n\n* JAX-RS standard for REST service implementation proposed by devonfw.\r\n\n* How to create REST client with devon4j using Synchronous call.\r\n\r\nLet&#39;s get started!!\r\n"},{"id":1525,"path":"https://www.katacoda.com/devonfw/scenarios/devon4j-migrate","type":"tutorial","title":"Migrate a devon4j project to the latest version","body":"Migrate a devon4j project to the latest version\r\n\n\n\nThe definition of each step of this tutorial can be found at https://github.com/devonfw-tutorials/tutorials/tree/main/devon4j-migrate. \n\nFeel free to report any errors to us or fix them yourself. Errors can be reported by creating an issue in the https://github.com/devonfw-tutorials/tutorials/issues[tutorials repository]. To fix the error fork the repository and create a pull request. Errors in the wiki can be reported and fixed in the https://github.com/devonfw-tutorials/tutorial-compiler[Tutorial-compiler repository].\nYou can find a description of what to look for when creating a pull request at the devonfw contribution guide: https://devonfw.com/website/pages/community/community.html#community.asciidoc_contributing-to-devonfw. If you want to create a tutorial you can start with the https://katacoda.com/devonfw/scenarios/create-your-own-tutorial[katacoda tutorial] and read the description for creating your own tutorials: https://github.com/devonfw-tutorials/tutorials/wiki/Development.\n\nThis tutorial mainly focuses on migrating an older version of devon4j project to the latest version using devon4j migrate command.\r\n\r\n\r\n\n## Prerequisites\r\n\n* devonfw IDE\r\n\r\n\n## Learning goals.\r\nHere in this tutorial you will learn \r\n\n* How to migrate an older version of devon4j project to the latest version.\r\n"},{"id":1526,"path":"https://www.katacoda.com/devonfw/scenarios/devon4ng-architecture","type":"tutorial","title":"devon4ng architecture","body":"devon4ng architecture\r\n## Prerequisites\n\nBasic Angular knowledge\n\n## Learning goals\n\nThis tutorial aims to explain concepts and principles of devon4ng architecture by refering an Angular application template. Below are the steps we will go through to understand it clearly.\n\n* Understand Angular architectural terminology (components and modules)\n* Different layers of an Angular application\n* Different types of modules - feature, core, shared\n\nYou will be refering a devon4ng application while going through the theoretical aspects of the tutorial.\n\nBy end of this tutorial you will have detailed understanding of principles followed by devon4ng application as well as its structure and architecture. \n\n\n\n\nThe definition of each step of this tutorial can be found at https://github.com/devonfw-tutorials/tutorials/tree/main/devon4ng-architecture. \n\nFeel free to report any errors to us or fix them yourself. Errors can be reported by creating an issue in the https://github.com/devonfw-tutorials/tutorials/issues[tutorials repository]. To fix the error fork the repository and create a pull request. Errors in the wiki can be reported and fixed in the https://github.com/devonfw-tutorials/tutorial-compiler[Tutorial-compiler repository].\nYou can find a description of what to look for when creating a pull request at the devonfw contribution guide: https://devonfw.com/website/pages/community/community.html#community.asciidoc_contributing-to-devonfw. If you want to create a tutorial you can start with the https://katacoda.com/devonfw/scenarios/create-your-own-tutorial[katacoda tutorial] and read the description for creating your own tutorials: https://github.com/devonfw-tutorials/tutorials/wiki/Development.\n\n"},{"id":1527,"path":"https://www.katacoda.com/devonfw/scenarios/devon4ng-mat-layout","type":"tutorial","title":"Create an Angular application with Angular Material components using devon4ng","body":"Create an Angular application with Angular Material components using devon4ng\r\n\n\n\nThe definition of each step of this tutorial can be found at https://github.com/devonfw-tutorials/tutorials/tree/main/devon4ng-mat-layout. \n\nFeel free to report any errors to us or fix them yourself. Errors can be reported by creating an issue in the https://github.com/devonfw-tutorials/tutorials/issues[tutorials repository]. To fix the error fork the repository and create a pull request. Errors in the wiki can be reported and fixed in the https://github.com/devonfw-tutorials/tutorial-compiler[Tutorial-compiler repository].\nYou can find a description of what to look for when creating a pull request at the devonfw contribution guide: https://devonfw.com/website/pages/community/community.html#community.asciidoc_contributing-to-devonfw. If you want to create a tutorial you can start with the https://katacoda.com/devonfw/scenarios/create-your-own-tutorial[katacoda tutorial] and read the description for creating your own tutorials: https://github.com/devonfw-tutorials/tutorials/wiki/Development.\n\nThe purpose of this tutorial is to get a basic understanding of creating layouts using Angular Material in a devon4ng application. You will create an application with a header containing some menu links and a sidenav with some navigation links.\n\n\n#\n## Prerequisites\n\n* Basic Angular knowledge\n\n\n#\n## Learning goals\nIn this tutorial you will learn how to:\n\n* create an Angular application using the devon command\n\n* add Angular Material to the application\n\n* import Angular Material components into your modules\n\n* use Material icons in the application\n\n* use a prebulit theme to style the application\n\n* create layout (containing a header with menu along with a sidenav with navigational links) with the Angular Material components\n"},{"id":1528,"path":"https://www.katacoda.com/devonfw/scenarios/devonfw-ide","type":"tutorial","title":"Bootstrap your devonfw development environment","body":"Bootstrap your devonfw development environment\r\n\n\n\nThe definition of each step of this tutorial can be found at https://github.com/devonfw-tutorials/tutorials/tree/main/devonfw-ide. \n\nFeel free to report any errors to us or fix them yourself. Errors can be reported by creating an issue in the https://github.com/devonfw-tutorials/tutorials/issues[tutorials repository]. To fix the error fork the repository and create a pull request. Errors in the wiki can be reported and fixed in the https://github.com/devonfw-tutorials/tutorial-compiler[Tutorial-compiler repository].\nYou can find a description of what to look for when creating a pull request at the devonfw contribution guide: https://devonfw.com/website/pages/community/community.html#community.asciidoc_contributing-to-devonfw. If you want to create a tutorial you can start with the https://katacoda.com/devonfw/scenarios/create-your-own-tutorial[katacoda tutorial] and read the description for creating your own tutorials: https://github.com/devonfw-tutorials/tutorials/wiki/Development.\n\ndevonfw offers complete IDE solution integrated with a lot of integrated tooling and initial settings. \nIt massively speeds up development, reduces risks and helps deliver better results.\n\n\n#\n## Prerequisites\n\n* User should have a prior experience with Eclipse or any IDE. \n\n\n#\n## Learning goals\n\n* After completing this scenario, you will have learned how to install devonfw development environment i.e., the devonfw IDE.\n\n\nMore information about devonfw IDE can be found on https://devonfw.com/website/pages/docs/devonfw-ide-introduction.asciidoc.html\n"},{"id":1529,"path":"../website/pages/architectures/solutions/authentication/index.html","type":"solution","title":"Authentication","body":"\nAuthentication\nAccess control is an important aspect for the security in IT application landscapes. There are two different aspects to distinguish:\nAuthentication (Who tries to access?)\nAuthorization (Is the one accessing allowed to do what he wants to do?)\nThis part deals with the recommendations on authentication.\nYou have the following problem to be solved\nIn large IT landscapes it is a highly recommended best-practice to centralize your authentication. Implemeting the actual authentication into every application or service is therefore considered as an anti-pattern. Instead we suggest to use a central identity and access management (IAM) solution based on established products (e.g. Keycloak).\nUsing a central IAM\nWhen using a central IAM, the user is redirected to the identity provider (IdP) when trying to access the application. The IdP returns a login page where the user can log in. After confirming that the user can access the application, the IdP returns an access token that the user can use to access the application. We recommend the use JSON Web Tokens (JWT) within the authentication flow, as this is a widely used method in modern web applications and RESTful services.\nParticipants integrate with the identity provider using protocols such as OpenId Connect, SAMLv2 or WebAuthn. The original incoming request is forwarded to the actual service and the token is added as a bearer token via HTTP header according to OAuth standard. In the application, the token can be validated according to the user&#x2019;s roles and groups.\nTypically, a gateway is placed in front of the IdP and applications to act as a reverse proxy for the actual service. Incoming traffic goes through the gateway and the gateway is then responsible for authentication through integration with the identity provider. In this way, multiple applications and services can be deployed without implementing integration between the service itself and the IdP. The access token can be validated only on the gateway side or additionally passed to the application for further validation.\nServices are implemented stateless and only accept requests with valid JWT from gateway. When one of your services invokes another service it simply passes on the JWT via HTTP header. This way all sub-sequent invocations happen within the context and with the permissions of the initial user.\nThe gateway should also act as a portal that integrates the UIs of your microservices so that end users do not notice which UI comes from which service, but have the user experience (UX) of a single monolithic UI.\nWhich protocol to use\nWe suggest using OIDC as the protocol for integration with the identity provider. It is easy to integrate and works well with mobile and web-based applications. OIDC uses JSON tokens and RESTful APIs to provide the authentication information. Therefore, it is a much more lightweight solution than SAML, which uses an XML and SOAP-based approach.\nValues for the customer\nall services are independent and decoupled from the actual authentication and IAM\nauthentication can be changed without touching any of your services, only changes need to be made to your gateway(s)\nin large and complex IT landscapes, there may be different requirements for authentication via different channels (e.g. to authenticate internal users via SPNEGO and external users via WebAuthn). In such a case, you can simply set up several variants of your gateway for each channel with different endpoint URLs.\nConventions\nWe recommend the following conventions:\ndefine a short but meaningful unique alphanumeric identifier for each of your services (app-id)\nestablish a clear URL scheme for accessing your apps, e.g. https://gateway.company.com/&#xAB;app-id&#xBB;/\nuse a cloud infrastructure platform that allows to manage an overlay network so you can configure loadbalancers or even a service-mesh mapping your service entry points to a consistent URL schema such as https://&#xAB;app-id&#xBB;:8443/&#xAB;app-id&#xBB;/\nthis way you do not need any configuration or business knowledge inside your gateway as the routing can be implemented fully generic\nuse app-id. as a prefix to all permission groups/roles specific to your service to avoid name clashing in your central IAM\nRelated documentations\ndevon4j authentication guide\ndevon4j JWT guide\nOAuth 2.0\nOpenID Connect\nKeycloak&#x2019;s securing apps guide\nIAM solutions\nKeycloak\nWSO2\nGluu Server\nForgeRock\n&#x2026;&#x200B;\n"},{"id":1530,"path":"../website/pages/architectures/solutions/cloudwatchCustomiceAlarmMessage/index.html","type":"solution","title":"Customise your cloudwatch alerts","body":"\nTable of Contents\nCustomise your cloudwatch alerts\nYou have the following problem to be solved\nThe proposed solution enables the customer\nRelated Architectures and Alternatives\nProducts &amp; Services\nCustomise your cloudwatch alerts\nYou have the following problem to be solved\nCloudwatch alarms give you the ability to notify you in case an alarm is triggered. The standard message layout of cloudwatch is very inflexible and not customisable. With this approach it is possible to fill HTML templates with further information, links and buttons to find the solution ASAP.\nThe proposed solution enables the customer\nto send out an customised e-mail template which looks more professional and has additional information compared to the standard cloudwatch alarm.\nRelated Architectures and Alternatives\nSee code here: https://github.com/AlessandroVol23/cloudwatch-custom-email-cdk\nProducts &amp; Services\nCloudwatch Alarm: Some cloudwatch alarm\nSNS Topic which will be triggered by the cloudwatch alarm\nLambda which will be called by the SNS topic\nSES will be used by the lambda to send out HTML emails\nAbout\nAbout devonfw\nFeatures\nTechnology Stack\nExplore\nGetting started\nArchitecture\nResources\nDocs\nUser guide\nReleases information\nWiki\nCommunity\nContributors\nWebsite Contribution\nTerms of Use\nSupport\nimport { UtilsModule } from '/website/shared/utils.js';\nimport { HeaderModule } from '/website/components/header/header.js';\nlet searchData = { index: null, documents: null };\nUtilsModule.loadIndex(searchData);\n$(window).on('load', function() {\nconst queryFun = () => {\nHeaderModule.queryFunction(searchData);\n};\nHeaderModule.searchOnClick(queryFun);\n});\nlet bb = document.getElementById('menu-button');\nbb.addEventListener('click', function() {\ndocument.querySelector('.website-navbar ul').classList.toggle('visible');\nconsole.log(document.querySelector('.website-navbar ul'))\n})\nimport { EditLinksModule } from '/website/shared/editlinks.js';\nlet alwaysVisible = true;\nif(document.location.pathname.endsWith(\"pages/welcome/welcome.html\")) {\nalwaysVisible = false;\n}\nEditLinksModule.addEditLinks(alwaysVisible);\nLast updated 2021-07-15 07:47:29 UTC\n"},{"id":1531,"path":"../website/pages/architectures/solutions/monitoring/index.html","type":"solution","title":"Context & Problem","body":"\nContext &amp; Problem\nTerminology\nUsed definition: A monitoring solution helps the monitoring consumer achieve the satisfactory level of control of a defined service. [1]\nThis definition already includes the following:\nDefined service: The resources you want to monitor aka monitored resources.\nLevel of control: That is your bandwidth in which your defined service operates normally aka known as baseline\nMeasuring: A measurement is a single act that quantifies an attribute of a part, equipment, service or process (CPU load, available memory etc.). Data measured is emitted by the monitored resources and aka telemetry.\nMonitoring consumer: The user trying to keep the service within its baseline boundaries. A single control plane is usually preferred to simplify the operations for the consumer aka monitoring plane. Depending on its perspective the area of cous might differ such as performance, costs, security etc. Independent from the underlying platform.\nActions might be triggered by the system or the consumer to achieve that. This might include:\nVisualize current state\nDetect Deviations from baseline\nRoot cause analysis\nForward externally\nMonitoring should be implemented as feedback loop where lessons learnt are the starting point for further improvements on the defined service side. E.g. by adaptive scaling depending on monitored traffic.\nThe use case defines what is the defined service and the perspectives and control level to be achieved. It also defines external dependencies/ preconditions that have to be considered. Deployment of monitored resources might also be part of it. The platform provides the technical capabilities on which the sue case is implemented. The picture below illustrates this:\nStandard Problems\nA general solution for all potential problems is not possible due to the multitude of different requirements. The idea is therefore to address certain standard features which are as follows:\nVisualizations\nMeasuring\nImproving Feedback Loop\nOptimization of alerts\nCorrelation of telemetry entries\nArchiving Telemetry Data\nAzure as Platform\nThe possibilities depend heavily on the perspective and the resources you want to monitor. A major tool to implement the monitoring plane is Azure Monitor with its features Application Insights and Log Analytics. The subsequent chapters focus on these major services. However, other services depending on your perspective might be relevant too. The following services relevant by category:\nPerformance: Azure Monitor (Network Monitor)\nAvailability: Azure Service Health, Azure Resource Health\nSecurity: Azure Service Health, Azure Sentinel, Azure AD\nCosts: Cost Management\nThe following conventions apply regarding the measurement for monitored resources:\nPush to monitoring plane\nIn that case telemetry is forwarded to the monitoring plane. This can be necessary if the telemetry is not available in Azure monitor out of the box or pulling from the monitored resources is not possible. Examples of forwarding that requires explicit activation:\nDiagnostic setting (differs per resource): requires a diagnostic setting to be activated.\nApp Insights Instrumentation/ Linking: Linked App Insights must be specified for the monitored resource\nManual forwarding: e.g. by scheduled process using API provided by Azure Monitor if the exporting options are not granular enough\nThis approach requires additional data sources on in the monitoring plane which might be inside Azure monitor (Log Analytics Workspace/ App Insights) or external.\nPull from monitored resource\nIn that case the telemetry data is read directly from the monitoring plane such as metrics. Logs cannot be read directly and require pushing. Compared to pushing this method is also faster.\nAzure Monitor as monitoring plane covers the following major features:\nTelemetry Analytics\nKusto is addressing that need and allows you to access external data sources such as blobs and internal data sources inside Azure Monitor. Graphical representation is also possible.\nVisualization (Workbooks, Dashboards, other services)\nAlerts\nTo react automatically if outside operational boundaries. Results from Kusto queries can be used as trigger.\nRoot Cause analysis (TODO)\nApplication Map &#x21D2; application dependencies in other services such as backend APIs or databases\nSmart Detection &#x21D2; warn you when anomalies in performance or utilization patterns\nUsage Analysis &#x21D2; features of your application are most frequently used\nRelease annotations &#x21D2; visual indicators in your Application Insights charts of new builds and other events. Possible to correlate changes in application performance to code releases.\nCross-component transaction diagnostics &#x21D2; shows you broken piece in the entire transaction\nSnapshot Debugger &#x21D2; collect a snapshot of a live application in case of an exception, to analyze it at a later stage.\nIntegration\nAzure Monitor has also extensive integration features. This includes:\nIntegrating telemetry from other Azure services (e.g. Azure Security Center also forwards to Azure Monitor)\nIntegrating external data sources (e.g. Blobs by using Kusto external operator)\nIntegrating third party tools such as Prometheus for Azure Kuberenetes\nExposing for data sources for external third party (e.g. Log Analytics Workspaces for Grafana)\nAzure Monitor pricing comes with the following:\nIngestion: Applies for additional data pushed to Azure monitor\nStorage: Data stored within Azure Monitor costs &#x21D2; Long term Archiving solution must be therefore found\nAlerts: Are charged as well &#x21D2; strategy for minimizing them is required\nSolution\nOverview\nThe solution is to use Azure Monitor and its features. The subsequent detail variations that can be used for solving the problems outlined above.\nVariations\nVisualization\nVisualization requires the following points:\nProviding a canvas\nCanvas refers to the area on which you place carious components. The following options exist:\nAzure\nThird party\nWorkbooks\nDashboards\nPower BI\nGrafana\nAuto refresh in 5 Min Intervall\nX\nX\n???\nFull screen\nX\n???\n???\nTabs\nX\n???\n???\nFixed Parameter lists\nX\n???\nX\nDrill down\nX\nX\nAdditional hosting required\nX\nTerraform Support\nX\nX\nX\nRegarding components for logs/ metrics:\nMetrics: Pull (Metrics explorer) or push (Kusto query targeting data source) possible\nLogs: Push to monitoring plane only\nGrafana can be used for visualization via using a connector for log analytics workspace\nData source\nCan be inside Azure Monitor or external. External stores can avoid high Azure Monitor costs for ingestion/ storage.\nNOTE Referencing an external data source requires authentication e.g. by using a shared access signature for a blob. Updating a saved query is only possible for log analytics.\nMeasuring\nThe table below shows possible options:\nDiagnostic Settings\nApp Insights\nPush via resource API\nMetrics Explorer\nPossible per resource\n(X)\n(X)\nX\n(X)\nTelemetry Customization\nLimited\nHigh\nLimited-High\nLimited\nCustom Logging in executed code\nX\nTelemetry always captured\nX\n(X)\nX\nX\nLatency\nMedium\nMedium\nMedium\nLow\nDirection\nPush\nPush\nPush\nPull\nComments:\nOption &#x201C;Push via resource API&#x201D; &#x21D2; A scheduled script that reads periodically telemetry and pushes it to monitoring plane using the Rest API\n&#x201E;Telemetry always captured&#x201C; &#x21D2; Some resources allow multiple ways to run something e.g. via UI or programmatically. If the telemetry is always captured the way does not matter.\nArchiving\nA good archiving store is blob storage. Lifecycle policies can be used to drop the blob after a predefined amount of time.\nWhen to use\nThis solution assumes that your control plane is in Azure and that your monitored resources are located in Azure.\n"},{"id":1532,"path":"../website/pages/architectures/solutions/openTelemetry/index.html","type":"solution","title":"Monitoring your microservices with openTelemetry","body":"\nMonitoring your microservices with openTelemetry\nWhere is the problem?\nWith the complexity and size of microservice systems, which include hundreds of small services, keeping an overview can be quite challenging. Usually one monolitic application can be scanned for potential errors, as failures in the system directly reference this one application. With microservices the area to search in could be narrowed down, but never to an extend adressing one specific service being the root cause. Therefore, to keep track of runtime problems and the fullfillment of nonfunctional reqirements corresponding to specififc microservices advanced monitoring needs emerge.\nThere are different proposals for collecting this telemetry data consisting of logs, traces and metrics with each proposal having their own benefits and disadvantages leading to a heterogenous landscape of these solutions special for each microservice. As these are configured on their own and little to no replacability options without nudging big change efforts are given, flexibility is limited blocking possibly better solutions. Concluding, overall and in the microservice teams there is not a central repository for looking up your microservices telemetry data but again a numerous amount of different hardly replacable solutions for different microservices making it difficult to gain a central overview e.g. via Grafana.\nThe value for the customer\nMonitoring in microservice settings generally benefits nonfunctional requirements such as performance, availability or security through transparent insights, while enabling proactive but also reactive handling of issues. By having all the telemetry data centrally stored and providing exchangeable solutions for the different types of data, no restrictions to design decisions is made and the customer can gain a fast overview over a great amount of microservices.\nIntroducing OpenTelemetry\nOpenTelemetry forms the combination of OpenTracing and OpenCensus collecting different telemetry data (metrics, logs, traces) for understanding the applications behavior and performance. Because of the standardization for processing telemetry data, OpenTelemetry acts as a central collector for whole application landscapes monitoring data, which is able to communicate with replacable logging-, tracing- or metrics-backends without changing configurations in the applications code.\nAddressing your business\nOpenTelemetry can be used in various use cases, but is best suited in the microservice context. Therefore, any business apllication relying on microservices would be a suited domain for applying an OpenTelemetry solution.\nOpenTelemetry architecture\nThe above example shows a reference architecture of multiple hosts (environments/applications).\nTraces and logs are automatically collected at each JAX-RS service. Other additionally defined metrics, traces or logs are also collected.\nThese applications send data directly to a otel-agent configured to use fewer resources. An otel-agent is a collector instance running with the application or on the same host as the application.\nThe agent then forwards the data to a collector that receives data from multiple agents. Collectors on this layer typically are allowed to use more resources and queue more data.\nThe collector then sends the data to the appropriate backend, in the solution provided by Jaeger, Zipkin or VictoriaMetrics. The Victoria backend serves metrics while Jaeger and Zipkin are two alternatives for tracing._\nAdditionally all the telemetry data can be visualized in a tool like Grafana.\nThe OpenTelemetry collector is an instance that makes it possible to receive telemetry data, optionally transform it and send the data on. Receiving, transforming and sending data is done via pipelines. A pipeline consists of a set of receivers, a set of optional processors and a set of exporters.\nimage::opel_collector_pipeline.png[]\nA reveiver transfers the telemetry data into the collector, which then can be processed on a processor. Finally, an exporter can send the data to a corresponding backend/destination. Further information can be found here\nList of available receivers, processors and exporters:\nreveivers\nprocessors\nexporters\nIn addition, extensions (Health Check, Performance Profiler, zPages) are provided that can be added to the collector to extend the primary functionality of the collector. These do not require direct access to telemetry data and enable additional functionality outside the usual pipeline.\nRelated documentations\nOpenTelemetry Collector\nOpenTelemetry Java documentation\nJaeger\nZipkin\nVictoriaMetrics\nGrafana\nRelated Architectures and Alternatives\nopenTracing\nopenCensus\n"}]