{"type":"solution","filename":"provisioning_azure_azuredevops/index.asciidoc","title":"Provisioning Solutions - Azure DevOps","breadcrumbs":[],"text":"//Category=Provisioning\n//Platform=Azure\n//Maturity level=Complete\n//Product=Azure DevOps\n\n:toc: macro\ntoc::[]\n:idprefix:\n:idseparator: -\n\n= Provisioning Solutions - Azure DevOps\n\ninclude::/home/runner/work/devonfw.github.io/devonfw.github.io/solutions/includes/provisioning_problem/index.asciidoc[]\n\ninclude::/home/runner/work/devonfw.github.io/devonfw.github.io/solutions/includes/provisioning_platforms/index.asciidoc[]\n\n== Provisioning Solutions - Azure DevOps\n=== Overview\n\nThe cloud native provisioning service in Azure is Azure DevOps formerly known as Team Foundation Server (TFS). Azure DevOps covers the full CI/ CD requiremenzs including project management. Due to its extensive extension features you can also replace features with other alternatives (see also under variations).\n\n*+++Note:+++* Azure DevOps will be superseeded by GitHub in the long run after Microsoft acquired GitHub. New features will be initially implemented there.\n\nThe services that (can) complement Azure DevOps:\n\n* Azure Key Vault for storing secrets/ exchange of settings\n* Azure App Configuration\n+\nThis service provides settings (key-value pairs) and feature toggles. Native integrations exist for typical application programming languages like .NET/ Java. However native integrations with terraform do not exist and it is also not hardened for sensitive information as key vault. Therefore, it is recommended to use that service as special case for application layer if feature toggles are needed.\n* Azure AD\n+\nAzure Active Directory provides the service principal the pipelines run with.\n* Monitoring\n+\n--\nAzure DevOps generates metrics to check the health pipelines and displays te state in the Azure DevOps portal. However no built-in forwarding to App Insights independent from the deployed application exists. The following options are available:\n\n** Continous monitoring: Monitoring which assumes Web Applications.\n** Rest API to read service health information manually as explained https://docs.microsoft.com/en-us/rest/api/azure/devops/status/?view=azure-devops-rest-6.0[here]. Check out the pattern monitoring cloudnative how polling and forwarding to azure monitor can be achieved.\n** audit streaming is similar to diagnostic settings (In preview as of 21.09.2021). It allows to configure a constant forwarding of telemetry to selected targets as described https://docs.microsoft.com/en-us/azure/devops/organizations/audit/auditing-streaming?view=azure-devops[here].\n--\n* Structural elements to model environments\n\nThe picture illustrates the setup with the major dependencies:\n\nimage::complementing_svcs_devops.png[Complementing Services, width=594, height=335]\n\n=== Pattern Details\n==== Geting Started\n\nMany aspects influence the setup of the service. Following a top down approach the following decisions have to be made:\n\n* Define landing zone of the service itself in Azure (out of scope)\n* Organizational mapping\n+\nThis yields the structural components to host provisioning which will be detailed in the next chapter. It introduces the possible components and guidelines for its structuring.\n* Modelling other outlined aspects across automation, infra/ app code and provisioning\n\nThe structural components are organizations, teams and projects. A team is a unit that supports many team-configurable tools. These tools help you plan and manage work, and make collaboration easier. Every team owns their own backlog, to create a new backlog you create a new team. By configuring teams and backlogs into a hierarchical structure, program owners can more easily track progress across teams, manage portfolios, and generate rollup data.\n\nA project in Azure DevOps contains the following set of features:\n\n* Boards and backlogs for agile planning\n* Pipelines for continuous integration and deployment\n* Repos\n+\nThe service comes with hosted git repositories inside that service. You can also use the following external source repositories: Bitbuckt Cloud, GitHub, Any generic git repo, Subversion\n\n* Testing\n+\n--\nAzure DevOps supports the following testing by https://docs.microsoft.com/en-us/azure/devops/test/create-test-cases?view=azure-devops[defining test suites with test cases]:\n\n\n* *Planned manual testing*. Manual testing by organizing tests into test plans and test suites by designated testers and test leads.\n* *User acceptance testing*. Testing carried out by designated user acceptance testers to verify the value delivered meets customer requirements, while reusing the test artifacts created by engineering teams.\n* *Exploratory testing*. Testing carried out by development teams, including developers, testers, UX teams, product owners and more, by exploring the software systems without using test plans or test suites.\n* *Stakeholder feedback*. Testing carried out by stakeholders outside the development team, such as users from marketing and sales divisions.\n\nTests can also be integrated in pipelines. Pipelines support a wide range of frameworks/ libraries.\n--\n* Each organization contains one or more projects\n\nYour business structure should act as a guide for the number of organizations, projects, and teams that you create in https://docs.microsoft.com/en-us/azure/devops/user-guide/plan-your-azure-devops-org-structure?bc=%2Fazure%2Fdevops%2Fget-started%2Fbreadcrumb%2Ftoc.json&toc=%2Fazure%2Fdevops%2Fget-started%2Ftoc.json&view=azure-devops[Azure DevOps]. Each organization gets its own free tier of services (up to five users for each service type) as follows. You can use all the services, or choose just what you need to complement your existing workflows.\n\n* Azure Pipelines: One hosted job with 1,800 minutes per month for CI/CD and one self-hosted job\n* Azure Boards: Work item tracking and Kanban boards\n* Azure Repos: for version control and management of source code and artifacts\n* Azure Artifacts: Package management\n* Testing: Continuous test integration throughout the project life cycle\n\nAdding multiple projects makes sense in the following cases (see https://docs.microsoft.com/en-us/azure/devops/organizations/projects/about-projects?view=azure-devops[azure projects]):\n\n* To prohibit or manage access to the information contained within a project to select groups\n* To support custom work tracking processes for specific business units within your organization\n* To support entirely separate business units that have their own administrative policies and administrators\n* To support testing customization activities or adding extensions before rolling out changes to the working project\n* To support an Open Source Software (OSS) project\n\nAdding teams instead of projects is recommended over projects due to https://docs.microsoft.com/en-us/azure/devops/boards/plans/agile-culture?view=azure-devops[agile culture]:\n\n* Visibility: It's much easier to view progress across all teams\n* Tracking and auditing: It's easier to link work items and other objects for tracking and auditing purposes\n* Maintainability: You minimize the maintenance of security groups and process updates.\n\nThe table below lists typical configurations along with their characteristics:\n[options=\"header\"]\n|=======================\n|Criteria|1 project, N teams      |1 org, N projects/ teams | N orgs\n|General guidance |\tSmaller or larger organizations with highly aligned teams | Good when different efforts require different processes (multi) | Legacy migration\n|Process    |Aligned processes across teams; team flexibility to customize boards, dashboards, and so on     |Different processes per prj;e.g. different work item types, custom fields   |same as many projects\n|=======================\n\n==== Remaining goals (Automation Code)\n\nThis chapter details how the above conceptual features can be achieved with Azure DevOps pipelines. \n\nThe pipeline *programming approach* can be either UI driven or programmatic by using YAML. YAML organizes pipelines into a hierarchy of stages, jobs and tasks. Tasks are the workhorse where activities are implemented. Tasks support scripting languages as stated below. They in turn allow to install additional libraries frameworks from third party providers such as terraform (or you use extensions that give you additional task types). The list below highlights a few YAML points you have to be aware of: \n\n* Passing files/ artefacts between jobs/ pipelines\n+\nPassing between jobs within the same pipeline requires publishing the files as pipeline artefacts and downloading it afterwards. Passing between syntax requires a different syntax and also requires a version.\n* Variables\n+\nVariables can have different scopes. A special syntax is required to publish them at runtime and to consume them in a different job (requires declaration). (https://docs.microsoft.com/en-us/azure/devops/pipelines/process/variables?view=azure-devops&tabs=yaml%2Cbatch[Link]). Various https://docs.microsoft.com/en-us/azure/devops/pipelines/build/variables?view=azure-devops&tabs=yaml[predefined] exist.\n* Obtaining client secret\n+\nScripting languages such as terraform might require the client secret for embedded scripting blocks. However,  terraform does not provide a way to get it. The only way was to include an AzureCLI scripting task. Setting the argument \"addSpnToEnvironment\" to true makes the value for scripting languages as environment variable. A script can then publish the variable so that the value is available in the YAML pipeline. \n\nPipelines that shall be *triggered* by pushing to the repo state in the trigger element the details like branch when they shall run.\nThe example below shows a scheduled trigger:\n```YAML\n# Disable all other triggers\npr: none\ntrigger: none\n\n# Define schedule\nschedules:\n# Note: Azure DevOps only understands the limited part of the cron\n#       expression below. See this link for further details:\n#       https://docs.microsoft.com/en-us/azure/devops/pipelines/process/scheduled-triggers?view=azure-devops&tabs=yaml\n# Note: With DevOps organization setting of UTC+1 Berlin,...\n#       for a given hour x you have to specify x-2 e.g. 16:00 will be\n#       started 18:00 o'clock\n- cron: \"30 5 * * MON,TUE,WED,THU,FRI\"\n  displayName: Business daily morning creation\n  always: true # also run if no code changes\n  branches:\n    include:\n    - 'refs/heads/master'\n```\nPull request (PR) triggers cause a pipeline to run whenever a pull request is opened with one of the specified target branches, or when changes are pushed to such a pull request. In Azure Repos Git, this functionality is implemented using branch policies. To enable pull request validation in Azure Git Repos, navigate to the branch policies for the desired branch, and configure the Build validation policy for that branch. For more information, see Configure branch policies. Draft pull requests do not trigger a pipeline even if you configure a branch policy. Building pull requests from Azure Repos forks is no different from building pull requests within the same repository or project. You can create forks only within the same organization that your project is part of (see https://docs.microsoft.com/en-us/azure/devops/pipelines/repos/azure-repos-git?view=azure-devops&tabs=yaml#pr-triggers[PR triggers]).\nTo trigger a pipeline upon the completion of another pipeline, specify the triggering pipeline as a pipeline resource. The following example has two pipelines - app-ci (the pipeline defined by the YAML snippet), and security-lib-ci (the triggering pipeline referenced by the pipeline resource). We want the app-ci pipeline to run automatically every time a new version of security-lib-ci is built.\n```YAML\n# this is being defined in app-ci pipeline\nresources:\n  pipelines:\n  - pipeline: securitylib   # Name of the pipeline resource\n    source: security-lib-ci # Name of the pipeline referenced by the pipeline resource\n    project: FabrikamProject # Required only if the source pipeline is in another project\n    trigger: true # Run app-ci pipeline when any run of security-lib-ci completes\n```\n\nImplicit Chaining for *orchestration* is possible by using trigger condition. Calling pipelines explicitly is so far only possible with scripting. The code snippet below shows an example:\n```Powershell\n#\n# Make call to schedule pipeline run\n#\n\n# Body\n$body = @{\n    stagesToSkip = @()\n    resources = @{\n        self = @{\n            refName = $branch_name\n        }\n    }\n    templateParameters = $params\n    variables = @{}\n}\n$bodyJson = $body | ConvertTo-Json\n# Uri extracted from the Azure DevOps UI\n# $org_uri and $prj_id contain names of current organization/ project\n# $pl_id denotes the internal pipeline id to be started\n$uri = \"${org_uri}${prj_id}/_apis/pipelines/${pl_id}/runs?api-version=5.1-preview.1\"\n\n# Output paramters\nWrite-Host(\"--------  Call ${pl_name} --------\")    \nWrite-Host(\"Headers: ${headersJson}\")\nWrite-Host(\"Json body: ${bodyJson}\")    \nWrite-Host(\"Uri: ${uri}\")    \n\ntry \n{\n    # Trigger pipeline\n    $result = Invoke-RestMethod -Method POST -Headers $headers -Uri $uri -Body $bodyJson\n    Write-Host(\"Result: ${result}\")        \n\n    # Wait until run completed\n    $buildid = $result.id\n    $start_time = (get-date).ToString('T')\n    Write-Host(\"------------ Loop until ${pl_name} completed --------\")\n    Write-Host(\"started runbuild ${buildid} at ${start_time}\")   \n    \n    # Uri for checking state\n    $uri = \"${org_uri}${prj_id}/_apis/pipelines/${pl_id}/runs/${buildid}?api-version=5.1-preview.1\"\n\n    Do {\n        Start-Sleep -Seconds 60\n        $current_time = (get-date).ToString('T')\n\n        # Retrieve current state\n        $result = Invoke-RestMethod -Method GET -Headers $headers -Uri $uri\n        $status = $result.state\n        Write-Host(\"Received state ${status} at ${current_time}...\")\n    } until ($status -eq \"completed\")\n\n    # return result\n    $pl_run_result = $result.result\n    Write-Host(\"Result: ${pl_run_result}\")   \n    return $pl_run_result\n}\ncatch { \n    $excMsg = $_.Exception.Message\n    Write-Host(\"Exception text: ${excMsg}\")\n    return \"Failed\"\n}\n```\nOrchestration must take dependencies into account. They might result from the deployed code or the scope of the pipeline (scope is e.g. a single microservice and code includes the libraries needed).\nOrchestrated pipelines must pass data between them. The recommended method is to use key vault. \n\n*Recreation of resources in short intervals* might cause pipelines to fail. Even if resources are deleted they might still exist in the background (even although soft delete is not applicable). Programming languages can therefore get confused if pipelines recreate things in short intervals. Creating a new resource group can solve the problem since they are part of the tecnical resource id.\n\nAs part of the *configuration* Azure DevOps provides the possibility to provide various settings that are used for development such as enforcing pull requests instead of direct pushes to the repo.\nThe major configuration mechanisms in YAML are variables, parameters and variable groups. Variable groups bundle multiple settings as key value pairs. Parameters are not possible in a variable section (Dynamic inclusion of variable groups is possible via file switching). If they are declared on top level they have to be passed when the pipeline is called programmatically or manually by the user.\n\n*Quality gates* can be enforced as follows:\n\n* Static code analysis:\n+\nVarious tool support exists depending on the programming language.\n* Automated tests (Unit, Integration, End-To-End)\n+\n--\nTests can be included in pipelines via additional libraries and additional previous installment through scripting. The task below uses an Azure CLI task to run tests for terraform:\n```YAML\n  - task: AzureCLI@2 \n    displayName: Run terratest\n    inputs: \n      azureSubscription: ${{parameters.svcConn}}\n      scriptType: bash\n      scriptLocation: 'inlineScript' \n      addSpnToEnvironment: true\n      inlineScript: | \n        # Expose required settings as environment variables\n        # ARM_XXX initialized by task due to addSpnToEnvironment = true\n        subsid=`az account show --query id -o tsv`\n        echo \"client_id:\"$servicePrincipalId\n        echo \"client_secret:\"$servicePrincipalKey\n        echo \"subscription_id:\"$subsid\n        echo \"tenant_id:\"$tenantId\n        export ARM_SUBSCRIPTION_ID=$subsid\n        export ARM_CLIENT_ID=$servicePrincipalId\n        export ARM_CLIENT_SECRET=$servicePrincipalKey\n        export ARM_TENANT_ID=$tenantId\n        # Backend settings\n        export storage_account_name=${{parameters.bkStname}}\n        export container_name=${{parameters.bkCntName}}\n        export key=${{parameters.bkRmKeyName}}\n        # Other settings\n        export resource_group_name=${{parameters.rgName}}\n        # Switch to directory with tests\n        pwd\n        cd test\n        # Testfile must end with \"<your name>_test.go\"\n        go test -v my_test.go\n```\n--\n\n* Manual approval e.g. for production\n+\n--\nYAML allows deployments to named environments. Approvers can then be defined for the named environments in the portal what causes the deployment pipeline to wait. However Approval must be done multiple times if you have multiple deplyoment blocks. The example below shows a deployment to the environment \"env-demo\":\n```YAML\njobs:\n- deployment:\n  displayName: run deploy template\n  pool:\n    vmImage: 'ubuntu-latest'\nenvironment: env-demo\n  strategy:\n    runOnce:\n      deploy:\n        steps:               \n        # - 1. Download artefact\n        - task: DownloadPipelineArtifact@2\n          displayName: Get artefact\n          inputs:\n            downloadPath: '$(build.artifactstagingdirectory)' \n            artifact: ${{parameters.pipelineArtifactName}}\n```\n--\n\n==== Remaining goals (Provisioning)\n\n*Configuration settings* can be broken down into key value pairs. As already stated key vault is the recommended place for storage. Azure App Configuration and variable groups can reference values in Key Vault. Key Value pairs must be selected in YAML based on the target environment. Switching based on the parameter value is possible by constructing filenames based on the parameter value. The resolved filenam contains then the variable group or the key value pairs. as shown below:\n\n(1) Main pipeline that requires switching\n```YAML\n...\n# Switch in the pipeline which is implemented in a shared repository\nvariables:\n- template: ./pipelines/configurations/vars-env-single-template.yaml@repo-shared\n  parameters: ${{parameters.envName}}\n...\n``` \n(2) Shared: Switch to correct configuration file\n```YAML\n...\nparameters:\n- name: envName\n  displayName: name of environment\n  type: string\n\n# Load filename with resolved parameter value\nvariables:\n- template: vars-env-def-${{parameters.envName}}-template.yaml\n``` \n(3) Shared: Configuration file vars-env-def-dev1.yaml\n```YAML\nvariables:\n  envNamePPE1MainScriptLocation: app/dev\n  envNamePPE1SvcLevel: Full\n  envNamePPE1BranchName: dev\n  envNamePPE1KvEnvName: $(envNameCRST)1\n``` \n\nAzure DevOps *can integrate* with various external tools. Pipelines can be called from external and allow calling external tools. Various third party tools can be manually installed or used via extensions.\n\nFor *compliance* Azure DevOps provides various settings inside Azure DevOps itself and via Azure Active Directory.\nPortal access to Boards, Repos, Pipelines, Artifacts and Test Plans can be controlled through Azure DevOps project settings (https://docs.microsoft.com/en-us/azure/devops/organizations/settings/set-services?view=azure-devops[Link]).\nAzure DevOps supports the following autthentication mechanisms to connect to services and resources in your organization (https://docs.microsoft.com/en-us/azure/devops/organizations/accounts/change-application-access-policies?view=azure-devops[Link]):\n\n* OAuth to generate tokens for accessing REST APIs for Azure DevOps. The Organizations and Profiles APIs support only OAuth.\n* SSH authentication to generate encryption keys for using Linux, macOS, and Windows running Git for Windows, but you can't use Git credential managers or personal access tokens (PATs) for HTTPS authentication.\n* Personal access token (PAT) to generate tokens for:\n+\n--\n* Accessing specific resources or activities, like builds or work items\n* Clients like Xcode and NuGet that require usernames and passwords as basic credentials and don't support Microsoft account and Azure Active Directory features like multi-factor authentication\n* Accessing REST APIs for Azure DevOps\n--\n\nUser permissions for team members are split in access levels and project permissions inside Azure DevOps. The Basic and higher access levels support full access to all Azure Boards features. Stakeholder access provides partial support to select features, allowing users to view and modify work items without having access to all other features. Additional restrictions are possible by Azure Active Directory settings using conditional access policies and MFA. Azure DevOps honors all conditional access policies 100% for our Web flows. For third-party client flow, like using a PAT with git.exe, IP fencing policies are supported only (no support for MFA policies).\nPermissions to work with repositories can be set under project’s repositories settings which also allows to disable forks. Many forks makes it hard to keep the overview and forking allows to download code into someones private account. Azure DevOps supports creating branch protection policies, which protect the code committed to the main branches (project settings => repo => branch policies).\nCompliance affects dealing with sensitive settings. As already stated key vault is the standard service for storing them at runtime. Exports from key vault can only be decrypted in a key vault instance. \nHence, secrets can be stored in a repository in a safe way without having to store the values in plain. Using them later should be done in a safe way. This includes publishing them in a safe way and passing them from YAML to terraform by avoiding log output in plain text. Avoiding log output passing them as environment variables/ files.\n\nThe following *repository* structure shows a conceptual breakdown that covers most aspects:\n\n* 1. Infra\n* 1.1. Infrastructure\n* 1.1.1. Other landing zones\n+\nRepresents other areas with shared functionality that are required. Examples are environments for monitoring, the environment containing Azure DevOps, Key Vault settings etc.\n* 1.1.2. App Environments\n+\nRepresents the environments where application is deployed to.\n* 1.1.2.1. Envs\n+\nThis level contains all infrastructure code for seting up en environment. The split between dev and non-dev leverages cost savings for less performant dev environments e.g. by picking cheaper service configurations or totally different Azure services.\n* 1.1.2.1.1. Dev\n* 1.1.2.1.2. Non-Dev\n* 1.1.2.1.3. Modules\n+\nFactored out modules for shared reuse. One example is a central module to generate the name for a given module.\n* 1.1.2.2. Envs-Mgmt\n+\nCaptures aspects assumed by the chosen programming language such as terraform for managing an environment. This includes for instance the backend creation code.\n* 1.2. Pipelines\n+\nPipelines for automating infrastrcuture deployment.\n* 2. App\n* 2.1. Application (Black Box)\n* 2.2. Pipelines\n+\nPipelines for automating app code deployment.\n* 3. Shared\n+\nCaptures shared aspects between infrastructure and application code such as publishing key vault secrets for a pipeline or triggering another pipeline.\n\n=== Variations\n\nThe following features of Azure DevOps can be replaced with alternatives:\n\n* Repos\n* Boards for project management\n* Azure Artefacts\n\nThe following alternatives on service level exist:\n\n* https://docs.microsoft.com/en-us/azure/lab-services/[Azure Lab Services] for Dev/ Test scenarios\n* https://kubernetes.io[Kubernetes]\n** Azure DevSpaces (Deprecated) in favor of “Bridge-to-kubernetes” for Dev/ Test scenarios\n** Bridge-to-Kubernetes\n\n=== When to use\n\nAzure DevOps makes sense if you want to provision to Azure due to its tight integration into the Azure platform. The following circumstances also speak for Azure DevOps:\n\n* You need a mature service on enterprise level\n* You don't need cloud agnostic pipelines e.g. due to a multi-cloud scenario\n* Your code repository is not GitHub and Azure DevOps provides integrations for it (GitHub Actions are a better alternative if your code repos are already on GitHub.)\n* You need a full blown provisioning service and plan to use the integrated repos that come with Azure DevOps\n\n== Credits\n\nimage::ms_guild_logo.png[MS Guild Logo, width=160, height=75, align=right, link=\"https://forms.office.com/Pages/ResponsePage.aspx?id=Wq6idgCfa0-V7V0z13xNYal7m2EdcFdNsyBBMUiro4NUNllHQTlPNU9QV1JRRjk3TTAwVUJCNThTRSQlQCN0PWcu\"]\n"}